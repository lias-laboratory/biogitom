{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkAX88H3RNRW"
      },
      "source": [
        "# **Package Installation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlL2v0xgmFJ-",
        "outputId": "beb2f96a-da82-4edb-f527-97d5c423dcff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.0.0\n",
            "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.0)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.45.1)\n",
            "Collecting cmake (from triton==2.0.0->torch==2.0.0)\n",
            "  Downloading cmake-3.31.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.0)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n",
            "Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m580.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cmake-3.31.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.8/27.8 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, cmake, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cpu\n",
            "    Uninstalling torch-2.5.1+cpu:\n",
            "      Successfully uninstalled torch-2.5.1+cpu\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cpu requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\n",
            "torchvision 0.20.1+cpu requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cmake-3.31.2 lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 triton-2.0.0\n",
            "Collecting torch-geometric==2.4.0\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (3.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (3.2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.6.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric==2.4.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (2024.12.14)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.4.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.4.0) (3.5.0)\n",
            "Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.4.0\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_scatter-2.1.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (494 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_sparse-0.6.18%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_cluster-1.6.3%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (751 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.3/751.3 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (208 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n",
            "Installing collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt20cpu torch-scatter-2.1.2+pt20cpu torch-sparse-0.6.18+pt20cpu torch-spline-conv-1.2.2+pt20cpu\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.6.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.12.14)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting deeponto\n",
            "  Downloading deeponto-0.9.2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting JPype1 (from deeponto)\n",
            "  Downloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting yacs (from deeponto)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deeponto) (2.0.0)\n",
            "Collecting anytree (from deeponto)\n",
            "  Downloading anytree-2.12.1-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from deeponto) (8.1.7)\n",
            "Collecting dill (from deeponto)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from deeponto) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deeponto) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deeponto) (1.6.0)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (from deeponto) (4.47.0)\n",
            "Collecting datasets (from deeponto)\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.7.5)\n",
            "Collecting pprintpp (from deeponto)\n",
            "  Downloading pprintpp-0.4.0-py2.py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.4.2)\n",
            "Collecting lxml (from deeponto)\n",
            "  Downloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting textdistance (from deeponto)\n",
            "  Downloading textdistance-4.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from deeponto) (7.7.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from deeponto) (5.5.6)\n",
            "Collecting enlighten (from deeponto)\n",
            "  Downloading enlighten-1.13.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Collecting rdflib (from deeponto)\n",
            "  Downloading rdflib-7.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.9.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anytree->deeponto) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (18.1.0)\n",
            "Collecting dill (from deeponto)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (4.67.1)\n",
            "Collecting xxhash (from datasets->deeponto)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets->deeponto)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->deeponto)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (6.0.2)\n",
            "Collecting blessed>=1.17.7 (from enlighten->deeponto)\n",
            "  Downloading blessed-1.20.0-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Collecting prefixed>=0.3.2 (from enlighten->deeponto)\n",
            "  Downloading prefixed-0.9.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (6.3.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->deeponto) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->deeponto) (3.0.13)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->deeponto) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->deeponto) (2024.11.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2024.2)\n",
            "Collecting isodate<1.0.0,>=0.7.2 (from rdflib->deeponto)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib->deeponto) (3.2.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deeponto) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deeponto) (3.5.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (0.15.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.10.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (75.1.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (1.13.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (2.0.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->deeponto) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deeponto) (3.31.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deeponto) (18.1.8)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (0.4.5)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (1.2.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->transformers[torch]->deeponto) (5.9.5)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.7->enlighten->deeponto) (0.2.13)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (5.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.18.3)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->deeponto)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (5.1.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (4.9.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->deeponto) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->deeponto) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (7.0.5)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.5.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy->deeponto) (3.0.2)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->deeponto) (5.7.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->deeponto) (24.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deeponto) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->deeponto) (0.8.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel->deeponto) (4.3.6)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (7.16.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.1.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel->deeponto) (0.7.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (3.0.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->deeponto) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (0.1.2)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.0.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.10.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.4.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.23.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.5.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.22.3)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.2.2)\n",
            "Downloading deeponto-0.9.2-py3-none-any.whl (89.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anytree-2.12.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading enlighten-1.13.0-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.8/493.8 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Downloading rdflib-7.1.1-py3-none-any.whl (562 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m562.4/562.4 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading textdistance-4.6.3-py3-none-any.whl (31 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prefixed-0.9.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: prefixed, pprintpp, yacs, xxhash, textdistance, lxml, JPype1, jedi, isodate, fsspec, dill, blessed, anytree, rdflib, multiprocess, enlighten, datasets, deeponto\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "Successfully installed JPype1-1.5.1 anytree-2.12.1 blessed-1.20.0 datasets-3.2.0 deeponto-0.9.2 dill-0.3.8 enlighten-1.13.0 fsspec-2024.9.0 isodate-0.7.2 jedi-0.19.2 lxml-5.3.0 multiprocess-0.70.16 pprintpp-0.4.0 prefixed-0.9.0 rdflib-7.1.1 textdistance-4.6.3 xxhash-3.5.0 yacs-0.1.8\n",
            "/bin/bash: line 1: username: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# We assume that PyTorch is already installed in the environment.\n",
        "# If not, this command installs it.\n",
        "!pip install torch==2.0.0\n",
        "\n",
        "# Install PyTorch Geometric, a library for creating graph neural networks using PyTorch.\n",
        "!pip install torch-geometric==2.4.0\n",
        "\n",
        "# Import PyTorch to access its functionalities.\n",
        "import torch\n",
        "\n",
        "# Install additional PyTorch Geometric dependencies for graph processing (scatter, sparse, cluster, spline-conv).\n",
        "# These packages enable operations like sparse tensors and convolutions on graphs.\n",
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
        "\n",
        "# Reinstall PyTorch Geometric to ensure all dependencies are correctly loaded.\n",
        "!pip install torch-geometric\n",
        "\n",
        "# Retrieve the installed version of PyTorch to ensure compatibility with other packages.\n",
        "torchversion = torch.__version__\n",
        "\n",
        "# Install the latest version of PyTorch Geometric directly from the GitHub repository.\n",
        "# This allows access to the most recent updates and features for graph-based neural networks.\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "# Install DeepOnto, a package specifically designed for ontology matching, particularly useful in biomedical applications.\n",
        "!pip install deeponto\n",
        "\n",
        "# Install a custom version of DeepOnto from a GitHub repository.\n",
        "# The '<username>' part should be replaced with the actual GitHub username of the repository maintainer.\n",
        "!pip install git+https://github.com/<username>/deeponto.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HPAlAgjLMVhw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0d1e647-5789-46a3-a2e6-2ff459fd6096"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter the maximum memory located to JVM [8g]: 8g\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import pandas for data manipulation and analysis, such as loading, processing, and saving tabular data.\n",
        "import pandas as pd\n",
        "\n",
        "# Import pickle for saving and loading serialized objects (e.g., trained models or preprocessed data).\n",
        "import pickle\n",
        "\n",
        "# Import function to convert a directed graph to an undirected one, useful for certain graph algorithms.\n",
        "from torch_geometric.utils import to_undirected\n",
        "\n",
        "# Import optimizer module from PyTorch for training models using gradient-based optimization techniques.\n",
        "import torch.optim as optim\n",
        "\n",
        "# Import PyTorch's modules for defining neural network architectures and operations:\n",
        "from torch.nn import (\n",
        "    Linear,       # For linear transformations (dense layers).\n",
        "    Sequential,   # For stacking layers sequentially.\n",
        "    BatchNorm1d,  # For normalizing input within mini-batches.\n",
        "    PReLU,        # Parametric ReLU activation function.\n",
        "    Dropout       # For regularization by randomly dropping connections during training.\n",
        ")\n",
        "\n",
        "# Import functional API from PyTorch for operations like activations and loss functions.\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Import Matplotlib for visualizations, such as plotting training loss curves.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import PyTorch Geometric's graph convolutional layers:\n",
        "from torch_geometric.nn import GCNConv, GINConv\n",
        "\n",
        "# Import pooling operations for aggregating node embeddings to graph-level representations:\n",
        "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
        "\n",
        "# Import NumPy for numerical operations, such as working with arrays and matrices.\n",
        "import numpy as np\n",
        "\n",
        "# Import time module for measuring execution time of code blocks.\n",
        "import time\n",
        "\n",
        "# Import typing module for specifying types in function arguments and return values.\n",
        "from typing import Optional, Tuple, Union, Callable\n",
        "\n",
        "# Import PyTorch's DataLoader and TensorDataset for handling data batching and loading during training.\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Import PyTorch's Parameter class for defining learnable parameters in custom models.\n",
        "from torch.nn import Parameter\n",
        "\n",
        "# Import math module for performing mathematical computations.\n",
        "import math\n",
        "\n",
        "# Import Tensor type from PyTorch for defining and manipulating tensors.\n",
        "from torch import Tensor\n",
        "\n",
        "# Import PyTorch's nn module for defining and building neural network architectures.\n",
        "import torch.nn as nn\n",
        "\n",
        "# Import initialization utilities from PyTorch Geometric for resetting weights and biases in layers.\n",
        "from torch_geometric.nn.inits import reset\n",
        "\n",
        "# Import the base class for defining message-passing layers in graph neural networks (GNNs).\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "\n",
        "# Import linear transformation utilities for creating dense representations in graph models.\n",
        "from torch_geometric.nn.dense.linear import Linear\n",
        "\n",
        "# Import typing utilities for defining adjacency matrices and tensor types specific to PyTorch Geometric.\n",
        "from torch_geometric.typing import Adj, OptTensor, PairTensor, SparseTensor\n",
        "\n",
        "# Import softmax function for normalizing attention scores in GNNs.\n",
        "from torch_geometric.utils import softmax\n",
        "\n",
        "# Import initialization utilities for weight initialization (e.g., Glorot initialization).\n",
        "from torch_geometric.nn.inits import glorot, zeros\n",
        "\n",
        "# Import F1 score metric from scikit-learn for evaluating model performance in binary/multi-class tasks.\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Import JSON module for reading and writing JSON files, useful for storing configuration or ontology data.\n",
        "import json\n",
        "\n",
        "# Import Ontology class from DeepOnto for representing and manipulating ontologies in the pipeline.\n",
        "from deeponto.onto import Ontology\n",
        "\n",
        "# Import tools from DeepOnto for handling Ontology Alignment Evaluation Initiative (OAEI) tasks.\n",
        "from deeponto.align.oaei import *\n",
        "\n",
        "# Import evaluation tools from DeepOnto for assessing alignment results using metrics like precision, recall, and F1.\n",
        "from deeponto.align.evaluation import AlignmentEvaluator\n",
        "\n",
        "# Import mapping utilities from DeepOnto for working with reference mappings and entity pairs.\n",
        "from deeponto.align.mapping import ReferenceMapping, EntityMapping\n",
        "\n",
        "# Import utility function for reading tables (e.g., TSV, CSV) from DeepOnto.\n",
        "from deeponto.utils import read_table\n",
        "\n",
        "# Importing the train_test_split function from sklearn's model_selection module.\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "# Command to list installed packages\n",
        "installed_packages = subprocess.check_output(['pip', 'freeze']).decode('utf-8')\n",
        "\n",
        "# Write the output to a requirements.txt file\n",
        "with open('requirements.txt', 'w') as file:\n",
        "    file.write(installed_packages)\n",
        "\n",
        "print(\"requirements.txt has been generated!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-U-Tm0REdjoE",
        "outputId": "9758d546-d72c-4503-97de-71f9c9794bae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "requirements.txt has been generated!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-abbBHOoRdWl"
      },
      "source": [
        "# **Paths Definition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVgl_Bb42naS",
        "outputId": "81820d2a-44a5-47b6-9d74-701c95fb24c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Importing the 'drive' module from Google Colab to interact with Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount the user's Google Drive to the Colab environment\n",
        "# After running this, a link will appear to authorize access, and Google Drive will be mounted at '/content/gdrive'\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "36ttssQ3W7cx"
      },
      "outputs": [],
      "source": [
        "# Define the source ontology name\n",
        "src_ent = \"omim\"\n",
        "\n",
        "# Define the target ontology name\n",
        "tgt_ent = \"ordo\"\n",
        "\n",
        "# Define the task name for this ontology matching process\n",
        "task = \"omim2ordo\"\n",
        "\n",
        "# Define the similarity threshold for validating matches\n",
        "thres = 0.20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SJpvkdwVSQye"
      },
      "outputs": [],
      "source": [
        "dir = \"/content/gdrive/My Drive/BioGITOM-VLDB/\"\n",
        "\n",
        "# Define the directory for the dataset containing source and target ontologies\n",
        "dataset_dir = f\"{dir}/Datasets/{task}\"\n",
        "\n",
        "# Define the data directory for storing embeddings, adjacency matrices, and related files\n",
        "data_dir = f\"{dir}/{task}/Data\"\n",
        "\n",
        "# Define the directory for storing the results\n",
        "results_dir = f\"{dir}/{task}/Results\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "eFDNSFef23er"
      },
      "outputs": [],
      "source": [
        "# Load the Source ontology using the Ontology class from DeepOnto\n",
        "# This initializes the source ontology by loading its .owl file.\n",
        "src_onto = Ontology(f\"{dataset_dir}/{src_ent}.owl\")\n",
        "\n",
        "# Load the Target ontology using the Ontology class from DeepOnto\n",
        "# This initializes the target ontology by loading its .owl file.\n",
        "tgt_onto = Ontology(f\"{dataset_dir}/{tgt_ent}.owl\")\n",
        "\n",
        "# Define the file path for the Source embeddings CSV file\n",
        "# Embeddings for the source ontology entities are stored in this file.\n",
        "src_Emb = f\"{data_dir}/{src_ent}_BERT_Hybrid_emb.csv\"\n",
        "\n",
        "# Define the file path for the Target embeddings CSV file\n",
        "# Embeddings for the target ontology entities are stored in this file.\n",
        "tgt_Emb = f\"{data_dir}/{tgt_ent}_BERT_Hybrid_emb.csv\"\n",
        "\n",
        "# Define the file path for the Source adjacency matrix\n",
        "# This file represents the relationships (edges) between entities in the source ontology.\n",
        "src_Adjacence = f\"{data_dir}/{src_ent}_adjacence.csv\"\n",
        "\n",
        "# Define the file path for the Target adjacency matrix\n",
        "# This file represents the relationships (edges) between entities in the target ontology.\n",
        "tgt_Adjacence = f\"{data_dir}/{tgt_ent}_adjacence.csv\"\n",
        "\n",
        "# Define the file path for the JSON file containing the Source ontology class labels\n",
        "# This file maps the source ontology entities to their labels or names.\n",
        "src_class = f\"{data_dir}/{src_ent}_classes.json\"\n",
        "\n",
        "# Define the file path for the JSON file containing the Target ontology class labels\n",
        "# This file maps the target ontology entities to their labels or names.\n",
        "tgt_class = f\"{data_dir}/{tgt_ent}_classes.json\"\n",
        "\n",
        "# Define the file path for the train data\n",
        "train_file = f\"{data_dir}/{task}_train.csv\"\n",
        "\n",
        "# Define the file path for the test data\n",
        "# The test file contains reference mappings (ground truth) between the source and target ontologies.\n",
        "test_file = f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "\n",
        "# Define the file path for the candidate mappings used during testing\n",
        "# This file includes the candidate pairs (source and target entities) for ranking and evaluation.\n",
        "test_cands = f\"{dataset_dir}/refs_equiv/test.cands.tsv\"\n",
        "\n",
        "# Define the file path for the candidate mappings between Source to Target entities\n",
        "# This file contains cleaned, combined, and encoded candidates used for predictions.\n",
        "candidates_Prediction = f\"{data_dir}/{task}_candidates_prediction.csv\"\n",
        "\n",
        "# Define the file path for the candidate mappings between Source to Target entities for ranking-based metrics\n",
        "# This file is used to compute ranking-based metrics like MRR and Hits@k.\n",
        "candidates_Rank = f\"{data_dir}/{task}_candidates.csv\"\n",
        "\n",
        "# Define the path where the prediction results will be saved in TSV format\n",
        "# This file will store the final predictions (mappings) between source and target entities.\n",
        "prediction_path = f\"{results_dir}/{task}_matching_results.tsv\"\n",
        "\n",
        "# Define the path where all prediction results will be saved in TSV format\n",
        "# This file will store detailed prediction results, including all candidate scores.\n",
        "all_predictions_path = f\"{results_dir}/{task}_all_predictions.tsv\"\n",
        "\n",
        "# Define the path where all ranking prediction results will be saved in TSV format\n",
        "# This file will store predictions sorted by rank based on their scores.\n",
        "all_predictions_path_ranked = f\"{results_dir}/{task}_all_predictions_ranked.tsv\"\n",
        "\n",
        "# Define the path where formatted ranking predictions will be saved in TSV format\n",
        "# This file will contain predictions formatted for evaluation using ranking-based metrics.\n",
        "formatted_predictions_path = f\"{results_dir}/{task}_formatted_predictions.tsv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqEXsgPGMVhw"
      },
      "source": [
        "# **GIT Architecture**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "A_d6XCsUMVhx"
      },
      "outputs": [],
      "source": [
        "# RGIT class definition which inherits from PyTorch Geometric's MessagePassing class\n",
        "class RGIT(MessagePassing):\n",
        "\n",
        "    _alpha: OptTensor  # Define _alpha as an optional tensor for storing attention weights\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        nn: Callable,  # Neural network to be used in the final layer of the GNN\n",
        "        in_channels: Union[int, Tuple[int, int]],  # Input dimension, can be a single or pair of integers\n",
        "        out_channels: int,  # Output dimension of the GNN\n",
        "        eps: float = 0.,  # GIN parameter: epsilon for GIN aggregation\n",
        "        train_eps: bool = False,  # GIN parameter: whether epsilon should be learnable\n",
        "        heads: int = 1,  # Transformer parameter: number of attention heads\n",
        "        dropout: float = 0.,  # Dropout rate for attention weights\n",
        "        edge_dim: Optional[int] = None,  # Dimension for edge attributes (optional)\n",
        "        bias: bool = True,  # Whether to use bias in linear layers\n",
        "        root_weight: bool = True,  # GIN parameter: whether to apply root weight in aggregation\n",
        "        **kwargs,  # Additional arguments passed to the parent class\n",
        "    ):\n",
        "        # Set the aggregation type to 'add' and initialize the parent class with node_dim=0\n",
        "        kwargs.setdefault('aggr', 'add')\n",
        "        super().__init__(node_dim=0, **kwargs)\n",
        "\n",
        "        # Initialize input/output dimensions, neural network, and GIN/transformer parameters\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.nn = nn  # Neural network used by the GNN\n",
        "        self.initial_eps = eps  # Initial value of epsilon for GIN\n",
        "\n",
        "        # Set epsilon to be learnable or fixed\n",
        "        if train_eps:\n",
        "            self.eps = torch.nn.Parameter(torch.empty(1))  # Learnable epsilon\n",
        "        else:\n",
        "            self.register_buffer('eps', torch.empty(1))  # Non-learnable epsilon (fixed)\n",
        "\n",
        "        # Initialize transformer-related parameters\n",
        "        self.heads = heads\n",
        "        self.dropout = dropout\n",
        "        self.edge_dim = edge_dim\n",
        "        self._alpha = None  # Placeholder for attention weights\n",
        "\n",
        "        # Handle case where in_channels is a single integer or a tuple\n",
        "        if isinstance(in_channels, int):\n",
        "            in_channels = (in_channels, in_channels)\n",
        "\n",
        "        # Define the linear layers for key, query, and value for the transformer mechanism\n",
        "        self.lin_key = Linear(in_channels[0], heads * out_channels)\n",
        "        self.lin_query = Linear(in_channels[1], heads * out_channels)\n",
        "        self.lin_value = Linear(in_channels[0], heads * out_channels)\n",
        "\n",
        "        # Define linear transformation for edge embeddings if provided\n",
        "        if edge_dim is not None:\n",
        "            self.lin_edge = Linear(edge_dim, heads * out_channels, bias=False)\n",
        "        else:\n",
        "            self.lin_edge = self.register_parameter('lin_edge', None)\n",
        "\n",
        "        # Reset all parameters to their initial values\n",
        "        self.reset_parameters()\n",
        "\n",
        "    # Function to reset model parameters\n",
        "    def reset_parameters(self):\n",
        "        super().reset_parameters()  # Call parent class reset method\n",
        "        self.lin_key.reset_parameters()  # Reset key linear layer\n",
        "        self.lin_query.reset_parameters()  # Reset query linear layer\n",
        "        self.lin_value.reset_parameters()  # Reset value linear layer\n",
        "        if self.edge_dim:\n",
        "            self.lin_edge.reset_parameters()  # Reset edge linear layer if used\n",
        "        reset(self.nn)  # Reset the neural network provided\n",
        "        self.eps.data.fill_(self.initial_eps)  # Initialize epsilon with the starting value\n",
        "\n",
        "    # Forward function defining how the input data flows through the model\n",
        "    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj,\n",
        "                edge_attr: OptTensor = None, return_attention_weights=None):\n",
        "        # Unpack number of heads and output channels\n",
        "        H, C = self.heads, self.out_channels\n",
        "\n",
        "        # If x is a tensor, treat it as a pair of tensors (source and target embeddings)\n",
        "        if isinstance(x, Tensor):\n",
        "            x: PairTensor = (x, x)\n",
        "\n",
        "        # Extract source node embeddings\n",
        "        x_t = x[0]\n",
        "\n",
        "        # Apply linear transformations and reshape query, key, and value for multi-head attention\n",
        "        query = self.lin_query(x[1]).view(-1, H, C)\n",
        "        key = self.lin_key(x[0]).view(-1, H, C)\n",
        "        value = self.lin_value(x[0]).view(-1, H, C)\n",
        "\n",
        "        # Propagate messages through the graph using the propagate function\n",
        "        out = self.propagate(edge_index, query=query, key=key, value=value,\n",
        "                             edge_attr=edge_attr, size=None)\n",
        "\n",
        "        # Retrieve attention weights and reset them\n",
        "        alpha = self._alpha\n",
        "        self._alpha = None  # Reset _alpha after use\n",
        "        out = out.mean(dim=1)  # Take the mean over all attention heads\n",
        "\n",
        "        # Apply GIN aggregation by adding epsilon-scaled original node embeddings\n",
        "        out = out + (1 + self.eps) * x_t\n",
        "        return self.nn(out)  # Pass through the neural network\n",
        "\n",
        "    # Message passing function which calculates attention and combines messages\n",
        "    def message(self, query_i: Tensor, key_j: Tensor, value_j: Tensor,\n",
        "                edge_attr: OptTensor, index: Tensor, ptr: OptTensor,\n",
        "                size_i: Optional[int]) -> Tensor:\n",
        "        # If edge attributes are used, apply linear transformation and add them to the key\n",
        "        if self.lin_edge is not None:\n",
        "            assert edge_attr is not None\n",
        "            edge_attr = self.lin_edge(edge_attr).view(-1, self.heads, self.out_channels)\n",
        "            key_j = key_j + edge_attr\n",
        "\n",
        "        # Calculate attention (alpha) using the dot product between query and key\n",
        "        alpha = (query_i * key_j).sum(dim=-1) / math.sqrt(self.out_channels)\n",
        "        alpha = softmax(alpha, index, ptr, size_i)  # Apply softmax to normalize attention\n",
        "        self._alpha = alpha  # Store attention weights\n",
        "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)  # Apply dropout\n",
        "\n",
        "        # Calculate the output message by applying attention to the value\n",
        "        out = value_j\n",
        "        if edge_attr is not None:\n",
        "            out = out + edge_attr  # Add edge embeddings to the output if present\n",
        "        out = out * alpha.view(-1, self.heads, 1)  # Scale by attention weights\n",
        "        return out\n",
        "\n",
        "    # String representation function for debugging or printing\n",
        "    def __repr__(self) -> str:\n",
        "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
        "                f'{self.out_channels}, heads={self.heads})')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qwFv6RgHmGCf"
      },
      "outputs": [],
      "source": [
        "# Define the RGIT_mod class, a multi-layer GNN that uses both RGIT and linear layers\n",
        "class RGIT_mod(torch.nn.Module):\n",
        "    \"\"\"Multi-layer RGIT with optional linear layers\"\"\"\n",
        "\n",
        "    # Initialize the model with hidden dimension, number of RGIT layers, and number of linear layers\n",
        "    def __init__(self, dim_h, num_layers, num_linear_layers=1):\n",
        "        super(RGIT_mod, self).__init__()\n",
        "        self.num_layers = num_layers  # Number of RGIT layers\n",
        "        self.num_linear_layers = num_linear_layers  # Number of linear layers\n",
        "        self.linears = torch.nn.ModuleList()  # List to store linear layers\n",
        "        self.rgit_layers = torch.nn.ModuleList()  # List to store RGIT layers\n",
        "\n",
        "        # Create a list of Linear and PReLU layers (for encoding entity names)\n",
        "        for _ in range(num_linear_layers):\n",
        "            self.linears.append(Linear(dim_h, dim_h))  # Linear transformation layer\n",
        "            self.linears.append(PReLU(num_parameters=dim_h))  # Parametric ReLU activation function\n",
        "\n",
        "        # Create a list of RGIT layers\n",
        "        for _ in range(num_layers):\n",
        "            self.rgit_layers.append(RGIT(  # Each RGIT layer contains a small MLP with Linear and PReLU\n",
        "                Sequential(Linear(dim_h, dim_h), PReLU(num_parameters=dim_h),\n",
        "                           Linear(dim_h, dim_h), PReLU(num_parameters=dim_h)), dim_h, dim_h))\n",
        "\n",
        "    # Forward pass through the model\n",
        "    def forward(self, x, edge_index):\n",
        "        # Apply the linear layers first to the input\n",
        "        for layer in self.linears:\n",
        "            x = layer(x)\n",
        "\n",
        "        # Then apply the RGIT layers for message passing\n",
        "        for layer in self.rgit_layers:\n",
        "            x = layer(x, edge_index)\n",
        "\n",
        "        return x  # Return the final node embeddings after all layers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxCn5ztKVztw"
      },
      "source": [
        "# **Gated Network Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "7MKQUv7o7zay"
      },
      "outputs": [],
      "source": [
        "class GatedCombination(nn.Module):\n",
        "    \"\"\"\n",
        "    A neural network module for combining embeddings using a gating mechanism\n",
        "    and evaluating their similarity. This class is particularly useful for\n",
        "    ontology matching tasks.\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): Dimensionality of the input embeddings.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim):\n",
        "        super(GatedCombination, self).__init__()\n",
        "\n",
        "        # Fully connected layer for gating mechanism on the first embedding pair (x1, x2)\n",
        "        self.gate_A_fc = nn.Linear(input_dim, input_dim)\n",
        "\n",
        "        # Fully connected layer for gating mechanism on the second embedding pair (x3, x4)\n",
        "        self.gate_B_fc = nn.Linear(input_dim, input_dim)\n",
        "\n",
        "        # Fully connected layer for final similarity classification\n",
        "        self.fc = nn.Linear(1, 1)\n",
        "\n",
        "    def forward(self, x1, x2, x3, x4, return_embeddings=False):\n",
        "        \"\"\"\n",
        "        Forward pass through the GatedCombination model.\n",
        "\n",
        "        Args:\n",
        "            x1 (torch.Tensor): First set of embeddings (e.g., updated source embeddings).\n",
        "            x2 (torch.Tensor): Second set of embeddings (e.g., original source embeddings).\n",
        "            x3 (torch.Tensor): Third set of embeddings (e.g., updated target embeddings).\n",
        "            x4 (torch.Tensor): Fourth set of embeddings (e.g., original target embeddings).\n",
        "            return_embeddings (bool): Whether to return the intermediate combined embeddings (a, b).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Probability score for binary classification if return_embeddings is False.\n",
        "            Tuple[torch.Tensor, torch.Tensor]: Intermediate embeddings (a, b) if return_embeddings is True.\n",
        "        \"\"\"\n",
        "        # Compute gating weights for the first pair of embeddings (x1, x2)\n",
        "        gate_values1 = torch.sigmoid(self.gate_A_fc(x1))\n",
        "\n",
        "        # Blend x1 and x2 using the computed gating weights\n",
        "        a = x1 * gate_values1 + x2 * (1 - gate_values1)\n",
        "\n",
        "        # Compute gating weights for the second pair of embeddings (x3, x4)\n",
        "        gate_values2 = torch.sigmoid(self.gate_B_fc(x3))\n",
        "\n",
        "        # Blend x3 and x4 using the computed gating weights\n",
        "        b = x3 * gate_values2 + x4 * (1 - gate_values2)\n",
        "\n",
        "        # If return_embeddings is True, return the intermediate blended embeddings\n",
        "        if return_embeddings:\n",
        "            return a, b\n",
        "\n",
        "        # Compute cosine similarity between the blended embeddings a and b\n",
        "        x = torch.cosine_similarity(a, b, dim=1)\n",
        "\n",
        "        # Apply a fully connected layer and sigmoid activation for classification\n",
        "        out = torch.sigmoid(self.fc(x.unsqueeze(1)))\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLJ5j9FNMVhy"
      },
      "source": [
        "# **Utility functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "k0L86DgUQjMU"
      },
      "outputs": [],
      "source": [
        "def adjacency_matrix_to_undirected_edge_index(adjacency_matrix):\n",
        "    \"\"\"\n",
        "    Converts an adjacency matrix into an undirected edge index for use in graph-based neural networks.\n",
        "\n",
        "    Args:\n",
        "        adjacency_matrix: A 2D list or array representing the adjacency matrix of a graph.\n",
        "\n",
        "    Returns:\n",
        "        edge_index_undirected: A PyTorch tensor representing the undirected edges.\n",
        "    \"\"\"\n",
        "    # Convert each element in the adjacency matrix to an integer (from boolean or float)\n",
        "    adjacency_matrix = [[int(element) for element in sublist] for sublist in adjacency_matrix]\n",
        "\n",
        "    # Convert the adjacency matrix into a PyTorch LongTensor (used for indexing)\n",
        "    edge_index = torch.tensor(adjacency_matrix, dtype=torch.long)\n",
        "\n",
        "    # Transpose the edge_index tensor so that rows represent edges in the form [source, target]\n",
        "    edge_index = edge_index.t().contiguous()\n",
        "\n",
        "    # Convert the directed edge_index into an undirected edge_index, meaning both directions are added (i.e., (i, j) and (j, i))\n",
        "    edge_index_undirected = to_undirected(edge_index)\n",
        "\n",
        "    return edge_index_undirected  # Return the undirected edge index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YvmOxkLcpf9w"
      },
      "outputs": [],
      "source": [
        "def build_indexed_dict(file_path):\n",
        "    \"\"\"\n",
        "    Builds a dictionary with numeric indexes for each key from a JSON file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): The path to the JSON file.\n",
        "\n",
        "    Returns:\n",
        "        indexed_dict (dict): A new dictionary where each key from the JSON file is assigned a numeric index.\n",
        "    \"\"\"\n",
        "    # Load the JSON file into a Python dictionary\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    # Create a new dictionary with numeric indexes as keys and the original JSON keys as values\n",
        "    indexed_dict = {index: key for index, key in enumerate(data.keys())}\n",
        "\n",
        "    return indexed_dict  # Return the newly created dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "QgFINoPGl9Wg"
      },
      "outputs": [],
      "source": [
        "def select_rows_by_index(embedding_vector, index_vector):\n",
        "    \"\"\"\n",
        "    Select rows from an embedding vector using an index vector.\n",
        "\n",
        "    Args:\n",
        "        embedding_vector (torch.Tensor): 2D tensor representing the embedding vector with shape [num_rows, embedding_size].\n",
        "        index_vector (torch.Tensor): 1D tensor representing the index vector.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: New tensor with selected rows from the embedding vector.\n",
        "    \"\"\"\n",
        "    # Use torch.index_select to select the desired rows\n",
        "    new_tensor = torch.index_select(embedding_vector, 0, index_vector)\n",
        "\n",
        "    return new_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "a12L7vEmmCJq"
      },
      "outputs": [],
      "source": [
        "def contrastive_loss(source_embeddings, target_embeddings, labels, margin=1.0):\n",
        "    \"\"\"\n",
        "    Computes the contrastive loss, a type of loss function used to train models in tasks like matching or similarity learning.\n",
        "\n",
        "    Args:\n",
        "        source_embeddings (torch.Tensor): Embeddings of the source graphs, shape [batch_size, embedding_size].\n",
        "        target_embeddings (torch.Tensor): Embeddings of the target graphs, shape [batch_size, embedding_size].\n",
        "        labels (torch.Tensor): Binary labels indicating if the pairs are matched (1) or not (0), shape [batch_size].\n",
        "        margin (float): Margin value for the contrastive loss. Defaults to 1.0.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The contrastive loss value.\n",
        "    \"\"\"\n",
        "    # Calculate the pairwise Euclidean distance between source and target embeddings\n",
        "    distances = F.pairwise_distance(source_embeddings, target_embeddings)\n",
        "\n",
        "    # Compute the contrastive loss:\n",
        "    # - For matched pairs (label == 1), the loss is the squared distance between embeddings.\n",
        "    # - For non-matched pairs (label == 0), the loss is based on how far apart the embeddings are,\n",
        "    #   but penalizes them only if the distance is less than the margin.\n",
        "    loss = torch.mean(\n",
        "        labels * 0.4 * distances.pow(2) +  # For positive pairs, minimize the distance (squared)\n",
        "        (1 - labels) * 0.4 * torch.max(torch.zeros_like(distances), margin - distances).pow(2)  # For negative pairs, maximize the distance (up to the margin)\n",
        "    )\n",
        "\n",
        "    return loss  # Return the computed contrastive loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZhCizXEb7D4N"
      },
      "outputs": [],
      "source": [
        "def Prediction_with_candidates(model, X1_tt, X2_tt, X3_tt, X4_tt, src_entity_tensor_o, tgt_entity_tensor_o,\n",
        "                                   indexed_dict_src, indexed_dict_tgt, all_predictions_path):\n",
        "    \"\"\"\n",
        "    Evaluates the GatedCombination model using the given embeddings and candidate entity pairs.\n",
        "    Saves the predictions and evaluation results to a file.\n",
        "\n",
        "    Args:\n",
        "        model: Trained GatedCombination model.\n",
        "        X1_tt, X2_tt, X3_tt, X4_tt (torch.Tensor): Tensors of source and target entity embeddings (updated and original).\n",
        "        src_entity_tensor_o, tgt_entity_tensor_o (torch.Tensor): Tensors of source and target entity indices.\n",
        "        indexed_dict_src, indexed_dict_tgt (dict): Dictionaries mapping entity indices to URIs for source and target.\n",
        "        output_file (str): Path to save the predictions and results.\n",
        "        hits_at_k_values (list): List of k-values for which hits@k is evaluated.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Move the model to CPU and set it to evaluation mode\n",
        "    model = model.to(\"cpu\")\n",
        "    model.eval()\n",
        "\n",
        "    # Set batch size for evaluation\n",
        "    batch_size_test = 32\n",
        "\n",
        "    # Create a DataLoader for the evaluation data\n",
        "    test_dataset = TensorDataset(X1_tt, X2_tt, X3_tt, X4_tt)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size_test)\n",
        "\n",
        "    # Prepare for collecting predictions and results\n",
        "    predictions = []\n",
        "    results = []\n",
        "    count_predictions = 0  # Counter for predictions above threshold (0.5)\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Disable gradient computation for evaluation\n",
        "    with torch.no_grad():\n",
        "        # Iterate over batches and compute model predictions\n",
        "        for batch_X1, batch_X2, batch_X3, batch_X4 in test_dataloader:\n",
        "            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n",
        "            predictions.extend(outputs.cpu().numpy())  # Collect predictions in CPU memory\n",
        "\n",
        "    end_time = time.time()\n",
        "    predicting_time = end_time - start_time\n",
        "    print(f\"Predicting time: {predicting_time:.2f} seconds\")\n",
        "\n",
        "    # Convert tensors to lists for easier iteration\n",
        "    src_indices = src_entity_tensor_o.tolist()\n",
        "    tgt_indices = tgt_entity_tensor_o.tolist()\n",
        "\n",
        "    # Prepare results\n",
        "    for i in range(len(predictions)):\n",
        "        if predictions[i] >= 0.00:  # Consider only predictions greater than 0.5\n",
        "            count_predictions += 1  # Increment the counter\n",
        "\n",
        "            # Map the source and target entity indices to their URIs\n",
        "            src_code = src_indices[i]\n",
        "            tgt_code = tgt_indices[i]\n",
        "\n",
        "            src_uri = indexed_dict_src.get(int(src_code), \"Unknown URI\")\n",
        "            tgt_uri = indexed_dict_tgt.get(int(tgt_code), \"Unknown URI\")\n",
        "\n",
        "            # Get the model's predicted score for the current pair\n",
        "            score = predictions[i]\n",
        "\n",
        "            # Append the results (with URIs instead of entity indices)\n",
        "            results.append({\n",
        "                'SrcEntity': src_uri,\n",
        "                'TgtEntity': tgt_uri,\n",
        "                'Score': score\n",
        "            })\n",
        "\n",
        "    # Convert the results into a pandas DataFrame\n",
        "    df_results = pd.DataFrame(results)\n",
        "\n",
        "    # Save the results to a TSV file\n",
        "    df_results.to_csv(all_predictions_path, sep='\\t', index=False)\n",
        "\n",
        "    print(f\"Predictions saved to {all_predictions_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TslUdYHBcGVj"
      },
      "outputs": [],
      "source": [
        "def filter_highest_predictions(input_file_path, output_file_path, threshold=thres):\n",
        "    # Load the all predictions file\n",
        "    df = pd.read_csv(input_file_path, sep='\\t')\n",
        "\n",
        "    # Extract the similarity score from the list in the 'Score' column\n",
        "    df['Score'] = df['Score'].apply(lambda x: float(x.strip('[]')))\n",
        "\n",
        "    # Sorting the dataframe by similarity score in descending order\n",
        "    df_sorted = df.sort_values(by='Score', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    # Initialize variables with threshold value\n",
        "    source_concepts = set(df_sorted['SrcEntity'])\n",
        "    target_concepts = set(df_sorted['TgtEntity'])\n",
        "    matched_sources = set()\n",
        "    matched_targets = set()\n",
        "    result = []\n",
        "\n",
        "    # Iterate through the sorted dataframe and find highest correspondences\n",
        "    for _, row in df_sorted.iterrows():\n",
        "        source, target, similarity = row['SrcEntity'], row['TgtEntity'], row['Score']\n",
        "\n",
        "        # Check if the source or target has already been matched and if the similarity is above the threshold\n",
        "        if source not in matched_sources and target not in matched_targets and similarity >= threshold:\n",
        "            # Add the match to the result list\n",
        "            result.append((source, target, similarity))\n",
        "            # Mark the source and target as matched\n",
        "            matched_sources.add(source)\n",
        "            matched_targets.add(target)\n",
        "\n",
        "    # Create a dataframe for the matching results with threshold applied\n",
        "    matching_results_df_threshold = pd.DataFrame(result, columns=['SrcEntity', 'TgtEntity', 'Score'])\n",
        "\n",
        "    # Save the matching results with the updated column names to a new TSV file\n",
        "    matching_results_df_threshold.to_csv(output_file_path, sep='\\t', index=False)\n",
        "\n",
        "    # Print the number of predictions saved\n",
        "    print(f\"Number of Positive Predictions : {len(matching_results_df_threshold)}\")\n",
        "\n",
        "    return matching_results_df_threshold, len(matching_results_df_threshold)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_mrr_and_hits(reference_file, predicted_file, output_file, k_values=[1, 5, 10]):\n",
        "    \"\"\"\n",
        "    Compute MRR and Hits@k for ontology matching predictions based on a reference file.\n",
        "\n",
        "    Args:\n",
        "        reference_file (str): Path to the reference file (test.cands.tsv format).\n",
        "        predicted_file (str): Path to the predictions file with scores.\n",
        "        output_file (str): Path to save the scored results.\n",
        "        k_values (list): List of k values for Hits@k.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing MRR and Hits@k metrics.\n",
        "    \"\"\"\n",
        "    # Read the reference mappings\n",
        "    test_candidate_mappings = read_table(reference_file).values.tolist()\n",
        "    ranking_results = []\n",
        "\n",
        "    # Read the predicted scores\n",
        "    predicted_data = pd.read_csv(predicted_file, sep=\"\\t\")\n",
        "    predicted_data[\"Score\"] = predicted_data[\"Score\"].apply(lambda x: float(x.strip(\"[]\")))\n",
        "\n",
        "    # Create a lookup dictionary for predicted scores\n",
        "    score_lookup = {}\n",
        "    for _, row in predicted_data.iterrows():\n",
        "        score_lookup[(row[\"SrcEntity\"], row[\"TgtEntity\"])] = row[\"Score\"]\n",
        "\n",
        "    for src_ref_class, tgt_ref_class, tgt_cands in test_candidate_mappings:\n",
        "        tgt_cands = eval(tgt_cands)  # Convert string to list of candidates\n",
        "        scored_cands = []\n",
        "        for tgt_cand in tgt_cands:\n",
        "            # Retrieve score for each candidate, defaulting to a very low score if not found\n",
        "            matching_score = score_lookup.get((src_ref_class, tgt_cand), -1e9)\n",
        "            scored_cands.append((tgt_cand, matching_score))\n",
        "\n",
        "        # Sort candidates by score in descending order\n",
        "        scored_cands = sorted(scored_cands, key=lambda x: x[1], reverse=True)\n",
        "        ranking_results.append((src_ref_class, tgt_ref_class, scored_cands))\n",
        "\n",
        "    # Save the ranked results to a file\n",
        "    pd.DataFrame(ranking_results, columns=[\"SrcEntity\", \"TgtEntity\", \"TgtCandidates\"]).to_csv(output_file, sep=\"\\t\", index=False)\n",
        "\n",
        "    # Compute MRR and Hits@k\n",
        "    total_entities = len(ranking_results)\n",
        "    reciprocal_ranks = []\n",
        "    hits_at_k = {k: 0 for k in k_values}\n",
        "\n",
        "    for src_entity, tgt_ref_class, tgt_cands in ranking_results:\n",
        "        ranked_candidates = [candidate[0] for candidate in tgt_cands]\n",
        "        if tgt_ref_class in ranked_candidates:\n",
        "            rank = ranked_candidates.index(tgt_ref_class) + 1\n",
        "            reciprocal_ranks.append(1 / rank)\n",
        "            for k in k_values:\n",
        "                if rank <= k:\n",
        "                    hits_at_k[k] += 1\n",
        "        else:\n",
        "            reciprocal_ranks.append(0)\n",
        "\n",
        "    mrr = sum(reciprocal_ranks) / total_entities\n",
        "    hits_at_k = {k: hits / total_entities for k, hits in hits_at_k.items()}\n",
        "\n",
        "    return {\"MRR\": mrr, \"Hits@k\": hits_at_k}"
      ],
      "metadata": {
        "id": "_ggVYlTiO_WA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HyWMsw1MVhz"
      },
      "source": [
        "# **Main Code**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC37FlwGDqGM"
      },
      "source": [
        "\n",
        "\n",
        "# Reading semantic node embeddings provided by the ENE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "FuEfSnw5mod0"
      },
      "outputs": [],
      "source": [
        "# Read the source embeddings from a CSV file into a pandas DataFrame\n",
        "df_embbedings_src = pd.read_csv(src_Emb, index_col=0)\n",
        "\n",
        "# Convert the DataFrame to a NumPy array, which will remove the index and store the data as a raw matrix\n",
        "numpy_array = df_embbedings_src.to_numpy()\n",
        "\n",
        "# Convert the NumPy array into a PyTorch FloatTensor, which is the format required for PyTorch operations\n",
        "x_src = torch.FloatTensor(numpy_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "STUwqMUXmlG2"
      },
      "outputs": [],
      "source": [
        "# Read the target embeddings from a CSV file into a pandas DataFrame\n",
        "df_embbedings_tgt = pd.read_csv(tgt_Emb, index_col=0)\n",
        "\n",
        "# Convert the DataFrame to a NumPy array, which removes the index and converts the data to a raw matrix\n",
        "numpy_array = df_embbedings_tgt.to_numpy()\n",
        "\n",
        "# Convert the NumPy array into a PyTorch FloatTensor, which is required for PyTorch operations\n",
        "x_tgt = torch.FloatTensor(numpy_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZIu9P08DqGN"
      },
      "source": [
        "# Reading adjacency Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "pH69Up40mycz"
      },
      "outputs": [],
      "source": [
        "# Read the source adjacency matrix from a CSV file into a pandas DataFrame\n",
        "df_ma1 = pd.read_csv(src_Adjacence, index_col=0)\n",
        "\n",
        "# Convert the DataFrame to a list of lists (Python native list format)\n",
        "ma1 = df_ma1.values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "hYCmAO5Ymzpl"
      },
      "outputs": [],
      "source": [
        "# Read the target adjacency matrix from a CSV file into a pandas DataFrame\n",
        "df_ma2 = pd.read_csv(tgt_Adjacence, index_col=0)\n",
        "\n",
        "# Convert the DataFrame to a list of lists (Python native list format)\n",
        "ma2 = df_ma2.values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSyksqh3TrU-"
      },
      "source": [
        "# Convert Adjacency matrix (in list format) to an undirected edge index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "uVt-Pce5m5ll"
      },
      "outputs": [],
      "source": [
        "# Convert the source adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n",
        "edge_src = adjacency_matrix_to_undirected_edge_index(ma1)\n",
        "\n",
        "# Convert the target adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n",
        "edge_tgt = adjacency_matrix_to_undirected_edge_index(ma2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9wMTRdqT4aY"
      },
      "source": [
        "# GIT Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "eqiEKCLSMVh3"
      },
      "outputs": [],
      "source": [
        "def train_model_gnn(model, x_src, edge_src, x_tgt, edge_tgt,\n",
        "                    tensor_term1, tensor_term2, tensor_score,\n",
        "                    learning_rate, weight_decay_value, num_epochs, print_interval=10):\n",
        "    \"\"\"\n",
        "    Trains a graph neural network (GNN) model using source and target embeddings and contrastive loss.\n",
        "\n",
        "    Args:\n",
        "        model: The GNN model to be trained.\n",
        "        x_src (torch.Tensor): Source node embeddings.\n",
        "        edge_src (torch.Tensor): Source graph edges.\n",
        "        x_tgt (torch.Tensor): Target node embeddings.\n",
        "        edge_tgt (torch.Tensor): Target graph edges.\n",
        "        tensor_term1 (torch.Tensor): Indices of the source nodes to be compared.\n",
        "        tensor_term2 (torch.Tensor): Indices of the target nodes to be compared.\n",
        "        tensor_score (torch.Tensor): Labels indicating if the pairs are matched (1) or not (0).\n",
        "        learning_rate (float): Learning rate for the optimizer.\n",
        "        weight_decay_value (float): Weight decay (L2 regularization) value for the optimizer.\n",
        "        num_epochs (int): Number of epochs for training.\n",
        "        print_interval (int): Interval at which training progress is printed (every `print_interval` epochs).\n",
        "\n",
        "    Returns:\n",
        "        model: The trained GNN model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 1: Set device (GPU or CPU) for computation\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Step 2: Move the model and all inputs to the selected device\n",
        "    model.to(device)\n",
        "    x_tgt = x_tgt.to(device)               # Target node embeddings\n",
        "    edge_tgt = edge_tgt.to(device)         # Target graph edges\n",
        "    x_src = x_src.to(device)               # Source node embeddings\n",
        "    edge_src = edge_src.to(device)         # Source graph edges\n",
        "    tensor_term1 = tensor_term1.to(device) # Indices for source nodes\n",
        "    tensor_term2 = tensor_term2.to(device) # Indices for target nodes\n",
        "    tensor_score = tensor_score.to(device) # Ground truth labels\n",
        "\n",
        "    # Step 3: Define optimizer with learning rate and regularization\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay_value)\n",
        "\n",
        "    # Step 4: Initialize list to store training losses\n",
        "    train_losses = []\n",
        "\n",
        "    # Record the start time of training\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Step 5: Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        # Zero out gradients from the previous iteration\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass: Compute embeddings for source and target graphs\n",
        "        out1 = model(x_src, edge_src)  # Updated source embeddings\n",
        "        out2 = model(x_tgt, edge_tgt)  # Updated target embeddings\n",
        "\n",
        "        # Extract specific rows of embeddings for terms being compared\n",
        "        src_embeddings = select_rows_by_index(out1, tensor_term1)\n",
        "        tgt_embeddings = select_rows_by_index(out2, tensor_term2)\n",
        "\n",
        "        # Compute contrastive loss based on the embeddings and ground truth labels\n",
        "        loss = contrastive_loss(src_embeddings, tgt_embeddings, tensor_score)\n",
        "\n",
        "        # Backward pass: Compute gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the model's parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Append the loss for this iteration to the list\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        # Print loss every `print_interval` epochs\n",
        "        if (epoch + 1) % print_interval == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item()}\")\n",
        "\n",
        "    # Step 6: Record end time of training\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Step 7: Plot the training loss over time\n",
        "    plt.semilogy(range(1, num_epochs + 1), train_losses, label=\"Training Loss\", marker='o')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Print the total training time\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training complete! Total training time: {training_time:.2f} seconds\")\n",
        "\n",
        "    # Step 8: Return the trained model\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "6_tzUG_emtBg"
      },
      "outputs": [],
      "source": [
        "# Initialize the GIT_mod model with the dimensionality of the target embeddings\n",
        "# The first argument is the dimensionality of the target node embeddings (x_tgt.shape[1])\n",
        "# The second argument (1) represents the number of RGIT layers in the model\n",
        "GIT_model = RGIT_mod(x_tgt.shape[1], 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "wVo-s7UQssSp"
      },
      "outputs": [],
      "source": [
        "# Reading the training pairs from a CSV file into a pandas DataFrame\n",
        "df_embbedings = pd.read_csv(train_file, index_col=0)\n",
        "\n",
        "# Extract the 'SrcEntity' and 'TgtEntity' columns as NumPy arrays and convert them to integers\n",
        "tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)  # Source entity indices\n",
        "tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)  # Target entity indices\n",
        "\n",
        "# Extract the 'Score' column as a NumPy array and convert it to floats\n",
        "tensor_score = df_embbedings['Score'].values.astype(float)  # Scores (labels) indicating if pairs match (1) or not (0)\n",
        "\n",
        "# Convert the NumPy arrays to PyTorch LongTensors (for indices) and FloatTensors (for scores)\n",
        "tensor_term1_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)  # Source entity tensor\n",
        "tensor_term2_o = torch.from_numpy(tensor_term2).type(torch.LongTensor)  # Target entity tensor\n",
        "tensor_score_o = torch.from_numpy(tensor_score).type(torch.FloatTensor)  # Score tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "agHlFNesMVh3",
        "outputId": "0dc80c0c-793b-4e6a-af49-7ac163d07e73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/1000], Training Loss: 0.0031576675828546286\n",
            "Epoch [20/1000], Training Loss: 0.002619890496134758\n",
            "Epoch [30/1000], Training Loss: 0.0023016927298158407\n",
            "Epoch [40/1000], Training Loss: 0.002068696077913046\n",
            "Epoch [50/1000], Training Loss: 0.0018954896368086338\n",
            "Epoch [60/1000], Training Loss: 0.0017570620402693748\n",
            "Epoch [70/1000], Training Loss: 0.0016409886302426457\n",
            "Epoch [80/1000], Training Loss: 0.0015419129049405456\n",
            "Epoch [90/1000], Training Loss: 0.0014567255275323987\n",
            "Epoch [100/1000], Training Loss: 0.0013823629124090075\n",
            "Epoch [110/1000], Training Loss: 0.0013164514675736427\n",
            "Epoch [120/1000], Training Loss: 0.0012573145795613527\n",
            "Epoch [130/1000], Training Loss: 0.0012038416462019086\n",
            "Epoch [140/1000], Training Loss: 0.0011552688665688038\n",
            "Epoch [150/1000], Training Loss: 0.0011106152087450027\n",
            "Epoch [160/1000], Training Loss: 0.0010698396945372224\n",
            "Epoch [170/1000], Training Loss: 0.001032143598422408\n",
            "Epoch [180/1000], Training Loss: 0.0009970745304599404\n",
            "Epoch [190/1000], Training Loss: 0.0009642566437833011\n",
            "Epoch [200/1000], Training Loss: 0.000933176779653877\n",
            "Epoch [210/1000], Training Loss: 0.0009040742879733443\n",
            "Epoch [220/1000], Training Loss: 0.0008761758217588067\n",
            "Epoch [230/1000], Training Loss: 0.0008497292874380946\n",
            "Epoch [240/1000], Training Loss: 0.00082461501006037\n",
            "Epoch [250/1000], Training Loss: 0.0008007602882571518\n",
            "Epoch [260/1000], Training Loss: 0.0007779918378219008\n",
            "Epoch [270/1000], Training Loss: 0.0007562455721199512\n",
            "Epoch [280/1000], Training Loss: 0.0007354799308814108\n",
            "Epoch [290/1000], Training Loss: 0.0007155483472160995\n",
            "Epoch [300/1000], Training Loss: 0.0006965813809074461\n",
            "Epoch [310/1000], Training Loss: 0.0006783647695556283\n",
            "Epoch [320/1000], Training Loss: 0.0006608697003684938\n",
            "Epoch [330/1000], Training Loss: 0.0006440700963139534\n",
            "Epoch [340/1000], Training Loss: 0.000627838191576302\n",
            "Epoch [350/1000], Training Loss: 0.0006122165941633284\n",
            "Epoch [360/1000], Training Loss: 0.0005971613572910428\n",
            "Epoch [370/1000], Training Loss: 0.0005827118875458837\n",
            "Epoch [380/1000], Training Loss: 0.0005686904187314212\n",
            "Epoch [390/1000], Training Loss: 0.0005551688955165446\n",
            "Epoch [400/1000], Training Loss: 0.0005421825917437673\n",
            "Epoch [410/1000], Training Loss: 0.0005296882591210306\n",
            "Epoch [420/1000], Training Loss: 0.0005177143611945212\n",
            "Epoch [430/1000], Training Loss: 0.0005062090931460261\n",
            "Epoch [440/1000], Training Loss: 0.0004951638984493911\n",
            "Epoch [450/1000], Training Loss: 0.0004845105286221951\n",
            "Epoch [460/1000], Training Loss: 0.00047423990326933563\n",
            "Epoch [470/1000], Training Loss: 0.00046436485718004405\n",
            "Epoch [480/1000], Training Loss: 0.00045488422620110214\n",
            "Epoch [490/1000], Training Loss: 0.00044580342364497483\n",
            "Epoch [500/1000], Training Loss: 0.00043706686119548976\n",
            "Epoch [510/1000], Training Loss: 0.00042866470175795257\n",
            "Epoch [520/1000], Training Loss: 0.00042056298116222024\n",
            "Epoch [530/1000], Training Loss: 0.0004128141445107758\n",
            "Epoch [540/1000], Training Loss: 0.0004053816373925656\n",
            "Epoch [550/1000], Training Loss: 0.0003982133639510721\n",
            "Epoch [560/1000], Training Loss: 0.0003913240216206759\n",
            "Epoch [570/1000], Training Loss: 0.0003846508916467428\n",
            "Epoch [580/1000], Training Loss: 0.0003781509294640273\n",
            "Epoch [590/1000], Training Loss: 0.000371834757970646\n",
            "Epoch [600/1000], Training Loss: 0.00036571064265444875\n",
            "Epoch [610/1000], Training Loss: 0.0003597379254642874\n",
            "Epoch [620/1000], Training Loss: 0.00035395074519328773\n",
            "Epoch [630/1000], Training Loss: 0.00034830195363610983\n",
            "Epoch [640/1000], Training Loss: 0.0003427649789955467\n",
            "Epoch [650/1000], Training Loss: 0.0003373928484506905\n",
            "Epoch [660/1000], Training Loss: 0.0003320834075566381\n",
            "Epoch [670/1000], Training Loss: 0.0003268623840995133\n",
            "Epoch [680/1000], Training Loss: 0.0003218711935915053\n",
            "Epoch [690/1000], Training Loss: 0.00031667956500314176\n",
            "Epoch [700/1000], Training Loss: 0.0003115568542852998\n",
            "Epoch [710/1000], Training Loss: 0.0003063418553210795\n",
            "Epoch [720/1000], Training Loss: 0.0003013960085809231\n",
            "Epoch [730/1000], Training Loss: 0.00029600333073176444\n",
            "Epoch [740/1000], Training Loss: 0.0002908977912738919\n",
            "Epoch [750/1000], Training Loss: 0.00028565022512339056\n",
            "Epoch [760/1000], Training Loss: 0.00028008612571284175\n",
            "Epoch [770/1000], Training Loss: 0.0002754103916231543\n",
            "Epoch [780/1000], Training Loss: 0.00026960126706399024\n",
            "Epoch [790/1000], Training Loss: 0.0002650571404956281\n",
            "Epoch [800/1000], Training Loss: 0.0002599454892333597\n",
            "Epoch [810/1000], Training Loss: 0.000254484242759645\n",
            "Epoch [820/1000], Training Loss: 0.00025013808044604957\n",
            "Epoch [830/1000], Training Loss: 0.0002457788505125791\n",
            "Epoch [840/1000], Training Loss: 0.00024088610371109098\n",
            "Epoch [850/1000], Training Loss: 0.00023783893266227096\n",
            "Epoch [860/1000], Training Loss: 0.00023329562100116163\n",
            "Epoch [870/1000], Training Loss: 0.00022928230464458466\n",
            "Epoch [880/1000], Training Loss: 0.0002268758398713544\n",
            "Epoch [890/1000], Training Loss: 0.00022405703202821314\n",
            "Epoch [900/1000], Training Loss: 0.00021951546659693122\n",
            "Epoch [910/1000], Training Loss: 0.0002167864586226642\n",
            "Epoch [920/1000], Training Loss: 0.00021394083159975708\n",
            "Epoch [930/1000], Training Loss: 0.00021176273003220558\n",
            "Epoch [940/1000], Training Loss: 0.00020884860714431852\n",
            "Epoch [950/1000], Training Loss: 0.00020935464999638498\n",
            "Epoch [960/1000], Training Loss: 0.00020472043252084404\n",
            "Epoch [970/1000], Training Loss: 0.00020256931020412594\n",
            "Epoch [980/1000], Training Loss: 0.00020040167146362364\n",
            "Epoch [990/1000], Training Loss: 0.00019919774786103517\n",
            "Epoch [1000/1000], Training Loss: 0.00019647605950012803\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete! Total training time: 652.31 seconds\n"
          ]
        }
      ],
      "source": [
        "# Train the GNN model using the provided source and target graph embeddings, edges, and training data\n",
        "trained_model = train_model_gnn(\n",
        "    model=GIT_model,                # The GNN model to be trained (initialized earlier)\n",
        "    x_src=x_src,                    # Source node embeddings (tensor for source graph)\n",
        "    edge_src=edge_src,              # Source graph edges (undirected edge index for source graph)\n",
        "    x_tgt=x_tgt,                    # Target node embeddings (tensor for target graph)\n",
        "    edge_tgt=edge_tgt,              # Target graph edges (undirected edge index for target graph)\n",
        "    tensor_term1=tensor_term1_o,    # Indices of source entities for training\n",
        "    tensor_term2=tensor_term2_o,    # Indices of target entities for training\n",
        "    tensor_score=tensor_score_o,    # Scores (labels) indicating if pairs match (1) or not (0)\n",
        "    learning_rate=0.0001,            # Learning rate for the Adam optimizer\n",
        "    weight_decay_value=1e-4,        # Weight decay for L2 regularization to prevent overfitting\n",
        "    num_epochs=1000,                # Number of training epochs\n",
        "    print_interval=10               # Interval at which to print training progress (every 10 epochs)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYyhvjcTUaae"
      },
      "source": [
        "# GIT Application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "BZ_VqP6tq6iD"
      },
      "outputs": [],
      "source": [
        "# Determine if a GPU is available and move the computations to it; otherwise, use the CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Assuming the model has been trained and hyperparameters (x_src, edge_src, x_tgt, edge_tgt) are set\n",
        "\n",
        "# Move the trained GIT_model to the device (GPU or CPU)\n",
        "GIT_model.to(device)\n",
        "\n",
        "# Move the data tensors to the same device (GPU or CPU)\n",
        "x_tgt = x_tgt.to(device)         # Target node embeddings\n",
        "edge_tgt = edge_tgt.to(device)   # Target graph edges\n",
        "x_src = x_src.to(device)         # Source node embeddings\n",
        "edge_src = edge_src.to(device)   # Source graph edges\n",
        "\n",
        "# Set the model to evaluation mode; this disables dropout and batch normalization\n",
        "GIT_model.eval()\n",
        "\n",
        "# Pass the source and target embeddings through the trained GNN model to update the embeddings\n",
        "with torch.no_grad():  # Disable gradient computation (inference mode)\n",
        "    embeddings_tgt = GIT_model(x_tgt, edge_tgt)  # Get updated embeddings for the target graph\n",
        "    embeddings_src = GIT_model(x_src, edge_src)  # Get updated embeddings for the source graph\n",
        "\n",
        "# Detach the embeddings from the computation graph and move them back to the CPU\n",
        "# This step is useful if you need to use the embeddings for tasks outside PyTorch (e.g., saving to disk)\n",
        "embeddings_tgt = embeddings_tgt.detach().cpu()  # Target graph embeddings\n",
        "embeddings_src = embeddings_src.detach().cpu()  # Source graph embeddings\n",
        "\n",
        "# At this point, embeddings_tgt and embeddings_src contain the updated embeddings, ready for downstream tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og5fdoGJrTCG"
      },
      "source": [
        "# Selecting embedding pairs to train the Gated Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "J0nTwc-dnjLn"
      },
      "outputs": [],
      "source": [
        "# Read the training pairs from a CSV file into a pandas DataFrame\n",
        "df_embeddings = pd.read_csv(train_file, index_col=0)\n",
        "\n",
        "# Extract columns and convert to NumPy arrays\n",
        "tensor_term1 = df_embeddings['SrcEntity'].values.astype(int)  # Source entity indices\n",
        "tensor_term2 = df_embeddings['TgtEntity'].values.astype(int)  # Target entity indices\n",
        "tensor_score = df_embeddings['Score'].values.astype(float)  # Matching scores\n",
        "\n",
        "# Split data into training and validation sets\n",
        "tensor_term1_train, tensor_term1_val, tensor_term2_train, tensor_term2_val, tensor_score_train, tensor_score_val = train_test_split(\n",
        "    tensor_term1, tensor_term2, tensor_score, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Convert split data to PyTorch tensors\n",
        "tensor_term1_train = torch.from_numpy(tensor_term1_train).type(torch.LongTensor)\n",
        "tensor_term2_train = torch.from_numpy(tensor_term2_train).type(torch.LongTensor)\n",
        "tensor_score_train = torch.from_numpy(tensor_score_train).type(torch.FloatTensor)\n",
        "\n",
        "tensor_term1_val = torch.from_numpy(tensor_term1_val).type(torch.LongTensor)\n",
        "tensor_term2_val = torch.from_numpy(tensor_term2_val).type(torch.LongTensor)\n",
        "tensor_score_val = torch.from_numpy(tensor_score_val).type(torch.FloatTensor)\n",
        "\n",
        "# Move the embeddings back to the CPU if not already there\n",
        "x_tgt = x_tgt.cpu()  # Target node embeddings\n",
        "x_src = x_src.cpu()  # Source node embeddings\n",
        "\n",
        "# Select embeddings for the training set\n",
        "X1_train = select_rows_by_index(embeddings_src, tensor_term1_train)\n",
        "X2_train = select_rows_by_index(x_src, tensor_term1_train)\n",
        "X3_train = select_rows_by_index(embeddings_tgt, tensor_term2_train)\n",
        "X4_train = select_rows_by_index(x_tgt, tensor_term2_train)\n",
        "\n",
        "# Select embeddings for the validation set\n",
        "X1_val = select_rows_by_index(embeddings_src, tensor_term1_val)\n",
        "X2_val = select_rows_by_index(x_src, tensor_term1_val)\n",
        "X3_val = select_rows_by_index(embeddings_tgt, tensor_term2_val)\n",
        "X4_val = select_rows_by_index(x_tgt, tensor_term2_val)\n",
        "\n",
        "# Now you have:\n",
        "# - Training tensors: X1_train, X2_train, X3_train, X4_train, tensor_score_train\n",
        "# - Validation tensors: X1_val, X2_val, X3_val, X4_val, tensor_score_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNdCgaTMExPK"
      },
      "source": [
        "# Gated Network Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Gof1eIPIWSVU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def train_gated_combination_model(X1_t, X2_t, X3_t, X4_t, tensor_score_o,\n",
        "                                  X1_val, X2_val, X3_val, X4_val, tensor_score_val,\n",
        "                                  epochs=120, batch_size=32, learning_rate=0.001, weight_decay=1e-5):\n",
        "    \"\"\"\n",
        "    Trains the GatedCombination model with training and validation data, using ReduceLROnPlateau scheduler.\n",
        "    Also calculates and displays F1-score during training and validation.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create datasets and DataLoaders\n",
        "    train_dataset = TensorDataset(X1_t, X2_t, X3_t, X4_t, tensor_score_o)\n",
        "    val_dataset = TensorDataset(X1_val, X2_val, X3_val, X4_val, tensor_score_val)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = GatedCombination(X1_t.shape[1]).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # Use ReduceLROnPlateau scheduler\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_train_loss = 0.0\n",
        "        y_true_train, y_pred_train = [], []\n",
        "\n",
        "        for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in train_loader:\n",
        "            batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (\n",
        "                batch_X1.to(device),\n",
        "                batch_X2.to(device),\n",
        "                batch_X3.to(device),\n",
        "                batch_X4.to(device),\n",
        "                batch_y.to(device),\n",
        "            )\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = F.binary_cross_entropy(outputs, batch_y.unsqueeze(1).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # Store true labels and predictions for F1-score\n",
        "            y_true_train.extend(batch_y.cpu().numpy())\n",
        "            y_pred_train.extend((outputs > 0.5).float().cpu().numpy())\n",
        "\n",
        "        train_loss = total_train_loss / len(train_loader)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # Calculate F1-score for training\n",
        "        train_f1 = f1_score(y_true_train, y_pred_train)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        total_val_loss = 0.0\n",
        "        y_true_val, y_pred_val = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in val_loader:\n",
        "                batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (\n",
        "                    batch_X1.to(device),\n",
        "                    batch_X2.to(device),\n",
        "                    batch_X3.to(device),\n",
        "                    batch_X4.to(device),\n",
        "                    batch_y.to(device),\n",
        "                )\n",
        "                outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n",
        "\n",
        "                # Compute loss\n",
        "                val_loss = F.binary_cross_entropy(outputs, batch_y.unsqueeze(1).float())\n",
        "                total_val_loss += val_loss.item()\n",
        "\n",
        "                # Store true labels and predictions for F1-score\n",
        "                y_true_val.extend(batch_y.cpu().numpy())\n",
        "                y_pred_val.extend((outputs > 0.5).float().cpu().numpy())\n",
        "\n",
        "        avg_val_loss = total_val_loss / len(val_loader)\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        # Calculate F1-score for validation\n",
        "        val_f1 = f1_score(y_true_val, y_pred_val)\n",
        "\n",
        "        # Step the scheduler with validation loss\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        # Print training and validation metrics\n",
        "        print(f\"Epoch [{epoch + 1}/{epochs}] Training Loss: {train_loss:.4f}, F1 Score: {train_f1:.4f} | \"\n",
        "              f\"Validation Loss: {avg_val_loss:.4f}, F1 Score: {val_f1:.4f}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Plotting training and validation loss\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label=\"Training Loss\", marker='o')\n",
        "    plt.plot(val_losses, label=\"Validation Loss\", marker='x')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Training complete! Total time: {end_time - start_time:.2f} seconds\")\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l11dgb8ei69T",
        "outputId": "8e0b7e96-a43c-4b0c-ed8a-1115ec4f4577"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100] Training Loss: 0.2404, F1 Score: 0.0000 | Validation Loss: 0.1387, F1 Score: 0.0000\n",
            "Epoch [2/100] Training Loss: 0.1163, F1 Score: 0.0000 | Validation Loss: 0.1111, F1 Score: 0.0000\n",
            "Epoch [3/100] Training Loss: 0.1079, F1 Score: 0.0000 | Validation Loss: 0.1083, F1 Score: 0.0000\n",
            "Epoch [4/100] Training Loss: 0.1033, F1 Score: 0.0000 | Validation Loss: 0.1073, F1 Score: 0.0000\n",
            "Epoch [5/100] Training Loss: 0.1027, F1 Score: 0.0000 | Validation Loss: 0.1071, F1 Score: 0.0000\n",
            "Epoch [6/100] Training Loss: 0.1022, F1 Score: 0.0000 | Validation Loss: 0.1063, F1 Score: 0.0000\n",
            "Epoch [7/100] Training Loss: 0.1015, F1 Score: 0.0000 | Validation Loss: 0.1058, F1 Score: 0.0000\n",
            "Epoch [8/100] Training Loss: 0.1008, F1 Score: 0.0000 | Validation Loss: 0.1048, F1 Score: 0.0000\n",
            "Epoch [9/100] Training Loss: 0.1000, F1 Score: 0.0000 | Validation Loss: 0.1039, F1 Score: 0.0000\n",
            "Epoch [10/100] Training Loss: 0.0992, F1 Score: 0.0000 | Validation Loss: 0.1030, F1 Score: 0.0000\n",
            "Epoch [11/100] Training Loss: 0.0982, F1 Score: 0.0000 | Validation Loss: 0.1019, F1 Score: 0.0000\n",
            "Epoch [12/100] Training Loss: 0.0972, F1 Score: 0.0000 | Validation Loss: 0.1007, F1 Score: 0.0000\n",
            "Epoch [13/100] Training Loss: 0.0960, F1 Score: 0.0000 | Validation Loss: 0.0988, F1 Score: 0.0000\n",
            "Epoch [14/100] Training Loss: 0.0917, F1 Score: 0.0000 | Validation Loss: 0.0920, F1 Score: 0.0000\n",
            "Epoch [15/100] Training Loss: 0.0850, F1 Score: 0.0000 | Validation Loss: 0.0848, F1 Score: 0.0000\n",
            "Epoch [16/100] Training Loss: 0.0783, F1 Score: 0.0000 | Validation Loss: 0.0778, F1 Score: 0.0000\n",
            "Epoch [17/100] Training Loss: 0.0717, F1 Score: 0.0000 | Validation Loss: 0.0708, F1 Score: 0.0000\n",
            "Epoch [18/100] Training Loss: 0.0653, F1 Score: 0.0000 | Validation Loss: 0.0642, F1 Score: 0.0000\n",
            "Epoch [19/100] Training Loss: 0.0593, F1 Score: 0.0000 | Validation Loss: 0.0580, F1 Score: 0.0000\n",
            "Epoch [20/100] Training Loss: 0.0537, F1 Score: 0.0000 | Validation Loss: 0.0527, F1 Score: 0.0000\n",
            "Epoch [21/100] Training Loss: 0.0486, F1 Score: 0.0000 | Validation Loss: 0.0474, F1 Score: 0.0000\n",
            "Epoch [22/100] Training Loss: 0.0441, F1 Score: 0.0823 | Validation Loss: 0.0427, F1 Score: 0.1192\n",
            "Epoch [23/100] Training Loss: 0.0403, F1 Score: 0.2463 | Validation Loss: 0.0388, F1 Score: 0.3277\n",
            "Epoch [24/100] Training Loss: 0.0368, F1 Score: 0.4258 | Validation Loss: 0.0359, F1 Score: 0.4978\n",
            "Epoch [25/100] Training Loss: 0.0340, F1 Score: 0.5518 | Validation Loss: 0.0329, F1 Score: 0.6064\n",
            "Epoch [26/100] Training Loss: 0.0314, F1 Score: 0.6644 | Validation Loss: 0.0303, F1 Score: 0.6641\n",
            "Epoch [27/100] Training Loss: 0.0294, F1 Score: 0.7015 | Validation Loss: 0.0286, F1 Score: 0.7299\n",
            "Epoch [28/100] Training Loss: 0.0275, F1 Score: 0.7474 | Validation Loss: 0.0263, F1 Score: 0.7646\n",
            "Epoch [29/100] Training Loss: 0.0261, F1 Score: 0.7697 | Validation Loss: 0.0251, F1 Score: 0.7966\n",
            "Epoch [30/100] Training Loss: 0.0248, F1 Score: 0.7849 | Validation Loss: 0.0239, F1 Score: 0.8149\n",
            "Epoch [31/100] Training Loss: 0.0237, F1 Score: 0.8040 | Validation Loss: 0.0228, F1 Score: 0.8169\n",
            "Epoch [32/100] Training Loss: 0.0227, F1 Score: 0.8176 | Validation Loss: 0.0218, F1 Score: 0.8269\n",
            "Epoch [33/100] Training Loss: 0.0220, F1 Score: 0.8323 | Validation Loss: 0.0213, F1 Score: 0.8367\n",
            "Epoch [34/100] Training Loss: 0.0213, F1 Score: 0.8363 | Validation Loss: 0.0200, F1 Score: 0.8444\n",
            "Epoch [35/100] Training Loss: 0.0207, F1 Score: 0.8432 | Validation Loss: 0.0198, F1 Score: 0.8539\n",
            "Epoch [36/100] Training Loss: 0.0202, F1 Score: 0.8462 | Validation Loss: 0.0195, F1 Score: 0.8650\n",
            "Epoch [37/100] Training Loss: 0.0197, F1 Score: 0.8504 | Validation Loss: 0.0186, F1 Score: 0.8613\n",
            "Epoch [38/100] Training Loss: 0.0194, F1 Score: 0.8553 | Validation Loss: 0.0190, F1 Score: 0.8728\n",
            "Epoch [39/100] Training Loss: 0.0191, F1 Score: 0.8588 | Validation Loss: 0.0179, F1 Score: 0.8650\n",
            "Epoch [40/100] Training Loss: 0.0187, F1 Score: 0.8574 | Validation Loss: 0.0178, F1 Score: 0.8650\n",
            "Epoch [41/100] Training Loss: 0.0184, F1 Score: 0.8679 | Validation Loss: 0.0177, F1 Score: 0.8706\n",
            "Epoch [42/100] Training Loss: 0.0183, F1 Score: 0.8642 | Validation Loss: 0.0171, F1 Score: 0.8836\n",
            "Epoch [43/100] Training Loss: 0.0181, F1 Score: 0.8670 | Validation Loss: 0.0175, F1 Score: 0.8850\n",
            "Epoch [44/100] Training Loss: 0.0178, F1 Score: 0.8683 | Validation Loss: 0.0170, F1 Score: 0.8836\n",
            "Epoch [45/100] Training Loss: 0.0178, F1 Score: 0.8668 | Validation Loss: 0.0165, F1 Score: 0.8871\n",
            "Epoch [46/100] Training Loss: 0.0175, F1 Score: 0.8757 | Validation Loss: 0.0164, F1 Score: 0.8800\n",
            "Epoch [47/100] Training Loss: 0.0174, F1 Score: 0.8739 | Validation Loss: 0.0164, F1 Score: 0.8889\n",
            "Epoch [48/100] Training Loss: 0.0173, F1 Score: 0.8703 | Validation Loss: 0.0163, F1 Score: 0.8836\n",
            "Epoch [49/100] Training Loss: 0.0171, F1 Score: 0.8765 | Validation Loss: 0.0161, F1 Score: 0.8818\n",
            "Epoch [50/100] Training Loss: 0.0171, F1 Score: 0.8725 | Validation Loss: 0.0163, F1 Score: 0.8854\n",
            "Epoch [51/100] Training Loss: 0.0170, F1 Score: 0.8773 | Validation Loss: 0.0162, F1 Score: 0.8924\n",
            "Epoch [52/100] Training Loss: 0.0169, F1 Score: 0.8783 | Validation Loss: 0.0159, F1 Score: 0.8871\n",
            "Epoch [53/100] Training Loss: 0.0168, F1 Score: 0.8829 | Validation Loss: 0.0158, F1 Score: 0.8871\n",
            "Epoch [54/100] Training Loss: 0.0167, F1 Score: 0.8795 | Validation Loss: 0.0158, F1 Score: 0.8800\n",
            "Epoch [55/100] Training Loss: 0.0167, F1 Score: 0.8775 | Validation Loss: 0.0162, F1 Score: 0.8959\n",
            "Epoch [56/100] Training Loss: 0.0166, F1 Score: 0.8797 | Validation Loss: 0.0156, F1 Score: 0.8924\n",
            "Epoch [57/100] Training Loss: 0.0166, F1 Score: 0.8819 | Validation Loss: 0.0155, F1 Score: 0.8906\n",
            "Epoch [58/100] Training Loss: 0.0165, F1 Score: 0.8802 | Validation Loss: 0.0156, F1 Score: 0.8889\n",
            "Epoch [59/100] Training Loss: 0.0165, F1 Score: 0.8799 | Validation Loss: 0.0156, F1 Score: 0.8924\n",
            "Epoch [60/100] Training Loss: 0.0165, F1 Score: 0.8801 | Validation Loss: 0.0154, F1 Score: 0.8871\n",
            "Epoch [61/100] Training Loss: 0.0164, F1 Score: 0.8846 | Validation Loss: 0.0155, F1 Score: 0.8836\n",
            "Epoch [62/100] Training Loss: 0.0164, F1 Score: 0.8846 | Validation Loss: 0.0156, F1 Score: 0.8818\n",
            "Epoch [63/100] Training Loss: 0.0163, F1 Score: 0.8823 | Validation Loss: 0.0152, F1 Score: 0.8906\n",
            "Epoch [64/100] Training Loss: 0.0163, F1 Score: 0.8862 | Validation Loss: 0.0156, F1 Score: 0.8706\n",
            "Epoch [65/100] Training Loss: 0.0163, F1 Score: 0.8851 | Validation Loss: 0.0151, F1 Score: 0.8906\n",
            "Epoch [66/100] Training Loss: 0.0163, F1 Score: 0.8807 | Validation Loss: 0.0155, F1 Score: 0.9028\n",
            "Epoch [67/100] Training Loss: 0.0163, F1 Score: 0.8854 | Validation Loss: 0.0153, F1 Score: 0.8889\n",
            "Epoch [68/100] Training Loss: 0.0163, F1 Score: 0.8815 | Validation Loss: 0.0154, F1 Score: 0.9028\n",
            "Epoch [69/100] Training Loss: 0.0162, F1 Score: 0.8823 | Validation Loss: 0.0154, F1 Score: 0.8959\n",
            "Epoch [70/100] Training Loss: 0.0162, F1 Score: 0.8850 | Validation Loss: 0.0150, F1 Score: 0.8942\n",
            "Epoch [71/100] Training Loss: 0.0162, F1 Score: 0.8846 | Validation Loss: 0.0153, F1 Score: 0.8889\n",
            "Epoch [72/100] Training Loss: 0.0161, F1 Score: 0.8901 | Validation Loss: 0.0151, F1 Score: 0.8871\n",
            "Epoch [73/100] Training Loss: 0.0162, F1 Score: 0.8818 | Validation Loss: 0.0158, F1 Score: 0.9045\n",
            "Epoch [74/100] Training Loss: 0.0162, F1 Score: 0.8856 | Validation Loss: 0.0150, F1 Score: 0.8871\n",
            "Epoch [75/100] Training Loss: 0.0162, F1 Score: 0.8839 | Validation Loss: 0.0149, F1 Score: 0.8924\n",
            "Epoch [76/100] Training Loss: 0.0161, F1 Score: 0.8864 | Validation Loss: 0.0149, F1 Score: 0.8889\n",
            "Epoch [77/100] Training Loss: 0.0161, F1 Score: 0.8816 | Validation Loss: 0.0155, F1 Score: 0.9011\n",
            "Epoch [78/100] Training Loss: 0.0161, F1 Score: 0.8864 | Validation Loss: 0.0151, F1 Score: 0.8871\n",
            "Epoch [79/100] Training Loss: 0.0162, F1 Score: 0.8840 | Validation Loss: 0.0150, F1 Score: 0.8942\n",
            "Epoch [80/100] Training Loss: 0.0161, F1 Score: 0.8886 | Validation Loss: 0.0150, F1 Score: 0.8942\n",
            "Epoch [81/100] Training Loss: 0.0163, F1 Score: 0.8864 | Validation Loss: 0.0154, F1 Score: 0.8959\n",
            "Epoch [82/100] Training Loss: 0.0162, F1 Score: 0.8854 | Validation Loss: 0.0152, F1 Score: 0.8994\n",
            "Epoch [83/100] Training Loss: 0.0161, F1 Score: 0.8850 | Validation Loss: 0.0151, F1 Score: 0.8924\n",
            "Epoch [84/100] Training Loss: 0.0161, F1 Score: 0.8818 | Validation Loss: 0.0151, F1 Score: 0.8924\n",
            "Epoch [85/100] Training Loss: 0.0160, F1 Score: 0.8850 | Validation Loss: 0.0149, F1 Score: 0.8924\n",
            "Epoch [86/100] Training Loss: 0.0161, F1 Score: 0.8870 | Validation Loss: 0.0151, F1 Score: 0.8976\n",
            "Epoch [87/100] Training Loss: 0.0161, F1 Score: 0.8870 | Validation Loss: 0.0150, F1 Score: 0.8994\n",
            "Epoch [88/100] Training Loss: 0.0161, F1 Score: 0.8862 | Validation Loss: 0.0152, F1 Score: 0.8906\n",
            "Epoch [89/100] Training Loss: 0.0160, F1 Score: 0.8823 | Validation Loss: 0.0154, F1 Score: 0.8997\n",
            "Epoch [90/100] Training Loss: 0.0162, F1 Score: 0.8807 | Validation Loss: 0.0148, F1 Score: 0.8871\n",
            "Epoch [91/100] Training Loss: 0.0161, F1 Score: 0.8856 | Validation Loss: 0.0150, F1 Score: 0.8976\n",
            "Epoch [92/100] Training Loss: 0.0160, F1 Score: 0.8829 | Validation Loss: 0.0155, F1 Score: 0.9014\n",
            "Epoch [93/100] Training Loss: 0.0161, F1 Score: 0.8848 | Validation Loss: 0.0152, F1 Score: 0.8997\n",
            "Epoch [94/100] Training Loss: 0.0161, F1 Score: 0.8846 | Validation Loss: 0.0152, F1 Score: 0.8994\n",
            "Epoch [95/100] Training Loss: 0.0161, F1 Score: 0.8856 | Validation Loss: 0.0151, F1 Score: 0.8906\n",
            "Epoch [96/100] Training Loss: 0.0160, F1 Score: 0.8854 | Validation Loss: 0.0148, F1 Score: 0.8927\n",
            "Epoch [97/100] Training Loss: 0.0160, F1 Score: 0.8872 | Validation Loss: 0.0154, F1 Score: 0.8959\n",
            "Epoch [98/100] Training Loss: 0.0161, F1 Score: 0.8834 | Validation Loss: 0.0149, F1 Score: 0.8818\n",
            "Epoch [99/100] Training Loss: 0.0161, F1 Score: 0.8831 | Validation Loss: 0.0154, F1 Score: 0.8906\n",
            "Epoch [100/100] Training Loss: 0.0160, F1 Score: 0.8818 | Validation Loss: 0.0148, F1 Score: 0.8924\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete! Total time: 733.17 seconds\n"
          ]
        }
      ],
      "source": [
        "# Train the GatedCombination model using training and validation data\n",
        "trained_model = train_gated_combination_model(\n",
        "    X1_train,          # Updated source embeddings (after applying the GNN model)\n",
        "    X2_train,          # Original source embeddings (before applying the GNN model)\n",
        "    X3_train,          # Updated target embeddings (after applying the GNN model)\n",
        "    X4_train,          # Original target embeddings (before applying the GNN model)\n",
        "    tensor_score_train, # Ground truth labels for the training set (1 for matched pairs, 0 for unmatched pairs)\n",
        "\n",
        "    X1_val,            # Updated source embeddings for the validation set\n",
        "    X2_val,            # Original source embeddings for the validation set\n",
        "    X3_val,            # Updated target embeddings for the validation set\n",
        "    X4_val,            # Original target embeddings for the validation set\n",
        "    tensor_score_val,  # Ground truth labels for the validation set (1 for matched pairs, 0 for unmatched pairs)\n",
        "\n",
        "    epochs=100,        # Number of epochs (iterations over the entire training dataset)\n",
        "    batch_size=32,     # Number of training samples processed in one forward/backward pass\n",
        "    learning_rate=0.001, # Learning rate for the optimizer (controls step size during optimization)\n",
        "    weight_decay=1e-4 # Weight decay (L2 regularization) to prevent overfitting\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAmLuMtGW9c2"
      },
      "source": [
        "# **Mappings Selector**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "lnFtpUAfJQHl"
      },
      "outputs": [],
      "source": [
        "# Build an indexed dictionary for the source ontology classes\n",
        "# src_class is the file path to the JSON file containing the source ontology classes\n",
        "indexed_dict_src = build_indexed_dict(src_class)\n",
        "\n",
        "# Build an indexed dictionary for the target ontology classes\n",
        "# tgt_class is the file path to the JSON file containing the target ontology classes\n",
        "indexed_dict_tgt = build_indexed_dict(tgt_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "beipwavuJQHl"
      },
      "outputs": [],
      "source": [
        "# Read the candidate pairs from a Candidates CSV file into a pandas DataFrame\n",
        "df_embbedings = pd.read_csv(candidates_Prediction, index_col=0)\n",
        "\n",
        "# Extract the 'SrcEntity' column (source entity indices) and convert it to a NumPy array of integers\n",
        "tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)\n",
        "\n",
        "# Extract the 'TgtEntity' column (target entity indices) and convert it to a NumPy array of integers\n",
        "tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)\n",
        "\n",
        "# Convert the source entity indices to a PyTorch LongTensor\n",
        "src_entity_tensor_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)\n",
        "\n",
        "# Convert the target entity indices to a PyTorch LongTensor\n",
        "tgt_entity_tenso_or = torch.from_numpy(tensor_term2).type(torch.LongTensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "ECLhmxyKJQHl"
      },
      "outputs": [],
      "source": [
        "# Select rows from the updated source embeddings based on the indices in src_entity_tensor_o\n",
        "X1_tt = select_rows_by_index(embeddings_src, src_entity_tensor_o)\n",
        "\n",
        "# Select rows from the original source embeddings based on the indices in src_entity_tensor_o\n",
        "X2_tt = select_rows_by_index(x_src, src_entity_tensor_o)\n",
        "\n",
        "# Select rows from the updated target embeddings based on the indices in tgt_entity_tenso_or\n",
        "X3_tt = select_rows_by_index(embeddings_tgt, tgt_entity_tenso_or)\n",
        "\n",
        "# Select rows from the original target embeddings based on the indices in tgt_entity_tenso_or\n",
        "X4_tt = select_rows_by_index(x_tgt, tgt_entity_tenso_or)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1986e70-73b5-4085-bdf4-1825016b4a69",
        "id": "UFP6OQR-7D4N"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting time: 12.30 seconds\n",
            "Predictions saved to /content/gdrive/My Drive/BioGITOM-VLDB//omim2ordo/Results/omim2ordo_all_predictions.tsv\n"
          ]
        }
      ],
      "source": [
        "# Generate predictions for candidate mappings using the trained GatedCombination model\n",
        "Prediction_with_candidates(\n",
        "    model=trained_model,             # The trained GatedCombination model used to evaluate similarity\n",
        "    X1_tt=X1_tt,                     # Updated source embeddings (after applying the GIT model)\n",
        "    X2_tt=X2_tt,                     # Original source embeddings (before applying the GIT model)\n",
        "    X3_tt=X3_tt,                     # Updated target embeddings (after applying the GIT model)\n",
        "    X4_tt=X4_tt,                     # Original target embeddings (before applying the GIT model)\n",
        "    src_entity_tensor_o=src_entity_tensor_o,  # Tensor of source entity indices used for evaluation\n",
        "    tgt_entity_tensor_o=tgt_entity_tenso_or,  # Tensor of target entity indices used for evaluation\n",
        "    indexed_dict_src=indexed_dict_src,        # Dictionary mapping source entity indices to their URIs\n",
        "    indexed_dict_tgt=indexed_dict_tgt,        # Dictionary mapping target entity indices to their URIs\n",
        "    all_predictions_path=all_predictions_path # Path to save all predictions with similarity scores in TSV format\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "mEc12J-B7D4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6aa47b3-64e0-45f0-c336-313543a3c572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Positive Predictions : 2463\n"
          ]
        }
      ],
      "source": [
        "# Filter the highest scoring predictions from the predictions file and save the results to a new file\n",
        "matching_results_df = filter_highest_predictions(\n",
        "    all_predictions_path,  # Path to the file containing all predictions with scores for all candidate pairs\n",
        "    prediction_path        # Path where the filtered predictions with highest scores will be saved\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIx74lNV7D4O"
      },
      "source": [
        "# **Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Global metrics calculation"
      ],
      "metadata": {
        "id": "Pp3IpBBfWn9m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkOewzXr7D4O",
        "outputId": "4a67c30f-9270-4e6f-c0bc-e6dd37655196"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Correct Predictions: 2103\n",
            "{'P': 0.854, 'R': 0.807, 'F1': 0.83}\n"
          ]
        }
      ],
      "source": [
        "# Retrieve the indices of the ignored classes (from source and target ontologies)\n",
        "ignored_class_index = get_ignored_class_index(src_onto)  # Get ignored class indices from source ontology\n",
        "ignored_class_index.update(get_ignored_class_index(tgt_onto))  # Update with ignored class indices from target ontology\n",
        "\n",
        "# Read the predicted mappings from the prediction results file\n",
        "preds = EntityMapping.read_table_mappings(prediction_path)\n",
        "\n",
        "# Read the reference mappings from the ground truth test file\n",
        "refs = ReferenceMapping.read_table_mappings(f\"{dataset_dir}/refs_equiv/test.tsv\")\n",
        "\n",
        "# Filter the predicted mappings to remove any mappings that involve ignored classes\n",
        "preds = remove_ignored_mappings(preds, ignored_class_index)\n",
        "\n",
        "# Compute the precision, recall, and F1-score by comparing predictions with the reference mappings\n",
        "results = AlignmentEvaluator.f1(preds, refs)\n",
        "\n",
        "preds2 = [p.to_tuple() for p in preds]\n",
        "refs2 = [r.to_tuple() for r in refs]\n",
        "\n",
        "correct= len(set(preds2).intersection(set(refs2)))\n",
        "\n",
        "print(f\"Number of Correct Predictions: {correct}\")\n",
        "\n",
        "# Print the computed precision, recall, and F1-score metrics\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ranked-based metrics calculation"
      ],
      "metadata": {
        "id": "aECB6igZW04C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "-AK-jADkSbTa"
      },
      "outputs": [],
      "source": [
        "# Read the candidate pairs from a Candidates CSV file into a pandas DataFrame\n",
        "df_embbedings = pd.read_csv(candidates_Rank, index_col=0)\n",
        "\n",
        "# Extract the 'SrcEntity' column (source entity indices) and convert it to a NumPy array of integers\n",
        "tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)\n",
        "\n",
        "# Extract the 'TgtEntity' column (target entity indices) and convert it to a NumPy array of integers\n",
        "tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)\n",
        "\n",
        "# Convert the source entity indices to a PyTorch LongTensor\n",
        "src_entity_tensor_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)\n",
        "\n",
        "# Convert the target entity indices to a PyTorch LongTensor\n",
        "tgt_entity_tenso_or = torch.from_numpy(tensor_term2).type(torch.LongTensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "oyOzcLv-SbTb"
      },
      "outputs": [],
      "source": [
        "# Select rows from the updated source embeddings based on the indices in src_entity_tensor_o\n",
        "X1_tt = select_rows_by_index(embeddings_src, src_entity_tensor_o)\n",
        "\n",
        "# Select rows from the original source embeddings based on the indices in src_entity_tensor_o\n",
        "X2_tt = select_rows_by_index(x_src, src_entity_tensor_o)\n",
        "\n",
        "# Select rows from the updated target embeddings based on the indices in tgt_entity_tenso_or\n",
        "X3_tt = select_rows_by_index(embeddings_tgt, tgt_entity_tenso_or)\n",
        "\n",
        "# Select rows from the original target embeddings based on the indices in tgt_entity_tenso_or\n",
        "X4_tt = select_rows_by_index(x_tgt, tgt_entity_tenso_or)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform ranking-based predictions using the trained GatedCombination model\n",
        "# Generate predictions for candidate mappings using the trained GatedCombination model\n",
        "Prediction_with_candidates(\n",
        "    model=trained_model,             # The trained GatedCombination model used to evaluate similarity\n",
        "    X1_tt=X1_tt,                     # Updated source embeddings (after applying the GIT model)\n",
        "    X2_tt=X2_tt,                     # Original source embeddings (before applying the GIT model)\n",
        "    X3_tt=X3_tt,                     # Updated target embeddings (after applying the GIT model)\n",
        "    X4_tt=X4_tt,                     # Original target embeddings (before applying the GIT model)\n",
        "    src_entity_tensor_o=src_entity_tensor_o,  # Tensor of source entity indices used for evaluation\n",
        "    tgt_entity_tensor_o=tgt_entity_tenso_or,  # Tensor of target entity indices used for evaluation\n",
        "    indexed_dict_src=indexed_dict_src,        # Dictionary mapping source entity indices to their URIs\n",
        "    indexed_dict_tgt=indexed_dict_tgt,        # Dictionary mapping target entity indices to their URIs\n",
        "    all_predictions_path=all_predictions_path_ranked, # Path where the ranked predictions will be saved in TSV format\n",
        ")"
      ],
      "metadata": {
        "id": "-O2f7X6cSb-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cd0e9a3-0312-4ddf-fbf3-5982052d12e1"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting time: 11.40 seconds\n",
            "Predictions saved to /content/gdrive/My Drive/BioGITOM-VLDB//omim2ordo/Results/omim2ordo_all_predictions_ranked.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "_402seVv7D4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9faebeca-c44c-4435-e961-40d2807e9a4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MRR and Hits@k Results:\n",
            "{'MRR': 0.8784377967329045, 'Hits@k': {1: 0.819961612284069, 5: 0.9512476007677543, 10: 0.9765834932821497}}\n"
          ]
        }
      ],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=all_predictions_path_ranked,             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n",
        "\n",
        "# Display the computed metrics\n",
        "print(\"MRR and Hits@k Results:\")\n",
        "print(results)  # Output the Mean Reciprocal Rank (MRR) and Hits@k metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "wStfa4eZ7D4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eff5e2ad-9c43-4853-de00-424135e3aab4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8784377967329045, 'Hits@1': 0.819961612284069, 'Hits@5': 0.9512476007677543, 'Hits@10': 0.9765834932821497}\n"
          ]
        }
      ],
      "source": [
        "# Call the ranking evaluation function, passing the path to the formatted predictions file.\n",
        "# Ks specifies the evaluation levels, checking if the correct target is within the top K candidates.\n",
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}