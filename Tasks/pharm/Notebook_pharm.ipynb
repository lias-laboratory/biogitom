{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkAX88H3RNRW"
      },
      "source": [
        "# **Package Installation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlL2v0xgmFJ-",
        "outputId": "e34e97a4-8cd5-4ab2-ffcc-adc309178152"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.0.0\n",
            "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.0)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.45.1)\n",
            "Collecting cmake (from triton==2.0.0->torch==2.0.0)\n",
            "  Downloading cmake-3.31.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.0)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n",
            "Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m698.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m942.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cmake-3.31.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.8/27.8 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, cmake, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cpu\n",
            "    Uninstalling torch-2.5.1+cpu:\n",
            "      Successfully uninstalled torch-2.5.1+cpu\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cpu requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\n",
            "torchvision 0.20.1+cpu requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cmake-3.31.2 lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 triton-2.0.0\n",
            "Collecting torch-geometric==2.4.0\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (3.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (3.2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.6.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric==2.4.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (2024.12.14)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.4.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.4.0) (3.5.0)\n",
            "Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.4.0\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_scatter-2.1.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (494 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_sparse-0.6.18%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_cluster-1.6.3%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (751 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.3/751.3 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (208 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n",
            "Installing collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt20cpu torch-scatter-2.1.2+pt20cpu torch-sparse-0.6.18+pt20cpu torch-spline-conv-1.2.2+pt20cpu\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.6.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.12.14)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting deeponto\n",
            "  Downloading deeponto-0.9.2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting JPype1 (from deeponto)\n",
            "  Downloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting yacs (from deeponto)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deeponto) (2.0.0)\n",
            "Collecting anytree (from deeponto)\n",
            "  Downloading anytree-2.12.1-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from deeponto) (8.1.7)\n",
            "Collecting dill (from deeponto)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from deeponto) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deeponto) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deeponto) (1.6.0)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (from deeponto) (4.47.1)\n",
            "Collecting datasets (from deeponto)\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.7.5)\n",
            "Collecting pprintpp (from deeponto)\n",
            "  Downloading pprintpp-0.4.0-py2.py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.4.2)\n",
            "Collecting lxml (from deeponto)\n",
            "  Downloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting textdistance (from deeponto)\n",
            "  Downloading textdistance-4.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from deeponto) (7.7.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from deeponto) (5.5.6)\n",
            "Collecting enlighten (from deeponto)\n",
            "  Downloading enlighten-1.13.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Collecting rdflib (from deeponto)\n",
            "  Downloading rdflib-7.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.9.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anytree->deeponto) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (18.1.0)\n",
            "Collecting dill (from deeponto)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (4.67.1)\n",
            "Collecting xxhash (from datasets->deeponto)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets->deeponto)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->deeponto)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (6.0.2)\n",
            "Collecting blessed>=1.17.7 (from enlighten->deeponto)\n",
            "  Downloading blessed-1.20.0-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Collecting prefixed>=0.3.2 (from enlighten->deeponto)\n",
            "  Downloading prefixed-0.9.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (6.3.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->deeponto) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->deeponto) (3.0.13)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->deeponto) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->deeponto) (2024.11.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2024.2)\n",
            "Collecting isodate<1.0.0,>=0.7.2 (from rdflib->deeponto)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib->deeponto) (3.2.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deeponto) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deeponto) (3.5.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (0.15.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.10.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (75.1.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (1.13.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (2.0.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->deeponto) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deeponto) (3.31.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deeponto) (18.1.8)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (0.4.5)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (1.2.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->transformers[torch]->deeponto) (5.9.5)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.7->enlighten->deeponto) (0.2.13)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (5.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.18.3)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->deeponto)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (5.1.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (4.9.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->deeponto) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->deeponto) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (7.1.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.5.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy->deeponto) (3.0.2)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->deeponto) (5.7.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->deeponto) (24.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deeponto) (1.3.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->deeponto) (0.8.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel->deeponto) (4.3.6)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (7.16.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.1.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel->deeponto) (0.7.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (3.0.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->deeponto) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (0.1.2)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.0.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.10.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.4.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.23.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.5.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.22.3)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.2.2)\n",
            "Downloading deeponto-0.9.2-py3-none-any.whl (89.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anytree-2.12.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading enlighten-1.13.0-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.8/493.8 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m100.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Downloading rdflib-7.1.1-py3-none-any.whl (562 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m562.4/562.4 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading textdistance-4.6.3-py3-none-any.whl (31 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prefixed-0.9.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: prefixed, pprintpp, yacs, xxhash, textdistance, lxml, JPype1, jedi, isodate, fsspec, dill, blessed, anytree, rdflib, multiprocess, enlighten, datasets, deeponto\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "Successfully installed JPype1-1.5.1 anytree-2.12.1 blessed-1.20.0 datasets-3.2.0 deeponto-0.9.2 dill-0.3.8 enlighten-1.13.0 fsspec-2024.9.0 isodate-0.7.2 jedi-0.19.2 lxml-5.3.0 multiprocess-0.70.16 pprintpp-0.4.0 prefixed-0.9.0 rdflib-7.1.1 textdistance-4.6.3 xxhash-3.5.0 yacs-0.1.8\n",
            "/bin/bash: line 1: username: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# We assume that PyTorch is already installed in the environment.\n",
        "# If not, this command installs it.\n",
        "!pip install torch==2.0.0\n",
        "\n",
        "# Install PyTorch Geometric, a library for creating graph neural networks using PyTorch.\n",
        "!pip install torch-geometric==2.4.0\n",
        "\n",
        "# Import PyTorch to access its functionalities.\n",
        "import torch\n",
        "\n",
        "# Install additional PyTorch Geometric dependencies for graph processing (scatter, sparse, cluster, spline-conv).\n",
        "# These packages enable operations like sparse tensors and convolutions on graphs.\n",
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
        "\n",
        "# Reinstall PyTorch Geometric to ensure all dependencies are correctly loaded.\n",
        "!pip install torch-geometric\n",
        "\n",
        "# Retrieve the installed version of PyTorch to ensure compatibility with other packages.\n",
        "torchversion = torch.__version__\n",
        "\n",
        "# Install the latest version of PyTorch Geometric directly from the GitHub repository.\n",
        "# This allows access to the most recent updates and features for graph-based neural networks.\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "# Install DeepOnto, a package specifically designed for ontology matching, particularly useful in biomedical applications.\n",
        "!pip install deeponto\n",
        "\n",
        "# Install a custom version of DeepOnto from a GitHub repository.\n",
        "# The '<username>' part should be replaced with the actual GitHub username of the repository maintainer.\n",
        "!pip install git+https://github.com/<username>/deeponto.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPAlAgjLMVhw",
        "outputId": "b4813a07-6d00-4485-ebb6-d4bb802a23b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter the maximum memory located to JVM [8g]: 8g\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import pandas for data manipulation and analysis, such as loading, processing, and saving tabular data.\n",
        "import pandas as pd\n",
        "\n",
        "# Import pickle for saving and loading serialized objects (e.g., trained models or preprocessed data).\n",
        "import pickle\n",
        "\n",
        "# Import function to convert a directed graph to an undirected one, useful for certain graph algorithms.\n",
        "from torch_geometric.utils import to_undirected\n",
        "\n",
        "# Import optimizer module from PyTorch for training models using gradient-based optimization techniques.\n",
        "import torch.optim as optim\n",
        "\n",
        "# Import PyTorch's modules for defining neural network architectures and operations:\n",
        "from torch.nn import (\n",
        "    Linear,       # For linear transformations (dense layers).\n",
        "    Sequential,   # For stacking layers sequentially.\n",
        "    BatchNorm1d,  # For normalizing input within mini-batches.\n",
        "    PReLU,        # Parametric ReLU activation function.\n",
        "    Dropout       # For regularization by randomly dropping connections during training.\n",
        ")\n",
        "\n",
        "# Import functional API from PyTorch for operations like activations and loss functions.\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Import Matplotlib for visualizations, such as plotting training loss curves.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import PyTorch Geometric's graph convolutional layers:\n",
        "from torch_geometric.nn import GCNConv, GINConv\n",
        "\n",
        "# Import pooling operations for aggregating node embeddings to graph-level representations:\n",
        "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
        "\n",
        "# Import NumPy for numerical operations, such as working with arrays and matrices.\n",
        "import numpy as np\n",
        "\n",
        "# Import time module for measuring execution time of code blocks.\n",
        "import time\n",
        "\n",
        "# Import typing module for specifying types in function arguments and return values.\n",
        "from typing import Optional, Tuple, Union, Callable\n",
        "\n",
        "# Import PyTorch's DataLoader and TensorDataset for handling data batching and loading during training.\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Import PyTorch's Parameter class for defining learnable parameters in custom models.\n",
        "from torch.nn import Parameter\n",
        "\n",
        "# Import math module for performing mathematical computations.\n",
        "import math\n",
        "\n",
        "# Import Tensor type from PyTorch for defining and manipulating tensors.\n",
        "from torch import Tensor\n",
        "\n",
        "# Import PyTorch's nn module for defining and building neural network architectures.\n",
        "import torch.nn as nn\n",
        "\n",
        "# Import initialization utilities from PyTorch Geometric for resetting weights and biases in layers.\n",
        "from torch_geometric.nn.inits import reset\n",
        "\n",
        "# Import the base class for defining message-passing layers in graph neural networks (GNNs).\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "\n",
        "# Import linear transformation utilities for creating dense representations in graph models.\n",
        "from torch_geometric.nn.dense.linear import Linear\n",
        "\n",
        "# Import typing utilities for defining adjacency matrices and tensor types specific to PyTorch Geometric.\n",
        "from torch_geometric.typing import Adj, OptTensor, PairTensor, SparseTensor\n",
        "\n",
        "# Import softmax function for normalizing attention scores in GNNs.\n",
        "from torch_geometric.utils import softmax\n",
        "\n",
        "# Import initialization utilities for weight initialization (e.g., Glorot initialization).\n",
        "from torch_geometric.nn.inits import glorot, zeros\n",
        "\n",
        "# Import F1 score metric from scikit-learn for evaluating model performance in binary/multi-class tasks.\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Import JSON module for reading and writing JSON files, useful for storing configuration or ontology data.\n",
        "import json\n",
        "\n",
        "# Import Ontology class from DeepOnto for representing and manipulating ontologies in the pipeline.\n",
        "from deeponto.onto import Ontology\n",
        "\n",
        "# Import tools from DeepOnto for handling Ontology Alignment Evaluation Initiative (OAEI) tasks.\n",
        "from deeponto.align.oaei import *\n",
        "\n",
        "# Import evaluation tools from DeepOnto for assessing alignment results using metrics like precision, recall, and F1.\n",
        "from deeponto.align.evaluation import AlignmentEvaluator\n",
        "\n",
        "# Import mapping utilities from DeepOnto for working with reference mappings and entity pairs.\n",
        "from deeponto.align.mapping import ReferenceMapping, EntityMapping\n",
        "\n",
        "# Import utility function for reading tables (e.g., TSV, CSV) from DeepOnto.\n",
        "from deeponto.utils import read_table\n",
        "\n",
        "# Importing the train_test_split function from sklearn's model_selection module.\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "n5j8x2HqWs4_"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "# Set the seed for PyTorch's random number generator to ensure reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Set the seed for NumPy's random number generator to ensure reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Set the seed for Python's built-in random module to ensure reproducibility\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQxSrJP7WoIj"
      },
      "source": [
        "# **Paths Definition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "detugQhiWoIk",
        "outputId": "314a8a40-66a4-42ea-a9d5-ea03d9e7aca1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Importing the 'drive' module from Google Colab to interact with Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount the user's Google Drive to the Colab environment\n",
        "# After running this, a link will appear to authorize access, and Google Drive will be mounted at '/content/gdrive'\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "36ttssQ3W7cx"
      },
      "outputs": [],
      "source": [
        "# Define the source ontology name\n",
        "src_ent = \"snomed.pharm\"\n",
        "\n",
        "# Define the target ontology name\n",
        "tgt_ent = \"ncit.pharm\"\n",
        "\n",
        "# Define the task name for this ontology matching process\n",
        "task = \"pharm\"\n",
        "\n",
        "# Define the similarity threshold for validating matches\n",
        "thres = 0.190"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SJpvkdwVSQye"
      },
      "outputs": [],
      "source": [
        "dir = \"/content/gdrive/My Drive/BioGITOM-VLDB/\"\n",
        "\n",
        "# Define the directory for the dataset containing source and target ontologies\n",
        "dataset_dir = f\"{dir}/Datasets/{task}\"\n",
        "\n",
        "# Define the data directory for storing embeddings, adjacency matrices, and related files\n",
        "data_dir = f\"{dir}/{task}/Data\"\n",
        "\n",
        "# Define the directory for storing the results\n",
        "results_dir = f\"{dir}/{task}/Results\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "eFDNSFef23er"
      },
      "outputs": [],
      "source": [
        "# Load the Source ontology using the Ontology class from DeepOnto\n",
        "# This initializes the source ontology by loading its .owl file.\n",
        "src_onto = Ontology(f\"{dataset_dir}/{src_ent}.owl\")\n",
        "\n",
        "# Load the Target ontology using the Ontology class from DeepOnto\n",
        "# This initializes the target ontology by loading its .owl file.\n",
        "tgt_onto = Ontology(f\"{dataset_dir}/{tgt_ent}.owl\")\n",
        "\n",
        "# Define the file path for the Source embeddings CSV file\n",
        "# Embeddings for the source ontology entities are stored in this file.\n",
        "src_Emb = f\"{data_dir}/{src_ent}_Sentence_SapBERT_emb.csv\"\n",
        "\n",
        "# Define the file path for the Target embeddings CSV file\n",
        "# Embeddings for the target ontology entities are stored in this file.\n",
        "tgt_Emb = f\"{data_dir}/{tgt_ent}_Sentence_SapBERT_emb.csv\"\n",
        "\n",
        "# Define the file path for the Source adjacency matrix\n",
        "# This file represents the relationships (edges) between entities in the source ontology.\n",
        "src_Adjacence = f\"{data_dir}/{src_ent}_adjacence.csv\"\n",
        "\n",
        "# Define the file path for the Target adjacency matrix\n",
        "# This file represents the relationships (edges) between entities in the target ontology.\n",
        "tgt_Adjacence = f\"{data_dir}/{tgt_ent}_adjacence.csv\"\n",
        "\n",
        "# Define the file path for the JSON file containing the Source ontology class labels\n",
        "# This file maps the source ontology entities to their labels or names.\n",
        "src_class = f\"{data_dir}/{src_ent}_classes.json\"\n",
        "\n",
        "# Define the file path for the JSON file containing the Target ontology class labels\n",
        "# This file maps the target ontology entities to their labels or names.\n",
        "tgt_class = f\"{data_dir}/{tgt_ent}_classes.json\"\n",
        "\n",
        "# Define the file path for the train data\n",
        "train_file = f\"{data_dir}/{task}_train.csv\"\n",
        "\n",
        "# Define the file path for the test data\n",
        "# The test file contains reference mappings (ground truth) between the source and target ontologies.\n",
        "test_file = f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "\n",
        "# Define the file path for the candidate mappings used during testing\n",
        "# This file includes the candidate pairs (source and target entities) for ranking and evaluation.\n",
        "test_cands = f\"{dataset_dir}/refs_equiv/test.cands.tsv\"\n",
        "\n",
        "# Define the file path for the candidate mappings between Source to Target entities\n",
        "# This file contains cleaned, combined, and encoded candidates used for predictions.\n",
        "candidates_Prediction = f\"{data_dir}/{task}_candidates_prediction.csv\"\n",
        "\n",
        "# Define the file path for the candidate mappings between Source to Target entities for ranking-based metrics\n",
        "# This file is used to compute ranking-based metrics like MRR and Hits@k.\n",
        "candidates_Rank = f\"{data_dir}/{task}_candidates.csv\"\n",
        "\n",
        "# Define the path where the prediction results will be saved in TSV format\n",
        "# This file will store the final predictions (mappings) between source and target entities.\n",
        "prediction_path = f\"{results_dir}/{task}_matching_results.tsv\"\n",
        "\n",
        "# Define the path where all prediction results will be saved in TSV format\n",
        "# This file will store detailed prediction results, including all candidate scores.\n",
        "all_predictions_path = f\"{results_dir}/{task}_all_predictions.tsv\"\n",
        "\n",
        "# Define the path where all ranking prediction results will be saved in TSV format\n",
        "# This file will store predictions sorted by rank based on their scores.\n",
        "all_predictions_path_ranked = f\"{results_dir}/{task}_all_predictions_ranked.tsv\"\n",
        "\n",
        "# Define the path where formatted ranking predictions will be saved in TSV format\n",
        "# This file will contain predictions formatted for evaluation using ranking-based metrics.\n",
        "formatted_predictions_path = f\"{results_dir}/{task}_formatted_predictions.tsv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqEXsgPGMVhw"
      },
      "source": [
        "# **GIT Architecture**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "A_d6XCsUMVhx"
      },
      "outputs": [],
      "source": [
        "# RGIT class definition which inherits from PyTorch Geometric's MessagePassing class\n",
        "class RGIT(MessagePassing):\n",
        "\n",
        "    _alpha: OptTensor  # Define _alpha as an optional tensor for storing attention weights\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        nn: Callable,  # Neural network to be used in the final layer of the GNN\n",
        "        in_channels: Union[int, Tuple[int, int]],  # Input dimension, can be a single or pair of integers\n",
        "        out_channels: int,  # Output dimension of the GNN\n",
        "        eps: float = 0.,  # GIN parameter: epsilon for GIN aggregation\n",
        "        train_eps: bool = False,  # GIN parameter: whether epsilon should be learnable\n",
        "        heads: int = 1,  # Transformer parameter: number of attention heads\n",
        "        dropout: float = 0.,  # Dropout rate for attention weights\n",
        "        edge_dim: Optional[int] = None,  # Dimension for edge attributes (optional)\n",
        "        bias: bool = True,  # Whether to use bias in linear layers\n",
        "        root_weight: bool = True,  # GIN parameter: whether to apply root weight in aggregation\n",
        "        **kwargs,  # Additional arguments passed to the parent class\n",
        "    ):\n",
        "        # Set the aggregation type to 'add' and initialize the parent class with node_dim=0\n",
        "        kwargs.setdefault('aggr', 'add')\n",
        "        super().__init__(node_dim=0, **kwargs)\n",
        "\n",
        "        # Initialize input/output dimensions, neural network, and GIN/transformer parameters\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.nn = nn  # Neural network used by the GNN\n",
        "        self.initial_eps = eps  # Initial value of epsilon for GIN\n",
        "\n",
        "        # Set epsilon to be learnable or fixed\n",
        "        if train_eps:\n",
        "            self.eps = torch.nn.Parameter(torch.empty(1))  # Learnable epsilon\n",
        "        else:\n",
        "            self.register_buffer('eps', torch.empty(1))  # Non-learnable epsilon (fixed)\n",
        "\n",
        "        # Initialize transformer-related parameters\n",
        "        self.heads = heads\n",
        "        self.dropout = dropout\n",
        "        self.edge_dim = edge_dim\n",
        "        self._alpha = None  # Placeholder for attention weights\n",
        "\n",
        "        # Handle case where in_channels is a single integer or a tuple\n",
        "        if isinstance(in_channels, int):\n",
        "            in_channels = (in_channels, in_channels)\n",
        "\n",
        "        # Define the linear layers for key, query, and value for the transformer mechanism\n",
        "        self.lin_key = Linear(in_channels[0], heads * out_channels)\n",
        "        self.lin_query = Linear(in_channels[1], heads * out_channels)\n",
        "        self.lin_value = Linear(in_channels[0], heads * out_channels)\n",
        "\n",
        "        # Define linear transformation for edge embeddings if provided\n",
        "        if edge_dim is not None:\n",
        "            self.lin_edge = Linear(edge_dim, heads * out_channels, bias=False)\n",
        "        else:\n",
        "            self.lin_edge = self.register_parameter('lin_edge', None)\n",
        "\n",
        "        # Reset all parameters to their initial values\n",
        "        self.reset_parameters()\n",
        "\n",
        "    # Function to reset model parameters\n",
        "    def reset_parameters(self):\n",
        "        super().reset_parameters()  # Call parent class reset method\n",
        "        self.lin_key.reset_parameters()  # Reset key linear layer\n",
        "        self.lin_query.reset_parameters()  # Reset query linear layer\n",
        "        self.lin_value.reset_parameters()  # Reset value linear layer\n",
        "        if self.edge_dim:\n",
        "            self.lin_edge.reset_parameters()  # Reset edge linear layer if used\n",
        "        reset(self.nn)  # Reset the neural network provided\n",
        "        self.eps.data.fill_(self.initial_eps)  # Initialize epsilon with the starting value\n",
        "\n",
        "    # Forward function defining how the input data flows through the model\n",
        "    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj,\n",
        "                edge_attr: OptTensor = None, return_attention_weights=None):\n",
        "        # Unpack number of heads and output channels\n",
        "        H, C = self.heads, self.out_channels\n",
        "\n",
        "        # If x is a tensor, treat it as a pair of tensors (source and target embeddings)\n",
        "        if isinstance(x, Tensor):\n",
        "            x: PairTensor = (x, x)\n",
        "\n",
        "        # Extract source node embeddings\n",
        "        x_t = x[0]\n",
        "\n",
        "        # Apply linear transformations and reshape query, key, and value for multi-head attention\n",
        "        query = self.lin_query(x[1]).view(-1, H, C)\n",
        "        key = self.lin_key(x[0]).view(-1, H, C)\n",
        "        value = self.lin_value(x[0]).view(-1, H, C)\n",
        "\n",
        "        # Propagate messages through the graph using the propagate function\n",
        "        out = self.propagate(edge_index, query=query, key=key, value=value,\n",
        "                             edge_attr=edge_attr, size=None)\n",
        "\n",
        "        # Retrieve attention weights and reset them\n",
        "        alpha = self._alpha\n",
        "        self._alpha = None  # Reset _alpha after use\n",
        "        out = out.mean(dim=1)  # Take the mean over all attention heads\n",
        "\n",
        "        # Apply GIN aggregation by adding epsilon-scaled original node embeddings\n",
        "        out = out + (1 + self.eps) * x_t\n",
        "        return self.nn(out)  # Pass through the neural network\n",
        "\n",
        "    # Message passing function which calculates attention and combines messages\n",
        "    def message(self, query_i: Tensor, key_j: Tensor, value_j: Tensor,\n",
        "                edge_attr: OptTensor, index: Tensor, ptr: OptTensor,\n",
        "                size_i: Optional[int]) -> Tensor:\n",
        "        # If edge attributes are used, apply linear transformation and add them to the key\n",
        "        if self.lin_edge is not None:\n",
        "            assert edge_attr is not None\n",
        "            edge_attr = self.lin_edge(edge_attr).view(-1, self.heads, self.out_channels)\n",
        "            key_j = key_j + edge_attr\n",
        "\n",
        "        # Calculate attention (alpha) using the dot product between query and key\n",
        "        alpha = (query_i * key_j).sum(dim=-1) / math.sqrt(self.out_channels)\n",
        "        alpha = softmax(alpha, index, ptr, size_i)  # Apply softmax to normalize attention\n",
        "        self._alpha = alpha  # Store attention weights\n",
        "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)  # Apply dropout\n",
        "\n",
        "        # Calculate the output message by applying attention to the value\n",
        "        out = value_j\n",
        "        if edge_attr is not None:\n",
        "            out = out + edge_attr  # Add edge embeddings to the output if present\n",
        "        out = out * alpha.view(-1, self.heads, 1)  # Scale by attention weights\n",
        "        return out\n",
        "\n",
        "    # String representation function for debugging or printing\n",
        "    def __repr__(self) -> str:\n",
        "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
        "                f'{self.out_channels}, heads={self.heads})')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qwFv6RgHmGCf"
      },
      "outputs": [],
      "source": [
        "# Define the RGIT_mod class, a multi-layer GNN that uses both RGIT and linear layers\n",
        "class RGIT_mod(torch.nn.Module):\n",
        "    \"\"\"Multi-layer RGIT with optional linear layers\"\"\"\n",
        "\n",
        "    # Initialize the model with hidden dimension, number of RGIT layers, and number of linear layers\n",
        "    def __init__(self, dim_h, num_layers, num_linear_layers=1):\n",
        "        super(RGIT_mod, self).__init__()\n",
        "        self.num_layers = num_layers  # Number of RGIT layers\n",
        "        self.num_linear_layers = num_linear_layers  # Number of linear layers\n",
        "        self.linears = torch.nn.ModuleList()  # List to store linear layers\n",
        "        self.rgit_layers = torch.nn.ModuleList()  # List to store RGIT layers\n",
        "\n",
        "        # Create a list of Linear and PReLU layers (for encoding entity names)\n",
        "        for _ in range(num_linear_layers):\n",
        "            self.linears.append(Linear(dim_h, dim_h))  # Linear transformation layer\n",
        "            self.linears.append(PReLU(num_parameters=dim_h))  # Parametric ReLU activation function\n",
        "\n",
        "        # Create a list of RGIT layers\n",
        "        for _ in range(num_layers):\n",
        "            self.rgit_layers.append(RGIT(  # Each RGIT layer contains a small MLP with Linear and PReLU\n",
        "                Sequential(Linear(dim_h, dim_h), PReLU(num_parameters=dim_h),\n",
        "                           Linear(dim_h, dim_h), PReLU(num_parameters=dim_h)), dim_h, dim_h))\n",
        "\n",
        "    # Forward pass through the model\n",
        "    def forward(self, x, edge_index):\n",
        "        # Apply the linear layers first to the input\n",
        "        for layer in self.linears:\n",
        "            x = layer(x)\n",
        "\n",
        "        # Then apply the RGIT layers for message passing\n",
        "        for layer in self.rgit_layers:\n",
        "            x = layer(x, edge_index)\n",
        "\n",
        "        return x  # Return the final node embeddings after all layers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxCn5ztKVztw"
      },
      "source": [
        "# **Gated Network Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7MKQUv7o7zay"
      },
      "outputs": [],
      "source": [
        "class GatedCombination(nn.Module):\n",
        "    \"\"\"\n",
        "    A neural network module for combining embeddings using a gating mechanism\n",
        "    and evaluating their similarity. This class is particularly useful for\n",
        "    ontology matching tasks.\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): Dimensionality of the input embeddings.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim):\n",
        "        super(GatedCombination, self).__init__()\n",
        "\n",
        "        # Fully connected layer for gating mechanism on the first embedding pair (x1, x2)\n",
        "        self.gate_A_fc = nn.Linear(input_dim, input_dim)\n",
        "\n",
        "        # Fully connected layer for gating mechanism on the second embedding pair (x3, x4)\n",
        "        self.gate_B_fc = nn.Linear(input_dim, input_dim)\n",
        "\n",
        "        # Fully connected layer for final similarity classification\n",
        "        self.fc = nn.Linear(1, 1)\n",
        "\n",
        "    def forward(self, x1, x2, x3, x4, return_embeddings=False):\n",
        "        \"\"\"\n",
        "        Forward pass through the GatedCombination model.\n",
        "\n",
        "        Args:\n",
        "            x1 (torch.Tensor): First set of embeddings (e.g., updated source embeddings).\n",
        "            x2 (torch.Tensor): Second set of embeddings (e.g., original source embeddings).\n",
        "            x3 (torch.Tensor): Third set of embeddings (e.g., updated target embeddings).\n",
        "            x4 (torch.Tensor): Fourth set of embeddings (e.g., original target embeddings).\n",
        "            return_embeddings (bool): Whether to return the intermediate combined embeddings (a, b).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Probability score for binary classification if return_embeddings is False.\n",
        "            Tuple[torch.Tensor, torch.Tensor]: Intermediate embeddings (a, b) if return_embeddings is True.\n",
        "        \"\"\"\n",
        "        # Compute gating weights for the first pair of embeddings (x1, x2)\n",
        "        gate_values1 = torch.sigmoid(self.gate_A_fc(x1))\n",
        "\n",
        "        # Blend x1 and x2 using the computed gating weights\n",
        "        a = x1 * gate_values1 + x2 * (1 - gate_values1)\n",
        "\n",
        "        # Compute gating weights for the second pair of embeddings (x3, x4)\n",
        "        gate_values2 = torch.sigmoid(self.gate_B_fc(x3))\n",
        "\n",
        "        # Blend x3 and x4 using the computed gating weights\n",
        "        b = x3 * gate_values2 + x4 * (1 - gate_values2)\n",
        "\n",
        "        # If return_embeddings is True, return the intermediate blended embeddings\n",
        "        if return_embeddings:\n",
        "            return a, b\n",
        "\n",
        "        # Compute cosine similarity between the blended embeddings a and b\n",
        "        x = torch.cosine_similarity(a, b, dim=1)\n",
        "\n",
        "        # Apply a fully connected layer and sigmoid activation for classification\n",
        "        out = torch.sigmoid(self.fc(x.unsqueeze(1)))\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLJ5j9FNMVhy"
      },
      "source": [
        "# **Utility functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "k0L86DgUQjMU"
      },
      "outputs": [],
      "source": [
        "def adjacency_matrix_to_undirected_edge_index(adjacency_matrix):\n",
        "    \"\"\"\n",
        "    Converts an adjacency matrix into an undirected edge index for use in graph-based neural networks.\n",
        "\n",
        "    Args:\n",
        "        adjacency_matrix: A 2D list or array representing the adjacency matrix of a graph.\n",
        "\n",
        "    Returns:\n",
        "        edge_index_undirected: A PyTorch tensor representing the undirected edges.\n",
        "    \"\"\"\n",
        "    # Convert each element in the adjacency matrix to an integer (from boolean or float)\n",
        "    adjacency_matrix = [[int(element) for element in sublist] for sublist in adjacency_matrix]\n",
        "\n",
        "    # Convert the adjacency matrix into a PyTorch LongTensor (used for indexing)\n",
        "    edge_index = torch.tensor(adjacency_matrix, dtype=torch.long)\n",
        "\n",
        "    # Transpose the edge_index tensor so that rows represent edges in the form [source, target]\n",
        "    edge_index = edge_index.t().contiguous()\n",
        "\n",
        "    # Convert the directed edge_index into an undirected edge_index, meaning both directions are added (i.e., (i, j) and (j, i))\n",
        "    edge_index_undirected = to_undirected(edge_index)\n",
        "\n",
        "    return edge_index_undirected  # Return the undirected edge index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YvmOxkLcpf9w"
      },
      "outputs": [],
      "source": [
        "def build_indexed_dict(file_path):\n",
        "    \"\"\"\n",
        "    Builds a dictionary with numeric indexes for each key from a JSON file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): The path to the JSON file.\n",
        "\n",
        "    Returns:\n",
        "        indexed_dict (dict): A new dictionary where each key from the JSON file is assigned a numeric index.\n",
        "    \"\"\"\n",
        "    # Load the JSON file into a Python dictionary\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    # Create a new dictionary with numeric indexes as keys and the original JSON keys as values\n",
        "    indexed_dict = {index: key for index, key in enumerate(data.keys())}\n",
        "\n",
        "    return indexed_dict  # Return the newly created dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QgFINoPGl9Wg"
      },
      "outputs": [],
      "source": [
        "def select_rows_by_index(embedding_vector, index_vector):\n",
        "    \"\"\"\n",
        "    Select rows from an embedding vector using an index vector.\n",
        "\n",
        "    Args:\n",
        "        embedding_vector (torch.Tensor): 2D tensor representing the embedding vector with shape [num_rows, embedding_size].\n",
        "        index_vector (torch.Tensor): 1D tensor representing the index vector.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: New tensor with selected rows from the embedding vector.\n",
        "    \"\"\"\n",
        "    # Use torch.index_select to select the desired rows\n",
        "    new_tensor = torch.index_select(embedding_vector, 0, index_vector)\n",
        "\n",
        "    return new_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "a12L7vEmmCJq"
      },
      "outputs": [],
      "source": [
        "def contrastive_loss(source_embeddings, target_embeddings, labels, margin=1.0):\n",
        "    \"\"\"\n",
        "    Computes the contrastive loss, a type of loss function used to train models in tasks like matching or similarity learning.\n",
        "\n",
        "    Args:\n",
        "        source_embeddings (torch.Tensor): Embeddings of the source graphs, shape [batch_size, embedding_size].\n",
        "        target_embeddings (torch.Tensor): Embeddings of the target graphs, shape [batch_size, embedding_size].\n",
        "        labels (torch.Tensor): Binary labels indicating if the pairs are matched (1) or not (0), shape [batch_size].\n",
        "        margin (float): Margin value for the contrastive loss. Defaults to 1.0.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The contrastive loss value.\n",
        "    \"\"\"\n",
        "    # Calculate the pairwise Euclidean distance between source and target embeddings\n",
        "    distances = F.pairwise_distance(source_embeddings, target_embeddings)\n",
        "\n",
        "    # Compute the contrastive loss:\n",
        "    # - For matched pairs (label == 1), the loss is the squared distance between embeddings.\n",
        "    # - For non-matched pairs (label == 0), the loss is based on how far apart the embeddings are,\n",
        "    #   but penalizes them only if the distance is less than the margin.\n",
        "    loss = torch.mean(\n",
        "        labels * 0.4 * distances.pow(2) +  # For positive pairs, minimize the distance (squared)\n",
        "        (1 - labels) * 0.4 * torch.max(torch.zeros_like(distances), margin - distances).pow(2)  # For negative pairs, maximize the distance (up to the margin)\n",
        "    )\n",
        "\n",
        "    return loss  # Return the computed contrastive loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZhCizXEb7D4N"
      },
      "outputs": [],
      "source": [
        "def Prediction_with_candidates(model, X1_tt, X2_tt, X3_tt, X4_tt, src_entity_tensor_o, tgt_entity_tensor_o,\n",
        "                                   indexed_dict_src, indexed_dict_tgt, all_predictions_path):\n",
        "    \"\"\"\n",
        "    Evaluates the GatedCombination model using the given embeddings and candidate entity pairs.\n",
        "    Saves the predictions and evaluation results to a file.\n",
        "\n",
        "    Args:\n",
        "        model: Trained GatedCombination model.\n",
        "        X1_tt, X2_tt, X3_tt, X4_tt (torch.Tensor): Tensors of source and target entity embeddings (updated and original).\n",
        "        src_entity_tensor_o, tgt_entity_tensor_o (torch.Tensor): Tensors of source and target entity indices.\n",
        "        indexed_dict_src, indexed_dict_tgt (dict): Dictionaries mapping entity indices to URIs for source and target.\n",
        "        output_file (str): Path to save the predictions and results.\n",
        "        hits_at_k_values (list): List of k-values for which hits@k is evaluated.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Move the model to CPU and set it to evaluation mode\n",
        "    model = model.to(\"cpu\")\n",
        "    model.eval()\n",
        "\n",
        "    # Set batch size for evaluation\n",
        "    batch_size_test = 32\n",
        "\n",
        "    # Create a DataLoader for the evaluation data\n",
        "    test_dataset = TensorDataset(X1_tt, X2_tt, X3_tt, X4_tt)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size_test)\n",
        "\n",
        "    # Prepare for collecting predictions and results\n",
        "    predictions = []\n",
        "    results = []\n",
        "    count_predictions = 0  # Counter for predictions above threshold (0.5)\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Disable gradient computation for evaluation\n",
        "    with torch.no_grad():\n",
        "        # Iterate over batches and compute model predictions\n",
        "        for batch_X1, batch_X2, batch_X3, batch_X4 in test_dataloader:\n",
        "            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n",
        "            predictions.extend(outputs.cpu().numpy())  # Collect predictions in CPU memory\n",
        "\n",
        "    end_time = time.time()\n",
        "    predicting_time = end_time - start_time\n",
        "    print(f\"Predicting time: {predicting_time:.2f} seconds\")\n",
        "\n",
        "    # Convert tensors to lists for easier iteration\n",
        "    src_indices = src_entity_tensor_o.tolist()\n",
        "    tgt_indices = tgt_entity_tensor_o.tolist()\n",
        "\n",
        "    # Prepare results\n",
        "    for i in range(len(predictions)):\n",
        "        if predictions[i] >= 0.00:  # Consider only predictions greater than 0.5\n",
        "            count_predictions += 1  # Increment the counter\n",
        "\n",
        "            # Map the source and target entity indices to their URIs\n",
        "            src_code = src_indices[i]\n",
        "            tgt_code = tgt_indices[i]\n",
        "\n",
        "            src_uri = indexed_dict_src.get(int(src_code), \"Unknown URI\")\n",
        "            tgt_uri = indexed_dict_tgt.get(int(tgt_code), \"Unknown URI\")\n",
        "\n",
        "            # Get the model's predicted score for the current pair\n",
        "            score = predictions[i]\n",
        "\n",
        "            # Append the results (with URIs instead of entity indices)\n",
        "            results.append({\n",
        "                'SrcEntity': src_uri,\n",
        "                'TgtEntity': tgt_uri,\n",
        "                'Score': score\n",
        "            })\n",
        "\n",
        "    # Convert the results into a pandas DataFrame\n",
        "    df_results = pd.DataFrame(results)\n",
        "\n",
        "    # Save the results to a TSV file\n",
        "    df_results.to_csv(all_predictions_path, sep='\\t', index=False)\n",
        "\n",
        "    print(f\"Predictions saved to {all_predictions_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "TslUdYHBcGVj"
      },
      "outputs": [],
      "source": [
        "def filter_highest_predictions(input_file_path, output_file_path, threshold=thres):\n",
        "    # Load the all predictions file\n",
        "    df = pd.read_csv(input_file_path, sep='\\t')\n",
        "\n",
        "    # Extract the similarity score from the list in the 'Score' column\n",
        "    df['Score'] = df['Score'].apply(lambda x: float(x.strip('[]')))\n",
        "\n",
        "    # Sorting the dataframe by similarity score in descending order\n",
        "    df_sorted = df.sort_values(by='Score', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    # Initialize variables with threshold value\n",
        "    source_concepts = set(df_sorted['SrcEntity'])\n",
        "    target_concepts = set(df_sorted['TgtEntity'])\n",
        "    matched_sources = set()\n",
        "    matched_targets = set()\n",
        "    result = []\n",
        "\n",
        "    # Iterate through the sorted dataframe and find highest correspondences\n",
        "    for _, row in df_sorted.iterrows():\n",
        "        source, target, similarity = row['SrcEntity'], row['TgtEntity'], row['Score']\n",
        "\n",
        "        # Check if the source or target has already been matched and if the similarity is above the threshold\n",
        "        if source not in matched_sources and target not in matched_targets and similarity >= threshold:\n",
        "            # Add the match to the result list\n",
        "            result.append((source, target, similarity))\n",
        "            # Mark the source and target as matched\n",
        "            matched_sources.add(source)\n",
        "            matched_targets.add(target)\n",
        "\n",
        "    # Create a dataframe for the matching results with threshold applied\n",
        "    matching_results_df_threshold = pd.DataFrame(result, columns=['SrcEntity', 'TgtEntity', 'Score'])\n",
        "\n",
        "    # Save the matching results with the updated column names to a new TSV file\n",
        "    matching_results_df_threshold.to_csv(output_file_path, sep='\\t', index=False)\n",
        "\n",
        "    # Print the number of predictions saved\n",
        "    print(f\"Number of Positive Predictions : {len(matching_results_df_threshold)}\")\n",
        "\n",
        "    return matching_results_df_threshold, len(matching_results_df_threshold)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_mrr_and_hits(reference_file, predicted_file, output_file, k_values=[1, 5, 10]):\n",
        "    \"\"\"\n",
        "    Compute MRR and Hits@k for ontology matching predictions based on a reference file.\n",
        "\n",
        "    Args:\n",
        "        reference_file (str): Path to the reference file (test.cands.tsv format).\n",
        "        predicted_file (str): Path to the predictions file with scores.\n",
        "        output_file (str): Path to save the scored results.\n",
        "        k_values (list): List of k values for Hits@k.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing MRR and Hits@k metrics.\n",
        "    \"\"\"\n",
        "    # Read the reference mappings\n",
        "    test_candidate_mappings = read_table(reference_file).values.tolist()\n",
        "    ranking_results = []\n",
        "\n",
        "    # Read the predicted scores\n",
        "    predicted_data = pd.read_csv(predicted_file, sep=\"\\t\")\n",
        "    predicted_data[\"Score\"] = predicted_data[\"Score\"].apply(lambda x: float(x.strip(\"[]\")))\n",
        "\n",
        "    # Create a lookup dictionary for predicted scores\n",
        "    score_lookup = {}\n",
        "    for _, row in predicted_data.iterrows():\n",
        "        score_lookup[(row[\"SrcEntity\"], row[\"TgtEntity\"])] = row[\"Score\"]\n",
        "\n",
        "    for src_ref_class, tgt_ref_class, tgt_cands in test_candidate_mappings:\n",
        "        tgt_cands = eval(tgt_cands)  # Convert string to list of candidates\n",
        "        scored_cands = []\n",
        "        for tgt_cand in tgt_cands:\n",
        "            # Retrieve score for each candidate, defaulting to a very low score if not found\n",
        "            matching_score = score_lookup.get((src_ref_class, tgt_cand), -1e9)\n",
        "            scored_cands.append((tgt_cand, matching_score))\n",
        "\n",
        "        # Sort candidates by score in descending order\n",
        "        scored_cands = sorted(scored_cands, key=lambda x: x[1], reverse=True)\n",
        "        ranking_results.append((src_ref_class, tgt_ref_class, scored_cands))\n",
        "\n",
        "    # Save the ranked results to a file\n",
        "    pd.DataFrame(ranking_results, columns=[\"SrcEntity\", \"TgtEntity\", \"TgtCandidates\"]).to_csv(output_file, sep=\"\\t\", index=False)\n",
        "\n",
        "    # Compute MRR and Hits@k\n",
        "    total_entities = len(ranking_results)\n",
        "    reciprocal_ranks = []\n",
        "    hits_at_k = {k: 0 for k in k_values}\n",
        "\n",
        "    for src_entity, tgt_ref_class, tgt_cands in ranking_results:\n",
        "        ranked_candidates = [candidate[0] for candidate in tgt_cands]\n",
        "        if tgt_ref_class in ranked_candidates:\n",
        "            rank = ranked_candidates.index(tgt_ref_class) + 1\n",
        "            reciprocal_ranks.append(1 / rank)\n",
        "            for k in k_values:\n",
        "                if rank <= k:\n",
        "                    hits_at_k[k] += 1\n",
        "        else:\n",
        "            reciprocal_ranks.append(0)\n",
        "\n",
        "    mrr = sum(reciprocal_ranks) / total_entities\n",
        "    hits_at_k = {k: hits / total_entities for k, hits in hits_at_k.items()}\n",
        "\n",
        "    return {\"MRR\": mrr, \"Hits@k\": hits_at_k}"
      ],
      "metadata": {
        "id": "_ggVYlTiO_WA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HyWMsw1MVhz"
      },
      "source": [
        "# **Main Code**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC37FlwGDqGM"
      },
      "source": [
        "\n",
        "\n",
        "# Reading semantic node embeddings provided by the ENE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "FuEfSnw5mod0"
      },
      "outputs": [],
      "source": [
        "# Read the source embeddings from a CSV file into a pandas DataFrame\n",
        "df_embbedings_src = pd.read_csv(src_Emb, index_col=0)\n",
        "\n",
        "# Convert the DataFrame to a NumPy array, which will remove the index and store the data as a raw matrix\n",
        "numpy_array = df_embbedings_src.to_numpy()\n",
        "\n",
        "# Convert the NumPy array into a PyTorch FloatTensor, which is the format required for PyTorch operations\n",
        "x_src = torch.FloatTensor(numpy_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "STUwqMUXmlG2"
      },
      "outputs": [],
      "source": [
        "# Read the target embeddings from a CSV file into a pandas DataFrame\n",
        "df_embbedings_tgt = pd.read_csv(tgt_Emb, index_col=0)\n",
        "\n",
        "# Convert the DataFrame to a NumPy array, which removes the index and converts the data to a raw matrix\n",
        "numpy_array = df_embbedings_tgt.to_numpy()\n",
        "\n",
        "# Convert the NumPy array into a PyTorch FloatTensor, which is required for PyTorch operations\n",
        "x_tgt = torch.FloatTensor(numpy_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZIu9P08DqGN"
      },
      "source": [
        "# Reading adjacency Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "pH69Up40mycz"
      },
      "outputs": [],
      "source": [
        "# Read the source adjacency matrix from a CSV file into a pandas DataFrame\n",
        "df_ma1 = pd.read_csv(src_Adjacence, index_col=0)\n",
        "\n",
        "# Convert the DataFrame to a list of lists (Python native list format)\n",
        "ma1 = df_ma1.values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hYCmAO5Ymzpl"
      },
      "outputs": [],
      "source": [
        "# Read the target adjacency matrix from a CSV file into a pandas DataFrame\n",
        "df_ma2 = pd.read_csv(tgt_Adjacence, index_col=0)\n",
        "\n",
        "# Convert the DataFrame to a list of lists (Python native list format)\n",
        "ma2 = df_ma2.values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSyksqh3TrU-"
      },
      "source": [
        "# Convert Adjacency matrix (in list format) to an undirected edge index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "uVt-Pce5m5ll"
      },
      "outputs": [],
      "source": [
        "# Convert the source adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n",
        "edge_src = adjacency_matrix_to_undirected_edge_index(ma1)\n",
        "\n",
        "# Convert the target adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n",
        "edge_tgt = adjacency_matrix_to_undirected_edge_index(ma2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9wMTRdqT4aY"
      },
      "source": [
        "# GIT Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "eqiEKCLSMVh3"
      },
      "outputs": [],
      "source": [
        "def train_model_gnn(model, x_src, edge_src, x_tgt, edge_tgt,\n",
        "                    tensor_term1, tensor_term2, tensor_score,\n",
        "                    learning_rate, weight_decay_value, num_epochs, print_interval=10):\n",
        "    \"\"\"\n",
        "    Trains a graph neural network (GNN) model using source and target embeddings and contrastive loss.\n",
        "\n",
        "    Args:\n",
        "        model: The GNN model to be trained.\n",
        "        x_src (torch.Tensor): Source node embeddings.\n",
        "        edge_src (torch.Tensor): Source graph edges.\n",
        "        x_tgt (torch.Tensor): Target node embeddings.\n",
        "        edge_tgt (torch.Tensor): Target graph edges.\n",
        "        tensor_term1 (torch.Tensor): Indices of the source nodes to be compared.\n",
        "        tensor_term2 (torch.Tensor): Indices of the target nodes to be compared.\n",
        "        tensor_score (torch.Tensor): Labels indicating if the pairs are matched (1) or not (0).\n",
        "        learning_rate (float): Learning rate for the optimizer.\n",
        "        weight_decay_value (float): Weight decay (L2 regularization) value for the optimizer.\n",
        "        num_epochs (int): Number of epochs for training.\n",
        "        print_interval (int): Interval at which training progress is printed (every `print_interval` epochs).\n",
        "\n",
        "    Returns:\n",
        "        model: The trained GNN model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 1: Set device (GPU or CPU) for computation\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Step 2: Move the model and all inputs to the selected device\n",
        "    model.to(device)\n",
        "    x_tgt = x_tgt.to(device)               # Target node embeddings\n",
        "    edge_tgt = edge_tgt.to(device)         # Target graph edges\n",
        "    x_src = x_src.to(device)               # Source node embeddings\n",
        "    edge_src = edge_src.to(device)         # Source graph edges\n",
        "    tensor_term1 = tensor_term1.to(device) # Indices for source nodes\n",
        "    tensor_term2 = tensor_term2.to(device) # Indices for target nodes\n",
        "    tensor_score = tensor_score.to(device) # Ground truth labels\n",
        "\n",
        "    # Step 3: Define optimizer with learning rate and regularization\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay_value)\n",
        "\n",
        "    # Step 4: Initialize list to store training losses\n",
        "    train_losses = []\n",
        "\n",
        "    # Record the start time of training\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Step 5: Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        # Zero out gradients from the previous iteration\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass: Compute embeddings for source and target graphs\n",
        "        out1 = model(x_src, edge_src)  # Updated source embeddings\n",
        "        out2 = model(x_tgt, edge_tgt)  # Updated target embeddings\n",
        "\n",
        "        # Extract specific rows of embeddings for terms being compared\n",
        "        src_embeddings = select_rows_by_index(out1, tensor_term1)\n",
        "        tgt_embeddings = select_rows_by_index(out2, tensor_term2)\n",
        "\n",
        "        # Compute contrastive loss based on the embeddings and ground truth labels\n",
        "        loss = contrastive_loss(src_embeddings, tgt_embeddings, tensor_score)\n",
        "\n",
        "        # Backward pass: Compute gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the model's parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Append the loss for this iteration to the list\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        # Print loss every `print_interval` epochs\n",
        "        if (epoch + 1) % print_interval == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item()}\")\n",
        "\n",
        "    # Step 6: Record end time of training\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Step 7: Plot the training loss over time\n",
        "    plt.semilogy(range(1, num_epochs + 1), train_losses, label=\"Training Loss\", marker='o')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Print the total training time\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training complete! Total training time: {training_time:.2f} seconds\")\n",
        "\n",
        "    # Step 8: Return the trained model\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "6_tzUG_emtBg"
      },
      "outputs": [],
      "source": [
        "# Initialize the GIT_mod model with the dimensionality of the target embeddings\n",
        "# The first argument is the dimensionality of the target node embeddings (x_tgt.shape[1])\n",
        "# The second argument (1) represents the number of RGIT layers in the model\n",
        "GIT_model = RGIT_mod(x_tgt.shape[1], 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wVo-s7UQssSp"
      },
      "outputs": [],
      "source": [
        "# Reading the training pairs from a CSV file into a pandas DataFrame\n",
        "df_embbedings = pd.read_csv(train_file, index_col=0)\n",
        "\n",
        "# Extract the 'SrcEntity' and 'TgtEntity' columns as NumPy arrays and convert them to integers\n",
        "tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)  # Source entity indices\n",
        "tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)  # Target entity indices\n",
        "\n",
        "# Extract the 'Score' column as a NumPy array and convert it to floats\n",
        "tensor_score = df_embbedings['Score'].values.astype(float)  # Scores (labels) indicating if pairs match (1) or not (0)\n",
        "\n",
        "# Convert the NumPy arrays to PyTorch LongTensors (for indices) and FloatTensors (for scores)\n",
        "tensor_term1_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)  # Source entity tensor\n",
        "tensor_term2_o = torch.from_numpy(tensor_term2).type(torch.LongTensor)  # Target entity tensor\n",
        "tensor_score_o = torch.from_numpy(tensor_score).type(torch.FloatTensor)  # Score tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "agHlFNesMVh3",
        "outputId": "d3cff05b-44fe-4a28-a993-fe18e3ff8c4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/1000], Training Loss: 0.001578646246343851\n",
            "Epoch [20/1000], Training Loss: 0.0013451318955048919\n",
            "Epoch [30/1000], Training Loss: 0.0012061356101185083\n",
            "Epoch [40/1000], Training Loss: 0.0011092904023826122\n",
            "Epoch [50/1000], Training Loss: 0.0010336419800296426\n",
            "Epoch [60/1000], Training Loss: 0.0009696094784885645\n",
            "Epoch [70/1000], Training Loss: 0.0009141432819887996\n",
            "Epoch [80/1000], Training Loss: 0.0008658556034788489\n",
            "Epoch [90/1000], Training Loss: 0.0008230470702983439\n",
            "Epoch [100/1000], Training Loss: 0.0007851108093746006\n",
            "Epoch [110/1000], Training Loss: 0.000752110849134624\n",
            "Epoch [120/1000], Training Loss: 0.0007234028307721019\n",
            "Epoch [130/1000], Training Loss: 0.0006987069500610232\n",
            "Epoch [140/1000], Training Loss: 0.0006768821040168405\n",
            "Epoch [150/1000], Training Loss: 0.0006580326589755714\n",
            "Epoch [160/1000], Training Loss: 0.0006416992982849479\n",
            "Epoch [170/1000], Training Loss: 0.0006274674669839442\n",
            "Epoch [180/1000], Training Loss: 0.0006151231937110424\n",
            "Epoch [190/1000], Training Loss: 0.0006043909816071391\n",
            "Epoch [200/1000], Training Loss: 0.000595020828768611\n",
            "Epoch [210/1000], Training Loss: 0.0005869049928151071\n",
            "Epoch [220/1000], Training Loss: 0.000579836661927402\n",
            "Epoch [230/1000], Training Loss: 0.0005735483136959374\n",
            "Epoch [240/1000], Training Loss: 0.000568097282666713\n",
            "Epoch [250/1000], Training Loss: 0.0005633042892441154\n",
            "Epoch [260/1000], Training Loss: 0.0005590505315922201\n",
            "Epoch [270/1000], Training Loss: 0.000555307196918875\n",
            "Epoch [280/1000], Training Loss: 0.0005518848192878067\n",
            "Epoch [290/1000], Training Loss: 0.0005488900933414698\n",
            "Epoch [300/1000], Training Loss: 0.000546238967217505\n",
            "Epoch [310/1000], Training Loss: 0.0005438884254544973\n",
            "Epoch [320/1000], Training Loss: 0.0005417790380306542\n",
            "Epoch [330/1000], Training Loss: 0.0005398887442424893\n",
            "Epoch [340/1000], Training Loss: 0.0005382020608521998\n",
            "Epoch [350/1000], Training Loss: 0.0005366486147977412\n",
            "Epoch [360/1000], Training Loss: 0.000535168161150068\n",
            "Epoch [370/1000], Training Loss: 0.0005338095361366868\n",
            "Epoch [380/1000], Training Loss: 0.0005325233214534819\n",
            "Epoch [390/1000], Training Loss: 0.0005313075380399823\n",
            "Epoch [400/1000], Training Loss: 0.0005301093915477395\n",
            "Epoch [410/1000], Training Loss: 0.0005288896500132978\n",
            "Epoch [420/1000], Training Loss: 0.0005276823067106307\n",
            "Epoch [430/1000], Training Loss: 0.0005265036597847939\n",
            "Epoch [440/1000], Training Loss: 0.0005253779236227274\n",
            "Epoch [450/1000], Training Loss: 0.0005242974148131907\n",
            "Epoch [460/1000], Training Loss: 0.0005232758121564984\n",
            "Epoch [470/1000], Training Loss: 0.0005223060143180192\n",
            "Epoch [480/1000], Training Loss: 0.000521367066539824\n",
            "Epoch [490/1000], Training Loss: 0.0005204631597734988\n",
            "Epoch [500/1000], Training Loss: 0.0005195731064304709\n",
            "Epoch [510/1000], Training Loss: 0.0005187068600207567\n",
            "Epoch [520/1000], Training Loss: 0.0005178023129701614\n",
            "Epoch [530/1000], Training Loss: 0.0005168353673070669\n",
            "Epoch [540/1000], Training Loss: 0.0005158473504707217\n",
            "Epoch [550/1000], Training Loss: 0.0005148374475538731\n",
            "Epoch [560/1000], Training Loss: 0.0005138287087902427\n",
            "Epoch [570/1000], Training Loss: 0.0005128247430548072\n",
            "Epoch [580/1000], Training Loss: 0.0005118288099765778\n",
            "Epoch [590/1000], Training Loss: 0.0005108605255372822\n",
            "Epoch [600/1000], Training Loss: 0.0005099074332974851\n",
            "Epoch [610/1000], Training Loss: 0.0005089770420454443\n",
            "Epoch [620/1000], Training Loss: 0.000508069759234786\n",
            "Epoch [630/1000], Training Loss: 0.0005071860505267978\n",
            "Epoch [640/1000], Training Loss: 0.0005063259159214795\n",
            "Epoch [650/1000], Training Loss: 0.000505486037582159\n",
            "Epoch [660/1000], Training Loss: 0.0005046726437285542\n",
            "Epoch [670/1000], Training Loss: 0.0005038755480200052\n",
            "Epoch [680/1000], Training Loss: 0.0005030921311117709\n",
            "Epoch [690/1000], Training Loss: 0.0005023389239795506\n",
            "Epoch [700/1000], Training Loss: 0.000501614180393517\n",
            "Epoch [710/1000], Training Loss: 0.000500920694321394\n",
            "Epoch [720/1000], Training Loss: 0.0005002362304367125\n",
            "Epoch [730/1000], Training Loss: 0.0004995408235117793\n",
            "Epoch [740/1000], Training Loss: 0.0004988113651052117\n",
            "Epoch [750/1000], Training Loss: 0.0004980124649591744\n",
            "Epoch [760/1000], Training Loss: 0.0004971544840373099\n",
            "Epoch [770/1000], Training Loss: 0.0004962333478033543\n",
            "Epoch [780/1000], Training Loss: 0.000495291780680418\n",
            "Epoch [790/1000], Training Loss: 0.0004943536478094757\n",
            "Epoch [800/1000], Training Loss: 0.0004934279131703079\n",
            "Epoch [810/1000], Training Loss: 0.0004925132379867136\n",
            "Epoch [820/1000], Training Loss: 0.0004916395409964025\n",
            "Epoch [830/1000], Training Loss: 0.0004907806287519634\n",
            "Epoch [840/1000], Training Loss: 0.0004899309715256095\n",
            "Epoch [860/1000], Training Loss: 0.0004882881767116487\n",
            "Epoch [870/1000], Training Loss: 0.00048749003326520324\n",
            "Epoch [880/1000], Training Loss: 0.00048671039985492826\n",
            "Epoch [890/1000], Training Loss: 0.0004859358596149832\n",
            "Epoch [900/1000], Training Loss: 0.000485181255498901\n",
            "Epoch [910/1000], Training Loss: 0.0004844560753554106\n",
            "Epoch [920/1000], Training Loss: 0.0004837082524318248\n",
            "Epoch [930/1000], Training Loss: 0.00048297824105247855\n",
            "Epoch [940/1000], Training Loss: 0.0004822794580832124\n",
            "Epoch [950/1000], Training Loss: 0.00048158044228330255\n",
            "Epoch [960/1000], Training Loss: 0.00048090709606185555\n",
            "Epoch [970/1000], Training Loss: 0.00048023462295532227\n",
            "Epoch [980/1000], Training Loss: 0.00047957885544747114\n",
            "Epoch [990/1000], Training Loss: 0.0004789187223650515\n",
            "Epoch [1000/1000], Training Loss: 0.00047827744856476784\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete! Total training time: 1715.46 seconds\n"
          ]
        }
      ],
      "source": [
        "# Train the GNN model using the provided source and target graph embeddings, edges, and training data\n",
        "trained_model = train_model_gnn(\n",
        "    model=GIT_model,                # The GNN model to be trained (initialized earlier)\n",
        "    x_src=x_src,                    # Source node embeddings (tensor for source graph)\n",
        "    edge_src=edge_src,              # Source graph edges (undirected edge index for source graph)\n",
        "    x_tgt=x_tgt,                    # Target node embeddings (tensor for target graph)\n",
        "    edge_tgt=edge_tgt,              # Target graph edges (undirected edge index for target graph)\n",
        "    tensor_term1=tensor_term1_o,    # Indices of source entities for training\n",
        "    tensor_term2=tensor_term2_o,    # Indices of target entities for training\n",
        "    tensor_score=tensor_score_o,    # Scores (labels) indicating if pairs match (1) or not (0)\n",
        "    learning_rate=0.0001,            # Learning rate for the Adam optimizer\n",
        "    weight_decay_value=1e-4,        # Weight decay for L2 regularization to prevent overfitting\n",
        "    num_epochs=1000,                # Number of training epochs\n",
        "    print_interval=10               # Interval at which to print training progress (every 10 epochs)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYyhvjcTUaae"
      },
      "source": [
        "# GIT Application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "BZ_VqP6tq6iD"
      },
      "outputs": [],
      "source": [
        "# Determine if a GPU is available and move the computations to it; otherwise, use the CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Assuming the model has been trained and hyperparameters (x_src, edge_src, x_tgt, edge_tgt) are set\n",
        "\n",
        "# Move the trained GIT_model to the device (GPU or CPU)\n",
        "GIT_model.to(device)\n",
        "\n",
        "# Move the data tensors to the same device (GPU or CPU)\n",
        "x_tgt = x_tgt.to(device)         # Target node embeddings\n",
        "edge_tgt = edge_tgt.to(device)   # Target graph edges\n",
        "x_src = x_src.to(device)         # Source node embeddings\n",
        "edge_src = edge_src.to(device)   # Source graph edges\n",
        "\n",
        "# Set the model to evaluation mode; this disables dropout and batch normalization\n",
        "GIT_model.eval()\n",
        "\n",
        "# Pass the source and target embeddings through the trained GNN model to update the embeddings\n",
        "with torch.no_grad():  # Disable gradient computation (inference mode)\n",
        "    embeddings_tgt = GIT_model(x_tgt, edge_tgt)  # Get updated embeddings for the target graph\n",
        "    embeddings_src = GIT_model(x_src, edge_src)  # Get updated embeddings for the source graph\n",
        "\n",
        "# Detach the embeddings from the computation graph and move them back to the CPU\n",
        "# This step is useful if you need to use the embeddings for tasks outside PyTorch (e.g., saving to disk)\n",
        "embeddings_tgt = embeddings_tgt.detach().cpu()  # Target graph embeddings\n",
        "embeddings_src = embeddings_src.detach().cpu()  # Source graph embeddings\n",
        "\n",
        "# At this point, embeddings_tgt and embeddings_src contain the updated embeddings, ready for downstream tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og5fdoGJrTCG"
      },
      "source": [
        "# Selecting embedding pairs to train the Gated Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "J0nTwc-dnjLn"
      },
      "outputs": [],
      "source": [
        "# Read the training pairs from a CSV file into a pandas DataFrame\n",
        "df_embeddings = pd.read_csv(train_file, index_col=0)\n",
        "\n",
        "# Extract columns and convert to NumPy arrays\n",
        "tensor_term1 = df_embeddings['SrcEntity'].values.astype(int)  # Source entity indices\n",
        "tensor_term2 = df_embeddings['TgtEntity'].values.astype(int)  # Target entity indices\n",
        "tensor_score = df_embeddings['Score'].values.astype(float)  # Matching scores\n",
        "\n",
        "# Split data into training and validation sets\n",
        "tensor_term1_train, tensor_term1_val, tensor_term2_train, tensor_term2_val, tensor_score_train, tensor_score_val = train_test_split(\n",
        "    tensor_term1, tensor_term2, tensor_score, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Convert split data to PyTorch tensors\n",
        "tensor_term1_train = torch.from_numpy(tensor_term1_train).type(torch.LongTensor)\n",
        "tensor_term2_train = torch.from_numpy(tensor_term2_train).type(torch.LongTensor)\n",
        "tensor_score_train = torch.from_numpy(tensor_score_train).type(torch.FloatTensor)\n",
        "\n",
        "tensor_term1_val = torch.from_numpy(tensor_term1_val).type(torch.LongTensor)\n",
        "tensor_term2_val = torch.from_numpy(tensor_term2_val).type(torch.LongTensor)\n",
        "tensor_score_val = torch.from_numpy(tensor_score_val).type(torch.FloatTensor)\n",
        "\n",
        "# Move the embeddings back to the CPU if not already there\n",
        "x_tgt = x_tgt.cpu()  # Target node embeddings\n",
        "x_src = x_src.cpu()  # Source node embeddings\n",
        "\n",
        "# Select embeddings for the training set\n",
        "X1_train = select_rows_by_index(embeddings_src, tensor_term1_train)\n",
        "X2_train = select_rows_by_index(x_src, tensor_term1_train)\n",
        "X3_train = select_rows_by_index(embeddings_tgt, tensor_term2_train)\n",
        "X4_train = select_rows_by_index(x_tgt, tensor_term2_train)\n",
        "\n",
        "# Select embeddings for the validation set\n",
        "X1_val = select_rows_by_index(embeddings_src, tensor_term1_val)\n",
        "X2_val = select_rows_by_index(x_src, tensor_term1_val)\n",
        "X3_val = select_rows_by_index(embeddings_tgt, tensor_term2_val)\n",
        "X4_val = select_rows_by_index(x_tgt, tensor_term2_val)\n",
        "\n",
        "# Now you have:\n",
        "# - Training tensors: X1_train, X2_train, X3_train, X4_train, tensor_score_train\n",
        "# - Validation tensors: X1_val, X2_val, X3_val, X4_val, tensor_score_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNdCgaTMExPK"
      },
      "source": [
        "# Gated Network Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Gof1eIPIWSVU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def train_gated_combination_model(X1_t, X2_t, X3_t, X4_t, tensor_score_o,\n",
        "                                  X1_val, X2_val, X3_val, X4_val, tensor_score_val,\n",
        "                                  epochs=120, batch_size=32, learning_rate=0.001, weight_decay=1e-5):\n",
        "    \"\"\"\n",
        "    Trains the GatedCombination model with training and validation data, using ReduceLROnPlateau scheduler.\n",
        "    Also calculates and displays F1-score during training and validation.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create datasets and DataLoaders\n",
        "    train_dataset = TensorDataset(X1_t, X2_t, X3_t, X4_t, tensor_score_o)\n",
        "    val_dataset = TensorDataset(X1_val, X2_val, X3_val, X4_val, tensor_score_val)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = GatedCombination(X1_t.shape[1]).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # Use ReduceLROnPlateau scheduler\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_train_loss = 0.0\n",
        "        y_true_train, y_pred_train = [], []\n",
        "\n",
        "        for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in train_loader:\n",
        "            batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (\n",
        "                batch_X1.to(device),\n",
        "                batch_X2.to(device),\n",
        "                batch_X3.to(device),\n",
        "                batch_X4.to(device),\n",
        "                batch_y.to(device),\n",
        "            )\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = F.binary_cross_entropy(outputs, batch_y.unsqueeze(1).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # Store true labels and predictions for F1-score\n",
        "            y_true_train.extend(batch_y.cpu().numpy())\n",
        "            y_pred_train.extend((outputs > 0.5).float().cpu().numpy())\n",
        "\n",
        "        train_loss = total_train_loss / len(train_loader)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # Calculate F1-score for training\n",
        "        train_f1 = f1_score(y_true_train, y_pred_train)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        total_val_loss = 0.0\n",
        "        y_true_val, y_pred_val = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in val_loader:\n",
        "                batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (\n",
        "                    batch_X1.to(device),\n",
        "                    batch_X2.to(device),\n",
        "                    batch_X3.to(device),\n",
        "                    batch_X4.to(device),\n",
        "                    batch_y.to(device),\n",
        "                )\n",
        "                outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n",
        "\n",
        "                # Compute loss\n",
        "                val_loss = F.binary_cross_entropy(outputs, batch_y.unsqueeze(1).float())\n",
        "                total_val_loss += val_loss.item()\n",
        "\n",
        "                # Store true labels and predictions for F1-score\n",
        "                y_true_val.extend(batch_y.cpu().numpy())\n",
        "                y_pred_val.extend((outputs > 0.5).float().cpu().numpy())\n",
        "\n",
        "        avg_val_loss = total_val_loss / len(val_loader)\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        # Calculate F1-score for validation\n",
        "        val_f1 = f1_score(y_true_val, y_pred_val)\n",
        "\n",
        "        # Step the scheduler with validation loss\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        # Print training and validation metrics\n",
        "        print(f\"Epoch [{epoch + 1}/{epochs}] Training Loss: {train_loss:.4f}, F1 Score: {train_f1:.4f} | \"\n",
        "              f\"Validation Loss: {avg_val_loss:.4f}, F1 Score: {val_f1:.4f}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Plotting training and validation loss\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label=\"Training Loss\", marker='o')\n",
        "    plt.plot(val_losses, label=\"Validation Loss\", marker='x')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Training complete! Total time: {end_time - start_time:.2f} seconds\")\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l11dgb8ei69T",
        "outputId": "2e2ffa22-e66e-47b8-ca86-b1e3d6499c3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100] Training Loss: 0.1289, F1 Score: 0.0000 | Validation Loss: 0.0675, F1 Score: 0.0000\n",
            "Epoch [2/100] Training Loss: 0.0633, F1 Score: 0.0000 | Validation Loss: 0.0634, F1 Score: 0.0000\n",
            "Epoch [3/100] Training Loss: 0.0615, F1 Score: 0.0000 | Validation Loss: 0.0621, F1 Score: 0.0000\n",
            "Epoch [4/100] Training Loss: 0.0603, F1 Score: 0.0000 | Validation Loss: 0.0609, F1 Score: 0.0000\n",
            "Epoch [5/100] Training Loss: 0.0590, F1 Score: 0.0000 | Validation Loss: 0.0595, F1 Score: 0.0000\n",
            "Epoch [6/100] Training Loss: 0.0575, F1 Score: 0.0000 | Validation Loss: 0.0580, F1 Score: 0.0000\n",
            "Epoch [7/100] Training Loss: 0.0558, F1 Score: 0.0000 | Validation Loss: 0.0547, F1 Score: 0.0000\n",
            "Epoch [8/100] Training Loss: 0.0492, F1 Score: 0.0000 | Validation Loss: 0.0459, F1 Score: 0.0000\n",
            "Epoch [9/100] Training Loss: 0.0406, F1 Score: 0.0000 | Validation Loss: 0.0374, F1 Score: 0.0000\n",
            "Epoch [10/100] Training Loss: 0.0327, F1 Score: 0.0000 | Validation Loss: 0.0299, F1 Score: 0.0000\n",
            "Epoch [11/100] Training Loss: 0.0263, F1 Score: 0.0000 | Validation Loss: 0.0241, F1 Score: 0.0000\n",
            "Epoch [12/100] Training Loss: 0.0213, F1 Score: 0.3015 | Validation Loss: 0.0198, F1 Score: 0.4873\n",
            "Epoch [13/100] Training Loss: 0.0176, F1 Score: 0.5834 | Validation Loss: 0.0169, F1 Score: 0.6308\n",
            "Epoch [14/100] Training Loss: 0.0151, F1 Score: 0.6822 | Validation Loss: 0.0146, F1 Score: 0.7037\n",
            "Epoch [15/100] Training Loss: 0.0134, F1 Score: 0.7424 | Validation Loss: 0.0134, F1 Score: 0.7424\n",
            "Epoch [16/100] Training Loss: 0.0123, F1 Score: 0.7736 | Validation Loss: 0.0124, F1 Score: 0.7750\n",
            "Epoch [17/100] Training Loss: 0.0115, F1 Score: 0.7972 | Validation Loss: 0.0117, F1 Score: 0.7933\n",
            "Epoch [18/100] Training Loss: 0.0110, F1 Score: 0.8125 | Validation Loss: 0.0112, F1 Score: 0.8075\n",
            "Epoch [19/100] Training Loss: 0.0106, F1 Score: 0.8234 | Validation Loss: 0.0108, F1 Score: 0.8145\n",
            "Epoch [20/100] Training Loss: 0.0103, F1 Score: 0.8307 | Validation Loss: 0.0107, F1 Score: 0.8222\n",
            "Epoch [21/100] Training Loss: 0.0101, F1 Score: 0.8352 | Validation Loss: 0.0104, F1 Score: 0.8235\n",
            "Epoch [22/100] Training Loss: 0.0099, F1 Score: 0.8418 | Validation Loss: 0.0103, F1 Score: 0.8184\n",
            "Epoch [23/100] Training Loss: 0.0098, F1 Score: 0.8413 | Validation Loss: 0.0103, F1 Score: 0.8210\n",
            "Epoch [24/100] Training Loss: 0.0097, F1 Score: 0.8418 | Validation Loss: 0.0102, F1 Score: 0.8274\n",
            "Epoch [25/100] Training Loss: 0.0097, F1 Score: 0.8374 | Validation Loss: 0.0102, F1 Score: 0.8362\n",
            "Epoch [26/100] Training Loss: 0.0096, F1 Score: 0.8495 | Validation Loss: 0.0101, F1 Score: 0.8286\n",
            "Epoch [27/100] Training Loss: 0.0096, F1 Score: 0.8484 | Validation Loss: 0.0101, F1 Score: 0.8337\n",
            "Epoch [28/100] Training Loss: 0.0096, F1 Score: 0.8478 | Validation Loss: 0.0100, F1 Score: 0.8299\n",
            "Epoch [29/100] Training Loss: 0.0095, F1 Score: 0.8456 | Validation Loss: 0.0101, F1 Score: 0.8337\n",
            "Epoch [30/100] Training Loss: 0.0095, F1 Score: 0.8456 | Validation Loss: 0.0101, F1 Score: 0.8324\n",
            "Epoch [31/100] Training Loss: 0.0095, F1 Score: 0.8495 | Validation Loss: 0.0100, F1 Score: 0.8378\n",
            "Epoch [32/100] Training Loss: 0.0095, F1 Score: 0.8500 | Validation Loss: 0.0103, F1 Score: 0.8424\n",
            "Epoch [33/100] Training Loss: 0.0095, F1 Score: 0.8478 | Validation Loss: 0.0100, F1 Score: 0.8350\n",
            "Epoch [34/100] Training Loss: 0.0095, F1 Score: 0.8495 | Validation Loss: 0.0102, F1 Score: 0.8324\n",
            "Epoch [35/100] Training Loss: 0.0095, F1 Score: 0.8500 | Validation Loss: 0.0099, F1 Score: 0.8324\n",
            "Epoch [36/100] Training Loss: 0.0095, F1 Score: 0.8511 | Validation Loss: 0.0100, F1 Score: 0.8312\n",
            "Epoch [37/100] Training Loss: 0.0095, F1 Score: 0.8456 | Validation Loss: 0.0099, F1 Score: 0.8337\n",
            "Epoch [38/100] Training Loss: 0.0095, F1 Score: 0.8495 | Validation Loss: 0.0100, F1 Score: 0.8337\n",
            "Epoch [39/100] Training Loss: 0.0095, F1 Score: 0.8511 | Validation Loss: 0.0100, F1 Score: 0.8412\n",
            "Epoch [40/100] Training Loss: 0.0095, F1 Score: 0.8495 | Validation Loss: 0.0102, F1 Score: 0.8366\n",
            "Epoch [41/100] Training Loss: 0.0095, F1 Score: 0.8538 | Validation Loss: 0.0100, F1 Score: 0.8274\n",
            "Epoch [42/100] Training Loss: 0.0095, F1 Score: 0.8478 | Validation Loss: 0.0100, F1 Score: 0.8328\n",
            "Epoch [43/100] Training Loss: 0.0095, F1 Score: 0.8484 | Validation Loss: 0.0101, F1 Score: 0.8415\n",
            "Epoch [44/100] Training Loss: 0.0095, F1 Score: 0.8505 | Validation Loss: 0.0100, F1 Score: 0.8299\n",
            "Epoch [45/100] Training Loss: 0.0095, F1 Score: 0.8489 | Validation Loss: 0.0101, F1 Score: 0.8350\n",
            "Epoch [46/100] Training Loss: 0.0095, F1 Score: 0.8495 | Validation Loss: 0.0100, F1 Score: 0.8337\n",
            "Epoch [47/100] Training Loss: 0.0095, F1 Score: 0.8516 | Validation Loss: 0.0100, F1 Score: 0.8286\n",
            "Epoch 00048: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch [48/100] Training Loss: 0.0095, F1 Score: 0.8484 | Validation Loss: 0.0100, F1 Score: 0.8328\n",
            "Epoch [49/100] Training Loss: 0.0094, F1 Score: 0.8554 | Validation Loss: 0.0099, F1 Score: 0.8391\n",
            "Epoch [50/100] Training Loss: 0.0094, F1 Score: 0.8554 | Validation Loss: 0.0099, F1 Score: 0.8403\n",
            "Epoch [51/100] Training Loss: 0.0094, F1 Score: 0.8559 | Validation Loss: 0.0099, F1 Score: 0.8378\n",
            "Epoch [52/100] Training Loss: 0.0094, F1 Score: 0.8532 | Validation Loss: 0.0099, F1 Score: 0.8341\n",
            "Epoch [53/100] Training Loss: 0.0094, F1 Score: 0.8538 | Validation Loss: 0.0099, F1 Score: 0.8362\n",
            "Epoch [54/100] Training Loss: 0.0094, F1 Score: 0.8549 | Validation Loss: 0.0099, F1 Score: 0.8328\n",
            "Epoch [55/100] Training Loss: 0.0094, F1 Score: 0.8522 | Validation Loss: 0.0100, F1 Score: 0.8328\n",
            "Epoch [56/100] Training Loss: 0.0094, F1 Score: 0.8505 | Validation Loss: 0.0099, F1 Score: 0.8362\n",
            "Epoch [57/100] Training Loss: 0.0094, F1 Score: 0.8527 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [58/100] Training Loss: 0.0094, F1 Score: 0.8532 | Validation Loss: 0.0100, F1 Score: 0.8375\n",
            "Epoch 00059: reducing learning rate of group 0 to 1.0000e-05.\n",
            "Epoch [59/100] Training Loss: 0.0094, F1 Score: 0.8538 | Validation Loss: 0.0100, F1 Score: 0.8362\n",
            "Epoch [60/100] Training Loss: 0.0094, F1 Score: 0.8538 | Validation Loss: 0.0099, F1 Score: 0.8337\n",
            "Epoch [61/100] Training Loss: 0.0093, F1 Score: 0.8532 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [62/100] Training Loss: 0.0093, F1 Score: 0.8532 | Validation Loss: 0.0099, F1 Score: 0.8337\n",
            "Epoch [63/100] Training Loss: 0.0093, F1 Score: 0.8532 | Validation Loss: 0.0099, F1 Score: 0.8337\n",
            "Epoch [64/100] Training Loss: 0.0093, F1 Score: 0.8527 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [65/100] Training Loss: 0.0093, F1 Score: 0.8532 | Validation Loss: 0.0099, F1 Score: 0.8337\n",
            "Epoch [66/100] Training Loss: 0.0093, F1 Score: 0.8527 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [67/100] Training Loss: 0.0094, F1 Score: 0.8532 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [68/100] Training Loss: 0.0093, F1 Score: 0.8538 | Validation Loss: 0.0099, F1 Score: 0.8337\n",
            "Epoch [69/100] Training Loss: 0.0093, F1 Score: 0.8538 | Validation Loss: 0.0099, F1 Score: 0.8337\n",
            "Epoch 00070: reducing learning rate of group 0 to 1.0000e-06.\n",
            "Epoch [70/100] Training Loss: 0.0093, F1 Score: 0.8532 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [71/100] Training Loss: 0.0093, F1 Score: 0.8538 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [72/100] Training Loss: 0.0093, F1 Score: 0.8538 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [73/100] Training Loss: 0.0093, F1 Score: 0.8538 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [74/100] Training Loss: 0.0093, F1 Score: 0.8538 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [75/100] Training Loss: 0.0093, F1 Score: 0.8538 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [76/100] Training Loss: 0.0093, F1 Score: 0.8538 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [77/100] Training Loss: 0.0093, F1 Score: 0.8538 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [78/100] Training Loss: 0.0093, F1 Score: 0.8538 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [79/100] Training Loss: 0.0093, F1 Score: 0.8538 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [80/100] Training Loss: 0.0093, F1 Score: 0.8538 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch 00081: reducing learning rate of group 0 to 1.0000e-07.\n",
            "Epoch [81/100] Training Loss: 0.0093, F1 Score: 0.8543 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [82/100] Training Loss: 0.0093, F1 Score: 0.8543 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [83/100] Training Loss: 0.0093, F1 Score: 0.8543 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [84/100] Training Loss: 0.0093, F1 Score: 0.8543 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [85/100] Training Loss: 0.0093, F1 Score: 0.8543 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [86/100] Training Loss: 0.0093, F1 Score: 0.8543 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [87/100] Training Loss: 0.0093, F1 Score: 0.8543 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [88/100] Training Loss: 0.0093, F1 Score: 0.8543 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [89/100] Training Loss: 0.0093, F1 Score: 0.8543 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [90/100] Training Loss: 0.0093, F1 Score: 0.8543 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [91/100] Training Loss: 0.0093, F1 Score: 0.8543 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch 00092: reducing learning rate of group 0 to 1.0000e-08.\n",
            "Epoch [92/100] Training Loss: 0.0093, F1 Score: 0.8543 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [93/100] Training Loss: 0.0093, F1 Score: 0.8543 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [94/100] Training Loss: 0.0093, F1 Score: 0.8543 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [95/100] Training Loss: 0.0093, F1 Score: 0.8543 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [96/100] Training Loss: 0.0093, F1 Score: 0.8543 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [97/100] Training Loss: 0.0093, F1 Score: 0.8543 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [98/100] Training Loss: 0.0093, F1 Score: 0.8543 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [99/100] Training Loss: 0.0093, F1 Score: 0.8543 | Validation Loss: 0.0099, F1 Score: 0.8350\n",
            "Epoch [100/100] Training Loss: 0.0093, F1 Score: 0.8543 | Validation Loss: 0.0099, F1 Score: 0.8350\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete! Total time: 2041.89 seconds\n"
          ]
        }
      ],
      "source": [
        "# Train the GatedCombination model using training and validation data\n",
        "trained_model = train_gated_combination_model(\n",
        "    X1_train,          # Updated source embeddings (after applying the GNN model)\n",
        "    X2_train,          # Original source embeddings (before applying the GNN model)\n",
        "    X3_train,          # Updated target embeddings (after applying the GNN model)\n",
        "    X4_train,          # Original target embeddings (before applying the GNN model)\n",
        "    tensor_score_train, # Ground truth labels for the training set (1 for matched pairs, 0 for unmatched pairs)\n",
        "\n",
        "    X1_val,            # Updated source embeddings for the validation set\n",
        "    X2_val,            # Original source embeddings for the validation set\n",
        "    X3_val,            # Updated target embeddings for the validation set\n",
        "    X4_val,            # Original target embeddings for the validation set\n",
        "    tensor_score_val,  # Ground truth labels for the validation set (1 for matched pairs, 0 for unmatched pairs)\n",
        "\n",
        "    epochs=100,        # Number of epochs (iterations over the entire training dataset)\n",
        "    batch_size=32,     # Number of training samples processed in one forward/backward pass\n",
        "    learning_rate=0.001, # Learning rate for the optimizer (controls step size during optimization)\n",
        "    weight_decay=1e-4 # Weight decay (L2 regularization) to prevent overfitting\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAmLuMtGW9c2"
      },
      "source": [
        "# **Mappings Selector**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "lnFtpUAfJQHl"
      },
      "outputs": [],
      "source": [
        "# Build an indexed dictionary for the source ontology classes\n",
        "# src_class is the file path to the JSON file containing the source ontology classes\n",
        "indexed_dict_src = build_indexed_dict(src_class)\n",
        "\n",
        "# Build an indexed dictionary for the target ontology classes\n",
        "# tgt_class is the file path to the JSON file containing the target ontology classes\n",
        "indexed_dict_tgt = build_indexed_dict(tgt_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "beipwavuJQHl"
      },
      "outputs": [],
      "source": [
        "# Read the candidate pairs from a Candidates CSV file into a pandas DataFrame\n",
        "df_embbedings = pd.read_csv(candidates_Prediction, index_col=0)\n",
        "\n",
        "# Extract the 'SrcEntity' column (source entity indices) and convert it to a NumPy array of integers\n",
        "tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)\n",
        "\n",
        "# Extract the 'TgtEntity' column (target entity indices) and convert it to a NumPy array of integers\n",
        "tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)\n",
        "\n",
        "# Convert the source entity indices to a PyTorch LongTensor\n",
        "src_entity_tensor_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)\n",
        "\n",
        "# Convert the target entity indices to a PyTorch LongTensor\n",
        "tgt_entity_tenso_or = torch.from_numpy(tensor_term2).type(torch.LongTensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "ECLhmxyKJQHl"
      },
      "outputs": [],
      "source": [
        "# Select rows from the updated source embeddings based on the indices in src_entity_tensor_o\n",
        "X1_tt = select_rows_by_index(embeddings_src, src_entity_tensor_o)\n",
        "\n",
        "# Select rows from the original source embeddings based on the indices in src_entity_tensor_o\n",
        "X2_tt = select_rows_by_index(x_src, src_entity_tensor_o)\n",
        "\n",
        "# Select rows from the updated target embeddings based on the indices in tgt_entity_tenso_or\n",
        "X3_tt = select_rows_by_index(embeddings_tgt, tgt_entity_tenso_or)\n",
        "\n",
        "# Select rows from the original target embeddings based on the indices in tgt_entity_tenso_or\n",
        "X4_tt = select_rows_by_index(x_tgt, tgt_entity_tenso_or)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c28c7854-dd97-4afe-ed1b-a03e7f12dd04",
        "id": "UFP6OQR-7D4N"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting time: 18.18 seconds\n",
            "Predictions saved to /content/gdrive/My Drive/BioGITOM-VLDB//pharm/Results/pharm_all_predictions.tsv\n"
          ]
        }
      ],
      "source": [
        "# Generate predictions for candidate mappings using the trained GatedCombination model\n",
        "Prediction_with_candidates(\n",
        "    model=trained_model,             # The trained GatedCombination model used to evaluate similarity\n",
        "    X1_tt=X1_tt,                     # Updated source embeddings (after applying the GIT model)\n",
        "    X2_tt=X2_tt,                     # Original source embeddings (before applying the GIT model)\n",
        "    X3_tt=X3_tt,                     # Updated target embeddings (after applying the GIT model)\n",
        "    X4_tt=X4_tt,                     # Original target embeddings (before applying the GIT model)\n",
        "    src_entity_tensor_o=src_entity_tensor_o,  # Tensor of source entity indices used for evaluation\n",
        "    tgt_entity_tensor_o=tgt_entity_tenso_or,  # Tensor of target entity indices used for evaluation\n",
        "    indexed_dict_src=indexed_dict_src,        # Dictionary mapping source entity indices to their URIs\n",
        "    indexed_dict_tgt=indexed_dict_tgt,        # Dictionary mapping target entity indices to their URIs\n",
        "    all_predictions_path=all_predictions_path # Path to save all predictions with similarity scores in TSV format\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "mEc12J-B7D4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56846ccc-d5fc-41d4-c215-5644f2c2e1ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Positive Predictions : 3259\n"
          ]
        }
      ],
      "source": [
        "# Filter the highest scoring predictions from the predictions file and save the results to a new file\n",
        "matching_results_df = filter_highest_predictions(\n",
        "    all_predictions_path,  # Path to the file containing all predictions with scores for all candidate pairs\n",
        "    prediction_path        # Path where the filtered predictions with highest scores will be saved\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIx74lNV7D4O"
      },
      "source": [
        "# **Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Global metrics calculation"
      ],
      "metadata": {
        "id": "Pp3IpBBfWn9m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "bkOewzXr7D4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3fbca5c-2654-4bb4-ee5f-9f17f20ed5ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Correct Predictions: 2646\n",
            "{'P': 0.812, 'R': 0.651, 'F1': 0.723}\n"
          ]
        }
      ],
      "source": [
        "# Retrieve the indices of the ignored classes (from source and target ontologies)\n",
        "ignored_class_index = get_ignored_class_index(src_onto)  # Get ignored class indices from source ontology\n",
        "ignored_class_index.update(get_ignored_class_index(tgt_onto))  # Update with ignored class indices from target ontology\n",
        "\n",
        "# Read the predicted mappings from the prediction results file\n",
        "preds = EntityMapping.read_table_mappings(prediction_path)\n",
        "\n",
        "# Read the reference mappings from the ground truth test file\n",
        "refs = ReferenceMapping.read_table_mappings(f\"{dataset_dir}/refs_equiv/test.tsv\")\n",
        "\n",
        "# Filter the predicted mappings to remove any mappings that involve ignored classes\n",
        "preds = remove_ignored_mappings(preds, ignored_class_index)\n",
        "\n",
        "# Compute the precision, recall, and F1-score by comparing predictions with the reference mappings\n",
        "results = AlignmentEvaluator.f1(preds, refs)\n",
        "\n",
        "preds2 = [p.to_tuple() for p in preds]\n",
        "refs2 = [r.to_tuple() for r in refs]\n",
        "\n",
        "correct= len(set(preds2).intersection(set(refs2)))\n",
        "\n",
        "print(f\"Number of Correct Predictions: {correct}\")\n",
        "\n",
        "# Print the computed precision, recall, and F1-score metrics\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ranked-based metrics calculation"
      ],
      "metadata": {
        "id": "aECB6igZW04C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "id": "-AK-jADkSbTa"
      },
      "outputs": [],
      "source": [
        "# Read the candidate pairs from a Candidates CSV file into a pandas DataFrame\n",
        "df_embbedings = pd.read_csv(candidates_Rank, index_col=0)\n",
        "\n",
        "# Extract the 'SrcEntity' column (source entity indices) and convert it to a NumPy array of integers\n",
        "tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)\n",
        "\n",
        "# Extract the 'TgtEntity' column (target entity indices) and convert it to a NumPy array of integers\n",
        "tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)\n",
        "\n",
        "# Convert the source entity indices to a PyTorch LongTensor\n",
        "src_entity_tensor_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)\n",
        "\n",
        "# Convert the target entity indices to a PyTorch LongTensor\n",
        "tgt_entity_tenso_or = torch.from_numpy(tensor_term2).type(torch.LongTensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "oyOzcLv-SbTb"
      },
      "outputs": [],
      "source": [
        "# Select rows from the updated source embeddings based on the indices in src_entity_tensor_o\n",
        "X1_tt = select_rows_by_index(embeddings_src, src_entity_tensor_o)\n",
        "\n",
        "# Select rows from the original source embeddings based on the indices in src_entity_tensor_o\n",
        "X2_tt = select_rows_by_index(x_src, src_entity_tensor_o)\n",
        "\n",
        "# Select rows from the updated target embeddings based on the indices in tgt_entity_tenso_or\n",
        "X3_tt = select_rows_by_index(embeddings_tgt, tgt_entity_tenso_or)\n",
        "\n",
        "# Select rows from the original target embeddings based on the indices in tgt_entity_tenso_or\n",
        "X4_tt = select_rows_by_index(x_tgt, tgt_entity_tenso_or)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform ranking-based predictions using the trained GatedCombination model\n",
        "# Generate predictions for candidate mappings using the trained GatedCombination model\n",
        "Prediction_with_candidates(\n",
        "    model=trained_model,             # The trained GatedCombination model used to evaluate similarity\n",
        "    X1_tt=X1_tt,                     # Updated source embeddings (after applying the GIT model)\n",
        "    X2_tt=X2_tt,                     # Original source embeddings (before applying the GIT model)\n",
        "    X3_tt=X3_tt,                     # Updated target embeddings (after applying the GIT model)\n",
        "    X4_tt=X4_tt,                     # Original target embeddings (before applying the GIT model)\n",
        "    src_entity_tensor_o=src_entity_tensor_o,  # Tensor of source entity indices used for evaluation\n",
        "    tgt_entity_tensor_o=tgt_entity_tenso_or,  # Tensor of target entity indices used for evaluation\n",
        "    indexed_dict_src=indexed_dict_src,        # Dictionary mapping source entity indices to their URIs\n",
        "    indexed_dict_tgt=indexed_dict_tgt,        # Dictionary mapping target entity indices to their URIs\n",
        "    all_predictions_path=all_predictions_path_ranked, # Path where the ranked predictions will be saved in TSV format\n",
        ")"
      ],
      "metadata": {
        "id": "-O2f7X6cSb-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c27b8fd0-9992-4315-cd68-3b9ba3a0e1d7"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting time: 17.46 seconds\n",
            "Predictions saved to /content/gdrive/My Drive/BioGITOM-VLDB//pharm/Results/pharm_all_predictions_ranked.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "_402seVv7D4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49c0099d-370d-475c-e31f-b1042aab842d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MRR and Hits@k Results:\n",
            "{'MRR': 0.9048131079540179, 'Hits@k': {1: 0.8412112259970458, 5: 0.982028557360906, 10: 0.9903988183161004}}\n"
          ]
        }
      ],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=all_predictions_path_ranked,             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n",
        "\n",
        "# Display the computed metrics\n",
        "print(\"MRR and Hits@k Results:\")\n",
        "print(results)  # Output the Mean Reciprocal Rank (MRR) and Hits@k metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "wStfa4eZ7D4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4407416e-f27e-4855-dda9-dbfa224dd9f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9048131079540179, 'Hits@1': 0.8412112259970458, 'Hits@5': 0.982028557360906, 'Hits@10': 0.9903988183161004}\n"
          ]
        }
      ],
      "source": [
        "# Call the ranking evaluation function, passing the path to the formatted predictions file.\n",
        "# Ks specifies the evaluation levels, checking if the correct target is within the top K candidates.\n",
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}