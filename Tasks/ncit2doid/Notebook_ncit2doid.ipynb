{"cells":[{"cell_type":"markdown","metadata":{"id":"MkAX88H3RNRW"},"source":["# **Package Installation**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":283964,"status":"ok","timestamp":1734686148295,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"SlL2v0xgmFJ-","outputId":"c32f27e5-434d-477e-8a0c-ad55a8175b1e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==2.0.0\n","  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.16.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n","  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n","  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n","  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n","  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n","  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n","  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.0.0 (from torch==2.0.0)\n","  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (75.1.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.45.1)\n","Collecting cmake (from triton==2.0.0->torch==2.0.0)\n","  Downloading cmake-3.31.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n","Collecting lit (from triton==2.0.0->torch==2.0.0)\n","  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n","Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m761.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m678.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cmake-3.31.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.8/27.8 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, cmake, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.1+cpu\n","    Uninstalling torch-2.5.1+cpu:\n","      Successfully uninstalled torch-2.5.1+cpu\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.5.1+cpu requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\n","torchvision 0.20.1+cpu requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed cmake-3.31.2 lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 triton-2.0.0\n","Collecting torch-geometric==2.4.0\n","  Downloading torch_geometric-2.4.0-py3-none-any.whl.metadata (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m916.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (4.67.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (3.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (2.32.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (3.2.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.6.0)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric==2.4.0) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (2024.12.14)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.4.0) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.4.0) (3.5.0)\n","Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-geometric\n","Successfully installed torch-geometric-2.4.0\n","Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_scatter-2.1.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (494 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_sparse-0.6.18%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-cluster\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_cluster-1.6.3%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (751 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.3/751.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-spline-conv\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (208 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n","Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n","Installing collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster\n","Successfully installed torch-cluster-1.6.3+pt20cpu torch-scatter-2.1.2+pt20cpu torch-sparse-0.6.18+pt20cpu torch-spline-conv-1.2.2+pt20cpu\n","Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.67.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.6.0)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.12.14)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting deeponto\n","  Downloading deeponto-0.9.2-py3-none-any.whl.metadata (15 kB)\n","Collecting JPype1 (from deeponto)\n","  Downloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting yacs (from deeponto)\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deeponto) (2.0.0)\n","Collecting anytree (from deeponto)\n","  Downloading anytree-2.12.1-py3-none-any.whl.metadata (8.1 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from deeponto) (8.1.7)\n","Collecting dill (from deeponto)\n","  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from deeponto) (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deeponto) (1.26.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deeponto) (1.6.0)\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (from deeponto) (4.47.0)\n","Collecting datasets (from deeponto)\n","  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.7.5)\n","Collecting pprintpp (from deeponto)\n","  Downloading pprintpp-0.4.0-py2.py3-none-any.whl.metadata (7.9 kB)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.4.2)\n","Collecting lxml (from deeponto)\n","  Downloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n","Collecting textdistance (from deeponto)\n","  Downloading textdistance-4.6.3-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from deeponto) (7.7.1)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from deeponto) (5.5.6)\n","Collecting enlighten (from deeponto)\n","  Downloading enlighten-1.13.0-py2.py3-none-any.whl.metadata (18 kB)\n","Collecting rdflib (from deeponto)\n","  Downloading rdflib-7.1.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.9.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anytree->deeponto) (1.17.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (18.1.0)\n","Collecting dill (from deeponto)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (4.67.1)\n","Collecting xxhash (from datasets->deeponto)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets->deeponto)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->deeponto)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (3.11.11)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (0.27.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (6.0.2)\n","Collecting blessed>=1.17.7 (from enlighten->deeponto)\n","  Downloading blessed-1.20.0-py2.py3-none-any.whl.metadata (13 kB)\n","Collecting prefixed>=0.3.2 (from enlighten->deeponto)\n","  Downloading prefixed-0.9.0-py2.py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (0.2.0)\n","Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (7.34.0)\n","Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (5.7.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (6.1.12)\n","Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (6.3.3)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->deeponto) (3.6.10)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->deeponto) (3.0.13)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->deeponto) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->deeponto) (2024.11.6)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2024.2)\n","Collecting isodate<1.0.0,>=0.7.2 (from rdflib->deeponto)\n","  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib->deeponto) (3.2.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deeponto) (1.13.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deeponto) (3.5.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.0.11)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.0.10)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.5.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (0.15.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.10.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.1.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (75.1.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.5.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (1.13.1)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (2.0.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->deeponto) (0.45.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deeponto) (3.31.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deeponto) (18.1.8)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (0.4.5)\n","Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (1.2.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->transformers[torch]->deeponto) (5.9.5)\n","Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.7->enlighten->deeponto) (0.2.13)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.3.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (5.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (24.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.18.3)\n","Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->deeponto)\n","  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (5.1.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (3.0.48)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (2.18.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (4.9.0)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (2.27.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (2024.12.14)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->deeponto) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->deeponto) (0.1.5)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (0.20.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (7.0.5)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.5.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy->deeponto) (3.0.2)\n","Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->deeponto) (5.7.2)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->deeponto) (24.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deeponto) (1.3.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->deeponto) (0.8.4)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel->deeponto) (4.3.6)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.2.1)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (23.1.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (5.10.4)\n","Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (7.16.4)\n","Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.6.0)\n","Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.3)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.18.1)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.21.1)\n","Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.1.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel->deeponto) (0.7.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (3.0.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->deeponto) (1.14.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (0.1.2)\n","Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.2.4)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.12.3)\n","Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.2.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.7.1)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.3.0)\n","Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.0.2)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.10.1)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.5.1)\n","Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.4.0)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.21.1)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.23.0)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (21.2.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.5.1)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.22.3)\n","Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.24.0)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.17.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.6)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.22)\n","Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.7.1)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.2.2)\n","Downloading deeponto-0.9.2-py3-none-any.whl (89.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading anytree-2.12.1-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading enlighten-1.13.0-py2.py3-none-any.whl (42 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.8/493.8 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n","Downloading rdflib-7.1.1-py3-none-any.whl (562 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m562.4/562.4 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading textdistance-4.6.3-py3-none-any.whl (31 kB)\n","Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n","Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading prefixed-0.9.0-py2.py3-none-any.whl (13 kB)\n","Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: prefixed, pprintpp, yacs, xxhash, textdistance, lxml, JPype1, jedi, isodate, fsspec, dill, blessed, anytree, rdflib, multiprocess, enlighten, datasets, deeponto\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","Successfully installed JPype1-1.5.1 anytree-2.12.1 blessed-1.20.0 datasets-3.2.0 deeponto-0.9.2 dill-0.3.8 enlighten-1.13.0 fsspec-2024.9.0 isodate-0.7.2 jedi-0.19.2 lxml-5.3.0 multiprocess-0.70.16 pprintpp-0.4.0 prefixed-0.9.0 rdflib-7.1.1 textdistance-4.6.3 xxhash-3.5.0 yacs-0.1.8\n","/bin/bash: line 1: username: No such file or directory\n"]}],"source":["# We assume that PyTorch is already installed in the environment.\n","# If not, this command installs it.\n","!pip install torch==2.0.0\n","\n","# Install PyTorch Geometric, a library for creating graph neural networks using PyTorch.\n","!pip install torch-geometric==2.4.0\n","\n","# Import PyTorch to access its functionalities.\n","import torch\n","\n","# Install additional PyTorch Geometric dependencies for graph processing (scatter, sparse, cluster, spline-conv).\n","# These packages enable operations like sparse tensors and convolutions on graphs.\n","!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","\n","# Reinstall PyTorch Geometric to ensure all dependencies are correctly loaded.\n","!pip install torch-geometric\n","\n","# Retrieve the installed version of PyTorch to ensure compatibility with other packages.\n","torchversion = torch.__version__\n","\n","# Install the latest version of PyTorch Geometric directly from the GitHub repository.\n","# This allows access to the most recent updates and features for graph-based neural networks.\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","\n","# Install DeepOnto, a package specifically designed for ontology matching, particularly useful in biomedical applications.\n","!pip install deeponto\n","\n","# Install a custom version of DeepOnto from a GitHub repository.\n","# The '<username>' part should be replaced with the actual GitHub username of the repository maintainer.\n","!pip install git+https://github.com/<username>/deeponto.git\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57269,"status":"ok","timestamp":1734686205559,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"HPAlAgjLMVhw","outputId":"57dbe0f4-3ae3-47c9-a042-41535c32aaf8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Please enter the maximum memory located to JVM [8g]: 8g\n","\n"]}],"source":["# Import pandas for data manipulation and analysis, such as loading, processing, and saving tabular data.\n","import pandas as pd\n","\n","# Import pickle for saving and loading serialized objects (e.g., trained models or preprocessed data).\n","import pickle\n","\n","# Import function to convert a directed graph to an undirected one, useful for certain graph algorithms.\n","from torch_geometric.utils import to_undirected\n","\n","# Import optimizer module from PyTorch for training models using gradient-based optimization techniques.\n","import torch.optim as optim\n","\n","# Import PyTorch's modules for defining neural network architectures and operations:\n","from torch.nn import (\n","    Linear,       # For linear transformations (dense layers).\n","    Sequential,   # For stacking layers sequentially.\n","    BatchNorm1d,  # For normalizing input within mini-batches.\n","    PReLU,        # Parametric ReLU activation function.\n","    Dropout       # For regularization by randomly dropping connections during training.\n",")\n","\n","# Import functional API from PyTorch for operations like activations and loss functions.\n","import torch.nn.functional as F\n","\n","# Import Matplotlib for visualizations, such as plotting training loss curves.\n","import matplotlib.pyplot as plt\n","\n","# Import PyTorch Geometric's graph convolutional layers:\n","from torch_geometric.nn import GCNConv, GINConv\n","\n","# Import pooling operations for aggregating node embeddings to graph-level representations:\n","from torch_geometric.nn import global_mean_pool, global_add_pool\n","\n","# Import NumPy for numerical operations, such as working with arrays and matrices.\n","import numpy as np\n","\n","# Import time module for measuring execution time of code blocks.\n","import time\n","\n","# Import typing module for specifying types in function arguments and return values.\n","from typing import Optional, Tuple, Union, Callable\n","\n","# Import PyTorch's DataLoader and TensorDataset for handling data batching and loading during training.\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","# Import PyTorch's Parameter class for defining learnable parameters in custom models.\n","from torch.nn import Parameter\n","\n","# Import math module for performing mathematical computations.\n","import math\n","\n","# Import Tensor type from PyTorch for defining and manipulating tensors.\n","from torch import Tensor\n","\n","# Import PyTorch's nn module for defining and building neural network architectures.\n","import torch.nn as nn\n","\n","# Import initialization utilities from PyTorch Geometric for resetting weights and biases in layers.\n","from torch_geometric.nn.inits import reset\n","\n","# Import the base class for defining message-passing layers in graph neural networks (GNNs).\n","from torch_geometric.nn.conv import MessagePassing\n","\n","# Import linear transformation utilities for creating dense representations in graph models.\n","from torch_geometric.nn.dense.linear import Linear\n","\n","# Import typing utilities for defining adjacency matrices and tensor types specific to PyTorch Geometric.\n","from torch_geometric.typing import Adj, OptTensor, PairTensor, SparseTensor\n","\n","# Import softmax function for normalizing attention scores in GNNs.\n","from torch_geometric.utils import softmax\n","\n","# Import initialization utilities for weight initialization (e.g., Glorot initialization).\n","from torch_geometric.nn.inits import glorot, zeros\n","\n","# Import F1 score metric from scikit-learn for evaluating model performance in binary/multi-class tasks.\n","from sklearn.metrics import f1_score\n","\n","# Import JSON module for reading and writing JSON files, useful for storing configuration or ontology data.\n","import json\n","\n","# Import Ontology class from DeepOnto for representing and manipulating ontologies in the pipeline.\n","from deeponto.onto import Ontology\n","\n","# Import tools from DeepOnto for handling Ontology Alignment Evaluation Initiative (OAEI) tasks.\n","from deeponto.align.oaei import *\n","\n","# Import evaluation tools from DeepOnto for assessing alignment results using metrics like precision, recall, and F1.\n","from deeponto.align.evaluation import AlignmentEvaluator\n","\n","# Import mapping utilities from DeepOnto for working with reference mappings and entity pairs.\n","from deeponto.align.mapping import ReferenceMapping, EntityMapping\n","\n","# Import utility function for reading tables (e.g., TSV, CSV) from DeepOnto.\n","from deeponto.utils import read_table\n","\n","# Importing the train_test_split function from sklearn's model_selection module.\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","source":["import random\n","\n","# Set the seed for PyTorch's random number generator to ensure reproducibility\n","torch.manual_seed(42)\n","\n","# Set the seed for NumPy's random number generator to ensure reproducibility\n","np.random.seed(42)\n","\n","# Set the seed for Python's built-in random module to ensure reproducibility\n","random.seed(42)"],"metadata":{"id":"zijK3T13W-VS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-abbBHOoRdWl"},"source":["# **Paths Definition**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18978,"status":"ok","timestamp":1734686224531,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"AVgl_Bb42naS","outputId":"ea51744b-2fc6-4ab8-9967-470eca3992fe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# Importing the 'drive' module from Google Colab to interact with Google Drive\n","from google.colab import drive\n","\n","# Mount the user's Google Drive to the Colab environment\n","# After running this, a link will appear to authorize access, and Google Drive will be mounted at '/content/gdrive'\n","drive.mount('/content/gdrive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"36ttssQ3W7cx"},"outputs":[],"source":["# Define the source ontology name\n","src_ent = \"ncit\"\n","\n","# Define the target ontology name\n","tgt_ent = \"doid\"\n","\n","# Define the task name for this ontology matching process\n","task = \"ncit2doid\"\n","\n","# Define the similarity threshold for validating matches\n","thres = 0.20"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SJpvkdwVSQye"},"outputs":[],"source":["dir = \"/content/gdrive/My Drive/BioGITOM-VLDB\"\n","\n","# Define the directory for the dataset containing source and target ontologies\n","dataset_dir = f\"{dir}/Datasets/{task}\"\n","\n","# Define the data directory for storing embeddings, adjacency matrices, and related files\n","data_dir = f\"{dir}/{task}/Data\"\n","\n","# Define the directory for storing the results\n","results_dir = f\"{dir}/{task}/Results\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eFDNSFef23er"},"outputs":[],"source":["# Load the Source ontology using the Ontology class from DeepOnto\n","# This initializes the source ontology by loading its .owl file.\n","src_onto = Ontology(f\"{dataset_dir}/{src_ent}.owl\")\n","\n","# Load the Target ontology using the Ontology class from DeepOnto\n","# This initializes the target ontology by loading its .owl file.\n","tgt_onto = Ontology(f\"{dataset_dir}/{tgt_ent}.owl\")\n","\n","# Define the file path for the Source embeddings CSV file\n","# Embeddings for the source ontology entities are stored in this file.\n","src_Emb = f\"{data_dir}/{src_ent}_BERT_Hybrid_emb.csv\"\n","\n","# Define the file path for the Target embeddings CSV file\n","# Embeddings for the target ontology entities are stored in this file.\n","tgt_Emb = f\"{data_dir}/{tgt_ent}_BERT_Hybrid_emb.csv\"\n","\n","# Define the file path for the Source adjacency matrix\n","# This file represents the relationships (edges) between entities in the source ontology.\n","src_Adjacence = f\"{data_dir}/{src_ent}_adjacence.csv\"\n","\n","# Define the file path for the Target adjacency matrix\n","# This file represents the relationships (edges) between entities in the target ontology.\n","tgt_Adjacence = f\"{data_dir}/{tgt_ent}_adjacence.csv\"\n","\n","# Define the file path for the JSON file containing the Source ontology class labels\n","# This file maps the source ontology entities to their labels or names.\n","src_class = f\"{data_dir}/{src_ent}_classes.json\"\n","\n","# Define the file path for the JSON file containing the Target ontology class labels\n","# This file maps the target ontology entities to their labels or names.\n","tgt_class = f\"{data_dir}/{tgt_ent}_classes.json\"\n","\n","# Define the file path for the train data\n","train_file = f\"{data_dir}/{task}_train.csv\"\n","\n","# Define the file path for the test data\n","# The test file contains reference mappings (ground truth) between the source and target ontologies.\n","test_file = f\"{dataset_dir}/refs_equiv/test.tsv\"\n","\n","# Define the file path for the candidate mappings used during testing\n","# This file includes the candidate pairs (source and target entities) for ranking and evaluation.\n","test_cands = f\"{dataset_dir}/refs_equiv/test.cands.tsv\"\n","\n","# Define the file path for the candidate mappings between Source to Target entities\n","# This file contains cleaned, combined, and encoded candidates used for predictions.\n","candidates_Prediction = f\"{data_dir}/{task}_candidates_prediction.csv\"\n","\n","# Define the file path for the candidate mappings between Source to Target entities for ranking-based metrics\n","# This file is used to compute ranking-based metrics like MRR and Hits@k.\n","candidates_Rank = f\"{data_dir}/{task}_candidates.csv\"\n","\n","# Define the path where the prediction results will be saved in TSV format\n","# This file will store the final predictions (mappings) between source and target entities.\n","prediction_path = f\"{results_dir}/{task}_matching_results.tsv\"\n","\n","# Define the path where all prediction results will be saved in TSV format\n","# This file will store detailed prediction results, including all candidate scores.\n","all_predictions_path = f\"{results_dir}/{task}_all_predictions.tsv\"\n","\n","# Define the path where all ranking prediction results will be saved in TSV format\n","# This file will store predictions sorted by rank based on their scores.\n","all_predictions_path_ranked = f\"{results_dir}/{task}_all_predictions_ranked.tsv\"\n","\n","# Define the path where formatted ranking predictions will be saved in TSV format\n","# This file will contain predictions formatted for evaluation using ranking-based metrics.\n","formatted_predictions_path = f\"{results_dir}/{task}_formatted_predictions.tsv\""]},{"cell_type":"markdown","metadata":{"id":"zqEXsgPGMVhw"},"source":["# **GIT Architecture**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A_d6XCsUMVhx"},"outputs":[],"source":["# RGIT class definition which inherits from PyTorch Geometric's MessagePassing class\n","class RGIT(MessagePassing):\n","\n","    _alpha: OptTensor  # Define _alpha as an optional tensor for storing attention weights\n","\n","    def __init__(\n","        self,\n","        nn: Callable,  # Neural network to be used in the final layer of the GNN\n","        in_channels: Union[int, Tuple[int, int]],  # Input dimension, can be a single or pair of integers\n","        out_channels: int,  # Output dimension of the GNN\n","        eps: float = 0.,  # GIN parameter: epsilon for GIN aggregation\n","        train_eps: bool = False,  # GIN parameter: whether epsilon should be learnable\n","        heads: int = 1,  # Transformer parameter: number of attention heads\n","        dropout: float = 0.,  # Dropout rate for attention weights\n","        edge_dim: Optional[int] = None,  # Dimension for edge attributes (optional)\n","        bias: bool = True,  # Whether to use bias in linear layers\n","        root_weight: bool = True,  # GIN parameter: whether to apply root weight in aggregation\n","        **kwargs,  # Additional arguments passed to the parent class\n","    ):\n","        # Set the aggregation type to 'add' and initialize the parent class with node_dim=0\n","        kwargs.setdefault('aggr', 'add')\n","        super().__init__(node_dim=0, **kwargs)\n","\n","        # Initialize input/output dimensions, neural network, and GIN/transformer parameters\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.nn = nn  # Neural network used by the GNN\n","        self.initial_eps = eps  # Initial value of epsilon for GIN\n","\n","        # Set epsilon to be learnable or fixed\n","        if train_eps:\n","            self.eps = torch.nn.Parameter(torch.empty(1))  # Learnable epsilon\n","        else:\n","            self.register_buffer('eps', torch.empty(1))  # Non-learnable epsilon (fixed)\n","\n","        # Initialize transformer-related parameters\n","        self.heads = heads\n","        self.dropout = dropout\n","        self.edge_dim = edge_dim\n","        self._alpha = None  # Placeholder for attention weights\n","\n","        # Handle case where in_channels is a single integer or a tuple\n","        if isinstance(in_channels, int):\n","            in_channels = (in_channels, in_channels)\n","\n","        # Define the linear layers for key, query, and value for the transformer mechanism\n","        self.lin_key = Linear(in_channels[0], heads * out_channels)\n","        self.lin_query = Linear(in_channels[1], heads * out_channels)\n","        self.lin_value = Linear(in_channels[0], heads * out_channels)\n","\n","        # Define linear transformation for edge embeddings if provided\n","        if edge_dim is not None:\n","            self.lin_edge = Linear(edge_dim, heads * out_channels, bias=False)\n","        else:\n","            self.lin_edge = self.register_parameter('lin_edge', None)\n","\n","        # Reset all parameters to their initial values\n","        self.reset_parameters()\n","\n","    # Function to reset model parameters\n","    def reset_parameters(self):\n","        super().reset_parameters()  # Call parent class reset method\n","        self.lin_key.reset_parameters()  # Reset key linear layer\n","        self.lin_query.reset_parameters()  # Reset query linear layer\n","        self.lin_value.reset_parameters()  # Reset value linear layer\n","        if self.edge_dim:\n","            self.lin_edge.reset_parameters()  # Reset edge linear layer if used\n","        reset(self.nn)  # Reset the neural network provided\n","        self.eps.data.fill_(self.initial_eps)  # Initialize epsilon with the starting value\n","\n","    # Forward function defining how the input data flows through the model\n","    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj,\n","                edge_attr: OptTensor = None, return_attention_weights=None):\n","        # Unpack number of heads and output channels\n","        H, C = self.heads, self.out_channels\n","\n","        # If x is a tensor, treat it as a pair of tensors (source and target embeddings)\n","        if isinstance(x, Tensor):\n","            x: PairTensor = (x, x)\n","\n","        # Extract source node embeddings\n","        x_t = x[0]\n","\n","        # Apply linear transformations and reshape query, key, and value for multi-head attention\n","        query = self.lin_query(x[1]).view(-1, H, C)\n","        key = self.lin_key(x[0]).view(-1, H, C)\n","        value = self.lin_value(x[0]).view(-1, H, C)\n","\n","        # Propagate messages through the graph using the propagate function\n","        out = self.propagate(edge_index, query=query, key=key, value=value,\n","                             edge_attr=edge_attr, size=None)\n","\n","        # Retrieve attention weights and reset them\n","        alpha = self._alpha\n","        self._alpha = None  # Reset _alpha after use\n","        out = out.mean(dim=1)  # Take the mean over all attention heads\n","\n","        # Apply GIN aggregation by adding epsilon-scaled original node embeddings\n","        out = out + (1 + self.eps) * x_t\n","        return self.nn(out)  # Pass through the neural network\n","\n","    # Message passing function which calculates attention and combines messages\n","    def message(self, query_i: Tensor, key_j: Tensor, value_j: Tensor,\n","                edge_attr: OptTensor, index: Tensor, ptr: OptTensor,\n","                size_i: Optional[int]) -> Tensor:\n","        # If edge attributes are used, apply linear transformation and add them to the key\n","        if self.lin_edge is not None:\n","            assert edge_attr is not None\n","            edge_attr = self.lin_edge(edge_attr).view(-1, self.heads, self.out_channels)\n","            key_j = key_j + edge_attr\n","\n","        # Calculate attention (alpha) using the dot product between query and key\n","        alpha = (query_i * key_j).sum(dim=-1) / math.sqrt(self.out_channels)\n","        alpha = softmax(alpha, index, ptr, size_i)  # Apply softmax to normalize attention\n","        self._alpha = alpha  # Store attention weights\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)  # Apply dropout\n","\n","        # Calculate the output message by applying attention to the value\n","        out = value_j\n","        if edge_attr is not None:\n","            out = out + edge_attr  # Add edge embeddings to the output if present\n","        out = out * alpha.view(-1, self.heads, 1)  # Scale by attention weights\n","        return out\n","\n","    # String representation function for debugging or printing\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}({self.in_channels}, '\n","                f'{self.out_channels}, heads={self.heads})')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qwFv6RgHmGCf"},"outputs":[],"source":["# Define the RGIT_mod class, a multi-layer GNN that uses both RGIT and linear layers\n","class RGIT_mod(torch.nn.Module):\n","    \"\"\"Multi-layer RGIT with optional linear layers\"\"\"\n","\n","    # Initialize the model with hidden dimension, number of RGIT layers, and number of linear layers\n","    def __init__(self, dim_h, num_layers, num_linear_layers=1):\n","        super(RGIT_mod, self).__init__()\n","        self.num_layers = num_layers  # Number of RGIT layers\n","        self.num_linear_layers = num_linear_layers  # Number of linear layers\n","        self.linears = torch.nn.ModuleList()  # List to store linear layers\n","        self.rgit_layers = torch.nn.ModuleList()  # List to store RGIT layers\n","\n","        # Create a list of Linear and PReLU layers (for encoding entity names)\n","        for _ in range(num_linear_layers):\n","            self.linears.append(Linear(dim_h, dim_h))  # Linear transformation layer\n","            self.linears.append(PReLU(num_parameters=dim_h))  # Parametric ReLU activation function\n","\n","        # Create a list of RGIT layers\n","        for _ in range(num_layers):\n","            self.rgit_layers.append(RGIT(  # Each RGIT layer contains a small MLP with Linear and PReLU\n","                Sequential(Linear(dim_h, dim_h), PReLU(num_parameters=dim_h),\n","                           Linear(dim_h, dim_h), PReLU(num_parameters=dim_h)), dim_h, dim_h))\n","\n","    # Forward pass through the model\n","    def forward(self, x, edge_index):\n","        # Apply the linear layers first to the input\n","        for layer in self.linears:\n","            x = layer(x)\n","\n","        # Then apply the RGIT layers for message passing\n","        for layer in self.rgit_layers:\n","            x = layer(x, edge_index)\n","\n","        return x  # Return the final node embeddings after all layers\n"]},{"cell_type":"markdown","metadata":{"id":"zxCn5ztKVztw"},"source":["# **Gated Network Architecture**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7MKQUv7o7zay"},"outputs":[],"source":["class GatedCombination(nn.Module):\n","    \"\"\"\n","    A neural network module for combining embeddings using a gating mechanism.\n","\n","    Args:\n","        input_dim (int): Dimensionality of the input embeddings.\n","    \"\"\"\n","    def __init__(self, input_dim):\n","        super(GatedCombination, self).__init__()\n","\n","        # Fully connected layer for gating mechanism on the first embedding pair (x1, x2)\n","        self.gate_A_fc = nn.Linear(input_dim, input_dim)\n","\n","        # Fully connected layer for gating mechanism on the second embedding pair (x3, x4)\n","        self.gate_B_fc = nn.Linear(input_dim, input_dim)\n","\n","        # Fully connected layer for final similarity classification\n","        self.fc = nn.Linear(1, 1)\n","\n","    def forward(self, x1, x2, x3, x4, return_embeddings=False):\n","        \"\"\"\n","        Forward pass through the GatedCombination model.\n","\n","        Args:\n","            x1 (torch.Tensor): First set of embeddings (e.g., updated source embeddings).\n","            x2 (torch.Tensor): Second set of embeddings (e.g., original source embeddings).\n","            x3 (torch.Tensor): Third set of embeddings (e.g., updated target embeddings).\n","            x4 (torch.Tensor): Fourth set of embeddings (e.g., original target embeddings).\n","            return_embeddings (bool): Whether to return the intermediate combined embeddings (a, b).\n","\n","        Returns:\n","            torch.Tensor: Probability score for binary classification if return_embeddings is False.\n","            Tuple[torch.Tensor, torch.Tensor]: Intermediate embeddings (a, b) if return_embeddings is True.\n","        \"\"\"\n","        # Compute gating weights for the first pair of embeddings (x1, x2)\n","        gate_values1 = torch.sigmoid(self.gate_A_fc(x1))\n","\n","        # Blend x1 and x2 using the computed gating weights\n","        a = x1 * gate_values1 + x2 * (1 - gate_values1)\n","\n","        # Compute gating weights for the second pair of embeddings (x3, x4)\n","        gate_values2 = torch.sigmoid(self.gate_B_fc(x3))\n","\n","        # Blend x3 and x4 using the computed gating weights\n","        b = x3 * gate_values2 + x4 * (1 - gate_values2)\n","\n","        # If return_embeddings is True, return the intermediate blended embeddings\n","        if return_embeddings:\n","            return a, b\n","\n","        # Compute cosine similarity between the blended embeddings a and b\n","        x = torch.cosine_similarity(a, b, dim=1)\n","\n","        # Apply a fully connected layer and sigmoid activation for classification\n","        out = torch.sigmoid(self.fc(x.unsqueeze(1)))\n","        return out"]},{"cell_type":"markdown","metadata":{"id":"aLJ5j9FNMVhy"},"source":["# **Utility functions**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k0L86DgUQjMU"},"outputs":[],"source":["def adjacency_matrix_to_undirected_edge_index(adjacency_matrix):\n","    \"\"\"\n","    Converts an adjacency matrix into an undirected edge index for use in graph-based neural networks.\n","\n","    Args:\n","        adjacency_matrix: A 2D list or array representing the adjacency matrix of a graph.\n","\n","    Returns:\n","        edge_index_undirected: A PyTorch tensor representing the undirected edges.\n","    \"\"\"\n","    # Convert each element in the adjacency matrix to an integer (from boolean or float)\n","    adjacency_matrix = [[int(element) for element in sublist] for sublist in adjacency_matrix]\n","\n","    # Convert the adjacency matrix into a PyTorch LongTensor (used for indexing)\n","    edge_index = torch.tensor(adjacency_matrix, dtype=torch.long)\n","\n","    # Transpose the edge_index tensor so that rows represent edges in the form [source, target]\n","    edge_index = edge_index.t().contiguous()\n","\n","    # Convert the directed edge_index into an undirected edge_index, meaning both directions are added (i.e., (i, j) and (j, i))\n","    edge_index_undirected = to_undirected(edge_index)\n","\n","    return edge_index_undirected  # Return the undirected edge index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YvmOxkLcpf9w"},"outputs":[],"source":["def build_indexed_dict(file_path):\n","    \"\"\"\n","    Builds a dictionary with numeric indexes for each key from a JSON file.\n","\n","    Args:\n","        file_path (str): The path to the JSON file.\n","\n","    Returns:\n","        indexed_dict (dict): A new dictionary where each key from the JSON file is assigned a numeric index.\n","    \"\"\"\n","    # Load the JSON file into a Python dictionary\n","    with open(file_path, 'r') as file:\n","        data = json.load(file)\n","\n","    # Create a new dictionary with numeric indexes as keys and the original JSON keys as values\n","    indexed_dict = {index: key for index, key in enumerate(data.keys())}\n","\n","    return indexed_dict  # Return the newly created dictionary"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QgFINoPGl9Wg"},"outputs":[],"source":["def select_rows_by_index(embedding_vector, index_vector):\n","    \"\"\"\n","    Select rows from an embedding vector using an index vector.\n","\n","    Args:\n","        embedding_vector (torch.Tensor): 2D tensor representing the embedding vector with shape [num_rows, embedding_size].\n","        index_vector (torch.Tensor): 1D tensor representing the index vector.\n","\n","    Returns:\n","        torch.Tensor: New tensor with selected rows from the embedding vector.\n","    \"\"\"\n","    # Use torch.index_select to select the desired rows\n","    new_tensor = torch.index_select(embedding_vector, 0, index_vector)\n","\n","    return new_tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a12L7vEmmCJq"},"outputs":[],"source":["def contrastive_loss(source_embeddings, target_embeddings, labels, margin=1.0):\n","    \"\"\"\n","    Computes the contrastive loss, a type of loss function used to train models in tasks like matching or similarity learning.\n","\n","    Args:\n","        source_embeddings (torch.Tensor): Embeddings of the source graphs, shape [batch_size, embedding_size].\n","        target_embeddings (torch.Tensor): Embeddings of the target graphs, shape [batch_size, embedding_size].\n","        labels (torch.Tensor): Binary labels indicating if the pairs are matched (1) or not (0), shape [batch_size].\n","        margin (float): Margin value for the contrastive loss. Defaults to 1.0.\n","\n","    Returns:\n","        torch.Tensor: The contrastive loss value.\n","    \"\"\"\n","    # Calculate the pairwise Euclidean distance between source and target embeddings\n","    distances = F.pairwise_distance(source_embeddings, target_embeddings)\n","\n","    # Compute the contrastive loss:\n","    # - For matched pairs (label == 1), the loss is the squared distance between embeddings.\n","    # - For non-matched pairs (label == 0), the loss is based on how far apart the embeddings are,\n","    #   but penalizes them only if the distance is less than the margin.\n","    loss = torch.mean(\n","        labels * 0.4 * distances.pow(2) +  # For positive pairs, minimize the distance (squared)\n","        (1 - labels) * 0.4 * torch.max(torch.zeros_like(distances), margin - distances).pow(2)  # For negative pairs, maximize the distance (up to the margin)\n","    )\n","\n","    return loss  # Return the computed contrastive loss\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZhCizXEb7D4N"},"outputs":[],"source":["def Prediction_with_candidates(model, X1_tt, X2_tt, X3_tt, X4_tt, src_entity_tensor_o, tgt_entity_tensor_o,\n","                                   indexed_dict_src, indexed_dict_tgt, all_predictions_path):\n","    \"\"\"\n","    Evaluates the GatedCombination model using the given embeddings and candidate entity pairs.\n","    Saves the predictions and evaluation results to a file.\n","\n","    Args:\n","        model: Trained GatedCombination model.\n","        X1_tt, X2_tt, X3_tt, X4_tt (torch.Tensor): Tensors of source and target entity embeddings (updated and original).\n","        src_entity_tensor_o, tgt_entity_tensor_o (torch.Tensor): Tensors of source and target entity indices.\n","        indexed_dict_src, indexed_dict_tgt (dict): Dictionaries mapping entity indices to URIs for source and target.\n","        output_file (str): Path to save the predictions and results.\n","        hits_at_k_values (list): List of k-values for which hits@k is evaluated.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    # Move the model to CPU and set it to evaluation mode\n","    model = model.to(\"cpu\")\n","    model.eval()\n","\n","    # Set batch size for evaluation\n","    batch_size_test = 32\n","\n","    # Create a DataLoader for the evaluation data\n","    test_dataset = TensorDataset(X1_tt, X2_tt, X3_tt, X4_tt)\n","    test_dataloader = DataLoader(test_dataset, batch_size=batch_size_test)\n","\n","    # Prepare for collecting predictions and results\n","    predictions = []\n","    results = []\n","    count_predictions = 0  # Counter for predictions above threshold (0.5)\n","\n","    # Measure prediction time\n","    start_time = time.time()\n","\n","    # Disable gradient computation for evaluation\n","    with torch.no_grad():\n","        # Iterate over batches and compute model predictions\n","        for batch_X1, batch_X2, batch_X3, batch_X4 in test_dataloader:\n","            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","            predictions.extend(outputs.cpu().numpy())  # Collect predictions in CPU memory\n","\n","    end_time = time.time()\n","    predicting_time = end_time - start_time\n","    print(f\"Predicting time: {predicting_time:.2f} seconds\")\n","\n","    # Convert tensors to lists for easier iteration\n","    src_indices = src_entity_tensor_o.tolist()\n","    tgt_indices = tgt_entity_tensor_o.tolist()\n","\n","    # Prepare results\n","    for i in range(len(predictions)):\n","        if predictions[i] >= 0.00:  # Consider only predictions greater than 0.5\n","            count_predictions += 1  # Increment the counter\n","\n","            # Map the source and target entity indices to their URIs\n","            src_code = src_indices[i]\n","            tgt_code = tgt_indices[i]\n","\n","            src_uri = indexed_dict_src.get(int(src_code), \"Unknown URI\")\n","            tgt_uri = indexed_dict_tgt.get(int(tgt_code), \"Unknown URI\")\n","\n","            # Get the model's predicted score for the current pair\n","            score = predictions[i]\n","\n","            # Append the results (with URIs instead of entity indices)\n","            results.append({\n","                'SrcEntity': src_uri,\n","                'TgtEntity': tgt_uri,\n","                'Score': score\n","            })\n","\n","    # Convert the results into a pandas DataFrame\n","    df_results = pd.DataFrame(results)\n","\n","    # Save the results to a TSV file\n","    df_results.to_csv(all_predictions_path, sep='\\t', index=False)\n","\n","    print(f\"Predictions saved to {all_predictions_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TslUdYHBcGVj"},"outputs":[],"source":["def filter_highest_predictions(input_file_path, output_file_path, threshold=thres):\n","    # Load the all predictions file\n","    df = pd.read_csv(input_file_path, sep='\\t')\n","\n","    # Extract the similarity score from the list in the 'Score' column\n","    df['Score'] = df['Score'].apply(lambda x: float(x.strip('[]')))\n","\n","    # Sorting the dataframe by similarity score in descending order\n","    df_sorted = df.sort_values(by='Score', ascending=False).reset_index(drop=True)\n","\n","    # Initialize variables with threshold value\n","    source_concepts = set(df_sorted['SrcEntity'])\n","    target_concepts = set(df_sorted['TgtEntity'])\n","    matched_sources = set()\n","    matched_targets = set()\n","    result = []\n","\n","    # Iterate through the sorted dataframe and find highest correspondences\n","    for _, row in df_sorted.iterrows():\n","        source, target, similarity = row['SrcEntity'], row['TgtEntity'], row['Score']\n","\n","        # Check if the source or target has already been matched and if the similarity is above the threshold\n","        if source not in matched_sources and target not in matched_targets and similarity >= threshold:\n","            # Add the match to the result list\n","            result.append((source, target, similarity))\n","            # Mark the source and target as matched\n","            matched_sources.add(source)\n","            matched_targets.add(target)\n","\n","    # Create a dataframe for the matching results with threshold applied\n","    matching_results_df_threshold = pd.DataFrame(result, columns=['SrcEntity', 'TgtEntity', 'Score'])\n","\n","    # Save the matching results with the updated column names to a new TSV file\n","    matching_results_df_threshold.to_csv(output_file_path, sep='\\t', index=False)\n","\n","    # Print the number of predictions saved\n","    print(f\"Number of Positive predictions: {len(matching_results_df_threshold)}\")\n","\n","    return matching_results_df_threshold, len(matching_results_df_threshold)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ggVYlTiO_WA"},"outputs":[],"source":["def compute_mrr_and_hits(reference_file, predicted_file, output_file, k_values=[1, 5, 10]):\n","    \"\"\"\n","    Compute MRR and Hits@k for ontology matching predictions based on a reference file.\n","\n","    Args:\n","        reference_file (str): Path to the reference file (test.cands.tsv format).\n","        predicted_file (str): Path to the predictions file with scores.\n","        output_file (str): Path to save the scored results.\n","        k_values (list): List of k values for Hits@k.\n","\n","    Returns:\n","        dict: A dictionary containing MRR and Hits@k metrics.\n","    \"\"\"\n","    # Read the reference mappings\n","    test_candidate_mappings = read_table(reference_file).values.tolist()\n","    ranking_results = []\n","\n","    # Read the predicted scores\n","    predicted_data = pd.read_csv(predicted_file, sep=\"\\t\")\n","    predicted_data[\"Score\"] = predicted_data[\"Score\"].apply(lambda x: float(x.strip(\"[]\")))\n","\n","    # Create a lookup dictionary for predicted scores\n","    score_lookup = {}\n","    for _, row in predicted_data.iterrows():\n","        score_lookup[(row[\"SrcEntity\"], row[\"TgtEntity\"])] = row[\"Score\"]\n","\n","    for src_ref_class, tgt_ref_class, tgt_cands in test_candidate_mappings:\n","        tgt_cands = eval(tgt_cands)  # Convert string to list of candidates\n","        scored_cands = []\n","        for tgt_cand in tgt_cands:\n","            # Retrieve score for each candidate, defaulting to a very low score if not found\n","            matching_score = score_lookup.get((src_ref_class, tgt_cand), -1e9)\n","            scored_cands.append((tgt_cand, matching_score))\n","\n","        # Sort candidates by score in descending order\n","        scored_cands = sorted(scored_cands, key=lambda x: x[1], reverse=True)\n","        ranking_results.append((src_ref_class, tgt_ref_class, scored_cands))\n","\n","    # Save the ranked results to a file\n","    pd.DataFrame(ranking_results, columns=[\"SrcEntity\", \"TgtEntity\", \"TgtCandidates\"]).to_csv(output_file, sep=\"\\t\", index=False)\n","\n","    # Compute MRR and Hits@k\n","    total_entities = len(ranking_results)\n","    reciprocal_ranks = []\n","    hits_at_k = {k: 0 for k in k_values}\n","\n","    for src_entity, tgt_ref_class, tgt_cands in ranking_results:\n","        ranked_candidates = [candidate[0] for candidate in tgt_cands]\n","        if tgt_ref_class in ranked_candidates:\n","            rank = ranked_candidates.index(tgt_ref_class) + 1\n","            reciprocal_ranks.append(1 / rank)\n","            for k in k_values:\n","                if rank <= k:\n","                    hits_at_k[k] += 1\n","        else:\n","            reciprocal_ranks.append(0)\n","\n","    mrr = sum(reciprocal_ranks) / total_entities\n","    hits_at_k = {k: hits / total_entities for k, hits in hits_at_k.items()}\n","\n","    return {\"MRR\": mrr, \"Hits@k\": hits_at_k}"]},{"cell_type":"markdown","metadata":{"id":"1HyWMsw1MVhz"},"source":["# **Main Code**\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"IC37FlwGDqGM"},"source":["\n","\n","# Reading semantic node embeddings provided by the ENE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FuEfSnw5mod0"},"outputs":[],"source":["# Read the source embeddings from a CSV file into a pandas DataFrame\n","df_embbedings_src = pd.read_csv(src_Emb, index_col=0)\n","\n","# Convert the DataFrame to a NumPy array, which will remove the index and store the data as a raw matrix\n","numpy_array = df_embbedings_src.to_numpy()\n","\n","# Convert the NumPy array into a PyTorch FloatTensor, which is the format required for PyTorch operations\n","x_src = torch.FloatTensor(numpy_array)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"STUwqMUXmlG2"},"outputs":[],"source":["# Read the target embeddings from a CSV file into a pandas DataFrame\n","df_embbedings_tgt = pd.read_csv(tgt_Emb, index_col=0)\n","\n","# Convert the DataFrame to a NumPy array, which removes the index and converts the data to a raw matrix\n","numpy_array = df_embbedings_tgt.to_numpy()\n","\n","# Convert the NumPy array into a PyTorch FloatTensor, which is required for PyTorch operations\n","x_tgt = torch.FloatTensor(numpy_array)"]},{"cell_type":"markdown","metadata":{"id":"jZIu9P08DqGN"},"source":["# Reading adjacency Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pH69Up40mycz"},"outputs":[],"source":["# Read the source adjacency matrix from a CSV file into a pandas DataFrame\n","df_ma1 = pd.read_csv(src_Adjacence, index_col=0)\n","\n","# Convert the DataFrame to a list of lists (Python native list format)\n","ma1 = df_ma1.values.tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hYCmAO5Ymzpl"},"outputs":[],"source":["# Read the target adjacency matrix from a CSV file into a pandas DataFrame\n","df_ma2 = pd.read_csv(tgt_Adjacence, index_col=0)\n","\n","# Convert the DataFrame to a list of lists (Python native list format)\n","ma2 = df_ma2.values.tolist()"]},{"cell_type":"markdown","metadata":{"id":"PSyksqh3TrU-"},"source":["# Convert Adjacency matrix (in list format) to an undirected edge index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uVt-Pce5m5ll"},"outputs":[],"source":["# Convert the source adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n","edge_src = adjacency_matrix_to_undirected_edge_index(ma1)\n","\n","# Convert the target adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n","edge_tgt = adjacency_matrix_to_undirected_edge_index(ma2)"]},{"cell_type":"markdown","metadata":{"id":"H9wMTRdqT4aY"},"source":["# GIT Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eqiEKCLSMVh3"},"outputs":[],"source":["def train_model_gnn(model, x_src, edge_src, x_tgt, edge_tgt,\n","                    tensor_term1, tensor_term2, tensor_score,\n","                    learning_rate, weight_decay_value, num_epochs, print_interval=10):\n","    \"\"\"\n","    Trains a graph neural network (GNN) model using source and target embeddings and contrastive loss.\n","\n","    Args:\n","        model: The GNN model to be trained.\n","        x_src (torch.Tensor): Source node embeddings.\n","        edge_src (torch.Tensor): Source graph edges.\n","        x_tgt (torch.Tensor): Target node embeddings.\n","        edge_tgt (torch.Tensor): Target graph edges.\n","        tensor_term1 (torch.Tensor): Indices of the source nodes to be compared.\n","        tensor_term2 (torch.Tensor): Indices of the target nodes to be compared.\n","        tensor_score (torch.Tensor): Labels indicating if the pairs are matched (1) or not (0).\n","        learning_rate (float): Learning rate for the optimizer.\n","        weight_decay_value (float): Weight decay (L2 regularization) value for the optimizer.\n","        num_epochs (int): Number of epochs for training.\n","        print_interval (int): Interval at which training progress is printed (every `print_interval` epochs).\n","\n","    Returns:\n","        model: The trained GNN model.\n","    \"\"\"\n","\n","    # Step 1: Set device (GPU or CPU) for computation\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    # Step 2: Move the model and all inputs to the selected device\n","    model.to(device)\n","    x_tgt = x_tgt.to(device)               # Target node embeddings\n","    edge_tgt = edge_tgt.to(device)         # Target graph edges\n","    x_src = x_src.to(device)               # Source node embeddings\n","    edge_src = edge_src.to(device)         # Source graph edges\n","    tensor_term1 = tensor_term1.to(device) # Indices for source nodes\n","    tensor_term2 = tensor_term2.to(device) # Indices for target nodes\n","    tensor_score = tensor_score.to(device) # Ground truth labels\n","\n","    # Step 3: Define optimizer with learning rate and regularization\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay_value)\n","\n","    # Step 4: Initialize list to store training losses\n","    train_losses = []\n","\n","    # Record the start time of training\n","    start_time = time.time()\n","\n","    # Step 5: Training loop\n","    for epoch in range(num_epochs):\n","        # Zero out gradients from the previous iteration\n","        optimizer.zero_grad()\n","\n","        # Forward pass: Compute embeddings for source and target graphs\n","        out1 = model(x_src, edge_src)  # Updated source embeddings\n","        out2 = model(x_tgt, edge_tgt)  # Updated target embeddings\n","\n","        # Extract specific rows of embeddings for terms being compared\n","        src_embeddings = select_rows_by_index(out1, tensor_term1)\n","        tgt_embeddings = select_rows_by_index(out2, tensor_term2)\n","\n","        # Compute contrastive loss based on the embeddings and ground truth labels\n","        loss = contrastive_loss(src_embeddings, tgt_embeddings, tensor_score)\n","\n","        # Backward pass: Compute gradients\n","        loss.backward()\n","\n","        # Update the model's parameters\n","        optimizer.step()\n","\n","        # Append the loss for this iteration to the list\n","        train_losses.append(loss.item())\n","\n","        # Print loss every `print_interval` epochs\n","        if (epoch + 1) % print_interval == 0:\n","            print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item()}\")\n","\n","    # Step 6: Record end time of training\n","    end_time = time.time()\n","\n","    # Step 7: Plot the training loss over time\n","    plt.semilogy(range(1, num_epochs + 1), train_losses, label=\"Training Loss\", marker='o')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    # Print the total training time\n","    training_time = end_time - start_time\n","    print(f\"Training complete! Total training time: {training_time:.2f} seconds\")\n","\n","    # Step 8: Return the trained model\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6_tzUG_emtBg"},"outputs":[],"source":["# Initialize the GIT_mod model with the dimensionality of the target embeddings\n","# The first argument is the dimensionality of the target node embeddings (x_tgt.shape[1])\n","# The second argument (1) represents the number of RGIT layers in the model\n","GIT_model = RGIT_mod(x_tgt.shape[1], 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wVo-s7UQssSp"},"outputs":[],"source":["# Reading the training pairs from a CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(train_file, index_col=0)\n","\n","# Extract the 'SrcEntity' and 'TgtEntity' columns as NumPy arrays and convert them to integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)  # Source entity indices\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)  # Target entity indices\n","\n","# Extract the 'Score' column as a NumPy array and convert it to floats\n","tensor_score = df_embbedings['Score'].values.astype(float)  # Scores (labels) indicating if pairs match (1) or not (0)\n","\n","# Convert the NumPy arrays to PyTorch LongTensors (for indices) and FloatTensors (for scores)\n","tensor_term1_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)  # Source entity tensor\n","tensor_term2_o = torch.from_numpy(tensor_term2).type(torch.LongTensor)  # Target entity tensor\n","tensor_score_o = torch.from_numpy(tensor_score).type(torch.FloatTensor)  # Score tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"agHlFNesMVh3","executionInfo":{"status":"ok","timestamp":1734687014054,"user_tz":-60,"elapsed":766458,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"513fac72-2a4e-47be-85d3-ebfdde99516b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [10/1000], Training Loss: 0.002295828890055418\n","Epoch [20/1000], Training Loss: 0.0017963878344744444\n","Epoch [30/1000], Training Loss: 0.001512985210865736\n","Epoch [40/1000], Training Loss: 0.0013124378165230155\n","Epoch [50/1000], Training Loss: 0.0011714603751897812\n","Epoch [60/1000], Training Loss: 0.0010636855149641633\n","Epoch [70/1000], Training Loss: 0.000975198345258832\n","Epoch [80/1000], Training Loss: 0.0009006476611830294\n","Epoch [90/1000], Training Loss: 0.0008367788977921009\n","Epoch [100/1000], Training Loss: 0.000781284470576793\n","Epoch [110/1000], Training Loss: 0.0007330962107516825\n","Epoch [120/1000], Training Loss: 0.0006905605550855398\n","Epoch [130/1000], Training Loss: 0.0006524539785459638\n","Epoch [140/1000], Training Loss: 0.0006186321843415499\n","Epoch [150/1000], Training Loss: 0.0005880582029931247\n","Epoch [160/1000], Training Loss: 0.0005607636994682252\n","Epoch [170/1000], Training Loss: 0.0005364239332266152\n","Epoch [180/1000], Training Loss: 0.0005147302872501314\n","Epoch [190/1000], Training Loss: 0.0004953136667609215\n","Epoch [200/1000], Training Loss: 0.00047765843919478357\n","Epoch [210/1000], Training Loss: 0.00046204758109524846\n","Epoch [220/1000], Training Loss: 0.0004476669419091195\n","Epoch [230/1000], Training Loss: 0.00043456206913106143\n","Epoch [240/1000], Training Loss: 0.00042254713480360806\n","Epoch [250/1000], Training Loss: 0.000411756569519639\n","Epoch [260/1000], Training Loss: 0.000401982048060745\n","Epoch [270/1000], Training Loss: 0.0003930771490558982\n","Epoch [280/1000], Training Loss: 0.0003850819484796375\n","Epoch [290/1000], Training Loss: 0.0003778151876758784\n","Epoch [300/1000], Training Loss: 0.0003711078315973282\n","Epoch [310/1000], Training Loss: 0.00036505426396615803\n","Epoch [320/1000], Training Loss: 0.00035957590444013476\n","Epoch [330/1000], Training Loss: 0.00035450898576527834\n","Epoch [340/1000], Training Loss: 0.0003497801080811769\n","Epoch [350/1000], Training Loss: 0.00034527474781498313\n","Epoch [360/1000], Training Loss: 0.00034104299265891314\n","Epoch [370/1000], Training Loss: 0.00033704371890053153\n","Epoch [380/1000], Training Loss: 0.0003331996558699757\n","Epoch [390/1000], Training Loss: 0.00032955469214357436\n","Epoch [400/1000], Training Loss: 0.00032608804758638144\n","Epoch [410/1000], Training Loss: 0.00032275408739224076\n","Epoch [420/1000], Training Loss: 0.00031962417415343225\n","Epoch [430/1000], Training Loss: 0.0003166378301102668\n","Epoch [440/1000], Training Loss: 0.00031379779102280736\n","Epoch [450/1000], Training Loss: 0.0003110630495939404\n","Epoch [460/1000], Training Loss: 0.00030847213929519057\n","Epoch [470/1000], Training Loss: 0.0003059347509406507\n","Epoch [480/1000], Training Loss: 0.00030346453422680497\n","Epoch [490/1000], Training Loss: 0.00030105121550150216\n","Epoch [500/1000], Training Loss: 0.0002986365288961679\n","Epoch [510/1000], Training Loss: 0.00029621602152474225\n","Epoch [520/1000], Training Loss: 0.00029377147438935935\n","Epoch [530/1000], Training Loss: 0.00029136883676983416\n","Epoch [540/1000], Training Loss: 0.00028900435427203774\n","Epoch [550/1000], Training Loss: 0.00028674359782598913\n","Epoch [560/1000], Training Loss: 0.00028456110158003867\n","Epoch [570/1000], Training Loss: 0.00028245922294445336\n","Epoch [580/1000], Training Loss: 0.0002803984680213034\n","Epoch [590/1000], Training Loss: 0.0002783536328934133\n","Epoch [600/1000], Training Loss: 0.0002763358934316784\n","Epoch [610/1000], Training Loss: 0.00027431026683188975\n","Epoch [620/1000], Training Loss: 0.00027222276548855007\n","Epoch [630/1000], Training Loss: 0.00027007379685528576\n","Epoch [640/1000], Training Loss: 0.0002678211312741041\n","Epoch [650/1000], Training Loss: 0.00026552396593615413\n","Epoch [660/1000], Training Loss: 0.000263198307948187\n","Epoch [670/1000], Training Loss: 0.0002609113580547273\n","Epoch [680/1000], Training Loss: 0.00025868185912258923\n","Epoch [690/1000], Training Loss: 0.0002565684262663126\n","Epoch [700/1000], Training Loss: 0.0002545573515817523\n","Epoch [710/1000], Training Loss: 0.00025270070182159543\n","Epoch [720/1000], Training Loss: 0.00025093182921409607\n","Epoch [730/1000], Training Loss: 0.0002492507337592542\n","Epoch [740/1000], Training Loss: 0.0002476828231010586\n","Epoch [750/1000], Training Loss: 0.0002461750991642475\n","Epoch [760/1000], Training Loss: 0.00024470192147418857\n","Epoch [770/1000], Training Loss: 0.00024329037114512175\n","Epoch [780/1000], Training Loss: 0.0002419281518086791\n","Epoch [790/1000], Training Loss: 0.00024061527801677585\n","Epoch [800/1000], Training Loss: 0.00023933738702908158\n","Epoch [810/1000], Training Loss: 0.00023810921993572265\n","Epoch [820/1000], Training Loss: 0.00023684540065005422\n","Epoch [830/1000], Training Loss: 0.00023559766123071313\n","Epoch [840/1000], Training Loss: 0.0002345831599086523\n","Epoch [850/1000], Training Loss: 0.00023328265524469316\n","Epoch [860/1000], Training Loss: 0.00023203843738883734\n","Epoch [870/1000], Training Loss: 0.00023060418607201427\n","Epoch [880/1000], Training Loss: 0.00022963641094975173\n","Epoch [890/1000], Training Loss: 0.00022816989803686738\n","Epoch [900/1000], Training Loss: 0.00022668896417599171\n","Epoch [910/1000], Training Loss: 0.0002253766724606976\n","Epoch [920/1000], Training Loss: 0.00022423797054216266\n","Epoch [930/1000], Training Loss: 0.00022262521088123322\n","Epoch [940/1000], Training Loss: 0.00022133722086437047\n","Epoch [950/1000], Training Loss: 0.00022047545644454658\n","Epoch [960/1000], Training Loss: 0.00021902738080825657\n","Epoch [970/1000], Training Loss: 0.0002178246941184625\n","Epoch [980/1000], Training Loss: 0.00021701579680666327\n","Epoch [990/1000], Training Loss: 0.00021613802528008819\n","Epoch [1000/1000], Training Loss: 0.00021494855172932148\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAkIAAAGwCAYAAABFFQqPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA60UlEQVR4nO3deXiU5d328XNmsocshJCEyI5sAUSWgAjoq6BsUsWlraJFbesrImKtPrghLi/qY/tYFVJsreJjRam2QhEBF1wQioBAEAwgIpuSgCxJCCHbzPX+QTMlQMhMcs/+/RxHjgNmrrnzm5vAnFyrzRhjBAAAEIHsgS4AAAAgUAhCAAAgYhGEAABAxCIIAQCAiEUQAgAAEYsgBAAAIhZBCAAARKyoQBcQ7Fwul/bt26ekpCTZbLZAlwMAADxgjNHRo0eVnZ0tu73+fh+CUAP27dunNm3aBLoMAADQCHv37lXr1q3rfZ4g1ICkpCRJJ25kcnJygKsBAACeKC0tVZs2bdyf4/UhCDWgdjgsOTmZIAQAQIhpaFoLk6UBAEDEIggBAICIRRACAAARizlCAICg5HQ6VV1dHegyEKSio6PlcDiafB2CEAAgqBhjVFRUpOLi4kCXgiCXmpqqrKysJu3zRxCqR15envLy8uR0OgNdCgBElNoQlJGRoYSEBDazxWmMMSovL9eBAwckSa1atWr0tWzGGGNVYeGotLRUKSkpKikpYfk8APiY0+nUN998o4yMDLVo0SLQ5SDIHTp0SAcOHFCXLl1OGybz9PObydIAgKBROycoISEhwJUgFNT+nDRlLhlBCAAQdBgOgyes+DlhjlAAOF1Ga3Ye1oGjFcpIitOADmly2PlLDwCAvxGE/Gzp5kI99m6BCksq3I+1SonT9LE5Gtmz8ZO9AACA9xga86Olmws18fX1dUKQJBWVVGji6+u1dHNhgCoDgPDidBmt2nFI/8z/Qat2HJLTFXrrgtq3b6/nnnvO4/affvqpbDYb2w54iR4hP3G6jB57t0Bn+qtoJNkkPfZugS7LyWKYDACawN897w3NU5k+fboeffRRr6+7du1aJSYmetz+wgsvVGFhoVJSUrz+Xt749NNPdckll+jIkSNKTU316ffyB4KQn6zZefi0nqCTGUmFJRVas/OwBnViySgANEZtz/up/+ms7XmffWNfy8NQYeF/evP/9re/6ZFHHtG2bdvcjzVr1sz9a2OMnE6noqIa/vht2bKlV3XExMQoKyvLq9eAoTG/OXC0/hDUmHYAECmMMSqvqmnw62hFtaYv/LrenndJenRhgY5WVHt0PU+32cvKynJ/paSkyGazuX+/detWJSUlacmSJerXr59iY2O1YsUK7dixQ1deeaUyMzPVrFkz5ebm6qOPPqpz3VOHxmw2m/7yl79o3LhxSkhIUOfOnbVw4UL386cOjb366qtKTU3V+++/r+7du6tZs2YaOXJkneBWU1Oju+66S6mpqWrRooWmTp2qCRMm6KqrrvLovZ/JkSNH9Itf/ELNmzdXQkKCRo0ape3bt7uf3717t8aOHavmzZsrMTFRPXr00OLFi92vHT9+vFq2bKn4+Hh17txZc+bMaXQtnqBHyE8ykuIsbQcAkeJ4tVM5j7zf5OsYSUWlFer16AcetS94fIQSYqz5mLz//vv1+9//Xh07dlTz5s21d+9ejR49WjNmzFBsbKxee+01jR07Vtu2bVPbtm3rvc5jjz2mZ555Rr/73e80c+ZMjR8/Xrt371ZaWtoZ25eXl+v3v/+9/vrXv8put+vGG2/Uvffeq7lz50qS/vu//1tz587VnDlz1L17dz3//PNasGCBLrnkkka/15tvvlnbt2/XwoULlZycrKlTp2r06NEqKChQdHS0Jk2apKqqKi1fvlyJiYkqKChw95pNmzZNBQUFWrJkidLT0/Xtt9/q+PHjja7FEwQhPxnQIU2tUuJUVFJxxv+t2CRlpZxYSg8ACC+PP/64LrvsMvfv09LS1Lt3b/fvn3jiCc2fP18LFy7UnXfeWe91br75Zl1//fWSpCeffFIvvPCC1qxZo5EjR56xfXV1tV588UV16tRJknTnnXfq8ccfdz8/c+ZMPfDAAxo3bpwkadasWe7emcaoDUArV67UhRdeKEmaO3eu2rRpowULFui6667Tnj17dM0116hXr16SpI4dO7pfv2fPHvXp00f9+/eXdKJXzNcIQn7isNs0fWyOJr6+XjapThiqnWY3fWwOE6UB4BTx0Q4VPD6iwXZrdh7WzXPWNtju1VtyPfpPZ3x00082r1X7wV6rrKxMjz76qN577z0VFhaqpqZGx48f1549e856nfPOO8/968TERCUnJ7vP2zqThIQEdwiSTpzJVdu+pKRE+/fv14ABA9zPOxwO9evXTy6Xy6v3V2vLli2KiorSwIED3Y+1aNFCXbt21ZYtWyRJd911lyZOnKgPPvhAw4cP1zXXXON+XxMnTtQ111yj9evX6/LLL9dVV13lDlS+whwhPxrZs5Vm39hXWSl1h7+yUuJ8MoEPAMKBzWZTQkxUg19DO7dUq5Q41fffSZtOrB4b2rmlR9ezcnfrU1d/3XvvvZo/f76efPJJff7558rPz1evXr1UVVV11utER0fXfU8221lDy5naB/qI0V/96lf67rvvdNNNN2nTpk3q37+/Zs6cKUkaNWqUdu/erd/85jfat2+fhg0bpnvvvden9RCE/Gxkz1ZaMfVStU8/cT7K1BFdtWLqpYQgAGii2p53SaeFoWDreV+5cqVuvvlmjRs3Tr169VJWVpZ27drl1xpSUlKUmZmptWv/04vmdDq1fv36Rl+ze/fuqqmp0erVq92PHTp0SNu2bVNOTo77sTZt2uj222/XO++8o9/+9rd66aWX3M+1bNlSEyZM0Ouvv67nnntOf/7znxtdjycYGgsAh92m5gkx2qVydcpoFhR/KQEgHNT2vJ+6j1BWkO3g37lzZ73zzjsaO3asbDabpk2b1ujhqKaYPHmynnrqKZ177rnq1q2bZs6cqSNHjnjUG7Zp0yYlJSW5f2+z2dS7d29deeWV+vWvf60//elPSkpK0v33369zzjlHV155pSTp7rvv1qhRo9SlSxcdOXJEn3zyibp37y5JeuSRR9SvXz/16NFDlZWVWrRokfs5XyEIBUi0/URnXE0I7nYKAMFsZM9WuiwnK6jPdHz22Wd166236sILL1R6erqmTp2q0tJSv9cxdepUFRUV6Re/+IUcDoduu+02jRgxQg5Hw/OjLrroojq/dzgcqqmp0Zw5czRlyhRdccUVqqqq0kUXXaTFixe7h+mcTqcmTZqk77//XsnJyRo5cqT+8Ic/SDqxF9IDDzygXbt2KT4+XkOHDtW8efOsf+MnsZlADxYGudLSUqWkpKikpETJycmWXfeGl77Qv3Yc0vM/P19Xnn+OZdcFgFBWUVGhnTt3qkOHDoqLYzsRf3O5XOrevbt++tOf6oknngh0OQ0628+Lp5/f9AgFSJTj3z1CTnIoACAwdu/erQ8++EAXX3yxKisrNWvWLO3cuVM33HBDoEvzGyZLB0j0v7toq53+HxMGAECS7Ha7Xn31VeXm5mrw4MHatGmTPvroI5/Pywkm9AgFSPS/e4SqmSMEAAiQNm3aaOXKlYEuI6DoEQqQKMeJHqEaeoQA4DRMX4UnrPg5IQgFSDRzhADgNLUri8rLywNcCUJB7c/JqRtHeoOhsQCJqp0jFIB9IwAgWDkcDqWmprqPgUhISLB0h2eEB2OMysvLdeDAAaWmpnq03L8+BKEAqV01Vl1DjxAAnCwrK0uSznqGFiBJqamp7p+XxiIIBUhM7RwheoQAoA6bzaZWrVopIyND1dXVgS4HQSo6OrpJPUG1CEIBYv/30FhBYalW7TgUdLueAkCgORwOSz7ogLMhCAXA0s2FemvtXknSsi0HtGzLAbUKsnNwAACIBKwa87Olmws18fX1OlblrPN4UUmFJr6+Xks3FwaoMgAAIg9ByI+cLqPH3i3QmaZH1z722LsFcrLJIgAAfkEQ8qM1Ow+rsKSi3ueNpMKSCq3Zedh/RQEAEMEIQn504Gj9Iagx7QAAQNMQhPwoIynO0nYAAKBpCEJ+1K9dczW0Qt5uO9EOAAD4HkGoHnl5ecrJyVFubq5l11y3+4gamgftMifaAQAA3yMI1WPSpEkqKCjQ2rVrLbsmc4QAAAguBCE/Yo4QAADBhSDkR8wRAgAguBCE/Ig5QgAABBeCkB8xRwgAgOBCEPIj5ggBABBcCEJ+NKBDmlqlxKm+aUI2Sa1S4jSgQ5o/ywIAIGIRhPzIYbdp+tgcSTpjGDKSpo/NkaOhGdUAAMASBCE/G9mzlWbf2FcpCdGnPZd6hscAAIDvEIQCpKS8+oyPTXx9vZZuLgxARQAARB6CkJ85XUaPvVugM62ir33ssXcL5GxonT0AAGgygpCfrdl5WIUl9S+PN5IKSyq0Zudh/xUFAECEIgj5GXsJAQAQPAhCfsZeQgAABA+CkJ8N6JDW4Oqw1IRo9hICAMAPCEJBiF2EAADwD4KQn63ZeVjFZ1g6f7Ij5dVMlgYAwA8IQn7m6SToDwuKfFwJAAAgCPmZp5Og/5m/j72EAADwMYKQnw3okKa0xIaP0jh0rIrhMQAAfIwg5GcOu01X9s72qG1RyXEfVwMAQGQjCAVA6+YJHrU7fKzKx5UAABDZCEIBkNYs1tJ2AACgcQhCAZCV7NmE6T2Hyn1cCQAAkY0gFAADOqQpK7nh3p55a/ewcgwAAB8iCAWAw27T9QPaNtiOU+gBAPAtglCAtE9P9Kgdp9ADAOA7BKEA4RR6AAACjyAUIP3aNZe9gdNV7bYT7QAAgG8QhAJk3e4jamgetMucaAcAAHyDIBQgns79YY4QAAC+QxAKEE/n/uw6yF5CAAD4CkEoQNhLCACAwCMIBQh7CQEAEHgEoQBiLyEAAAKLIBRA7CUEAEBgEYQCiL2EAAAILIJQALGXEAAAgUUQCiBP5/58WFDk40oAAIhMBKEA8nTuzz/z97GEHgAAHyAIBdCADmlKS4xusN2hY1UsoQcAwAcIQgHksNt0Ze9sj9oWlRz3cTUAAEQeglCAtW6e4FG7w8eqfFwJAACRhyAUYKkJMZa2AwAAniMIBVhxuWc9PZ62AwAAniMIBVhas4YPXpWk74uZIwQAgNUIQvXIy8tTTk6OcnNzffp9spI9W0K/kCX0AABYjiBUj0mTJqmgoEBr16716fdhCT0AAIFDEAowh92mceef41FbTqEHAMBaBKEgcGm3TI/apSd6Np8IAAB4hiAUDBo4gd7rdgAAwCMEoSBwsKzSo3bLtuz3cSUAAEQWglAQ4PBVAAACgyAUBFg5BgBAYBCEggArxwAACAyCUJBg5RgAAP5HEAoWHq4IW7uLoTEAAKxCEAoSnq4ce3XVLiZMAwBgEYJQkPB05VhxeTUTpgEAsAhBKEgM6JCmlLgoj9oWlXASPQAAViAIBQmH3abLcjybMH34WJWPqwEAIDIQhILI4M4tPWr3fTE9QgAAWIEgFESykj2bJ7SQHaYBALAEQSiIsMM0AAD+RRAKIg67TVf2zvaoLROmAQBoOoJQkGndPMGjdiu/PejjSgAACH8EoSCT1syzIzQ+2nKAeUIAADQRQSjIeDphuvg4GysCANBUBKEgw8aKAAD4D0EoyLCxIgAA/kMQCkKDOqV71C41IcbHlQAAEN4IQkGouNyznp5VO1g5BgBAUxCEghArxwAA8A+CUBBi5RgAAP5BEApCrBwDAMA/CEJByJuVY+wwDQBA4xGEgtTgzi09ard4cxHzhAAAaCSCUJDydJ5QeZVTX+w45ONqAAAITwShIDWgQ5oSYxwetX199S7fFgMAQJgiCAUph92mi7p4Njz2+fZDDI8BANAIBKEgduMF7TxqV1ZZwzJ6AAAagSAUxC7o2ELx0Z79EbGMHgAA7xGEgpjDbtOYXq08assyegAAvEcQCnKeLqPnuA0AALxHEApyHLcBAIDvEISCHMdtAADgOwShIOfNcRuHj1X5uBoAAMILQSgEDOqU7lG7PYfLfVwJAADhhSAUAorLPevpmb/hByZMAwDgBYJQCEhrFutRu9IKNlYEAMAbBKEQ4OnKMUn64OtCH1YCAEB4IQiFgAEd0pQU59kBrP9Yz/AYAACeIgiFAIfdpmv7tvaoLcNjAAB4jiAUIi7v4dlRGxLDYwAAeIogFCIYHgMAwHoEoRDB8BgAANYjCIUQhscAALAWQSiEeDM8Nm/tXobHAABoAEEohHgzPHa82qUvdhzycUUAAIQ2glCI8WZ47PXVu3xXCAAAYYAgFGIGdEhTYqxnw2OfbP2R4TEAAM6CIBRiHHabfj2kg0dtK2oYHgMA4GwIQiFo8rAuirJ51nbljh99WwwAACGMIBSCHHab+rZr7lHbL3cd8XE1AACELoJQiMrtkOZRuw17ipknBABAPQhCIerCTuketat2Gc1ctt3H1QAAEJoIQiHqgo4tFBvl2R/fX1Z8R68QAABnQBAKUQ67TZd2y/CobVmlk7PHAAA4A4JQCLvxgnYet+XsMQAATkcQCmEXdGyhuGjP/gjnrt7D8BgAAKcgCIUwh92m63PbeNS2ysmkaQAATkUQCnHenD324mc76BUCAOAkBKEQ583ZYxy5AQBAXQShEOfN2WMSJ9IDAHAyglAYmDysi6Ltnh0+xon0AAD8B0EoDDjsNk26pJNHbRkeAwDgPwhCYcKbE+lf+2KXT2sBACBUEITChDcn0i/bsp/hMQAARBAKK56eSF/jEnsKAQAgglBY8fREeknK++RbeoUAABGPIBRGTpxI79lEoWoXO00DAEAQCiMOu00TL/Zs9ZhErxAAAAShMOPNnkL0CgEAIl3YB6Hi4mL1799f559/vnr27KmXXnop0CX5lDd7CkmcPwYAiGxhH4SSkpK0fPly5efna/Xq1XryySd16FB4byjoTa8QGywCACJZ2Achh8OhhIQESVJlZaWMMTImvHtAvO0VYoNFAECkCngQWr58ucaOHavs7GzZbDYtWLDgtDZ5eXlq37694uLiNHDgQK1Zs8ar71FcXKzevXurdevWuu+++5Se7vky81A1eVgXOTzcaZoNFgEAkSrgQejYsWPq3bu38vLyzvj83/72N91zzz2aPn261q9fr969e2vEiBE6cOCAu03t/J9Tv/bt2ydJSk1N1caNG7Vz50698cYb2r9/f731VFZWqrS0tM5XKHLYbbosJ9OjtmywCACIVDYTRONENptN8+fP11VXXeV+bODAgcrNzdWsWbMkSS6XS23atNHkyZN1//33e/097rjjDl166aW69tprz/j8o48+qscee+y0x0tKSpScnOz19wukld8e1Pi/rPaobbTdpq3/b5QcHs4tAgAgmJWWliolJaXBz++A9widTVVVldatW6fhw4e7H7Pb7Ro+fLhWrVrl0TX279+vo0ePSjoRZpYvX66uXbvW2/6BBx5QSUmJ+2vv3r1NexMBxAaLAACcXVAHoYMHD8rpdCozs+4QT2ZmpoqKijy6xu7duzV06FD17t1bQ4cO1eTJk9WrV69628fGxio5ObnOV6hig0UAAM4uqjEv2rt3r2w2m1q3bi1JWrNmjd544w3l5OTotttus7TAphowYIDy8/MDXUbATB7WRXmf7FC1BwGntlfo7su6+KEyAAACr1E9QjfccIM++eQTSVJRUZEuu+wyrVmzRg899JAef/xxy4pLT0+Xw+E4bXLz/v37lZWVZdn3CWfeLqWnVwgAEEkaFYQ2b96sAQMGSJLeeust9ezZU//61780d+5cvfrqq5YVFxMTo379+mnZsmXux1wul5YtW6ZBgwZZ9n3CHcduAABwZo0KQtXV1YqNjZUkffTRR/rJT34iSerWrZsKCwu9ulZZWZny8/Pdw1c7d+5Ufn6+9uzZI0m655579NJLL+l///d/tWXLFk2cOFHHjh3TLbfc0pjSIxLHbgAAcGaNCkI9evTQiy++qM8//1wffvihRo4cKUnat2+fWrRo4dW1vvzyS/Xp00d9+vSRdCL49OnTR4888ogk6Wc/+5l+//vf65FHHtH555+v/Px8LV269LQJ1Dg7jt0AAOB0jdpH6NNPP9W4ceNUWlqqCRMm6JVXXpEkPfjgg9q6daveeecdywsNFE/3IQgFz324Tc8t+9ajtiN6ZOpPN/X3cUUAAPiGp5/fjd5Q0el0qrS0VM2bN3c/tmvXLiUkJCgjI6MxlwxK4RSEnC6jLg8tltODP3GHTfpmxmg2WAQAhCSfbqh4/PhxVVZWukPQ7t279dxzz2nbtm1hFYLCjTfHbjiNNOXNDT6uCACAwGpUELryyiv12muvSTpxoOnAgQP1P//zP7rqqqs0e/ZsSwuEtW4a1N7jtos2FWrxV95NfgcAIJQ0KgitX79eQ4cOlST9/e9/V2Zmpnbv3q3XXntNL7zwgqUFwlreHLshSfe8lc8KMgBA2GpUECovL1dSUpIk6YMPPtDVV18tu92uCy64QLt377a0wEDJy8tTTk6OcnNzA12Kpbw9dqOixsW+QgCAsNWoIHTuuedqwYIF2rt3r95//31dfvnlkqQDBw6E/ITiWpMmTVJBQYHWrl0b6FIs581Seol9hQAA4atRQeiRRx7Rvffeq/bt22vAgAHuXZ4/+OAD935ACF7ebrDIvkIAgHDV6OXzRUVFKiwsVO/evWW3n8hTa9asUXJysrp162ZpkYEUTsvnT+Z0GeVMW6JKT9bSi32FAAChxafL5yUpKytLffr00b59+/T9999LOnHSeziFoHDmsNv0h5+d73H7D77ez/AYACDsNCoIuVwuPf7440pJSVG7du3Url07paam6oknnpDL5bK6RvjI6POydX4bz3q5jKSfvvgv3xYEAICfNSoIPfTQQ5o1a5aefvppbdiwQRs2bNCTTz6pmTNnatq0aVbXCB+6b0R3j9uu21Osdzfu82E1AAD4V6PmCGVnZ+vFF190nzpf65///KfuuOMO/fDDD5YVGGjhOkeoltNllPPIElXWePZjEOOwacsTozh6AwAQ1Hw6R+jw4cNnnAvUrVs3HT58uDGXRIB4u69QldOwrxAAIGw0Kgj17t1bs2bNOu3xWbNm6bzzzmtyUfAvb/cVmvnxdiZOAwDCQlRjXvTMM89ozJgx+uijj9x7CK1atUp79+7V4sWLLS0Qvuew2/SHn/bWnfPyPWpfeyDrrPF9fVsYAAA+1qgeoYsvvljffPONxo0bp+LiYhUXF+vqq6/W119/rb/+9a9W1wg/uOL8c9S3bYrH7RdtKlRVDSsEAQChrdEbKp7Jxo0b1bdvXzmdTqsuGXDhPln6ZE6XUZeHFsvDPRZ1QYc0zfu/g3xbFAAAjeDzDRURfhx2myZfeq7H7b/YeViLvyr0YUUAAPgWQage4Xr6fEMmD+sihxcr4+95K5+J0wCAkEUQqkc4nz5/Ng67TZP+j3cHsrKcHgAQqrxaNXb11Vef9fni4uKm1IIgMeWyrsr7dIfHc4VeWLZdk4d1ZpNFAEDI8apHKCUl5axf7dq10y9+8Qtf1Qo/8XaukEucQwYACE2WrhoLR5G0auxkTpdRzrQlqvS0W0jSzOv7aGzvbB9WBQCAZ1g1hiZx2G36w8/O9+o1v2XiNAAgxBCEUK/R52VrTK9Mj9tzDhkAINQQhHBWL1zfz6tzyF5YxjlkAIDQQRDCWdWeQ+YpJk4DAEIJQQgNuuL8c9S+RbzH7dftKda7G/f5sCIAAKxBEIJHZow7z6v2v/nbBobIAABBjyAEj1zQsYUSYzz/calxSVPe3ODDigAAaDqCEDzisNv0u2s9nyskSYs2FaqqxuWjigAAaDqCEDw2+rxs/XJIO69eM+b55T6qBgCApiMIwSvTruipvm1SPG6//cdjemJRgQ8rAgCg8QhC9cjLy1NOTo5yc3MDXUrQeXviYHlzvOrLK3Zq8VeFPqsHAIDG4qyxBkTqWWMNefb9rXrhkx0et4+ySdtmjOaEegCAX3DWGHxqymVd5fAi09QYNloEAAQfghAaxWG36XkvD2Vlo0UAQLAhCKHRrjj/HPVt6/nEaUm6ex4bLQIAggdBCE3y9u2DFeXFT5HTSJPfWO+7ggAA8AJBCE3isNv0ws/7ePWaxZuLWEUGAAgKBCE0WWM2WrzrzfUMkQEAAo4gBEtMu6KnOrdM9Lh9jZGum73ShxUBANAwghAs896Ui7xqv35vCbtOAwACiiAEy8RE2TWmV6ZXr2HXaQBAIBGEYKkXru/n1SoyiflCAIDAIQjBUo1ZRVZjpDvnrvNRRQAA1I8gBMs1ZhXZkq/3a8Z7zBcCAPgXQQg+Me2Knurbxrtdp1/6nPlCAAD/IgjBZ96eOFjeHjbPfCEAgD8RhOAzDrtNL3h5MCun1AMA/IkgBJ9qzMGsnFIPAPAXghB8ztuDWSVpypucUg8A8D2CUD3y8vKUk5Oj3NzcQJcS8hqzpN4ladjvP/ZNQQAA/JvNGMN/u8+itLRUKSkpKikpUXJycqDLCWkz3vtaL32+y6vX9MxO0qK7vDu6AwAATz+/6RGC3zw0podG9vTuCI7N+47ql6+u9VFFAIBIRxCCX+Xd4P0RHMu2HmDyNADAJwhC8KvGzBeSpMlMngYA+ABBCH7XmCM4JOnS3zF5GgBgLYIQAmLaFT11add0r16z+0iFxjz/mY8qAgBEIoIQAuaVWwaqZ6tmXr3m68IywhAAwDIEIQTUoikXKzM5xqvXfF1YpiteWO6jigAAkYQghID7/L+Gef2azfuO6tY5a3xQDQAgkhCEEHAxUfZGTZ7+eNuPeuzdr31QEQAgUhCEEBSmXdFTPbO9my8kSXNW7tITiwhDAIDGIQghaCy662L18HLytCS9vGKXZrxX4IOKAADhjiCEoPLelMaFoZc+36nFXxX6oCIAQDgjCCHovDflYrVPi/P6dZPeWM/u0wAArxCEEJSW3Xup1z+cRuw+DQDwDkEIQclht2nWDd6fSbb7SIX+zzPL6BkCAHiEIISgNfq8bP16aHuvX7frcIW6PLhYSzczZwgAcHYEIQS1h8b00C+HtPf6dU5Jt7++njAEADgrghCC3rQreuiWwd5vuChJE19fr6oal8UVAQDCBUEIIWH6WO9Pq5dOTKDu+vASLf5qn/VFAQBCHkGoHnl5ecrJyVFubm6gS8G/Nea0eulEGLrjjQ2a8R47UAMA6rIZY1hecxalpaVKSUlRSUmJkpOTA10OJI15/jN9XVjWqNf+ckh7Tbuih8UVAQCCjaef3/QIIeQ0dvdp6cRxHJxNBgCoRRBCSGpqGHrs3c0WVwQACEUEIYSspoShOSt369Y5qy2uCAAQaghCCGlNCUMfbzuoK57/zOKKAAChhCCEkPfelIvVMzupUa/dXFjGkRwAEMEIQggLi+66SJd2bdmo1+46XKHODy5mryEAiEAEIYSNV24ZoAkXNm4HapdO7DX0xCImUQNAJCEIIaw89pOeGtatcT1DkvTyCiZRA0AkIQgh7Lx884AmhaGPtx1k3hAARAiCEMLSyzcP0C+HdGj063cdrtC5Dy7WovwfLKwKABBsCEIIW9OuyNGsn/dp9OuNpDvn5euXrzJUBgDhiiCEsHbF+dn64w19m3SNZVsZKgOAcEUQQtgbfV4rvXhjXzlsjb8GQ2UAEJ4IQogII3u20jczRqtP65RGX6N2qOzWOV9YVxgAIKAIQogYDrtN8+8colsGt2/SdT7edki5T3zAUBkAhAGCECLO9LE99OuhjV9RJkk/HqtWJ4bKACDkEYQQkR4ak6M/3tC3yX8B7pyXr8v+5xNV1bgsqQsA4F8EIUSs0ee10vYnmzZvSJK2/1iuLg8v4XgOAAhBBCFEtNp5Q03ZfLHWyyt2a+CTH9A7BAAhhCAE6MTmi1YMle0vrVaXh5fosXc3WVIXAMC3CELAv9UOlfVtk9rka81ZuUe9H11K7xAABDmCEHASh92mdyYN1szrG380R62SCqe6PLxEP3vxXwQiAAhSBCHgDMb2ztaOJ0erZWJ0k6+1etcRdXl4iW5/fS17DwFAkCEIAfVw2G1aO+1yXdqtpSXXW7r5gDo9uFjPvr+VQAQAQYIgBDTglZsHaOb1fdSEo8rqeOGTHTqXQAQAQYEgVI+8vDzl5OQoNzc30KUgCIztna1vLZpILZ04t4xABACBZzPG8C/wWZSWliolJUUlJSVKTk4OdDkIAu9u3Kcp8zbIyuxikzT5kk6acllXOexW9T0BQOTy9PObINQAghDOxOkymvzGei3eXGTpdQlEAGANgpBFCEI4m6oalwbM+FDFx2ssv/bV52fr6Wt7KyaKEWwA8Jann9/8Cws0QUyUXfnTR+jWwe0tv/Y7+fvU5eEluu7FlexDBAA+Qo9QA+gRgqeqaly66eUvtHrnEZ9cv1N6oh79SQ9deG46w2YA0ACGxixCEIK3qmpcuviZj1VYWumz7zGud7b++zqGzQCgPgQhixCE0Fj/zP9Bv/lbvqWry06VkRSrXw3poJsHdyAUAcBJCEIWIQihKZwuo+c//EYzP/lWvv6LxtAZAPwHQcgiBCFYwVfL7esztFML/XlCruJjHH75fgAQbAhCFiEIwUpVNS7d/4+NemfDPr98v5Q4hyZd0pmhMwARhyBkEYIQfMHfPUSSlJEUo18N6UgoAhARCEIWIQjBl2p7iBbk7/PppOpTMckaQLgjCFmEIAR/cLqM/rX9oO79R772l1b59XsTigCEI4KQRQhC8LfjVU6N++MKbS0q8/v3To2P0u0Xd9KtQzoSigCENIKQRQhCCJTaYbP5G/b5fOn9mSRE29Wnbapuu6iThnRuyZJ8ACGFIGQRghACzekyWrHtR90//yuf7lbdkI7pCfp5bluG0ACEBIKQRQhCCCaBmlx9qtT4KF3cJUPX9mvNBo4AghJByCIEIQSj2snVz3/8jdbtLg7I0NnJWiXHasKF7ZlbBCBoEIQsQhBCsKsNRY++u1k7DpYHuhzmFgEICgQhixCEEEqqalyas/I75X2yQ6UVNYEuR5KUlhCtDumJGtEji/lFAPyGIGQRghBC1fEqpx5ftFnvfVWo0gpnoMtxS42P1sVdWjK/CIBPEYQsQhBCOAiWSdZn0jwhWh3pMQJgMYKQRQhCCCe184neXrdHy7cfVPHx4Bg+O1lijF3dspIJRgCahCBkEYIQwllVjUsvr9ihP332XVCGIkmKdUht0xKVk53CcBoAjxGELEIQQqSonWg9b80e7Tx0PNDlnFVSrEOdM5I0sie9RgDOjCBkEYIQItHJQ2gfbT2g8ipXoEs6K3qNAJyKIGQRghDwnxVoHxXs149l1YEuxyPNYuxqlRJPOAIiFEHIIgQhoK7a3qK3vtytj7f9qGNB3lt0MlaoAZGDIGQRghBwdqE0t+hUMXapZVKcslLiCEdAmCEIWYQgBHju5LlFa3YdVlFpVaBL8hrzjYDwQBCyCEEIaLxwCEYSQ2pAKCIIWYQgBFjH6TJase1Hvbj8W+34sUxHyqtVHTpTjNwYUgOCH0HIIgQhwLdqV6T969uD2l9aqYqa0PwniSE1ILgQhJooLy9PeXl5cjqd+uabbwhCgJ/U7nb9j3Xfa19xhcpDscvo31Ljo5SRFKvurQhHgL8RhCxCjxAQWCcv11+354gOllWryhm6/2ylxDmUFBetzGSG1QBfIghZhCAEBJ9w6jWSpPgoqUWzOMIRYCGCkEUIQkDwO7XXqLi8JuTDUZxDahYXraS4aF3YqYUevqKH4mMcgS4LCBkEIYsQhIDQdOoKtdKKmpCdiF3LISk5IVotm8Xo6r6tdeuQjvQcAfUgCFmEIASEj5OH1H48WqnKGlfIh6MYu5QQG6VmsVHq27a5ruvfhknZgAhCliEIAeEt3OYb1UqItiktMZZwhIhFELIIQQiILOE4pFYrKdahzhlJGtmTCdkIfwQhixCEAITjkJp0YlgtIzmOXiOEJYKQRQhCAM4kXIfUEmPsOic1nsnYCHkEIYsQhAB44tQhtfIqp8qqQj8cxTpsatcigWCEkEMQsghBCEBjnRqOapwulVW5Qnpn7FiHTc0TY9SpZaJuu6iThnRuyXAaghJByCIEIQBWO/mg2UNlVSHfc5QU61B6s1g2fkRQIQhZhCAEwNdqd8Z+e90eFRSWqryqJqR3x2bjRwQDgpBFCEIAAqWqxqU5K7/T+5uLVFhSriPlobuUP8YuJcYRjuA/BCGLEIQABJNTw9HRitCdlM2u2PAlgpBFCEIAgt3JQ2tf7yvR/tLKkA1HkpQYbVNqQqyyUuI0ogebP6JxCEIWIQgBCEW14eitL3dr3Z4jOlhWHdKr1WLsUlpCtGqMlBQXzcRsNIggZBGCEIBwUTustnRTobYfKAvpXqNa0ZKS4h1yycYQG+ogCFmEIAQgXJ06pPZDcUXITsY+k/goKT7aobjoKDWLi1L3Vim6tl9rQlKEIAhZhCAEIJKc3Gu0pehoWAWjk6XE2uWw22RsdlayhSmCkEUIQgAi2cmr1L47WKbi485Al+RTMXYpPsYhh030JIU4gpBFCEIA8B+nbv64r6RC5WEw18hTtT1JzEkKfgQhixCEAODswmnjx6aonZMU47Cryuli2C3ACEIWIQgBgPcIR6erHXaLdtjVNi1RI3uyR5IvEYQsQhACAGuE067YVoqxSy0SYyQZVbvYJ8kqBCGLEIQAwHdO3fjxWKVTlTWuiO89qlW7T5LTSFF2m9ISY5WTzeRtTxCELEIQAgD/q6px6eUVO/SPdd/rx6OVctikihqj8mp6kE6WEudQYoxDdrtdmckcSXIygpBFCEIAEDxOHl4rKj0u4zI6WskQ26niHFJibJSioxzq1DJRt13USUM6t4yoHiSCkEUIQgAQ/E7dJftIeZWcLjHMdopI2m2bIGQRghAAhLZTe5FkJGOMjhxnJdvJwm2YjSBkEYIQAISvU1eyVVa75DT0JJ2sdtl/qE3WJghZhCAEAJGpvp4k5iT9R2K0TUmxUapyngiQwbRHEkHIIgQhAMCp6puT5LBJMQ67iisYdpOkaJuUFOdQbJRDklFljf923CYIWYQgBABojDMNu5VVuVTl5GP3ZBlJsfrVkA6W9yARhCxCEAIAWOlMeyTFRjlUUlET0fsk2STddlEHPTA6x5LrEYQsQhACAPjLmfZJqp24HSkh6f9aFIYIQhYhCAEAgoHTZbRi2496cfm32vFjmWqcLrmMTcUVNYEuzVJ2m7T1iVFNHibz9PM7qknfBQAA+IXDbtPF3TN0cfeMOo+fPHG7oLBU5VU1Kq90qrjCGaBKm8ZlpL+u2qVfDu3ol+9HEAIAIIQ57DYN7dpSQ7u2rPN4fSvbnC4T9Mv/dx8u99v3IggBABCG6gtIUvAPs7VLS/Db9yIIAQAQYTwdZjtWWa3Kav9O1rbbpJsGtffL95IIQgAA4N8a6kX61/aDeuvL3Vq354iOVTrdG0hWOa3bI+nXQ/27IzVBCAAANOhsIalW7fL/pZsKtfvwMfdu27U7S5/toFur9xHyFMvnG8DyeQAArHPyXkkHyiqVmeSbk+7ZR8giBCEAAEKPp5/fgTsWFgAAIMAIQvXIy8tTTk6OcnNzA10KAADwEYbGGsDQGAAAoYehMQAAgAYQhAAAQMQiCAEAgIhFEAIAABGLIAQAACIWQQgAAEQszhprQO3uAqWlpQGuBAAAeKr2c7uhXYIIQg04evSoJKlNmzYBrgQAAHjr6NGjSklJqfd5NlRsgMvl0r59+5SUlCSbzWbZdUtLS9WmTRvt3buXjRp9iPvsH9xn/+A++w/32j98eZ+NMTp69Kiys7Nlt9c/E4geoQbY7Xa1bt3aZ9dPTk7mL5kfcJ/9g/vsH9xn/+Fe+4ev7vPZeoJqMVkaAABELIIQAACIWAShAImNjdX06dMVGxsb6FLCGvfZP7jP/sF99h/utX8Ew31msjQAAIhY9AgBAICIRRACAAARiyAEAAAiFkEIAABELIJQAOTl5al9+/aKi4vTwIEDtWbNmkCXFFKeeuop5ebmKikpSRkZGbrqqqu0bdu2Om0qKio0adIktWjRQs2aNdM111yj/fv312mzZ88ejRkzRgkJCcrIyNB9992nmpoaf76VkPL000/LZrPp7rvvdj/GfbbGDz/8oBtvvFEtWrRQfHy8evXqpS+//NL9vDFGjzzyiFq1aqX4+HgNHz5c27dvr3ONw4cPa/z48UpOTlZqaqp++ctfqqyszN9vJag5nU5NmzZNHTp0UHx8vDp16qQnnniizllU3GvvLV++XGPHjlV2drZsNpsWLFhQ53mr7ulXX32loUOHKi4uTm3atNEzzzxjzRsw8Kt58+aZmJgY88orr5ivv/7a/PrXvzapqalm//79gS4tZIwYMcLMmTPHbN682eTn55vRo0ebtm3bmrKyMneb22+/3bRp08YsW7bMfPnll+aCCy4wF154ofv5mpoa07NnTzN8+HCzYcMGs3jxYpOenm4eeOCBQLyloLdmzRrTvn17c95555kpU6a4H+c+N93hw4dNu3btzM0332xWr15tvvvuO/P++++bb7/91t3m6aefNikpKWbBggVm48aN5ic/+Ynp0KGDOX78uLvNyJEjTe/evc0XX3xhPv/8c3Puueea66+/PhBvKWjNmDHDtGjRwixatMjs3LnTvP3226ZZs2bm+eefd7fhXntv8eLF5qGHHjLvvPOOkWTmz59f53kr7mlJSYnJzMw048ePN5s3bzZvvvmmiY+PN3/605+aXD9ByM8GDBhgJk2a5P690+k02dnZ5qmnngpgVaHtwIEDRpL57LPPjDHGFBcXm+joaPP222+722zZssVIMqtWrTLGnPiLa7fbTVFRkbvN7NmzTXJysqmsrPTvGwhyR48eNZ07dzYffvihufjii91BiPtsjalTp5ohQ4bU+7zL5TJZWVnmd7/7nfux4uJiExsba958801jjDEFBQVGklm7dq27zZIlS4zNZjM//PCD74oPMWPGjDG33nprnceuvvpqM378eGMM99oKpwYhq+7pH//4R9O8efM6/25MnTrVdO3atck1MzTmR1VVVVq3bp2GDx/ufsxut2v48OFatWpVACsLbSUlJZKktLQ0SdK6detUXV1d5z5369ZNbdu2dd/nVatWqVevXsrMzHS3GTFihEpLS/X111/7sfrgN2nSJI0ZM6bO/ZS4z1ZZuHCh+vfvr+uuu04ZGRnq06ePXnrpJffzO3fuVFFRUZ37nJKSooEDB9a5z6mpqerfv7+7zfDhw2W327V69Wr/vZkgd+GFF2rZsmX65ptvJEkbN27UihUrNGrUKEnca1+w6p6uWrVKF110kWJiYtxtRowYoW3btunIkSNNqpFDV/3o4MGDcjqddT4UJCkzM1Nbt24NUFWhzeVy6e6779bgwYPVs2dPSVJRUZFiYmKUmppap21mZqaKiorcbc7051D7HE6YN2+e1q9fr7Vr1572HPfZGt99951mz56te+65Rw8++KDWrl2ru+66SzExMZowYYL7Pp3pPp58nzMyMuo8HxUVpbS0NO7zSe6//36VlpaqW7ducjgccjqdmjFjhsaPHy9J3GsfsOqeFhUVqUOHDqddo/a55s2bN7pGghBC2qRJk7R582atWLEi0KWEnb1792rKlCn68MMPFRcXF+hywpbL5VL//v315JNPSpL69OmjzZs368UXX9SECRMCXF14eeuttzR37ly98cYb6tGjh/Lz83X33XcrOzubex3BGBrzo/T0dDkcjtNW1ezfv19ZWVkBqip03XnnnVq0aJE++eQTtW7d2v14VlaWqqqqVFxcXKf9yfc5KyvrjH8Otc/hxNDXgQMH1LdvX0VFRSkqKkqfffaZXnjhBUVFRSkzM5P7bIFWrVopJyenzmPdu3fXnj17JP3nPp3t342srCwdOHCgzvM1NTU6fPgw9/kk9913n+6//379/Oc/V69evXTTTTfpN7/5jZ566ilJ3GtfsOqe+vLfEoKQH8XExKhfv35atmyZ+zGXy6Vly5Zp0KBBAawstBhjdOedd2r+/Pn6+OOPT+su7devn6Kjo+vc523btmnPnj3u+zxo0CBt2rSpzl++Dz/8UMnJyad9KEWqYcOGadOmTcrPz3d/9e/fX+PHj3f/mvvcdIMHDz5t+4dvvvlG7dq1kyR16NBBWVlZde5zaWmpVq9eXec+FxcXa926de42H3/8sVwulwYOHOiHdxEaysvLZbfX/dhzOBxyuVySuNe+YNU9HTRokJYvX67q6mp3mw8//FBdu3Zt0rCYJJbP+9u8efNMbGysefXVV01BQYG57bbbTGpqap1VNTi7iRMnmpSUFPPpp5+awsJC91d5ebm7ze23327atm1rPv74Y/Pll1+aQYMGmUGDBrmfr13Wffnll5v8/HyzdOlS07JlS5Z1N+DkVWPGcJ+tsGbNGhMVFWVmzJhhtm/fbubOnWsSEhLM66+/7m7z9NNPm9TUVPPPf/7TfPXVV+bKK6884/LjPn36mNWrV5sVK1aYzp07R/SS7jOZMGGCOeecc9zL59955x2Tnp5u/uu//svdhnvtvaNHj5oNGzaYDRs2GEnm2WefNRs2bDC7d+82xlhzT4uLi01mZqa56aabzObNm828efNMQkICy+dD1cyZM03btm1NTEyMGTBggPniiy8CXVJIkXTGrzlz5rjbHD9+3Nxxxx2mefPmJiEhwYwbN84UFhbWuc6uXbvMqFGjTHx8vElPTze//e1vTXV1tZ/fTWg5NQhxn63x7rvvmp49e5rY2FjTrVs38+c//7nO8y6Xy0ybNs1kZmaa2NhYM2zYMLNt27Y6bQ4dOmSuv/5606xZM5OcnGxuueUWc/ToUX++jaBXWlpqpkyZYtq2bWvi4uJMx44dzUMPPVRnSTb32nuffPLJGf9NnjBhgjHGunu6ceNGM2TIEBMbG2vOOecc8/TTT1tSv82Yk7bUBAAAiCDMEQIAABGLIAQAACIWQQgAAEQsghAAAIhYBCEAABCxCEIAACBiEYQAAEDEIggBAICIRRACAC/ZbDYtWLAg0GUAsABBCEBIufnmm2Wz2U77GjlyZKBLAxCCogJdAAB4a+TIkZozZ06dx2JjYwNUDYBQRo8QgJATGxurrKysOl/NmzeXdGLYavbs2Ro1apTi4+PVsWNH/f3vf6/z+k2bNunSSy9VfHy8WrRoodtuu01lZWV12rzyyivq0aOHYmNj1apVK9155511nj948KDGjRunhIQEde7cWQsXLvTtmwbgEwQhAGFn2rRpuuaaa7Rx40aNHz9eP//5z7VlyxZJ0rFjxzRixAg1b95ca9eu1dtvv62PPvqoTtCZPXu2Jk2apNtuu02bNm3SwoULde6559b5Ho899ph++tOf6quvvtLo0aM1fvx4HT582K/vE4AFLDnDHgD8ZMKECcbhcJjExMQ6XzNmzDDGGCPJ3H777XVeM3DgQDNx4kRjjDF//vOfTfPmzU1ZWZn7+ffee8/Y7XZTVFRkjDEmOzvbPPTQQ/XWIMk8/PDD7t+XlZUZSWbJkiWWvU8A/sEcIQAh55JLLtHs2bPrPJaWlub+9aBBg+o8N2jQIOXn50uStmzZot69eysxMdH9/ODBg+VyubRt2zbZbDbt27dPw4YNO2sN5513nvvXiYmJSk5O1oEDBxr7lgAECEEIQMhJTEw8bajKKvHx8R61i46OrvN7m80ml8vli5IA+BBzhACEnS+++OK033fv3l2S1L17d23cuFHHjh1zP79y5UrZ7XZ17dpVSUlJat++vZYtW+bXmgEEBj1CAEJOZWWlioqK6jwWFRWl9PR0SdLbb7+t/v37a8iQIZo7d67WrFmjl19+WZI0fvx4TZ8+XRMmTNCjjz6qH3/8UZMnT9ZNN92kzMxMSdKjjz6q22+/XRkZGRo1apSOHj2qlStXavLkyf59owB8jiAEIOQsXbpUrVq1qvNY165dtXXrVkknVnTNmzdPd9xxh1q1aqU333xTOTk5kqSEhAS9//77mjJlinJzc5WQkKBrrrlGzz77rPtaEyZMUEVFhf7whz/o3nvvVXp6uq699lr/vUEAfmMzxphAFwEAVrHZbJo/f76uuuqqQJcCIAQwRwgAAEQsghAAAIhYzBECEFYY7QfgDXqEAABAxCIIAQCAiEUQAgAAEYsgBAAAIhZBCAAARCyCEAAAiFgEIQAAELEIQgAAIGL9fxC5ERU1gXyyAAAAAElFTkSuQmCC\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training complete! Total training time: 766.19 seconds\n"]}],"source":["# Train the GNN model using the provided source and target graph embeddings, edges, and training data\n","trained_model = train_model_gnn(\n","    model=GIT_model,                # The GNN model to be trained (initialized earlier)\n","    x_src=x_src,                    # Source node embeddings (tensor for source graph)\n","    edge_src=edge_src,              # Source graph edges (undirected edge index for source graph)\n","    x_tgt=x_tgt,                    # Target node embeddings (tensor for target graph)\n","    edge_tgt=edge_tgt,              # Target graph edges (undirected edge index for target graph)\n","    tensor_term1=tensor_term1_o,    # Indices of source entities for training\n","    tensor_term2=tensor_term2_o,    # Indices of target entities for training\n","    tensor_score=tensor_score_o,    # Scores (labels) indicating if pairs match (1) or not (0)\n","    learning_rate=0.0001,            # Learning rate for the Adam optimizer\n","    weight_decay_value=1e-4,        # Weight decay for L2 regularization to prevent overfitting\n","    num_epochs=1000,                # Number of training epochs\n","    print_interval=10               # Interval at which to print training progress (every 10 epochs)\n",")"]},{"cell_type":"markdown","metadata":{"id":"MYyhvjcTUaae"},"source":["# GIT Application"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BZ_VqP6tq6iD"},"outputs":[],"source":["# Determine if a GPU is available and move the computations to it; otherwise, use the CPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Assuming the model has been trained and hyperparameters (x_src, edge_src, x_tgt, edge_tgt) are set\n","\n","# Move the trained GIT_model to the device (GPU or CPU)\n","GIT_model.to(device)\n","\n","# Move the data tensors to the same device (GPU or CPU)\n","x_tgt = x_tgt.to(device)         # Target node embeddings\n","edge_tgt = edge_tgt.to(device)   # Target graph edges\n","x_src = x_src.to(device)         # Source node embeddings\n","edge_src = edge_src.to(device)   # Source graph edges\n","\n","# Set the model to evaluation mode; this disables dropout and batch normalization\n","GIT_model.eval()\n","\n","# Pass the source and target embeddings through the trained GNN model to update the embeddings\n","with torch.no_grad():  # Disable gradient computation (inference mode)\n","    embeddings_tgt = GIT_model(x_tgt, edge_tgt)  # Get updated embeddings for the target graph\n","    embeddings_src = GIT_model(x_src, edge_src)  # Get updated embeddings for the source graph\n","\n","# Detach the embeddings from the computation graph and move them back to the CPU\n","# This step is useful if you need to use the embeddings for tasks outside PyTorch (e.g., saving to disk)\n","embeddings_tgt = embeddings_tgt.detach().cpu()  # Target graph embeddings\n","embeddings_src = embeddings_src.detach().cpu()  # Source graph embeddings\n","\n","# At this point, embeddings_tgt and embeddings_src contain the updated embeddings, ready for downstream tasks"]},{"cell_type":"markdown","metadata":{"id":"Og5fdoGJrTCG"},"source":["# Selecting embedding pairs to train the Gated Network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J0nTwc-dnjLn"},"outputs":[],"source":["# Read the training pairs from a CSV file into a pandas DataFrame\n","df_embeddings = pd.read_csv(train_file, index_col=0)\n","\n","# Extract columns and convert to NumPy arrays\n","tensor_term1 = df_embeddings['SrcEntity'].values.astype(int)  # Source entity indices\n","tensor_term2 = df_embeddings['TgtEntity'].values.astype(int)  # Target entity indices\n","tensor_score = df_embeddings['Score'].values.astype(float)  # Matching scores\n","\n","# Split data into training and validation sets\n","tensor_term1_train, tensor_term1_val, tensor_term2_train, tensor_term2_val, tensor_score_train, tensor_score_val = train_test_split(\n","    tensor_term1, tensor_term2, tensor_score, test_size=0.3, random_state=42\n",")\n","\n","# Convert split data to PyTorch tensors\n","tensor_term1_train = torch.from_numpy(tensor_term1_train).type(torch.LongTensor)\n","tensor_term2_train = torch.from_numpy(tensor_term2_train).type(torch.LongTensor)\n","tensor_score_train = torch.from_numpy(tensor_score_train).type(torch.FloatTensor)\n","\n","tensor_term1_val = torch.from_numpy(tensor_term1_val).type(torch.LongTensor)\n","tensor_term2_val = torch.from_numpy(tensor_term2_val).type(torch.LongTensor)\n","tensor_score_val = torch.from_numpy(tensor_score_val).type(torch.FloatTensor)\n","\n","# Move the embeddings back to the CPU if not already there\n","x_tgt = x_tgt.cpu()  # Target node embeddings\n","x_src = x_src.cpu()  # Source node embeddings\n","\n","# Select embeddings for the training set\n","X1_train = select_rows_by_index(embeddings_src, tensor_term1_train)\n","X2_train = select_rows_by_index(x_src, tensor_term1_train)\n","X3_train = select_rows_by_index(embeddings_tgt, tensor_term2_train)\n","X4_train = select_rows_by_index(x_tgt, tensor_term2_train)\n","\n","# Select embeddings for the validation set\n","X1_val = select_rows_by_index(embeddings_src, tensor_term1_val)\n","X2_val = select_rows_by_index(x_src, tensor_term1_val)\n","X3_val = select_rows_by_index(embeddings_tgt, tensor_term2_val)\n","X4_val = select_rows_by_index(x_tgt, tensor_term2_val)\n","\n","# Now you have:\n","# - Training tensors: X1_train, X2_train, X3_train, X4_train, tensor_score_train\n","# - Validation tensors: X1_val, X2_val, X3_val, X4_val, tensor_score_val"]},{"cell_type":"markdown","metadata":{"id":"fNdCgaTMExPK"},"source":["# Gated Network Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gof1eIPIWSVU"},"outputs":[],"source":["from sklearn.metrics import f1_score\n","\n","def train_gated_combination_model(X1_t, X2_t, X3_t, X4_t, tensor_score_o,\n","                                  X1_val, X2_val, X3_val, X4_val, tensor_score_val,\n","                                  epochs=120, batch_size=32, learning_rate=0.001, weight_decay=1e-5):\n","    \"\"\"\n","    Trains the GatedCombination model with training and validation data, using ReduceLROnPlateau scheduler.\n","    Also calculates and displays F1-score during training and validation.\n","    \"\"\"\n","\n","    # Create datasets and DataLoaders\n","    train_dataset = TensorDataset(X1_t, X2_t, X3_t, X4_t, tensor_score_o)\n","    val_dataset = TensorDataset(X1_val, X2_val, X3_val, X4_val, tensor_score_val)\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = GatedCombination(X1_t.shape[1]).to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","\n","    # Use ReduceLROnPlateau scheduler\n","    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n","\n","    train_losses, val_losses = [], []\n","\n","    start_time = time.time()\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        total_train_loss = 0.0\n","        y_true_train, y_pred_train = [], []\n","\n","        for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in train_loader:\n","            batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (\n","                batch_X1.to(device),\n","                batch_X2.to(device),\n","                batch_X3.to(device),\n","                batch_X4.to(device),\n","                batch_y.to(device),\n","            )\n","            optimizer.zero_grad()\n","\n","            # Forward pass\n","            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","\n","            # Compute loss\n","            loss = F.binary_cross_entropy(outputs, batch_y.unsqueeze(1).float())\n","            loss.backward()\n","            optimizer.step()\n","            total_train_loss += loss.item()\n","\n","            # Store true labels and predictions for F1-score\n","            y_true_train.extend(batch_y.cpu().numpy())\n","            y_pred_train.extend((outputs > 0.5).float().cpu().numpy())\n","\n","        train_loss = total_train_loss / len(train_loader)\n","        train_losses.append(train_loss)\n","\n","        # Calculate F1-score for training\n","        train_f1 = f1_score(y_true_train, y_pred_train)\n","\n","        # Validation phase\n","        model.eval()\n","        total_val_loss = 0.0\n","        y_true_val, y_pred_val = [], []\n","\n","        with torch.no_grad():\n","            for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in val_loader:\n","                batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (\n","                    batch_X1.to(device),\n","                    batch_X2.to(device),\n","                    batch_X3.to(device),\n","                    batch_X4.to(device),\n","                    batch_y.to(device),\n","                )\n","                outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","\n","                # Compute loss\n","                val_loss = F.binary_cross_entropy(outputs, batch_y.unsqueeze(1).float())\n","                total_val_loss += val_loss.item()\n","\n","                # Store true labels and predictions for F1-score\n","                y_true_val.extend(batch_y.cpu().numpy())\n","                y_pred_val.extend((outputs > 0.5).float().cpu().numpy())\n","\n","        avg_val_loss = total_val_loss / len(val_loader)\n","        val_losses.append(avg_val_loss)\n","\n","        # Calculate F1-score for validation\n","        val_f1 = f1_score(y_true_val, y_pred_val)\n","\n","        # Step the scheduler with validation loss\n","        scheduler.step(avg_val_loss)\n","\n","        # Print training and validation metrics\n","        print(f\"Epoch [{epoch + 1}/{epochs}] Training Loss: {train_loss:.4f}, F1 Score: {train_f1:.4f} | \"\n","              f\"Validation Loss: {avg_val_loss:.4f}, F1 Score: {val_f1:.4f}\")\n","\n","    end_time = time.time()\n","\n","    # Plotting training and validation loss\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(train_losses, label=\"Training Loss\", marker='o')\n","    plt.plot(val_losses, label=\"Validation Loss\", marker='x')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    print(f\"Training complete! Total time: {end_time - start_time:.2f} seconds\")\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l11dgb8ei69T","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1734687876349,"user_tz":-60,"elapsed":861535,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"fc898738-8ac0-45af-f5ee-9e01a7fa88d7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/100] Training Loss: 0.4193, F1 Score: 0.0241 | Validation Loss: 0.2019, F1 Score: 0.0000\n","Epoch [2/100] Training Loss: 0.1516, F1 Score: 0.0000 | Validation Loss: 0.1260, F1 Score: 0.0000\n","Epoch [3/100] Training Loss: 0.1159, F1 Score: 0.0000 | Validation Loss: 0.1126, F1 Score: 0.0000\n","Epoch [4/100] Training Loss: 0.1103, F1 Score: 0.0000 | Validation Loss: 0.1115, F1 Score: 0.0000\n","Epoch [5/100] Training Loss: 0.1097, F1 Score: 0.0000 | Validation Loss: 0.1109, F1 Score: 0.0000\n","Epoch [6/100] Training Loss: 0.1092, F1 Score: 0.0000 | Validation Loss: 0.1104, F1 Score: 0.0000\n","Epoch [7/100] Training Loss: 0.1084, F1 Score: 0.0000 | Validation Loss: 0.1096, F1 Score: 0.0000\n","Epoch [8/100] Training Loss: 0.1074, F1 Score: 0.0000 | Validation Loss: 0.1086, F1 Score: 0.0000\n","Epoch [9/100] Training Loss: 0.1063, F1 Score: 0.0000 | Validation Loss: 0.1075, F1 Score: 0.0000\n","Epoch [10/100] Training Loss: 0.1050, F1 Score: 0.0000 | Validation Loss: 0.1058, F1 Score: 0.0000\n","Epoch [11/100] Training Loss: 0.1033, F1 Score: 0.0000 | Validation Loss: 0.1039, F1 Score: 0.0000\n","Epoch [12/100] Training Loss: 0.1014, F1 Score: 0.0000 | Validation Loss: 0.1019, F1 Score: 0.0000\n","Epoch [13/100] Training Loss: 0.0991, F1 Score: 0.0000 | Validation Loss: 0.0993, F1 Score: 0.0000\n","Epoch [14/100] Training Loss: 0.0953, F1 Score: 0.0000 | Validation Loss: 0.0918, F1 Score: 0.0000\n","Epoch [15/100] Training Loss: 0.0848, F1 Score: 0.0000 | Validation Loss: 0.0803, F1 Score: 0.0000\n","Epoch [16/100] Training Loss: 0.0736, F1 Score: 0.0000 | Validation Loss: 0.0690, F1 Score: 0.0000\n","Epoch [17/100] Training Loss: 0.0630, F1 Score: 0.0000 | Validation Loss: 0.0589, F1 Score: 0.0000\n","Epoch [18/100] Training Loss: 0.0534, F1 Score: 0.0000 | Validation Loss: 0.0496, F1 Score: 0.0000\n","Epoch [19/100] Training Loss: 0.0451, F1 Score: 0.0000 | Validation Loss: 0.0418, F1 Score: 0.0000\n","Epoch [20/100] Training Loss: 0.0380, F1 Score: 0.2473 | Validation Loss: 0.0354, F1 Score: 0.4632\n","Epoch [21/100] Training Loss: 0.0323, F1 Score: 0.5464 | Validation Loss: 0.0303, F1 Score: 0.6445\n","Epoch [22/100] Training Loss: 0.0276, F1 Score: 0.7139 | Validation Loss: 0.0259, F1 Score: 0.7365\n","Epoch [23/100] Training Loss: 0.0240, F1 Score: 0.7804 | Validation Loss: 0.0232, F1 Score: 0.8174\n","Epoch [24/100] Training Loss: 0.0211, F1 Score: 0.8346 | Validation Loss: 0.0203, F1 Score: 0.8515\n","Epoch [25/100] Training Loss: 0.0188, F1 Score: 0.8690 | Validation Loss: 0.0182, F1 Score: 0.8679\n","Epoch [26/100] Training Loss: 0.0171, F1 Score: 0.8820 | Validation Loss: 0.0167, F1 Score: 0.8939\n","Epoch [27/100] Training Loss: 0.0156, F1 Score: 0.8994 | Validation Loss: 0.0154, F1 Score: 0.9009\n","Epoch [28/100] Training Loss: 0.0146, F1 Score: 0.9027 | Validation Loss: 0.0144, F1 Score: 0.9066\n","Epoch [29/100] Training Loss: 0.0137, F1 Score: 0.9136 | Validation Loss: 0.0137, F1 Score: 0.9109\n","Epoch [30/100] Training Loss: 0.0130, F1 Score: 0.9211 | Validation Loss: 0.0132, F1 Score: 0.9202\n","Epoch [31/100] Training Loss: 0.0124, F1 Score: 0.9241 | Validation Loss: 0.0127, F1 Score: 0.9202\n","Epoch [32/100] Training Loss: 0.0120, F1 Score: 0.9287 | Validation Loss: 0.0122, F1 Score: 0.9320\n","Epoch [33/100] Training Loss: 0.0116, F1 Score: 0.9323 | Validation Loss: 0.0118, F1 Score: 0.9294\n","Epoch [34/100] Training Loss: 0.0113, F1 Score: 0.9363 | Validation Loss: 0.0117, F1 Score: 0.9333\n","Epoch [35/100] Training Loss: 0.0110, F1 Score: 0.9369 | Validation Loss: 0.0114, F1 Score: 0.9333\n","Epoch [36/100] Training Loss: 0.0108, F1 Score: 0.9369 | Validation Loss: 0.0112, F1 Score: 0.9361\n","Epoch [37/100] Training Loss: 0.0106, F1 Score: 0.9392 | Validation Loss: 0.0111, F1 Score: 0.9307\n","Epoch [38/100] Training Loss: 0.0105, F1 Score: 0.9388 | Validation Loss: 0.0111, F1 Score: 0.9373\n","Epoch [39/100] Training Loss: 0.0103, F1 Score: 0.9404 | Validation Loss: 0.0109, F1 Score: 0.9361\n","Epoch [40/100] Training Loss: 0.0102, F1 Score: 0.9399 | Validation Loss: 0.0107, F1 Score: 0.9361\n","Epoch [41/100] Training Loss: 0.0101, F1 Score: 0.9393 | Validation Loss: 0.0107, F1 Score: 0.9399\n","Epoch [42/100] Training Loss: 0.0100, F1 Score: 0.9410 | Validation Loss: 0.0105, F1 Score: 0.9386\n","Epoch [43/100] Training Loss: 0.0100, F1 Score: 0.9404 | Validation Loss: 0.0103, F1 Score: 0.9386\n","Epoch [44/100] Training Loss: 0.0099, F1 Score: 0.9399 | Validation Loss: 0.0103, F1 Score: 0.9399\n","Epoch [45/100] Training Loss: 0.0098, F1 Score: 0.9449 | Validation Loss: 0.0104, F1 Score: 0.9373\n","Epoch [46/100] Training Loss: 0.0098, F1 Score: 0.9416 | Validation Loss: 0.0102, F1 Score: 0.9386\n","Epoch [47/100] Training Loss: 0.0098, F1 Score: 0.9417 | Validation Loss: 0.0103, F1 Score: 0.9373\n","Epoch [48/100] Training Loss: 0.0097, F1 Score: 0.9411 | Validation Loss: 0.0105, F1 Score: 0.9373\n","Epoch [49/100] Training Loss: 0.0097, F1 Score: 0.9416 | Validation Loss: 0.0103, F1 Score: 0.9399\n","Epoch [50/100] Training Loss: 0.0097, F1 Score: 0.9422 | Validation Loss: 0.0103, F1 Score: 0.9412\n","Epoch [51/100] Training Loss: 0.0097, F1 Score: 0.9421 | Validation Loss: 0.0102, F1 Score: 0.9361\n","Epoch [52/100] Training Loss: 0.0096, F1 Score: 0.9432 | Validation Loss: 0.0102, F1 Score: 0.9412\n","Epoch [53/100] Training Loss: 0.0096, F1 Score: 0.9439 | Validation Loss: 0.0100, F1 Score: 0.9399\n","Epoch [54/100] Training Loss: 0.0096, F1 Score: 0.9400 | Validation Loss: 0.0103, F1 Score: 0.9399\n","Epoch [55/100] Training Loss: 0.0096, F1 Score: 0.9434 | Validation Loss: 0.0102, F1 Score: 0.9412\n","Epoch [56/100] Training Loss: 0.0096, F1 Score: 0.9406 | Validation Loss: 0.0102, F1 Score: 0.9424\n","Epoch [57/100] Training Loss: 0.0096, F1 Score: 0.9434 | Validation Loss: 0.0103, F1 Score: 0.9386\n","Epoch [58/100] Training Loss: 0.0096, F1 Score: 0.9439 | Validation Loss: 0.0102, F1 Score: 0.9386\n","Epoch [59/100] Training Loss: 0.0095, F1 Score: 0.9433 | Validation Loss: 0.0101, F1 Score: 0.9412\n","Epoch [60/100] Training Loss: 0.0095, F1 Score: 0.9450 | Validation Loss: 0.0102, F1 Score: 0.9386\n","Epoch [61/100] Training Loss: 0.0095, F1 Score: 0.9406 | Validation Loss: 0.0106, F1 Score: 0.9399\n","Epoch [62/100] Training Loss: 0.0095, F1 Score: 0.9455 | Validation Loss: 0.0100, F1 Score: 0.9386\n","Epoch [63/100] Training Loss: 0.0095, F1 Score: 0.9459 | Validation Loss: 0.0102, F1 Score: 0.9386\n","Epoch [64/100] Training Loss: 0.0095, F1 Score: 0.9450 | Validation Loss: 0.0101, F1 Score: 0.9386\n","Epoch [65/100] Training Loss: 0.0095, F1 Score: 0.9427 | Validation Loss: 0.0100, F1 Score: 0.9412\n","Epoch [66/100] Training Loss: 0.0095, F1 Score: 0.9422 | Validation Loss: 0.0100, F1 Score: 0.9399\n","Epoch [67/100] Training Loss: 0.0095, F1 Score: 0.9417 | Validation Loss: 0.0103, F1 Score: 0.9386\n","Epoch [68/100] Training Loss: 0.0095, F1 Score: 0.9439 | Validation Loss: 0.0102, F1 Score: 0.9399\n","Epoch [69/100] Training Loss: 0.0095, F1 Score: 0.9411 | Validation Loss: 0.0101, F1 Score: 0.9373\n","Epoch [70/100] Training Loss: 0.0095, F1 Score: 0.9422 | Validation Loss: 0.0101, F1 Score: 0.9424\n","Epoch [71/100] Training Loss: 0.0095, F1 Score: 0.9439 | Validation Loss: 0.0100, F1 Score: 0.9399\n","Epoch [72/100] Training Loss: 0.0095, F1 Score: 0.9416 | Validation Loss: 0.0103, F1 Score: 0.9386\n","Epoch [73/100] Training Loss: 0.0095, F1 Score: 0.9422 | Validation Loss: 0.0104, F1 Score: 0.9386\n","Epoch [74/100] Training Loss: 0.0095, F1 Score: 0.9428 | Validation Loss: 0.0100, F1 Score: 0.9399\n","Epoch [75/100] Training Loss: 0.0095, F1 Score: 0.9433 | Validation Loss: 0.0101, F1 Score: 0.9412\n","Epoch [76/100] Training Loss: 0.0095, F1 Score: 0.9444 | Validation Loss: 0.0102, F1 Score: 0.9361\n","Epoch 00077: reducing learning rate of group 0 to 1.0000e-04.\n","Epoch [77/100] Training Loss: 0.0095, F1 Score: 0.9399 | Validation Loss: 0.0105, F1 Score: 0.9399\n","Epoch [78/100] Training Loss: 0.0094, F1 Score: 0.9494 | Validation Loss: 0.0100, F1 Score: 0.9450\n","Epoch [79/100] Training Loss: 0.0093, F1 Score: 0.9489 | Validation Loss: 0.0100, F1 Score: 0.9412\n","Epoch [80/100] Training Loss: 0.0093, F1 Score: 0.9478 | Validation Loss: 0.0100, F1 Score: 0.9424\n","Epoch [81/100] Training Loss: 0.0093, F1 Score: 0.9473 | Validation Loss: 0.0100, F1 Score: 0.9424\n","Epoch [82/100] Training Loss: 0.0093, F1 Score: 0.9461 | Validation Loss: 0.0100, F1 Score: 0.9399\n","Epoch [83/100] Training Loss: 0.0093, F1 Score: 0.9467 | Validation Loss: 0.0100, F1 Score: 0.9412\n","Epoch [84/100] Training Loss: 0.0093, F1 Score: 0.9461 | Validation Loss: 0.0100, F1 Score: 0.9412\n","Epoch [85/100] Training Loss: 0.0094, F1 Score: 0.9461 | Validation Loss: 0.0100, F1 Score: 0.9412\n","Epoch [86/100] Training Loss: 0.0093, F1 Score: 0.9467 | Validation Loss: 0.0100, F1 Score: 0.9399\n","Epoch [87/100] Training Loss: 0.0094, F1 Score: 0.9450 | Validation Loss: 0.0100, F1 Score: 0.9399\n","Epoch [88/100] Training Loss: 0.0094, F1 Score: 0.9467 | Validation Loss: 0.0100, F1 Score: 0.9412\n","Epoch [89/100] Training Loss: 0.0094, F1 Score: 0.9467 | Validation Loss: 0.0100, F1 Score: 0.9399\n","Epoch 00090: reducing learning rate of group 0 to 1.0000e-05.\n","Epoch [90/100] Training Loss: 0.0094, F1 Score: 0.9456 | Validation Loss: 0.0100, F1 Score: 0.9412\n","Epoch [91/100] Training Loss: 0.0093, F1 Score: 0.9473 | Validation Loss: 0.0100, F1 Score: 0.9399\n","Epoch [92/100] Training Loss: 0.0093, F1 Score: 0.9473 | Validation Loss: 0.0100, F1 Score: 0.9399\n","Epoch [93/100] Training Loss: 0.0093, F1 Score: 0.9473 | Validation Loss: 0.0100, F1 Score: 0.9399\n","Epoch [94/100] Training Loss: 0.0093, F1 Score: 0.9473 | Validation Loss: 0.0100, F1 Score: 0.9399\n","Epoch [95/100] Training Loss: 0.0093, F1 Score: 0.9473 | Validation Loss: 0.0100, F1 Score: 0.9399\n","Epoch [96/100] Training Loss: 0.0093, F1 Score: 0.9473 | Validation Loss: 0.0100, F1 Score: 0.9399\n","Epoch [97/100] Training Loss: 0.0093, F1 Score: 0.9467 | Validation Loss: 0.0100, F1 Score: 0.9399\n","Epoch [98/100] Training Loss: 0.0093, F1 Score: 0.9467 | Validation Loss: 0.0100, F1 Score: 0.9399\n","Epoch [99/100] Training Loss: 0.0093, F1 Score: 0.9473 | Validation Loss: 0.0100, F1 Score: 0.9399\n","Epoch [100/100] Training Loss: 0.0093, F1 Score: 0.9467 | Validation Loss: 0.0100, F1 Score: 0.9399\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x500 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training complete! Total time: 861.18 seconds\n"]}],"source":["# Train the GatedCombination model using training and validation data\n","trained_model = train_gated_combination_model(\n","    X1_train,          # Updated source embeddings (after applying the GNN model)\n","    X2_train,          # Original source embeddings (before applying the GNN model)\n","    X3_train,          # Updated target embeddings (after applying the GNN model)\n","    X4_train,          # Original target embeddings (before applying the GNN model)\n","    tensor_score_train, # Ground truth labels for the training set (1 for matched pairs, 0 for unmatched pairs)\n","\n","    X1_val,            # Updated source embeddings for the validation set\n","    X2_val,            # Original source embeddings for the validation set\n","    X3_val,            # Updated target embeddings for the validation set\n","    X4_val,            # Original target embeddings for the validation set\n","    tensor_score_val,  # Ground truth labels for the validation set (1 for matched pairs, 0 for unmatched pairs)\n","\n","    epochs=100,        # Number of epochs (iterations over the entire training dataset)\n","    batch_size=32,     # Number of training samples processed in one forward/backward pass\n","    learning_rate=0.001, # Learning rate for the optimizer (controls step size during optimization)\n","    weight_decay=1e-4  # Weight decay (L2 regularization) to prevent overfitting\n",")"]},{"cell_type":"markdown","metadata":{"id":"uAmLuMtGW9c2"},"source":["# **Mappings Selector**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lnFtpUAfJQHl"},"outputs":[],"source":["# Build an indexed dictionary for the source ontology classes\n","# src_class is the file path to the JSON file containing the source ontology classes\n","indexed_dict_src = build_indexed_dict(src_class)\n","\n","# Build an indexed dictionary for the target ontology classes\n","# tgt_class is the file path to the JSON file containing the target ontology classes\n","indexed_dict_tgt = build_indexed_dict(tgt_class)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"beipwavuJQHl"},"outputs":[],"source":["# Read the candidate pairs from a Candidates CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(candidates_Prediction, index_col=0)\n","\n","# Extract the 'SrcEntity' column (source entity indices) and convert it to a NumPy array of integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)\n","\n","# Extract the 'TgtEntity' column (target entity indices) and convert it to a NumPy array of integers\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)\n","\n","# Convert the source entity indices to a PyTorch LongTensor\n","src_entity_tensor_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)\n","\n","# Convert the target entity indices to a PyTorch LongTensor\n","tgt_entity_tenso_or = torch.from_numpy(tensor_term2).type(torch.LongTensor)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ECLhmxyKJQHl"},"outputs":[],"source":["# Select rows from the updated source embeddings based on the indices in src_entity_tensor_o\n","X1_tt = select_rows_by_index(embeddings_src, src_entity_tensor_o)\n","\n","# Select rows from the original source embeddings based on the indices in src_entity_tensor_o\n","X2_tt = select_rows_by_index(x_src, src_entity_tensor_o)\n","\n","# Select rows from the updated target embeddings based on the indices in tgt_entity_tenso_or\n","X3_tt = select_rows_by_index(embeddings_tgt, tgt_entity_tenso_or)\n","\n","# Select rows from the original target embeddings based on the indices in tgt_entity_tenso_or\n","X4_tt = select_rows_by_index(x_tgt, tgt_entity_tenso_or)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UFP6OQR-7D4N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734687917181,"user_tz":-60,"elapsed":39256,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"429d43ec-f0fe-4827-c5d0-c28ad9caba2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting time: 15.49 seconds\n","Predictions saved to /content/gdrive/My Drive/BioGITOM-VLDB/ncit2doid/Results/ncit2doid_all_predictions.tsv\n"]}],"source":["# Generate predictions for candidate mappings using the trained GatedCombination model\n","Prediction_with_candidates(\n","    model=trained_model,             # The trained GatedCombination model used to evaluate similarity\n","    X1_tt=X1_tt,                     # Updated source embeddings (after applying the GIT model)\n","    X2_tt=X2_tt,                     # Original source embeddings (before applying the GIT model)\n","    X3_tt=X3_tt,                     # Updated target embeddings (after applying the GIT model)\n","    X4_tt=X4_tt,                     # Original target embeddings (before applying the GIT model)\n","    src_entity_tensor_o=src_entity_tensor_o,  # Tensor of source entity indices used for evaluation\n","    tgt_entity_tensor_o=tgt_entity_tenso_or,  # Tensor of target entity indices used for evaluation\n","    indexed_dict_src=indexed_dict_src,        # Dictionary mapping source entity indices to their URIs\n","    indexed_dict_tgt=indexed_dict_tgt,        # Dictionary mapping target entity indices to their URIs\n","    all_predictions_path=all_predictions_path # Path to save all predictions with similarity scores in TSV format\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mEc12J-B7D4N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734687933061,"user_tz":-60,"elapsed":15891,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"be94f566-0563-4a6a-934f-9616ff963f88"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Positive predictions: 3217\n"]}],"source":["# Filter the highest scoring predictions from the predictions file and save the results to a new file\n","matching_results_df = filter_highest_predictions(\n","    all_predictions_path,  # Path to the file containing all predictions with scores for all candidate pairs\n","    prediction_path        # Path where the filtered predictions with highest scores will be saved\n",")"]},{"cell_type":"markdown","metadata":{"id":"BIx74lNV7D4O"},"source":["# **Evaluation**"]},{"cell_type":"markdown","metadata":{"id":"Pp3IpBBfWn9m"},"source":["# Global metrics calculation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bkOewzXr7D4O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734687933871,"user_tz":-60,"elapsed":814,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"0b708f0d-e033-4cd9-bea5-3c8f0b3af493"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Correct Predictions: 2946\n","{'P': 0.916, 'R': 0.898, 'F1': 0.907}\n"]}],"source":["# Retrieve the indices of the ignored classes (from source and target ontologies)\n","ignored_class_index = get_ignored_class_index(src_onto)  # Get ignored class indices from source ontology\n","ignored_class_index.update(get_ignored_class_index(tgt_onto))  # Update with ignored class indices from target ontology\n","\n","# Read the predicted mappings from the prediction results file\n","preds = EntityMapping.read_table_mappings(prediction_path)\n","\n","# Read the reference mappings from the ground truth test file\n","refs = ReferenceMapping.read_table_mappings(f\"{dataset_dir}/refs_equiv/test.tsv\")\n","\n","# Filter the predicted mappings to remove any mappings that involve ignored classes\n","preds = remove_ignored_mappings(preds, ignored_class_index)\n","\n","# Compute the precision, recall, and F1-score by comparing predictions with the reference mappings\n","results = AlignmentEvaluator.f1(preds, refs)\n","\n","preds2 = [p.to_tuple() for p in preds]\n","refs2 = [r.to_tuple() for r in refs]\n","\n","correct= len(set(preds2).intersection(set(refs2)))\n","\n","print(f\"Number of Correct Predictions: {correct}\")\n","\n","# Print the computed precision, recall, and F1-score metrics\n","print(results)"]},{"cell_type":"markdown","metadata":{"id":"aECB6igZW04C"},"source":["# Ranked-based metrics calculation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-AK-jADkSbTa"},"outputs":[],"source":["# Read the candidate pairs from a Candidates CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(candidates_Rank, index_col=0)\n","\n","# Extract the 'SrcEntity' column (source entity indices) and convert it to a NumPy array of integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)\n","\n","# Extract the 'TgtEntity' column (target entity indices) and convert it to a NumPy array of integers\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)\n","\n","# Convert the source entity indices to a PyTorch LongTensor\n","src_entity_tensor_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)\n","\n","# Convert the target entity indices to a PyTorch LongTensor\n","tgt_entity_tenso_or = torch.from_numpy(tensor_term2).type(torch.LongTensor)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oyOzcLv-SbTb"},"outputs":[],"source":["# Select rows from the updated source embeddings based on the indices in src_entity_tensor_o\n","X1_tt = select_rows_by_index(embeddings_src, src_entity_tensor_o)\n","\n","# Select rows from the original source embeddings based on the indices in src_entity_tensor_o\n","X2_tt = select_rows_by_index(x_src, src_entity_tensor_o)\n","\n","# Select rows from the updated target embeddings based on the indices in tgt_entity_tenso_or\n","X3_tt = select_rows_by_index(embeddings_tgt, tgt_entity_tenso_or)\n","\n","# Select rows from the original target embeddings based on the indices in tgt_entity_tenso_or\n","X4_tt = select_rows_by_index(x_tgt, tgt_entity_tenso_or)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-O2f7X6cSb-m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734687972385,"user_tz":-60,"elapsed":37463,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"bf6ab3a3-e5cc-4d16-c92b-50b15225046b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting time: 14.64 seconds\n","Predictions saved to /content/gdrive/My Drive/BioGITOM-VLDB/ncit2doid/Results/ncit2doid_all_predictions_ranked.tsv\n"]}],"source":["# Perform ranking-based predictions using the trained GatedCombination model\n","# Generate predictions for candidate mappings using the trained GatedCombination model\n","Prediction_with_candidates(\n","    model=trained_model,             # The trained GatedCombination model used to evaluate similarity\n","    X1_tt=X1_tt,                     # Updated source embeddings (after applying the GIT model)\n","    X2_tt=X2_tt,                     # Original source embeddings (before applying the GIT model)\n","    X3_tt=X3_tt,                     # Updated target embeddings (after applying the GIT model)\n","    X4_tt=X4_tt,                     # Original target embeddings (before applying the GIT model)\n","    src_entity_tensor_o=src_entity_tensor_o,  # Tensor of source entity indices used for evaluation\n","    tgt_entity_tensor_o=tgt_entity_tenso_or,  # Tensor of target entity indices used for evaluation\n","    indexed_dict_src=indexed_dict_src,        # Dictionary mapping source entity indices to their URIs\n","    indexed_dict_tgt=indexed_dict_tgt,        # Dictionary mapping target entity indices to their URIs\n","    all_predictions_path=all_predictions_path_ranked, # Path where the ranked predictions will be saved in TSV format\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_402seVv7D4O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734687991225,"user_tz":-60,"elapsed":18844,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"9e6e0a4c-d8ef-49a8-a15c-860f9ab76a92"},"outputs":[{"output_type":"stream","name":"stdout","text":["MRR and Hits@k Results:\n","{'MRR': 0.9344311332059976, 'Hits@k': {1: 0.8957317073170732, 5: 0.9820121951219513, 10: 0.9917682926829269}}\n"]}],"source":["# Compute MRR and Hits@k metrics\n","# This function evaluates the predicted rankings against the reference mappings\n","results = compute_mrr_and_hits(\n","    reference_file=test_cands,             # Reference file with true ranks\n","    predicted_file=all_predictions_path_ranked,             # File containing predicted rankings\n","    output_file=formatted_predictions_path,    # File path to save formatted predictions\n","    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",")\n","\n","# Display the computed metrics\n","print(\"MRR and Hits@k Results:\")\n","print(results)  # Output the Mean Reciprocal Rank (MRR) and Hits@k metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wStfa4eZ7D4O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734687994951,"user_tz":-60,"elapsed":3738,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"cead8d22-cf6d-46f2-d8f1-4d26a19840ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ranking Evaluation Results at K=1, 5, and 10:\n","{'MRR': 0.9344311332059976, 'Hits@1': 0.8957317073170732, 'Hits@5': 0.9820121951219513, 'Hits@10': 0.9917682926829269}\n"]}],"source":["# Call the ranking evaluation function, passing the path to the formatted predictions file.\n","# Ks specifies the evaluation levels, checking if the correct target is within the top K candidates.\n","results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n","print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n","print(results)"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}