{"cells":[{"cell_type":"markdown","metadata":{"id":"MkAX88H3RNRW"},"source":["# **Package Installation**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SlL2v0xgmFJ-","outputId":"55f1473f-d864-41f6-e392-fb2fa1399cbe","executionInfo":{"status":"ok","timestamp":1734709349080,"user_tz":-60,"elapsed":204170,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==2.0.0\n","  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.16.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n","  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n","  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n","  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n","  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n","  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n","  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.0.0 (from torch==2.0.0)\n","  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (75.1.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.45.1)\n","Collecting cmake (from triton==2.0.0->torch==2.0.0)\n","  Downloading cmake-3.31.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n","Collecting lit (from triton==2.0.0->torch==2.0.0)\n","  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n","Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m810.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cmake-3.31.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.8/27.8 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, cmake, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.1+cpu\n","    Uninstalling torch-2.5.1+cpu:\n","      Successfully uninstalled torch-2.5.1+cpu\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.5.1+cpu requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\n","torchvision 0.20.1+cpu requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed cmake-3.31.2 lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 triton-2.0.0\n","Collecting torch-geometric==2.4.0\n","  Downloading torch_geometric-2.4.0-py3-none-any.whl.metadata (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (4.67.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (3.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (2.32.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (3.2.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.6.0)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric==2.4.0) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (2024.12.14)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.4.0) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.4.0) (3.5.0)\n","Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-geometric\n","Successfully installed torch-geometric-2.4.0\n","Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_scatter-2.1.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (494 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_sparse-0.6.18%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-cluster\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_cluster-1.6.3%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (751 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.3/751.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-spline-conv\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (208 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n","Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n","Installing collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster\n","Successfully installed torch-cluster-1.6.3+pt20cpu torch-scatter-2.1.2+pt20cpu torch-sparse-0.6.18+pt20cpu torch-spline-conv-1.2.2+pt20cpu\n","Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.67.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.6.0)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.12.14)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting deeponto\n","  Downloading deeponto-0.9.2-py3-none-any.whl.metadata (15 kB)\n","Collecting JPype1 (from deeponto)\n","  Downloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting yacs (from deeponto)\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deeponto) (2.0.0)\n","Collecting anytree (from deeponto)\n","  Downloading anytree-2.12.1-py3-none-any.whl.metadata (8.1 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from deeponto) (8.1.7)\n","Collecting dill (from deeponto)\n","  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from deeponto) (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deeponto) (1.26.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deeponto) (1.6.0)\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (from deeponto) (4.47.0)\n","Collecting datasets (from deeponto)\n","  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.7.5)\n","Collecting pprintpp (from deeponto)\n","  Downloading pprintpp-0.4.0-py2.py3-none-any.whl.metadata (7.9 kB)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.4.2)\n","Collecting lxml (from deeponto)\n","  Downloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n","Collecting textdistance (from deeponto)\n","  Downloading textdistance-4.6.3-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from deeponto) (7.7.1)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from deeponto) (5.5.6)\n","Collecting enlighten (from deeponto)\n","  Downloading enlighten-1.13.0-py2.py3-none-any.whl.metadata (18 kB)\n","Collecting rdflib (from deeponto)\n","  Downloading rdflib-7.1.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.9.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anytree->deeponto) (1.17.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (18.1.0)\n","Collecting dill (from deeponto)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (4.67.1)\n","Collecting xxhash (from datasets->deeponto)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets->deeponto)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->deeponto)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (3.11.11)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (0.27.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (6.0.2)\n","Collecting blessed>=1.17.7 (from enlighten->deeponto)\n","  Downloading blessed-1.20.0-py2.py3-none-any.whl.metadata (13 kB)\n","Collecting prefixed>=0.3.2 (from enlighten->deeponto)\n","  Downloading prefixed-0.9.0-py2.py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (0.2.0)\n","Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (7.34.0)\n","Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (5.7.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (6.1.12)\n","Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (6.3.3)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->deeponto) (3.6.10)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->deeponto) (3.0.13)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->deeponto) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->deeponto) (2024.11.6)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2024.2)\n","Collecting isodate<1.0.0,>=0.7.2 (from rdflib->deeponto)\n","  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib->deeponto) (3.2.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deeponto) (1.13.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deeponto) (3.5.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.0.11)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.0.10)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.5.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (0.15.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.10.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.1.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (75.1.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.5.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (1.13.1)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (2.0.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->deeponto) (0.45.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deeponto) (3.31.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deeponto) (18.1.8)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (0.4.5)\n","Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (1.2.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->transformers[torch]->deeponto) (5.9.5)\n","Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.7->enlighten->deeponto) (0.2.13)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.3.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (5.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (24.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.18.3)\n","Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->deeponto)\n","  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (5.1.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (3.0.48)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (2.18.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (4.9.0)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (2.27.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (2024.12.14)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->deeponto) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->deeponto) (0.1.5)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (0.20.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (7.0.5)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.5.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy->deeponto) (3.0.2)\n","Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->deeponto) (5.7.2)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->deeponto) (24.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deeponto) (1.3.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->deeponto) (0.8.4)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel->deeponto) (4.3.6)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.2.1)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (23.1.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (5.10.4)\n","Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (7.16.4)\n","Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.6.0)\n","Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.3)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.18.1)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.21.1)\n","Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.1.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel->deeponto) (0.7.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (3.0.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->deeponto) (1.14.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (0.1.2)\n","Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.2.4)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.12.3)\n","Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.2.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.7.1)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.3.0)\n","Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.0.2)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.10.1)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.5.1)\n","Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.4.0)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.21.1)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.23.0)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (21.2.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.5.1)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.22.3)\n","Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.24.0)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.17.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.6)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.22)\n","Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.7.1)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.2.2)\n","Downloading deeponto-0.9.2-py3-none-any.whl (89.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading anytree-2.12.1-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading enlighten-1.13.0-py2.py3-none-any.whl (42 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.8/493.8 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n","Downloading rdflib-7.1.1-py3-none-any.whl (562 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m562.4/562.4 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading textdistance-4.6.3-py3-none-any.whl (31 kB)\n","Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n","Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading prefixed-0.9.0-py2.py3-none-any.whl (13 kB)\n","Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: prefixed, pprintpp, yacs, xxhash, textdistance, lxml, JPype1, jedi, isodate, fsspec, dill, blessed, anytree, rdflib, multiprocess, enlighten, datasets, deeponto\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","Successfully installed JPype1-1.5.1 anytree-2.12.1 blessed-1.20.0 datasets-3.2.0 deeponto-0.9.2 dill-0.3.8 enlighten-1.13.0 fsspec-2024.9.0 isodate-0.7.2 jedi-0.19.2 lxml-5.3.0 multiprocess-0.70.16 pprintpp-0.4.0 prefixed-0.9.0 rdflib-7.1.1 textdistance-4.6.3 xxhash-3.5.0 yacs-0.1.8\n","/bin/bash: line 1: username: No such file or directory\n"]}],"source":["# We assume that PyTorch is already installed in the environment.\n","# If not, this command installs it.\n","!pip install torch==2.0.0\n","\n","# Install PyTorch Geometric, a library for creating graph neural networks using PyTorch.\n","!pip install torch-geometric==2.4.0\n","\n","# Import PyTorch to access its functionalities.\n","import torch\n","\n","# Install additional PyTorch Geometric dependencies for graph processing (scatter, sparse, cluster, spline-conv).\n","# These packages enable operations like sparse tensors and convolutions on graphs.\n","!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","\n","# Reinstall PyTorch Geometric to ensure all dependencies are correctly loaded.\n","!pip install torch-geometric\n","\n","# Retrieve the installed version of PyTorch to ensure compatibility with other packages.\n","torchversion = torch.__version__\n","\n","# Install the latest version of PyTorch Geometric directly from the GitHub repository.\n","# This allows access to the most recent updates and features for graph-based neural networks.\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","\n","# Install DeepOnto, a package specifically designed for ontology matching, particularly useful in biomedical applications.\n","!pip install deeponto\n","\n","# Install a custom version of DeepOnto from a GitHub repository.\n","# The '<username>' part should be replaced with the actual GitHub username of the repository maintainer.\n","!pip install git+https://github.com/<username>/deeponto.git\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HPAlAgjLMVhw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0aedbb2c-ea9d-4af8-9fd5-6d4eadb75863","executionInfo":{"status":"ok","timestamp":1734709398832,"user_tz":-60,"elapsed":49442,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Please enter the maximum memory located to JVM [8g]: 8g\n","\n"]}],"source":["# Import pandas for data manipulation and analysis, such as loading, processing, and saving tabular data.\n","import pandas as pd\n","\n","# Import pickle for saving and loading serialized objects (e.g., trained models or preprocessed data).\n","import pickle\n","\n","# Import function to convert a directed graph to an undirected one, useful for certain graph algorithms.\n","from torch_geometric.utils import to_undirected\n","\n","# Import optimizer module from PyTorch for training models using gradient-based optimization techniques.\n","import torch.optim as optim\n","\n","# Import PyTorch's modules for defining neural network architectures and operations:\n","from torch.nn import (\n","    Linear,       # For linear transformations (dense layers).\n","    Sequential,   # For stacking layers sequentially.\n","    BatchNorm1d,  # For normalizing input within mini-batches.\n","    PReLU,        # Parametric ReLU activation function.\n","    Dropout       # For regularization by randomly dropping connections during training.\n",")\n","\n","# Import functional API from PyTorch for operations like activations and loss functions.\n","import torch.nn.functional as F\n","\n","# Import Matplotlib for visualizations, such as plotting training loss curves.\n","import matplotlib.pyplot as plt\n","\n","# Import PyTorch Geometric's graph convolutional layers:\n","from torch_geometric.nn import GCNConv, GINConv\n","\n","# Import pooling operations for aggregating node embeddings to graph-level representations:\n","from torch_geometric.nn import global_mean_pool, global_add_pool\n","\n","# Import NumPy for numerical operations, such as working with arrays and matrices.\n","import numpy as np\n","\n","# Import time module for measuring execution time of code blocks.\n","import time\n","\n","# Import typing module for specifying types in function arguments and return values.\n","from typing import Optional, Tuple, Union, Callable\n","\n","# Import PyTorch's DataLoader and TensorDataset for handling data batching and loading during training.\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","# Import PyTorch's Parameter class for defining learnable parameters in custom models.\n","from torch.nn import Parameter\n","\n","# Import math module for performing mathematical computations.\n","import math\n","\n","# Import Tensor type from PyTorch for defining and manipulating tensors.\n","from torch import Tensor\n","\n","# Import PyTorch's nn module for defining and building neural network architectures.\n","import torch.nn as nn\n","\n","# Import initialization utilities from PyTorch Geometric for resetting weights and biases in layers.\n","from torch_geometric.nn.inits import reset\n","\n","# Import the base class for defining message-passing layers in graph neural networks (GNNs).\n","from torch_geometric.nn.conv import MessagePassing\n","\n","# Import linear transformation utilities for creating dense representations in graph models.\n","from torch_geometric.nn.dense.linear import Linear\n","\n","# Import typing utilities for defining adjacency matrices and tensor types specific to PyTorch Geometric.\n","from torch_geometric.typing import Adj, OptTensor, PairTensor, SparseTensor\n","\n","# Import softmax function for normalizing attention scores in GNNs.\n","from torch_geometric.utils import softmax\n","\n","# Import initialization utilities for weight initialization (e.g., Glorot initialization).\n","from torch_geometric.nn.inits import glorot, zeros\n","\n","# Import F1 score metric from scikit-learn for evaluating model performance in binary/multi-class tasks.\n","from sklearn.metrics import f1_score\n","\n","# Import JSON module for reading and writing JSON files, useful for storing configuration or ontology data.\n","import json\n","\n","# Import Ontology class from DeepOnto for representing and manipulating ontologies in the pipeline.\n","from deeponto.onto import Ontology\n","\n","# Import tools from DeepOnto for handling Ontology Alignment Evaluation Initiative (OAEI) tasks.\n","from deeponto.align.oaei import *\n","\n","# Import evaluation tools from DeepOnto for assessing alignment results using metrics like precision, recall, and F1.\n","from deeponto.align.evaluation import AlignmentEvaluator\n","\n","# Import mapping utilities from DeepOnto for working with reference mappings and entity pairs.\n","from deeponto.align.mapping import ReferenceMapping, EntityMapping\n","\n","# Import utility function for reading tables (e.g., TSV, CSV) from DeepOnto.\n","from deeponto.utils import read_table\n","\n","# Importing the train_test_split function from sklearn's model_selection module.\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"-abbBHOoRdWl"},"source":["# **Paths Definition**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AVgl_Bb42naS","outputId":"fddc7545-6d80-4ab3-d8c6-24819218f846","executionInfo":{"status":"ok","timestamp":1734709420795,"user_tz":-60,"elapsed":21966,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# Importing the 'drive' module from Google Colab to interact with Google Drive\n","from google.colab import drive\n","\n","# Mount the user's Google Drive to the Colab environment\n","# After running this, a link will appear to authorize access, and Google Drive will be mounted at '/content/gdrive'\n","drive.mount('/content/gdrive')\n"]},{"cell_type":"code","source":["import random\n","\n","# Set the seed for PyTorch's random number generator to ensure reproducibility\n","torch.manual_seed(42)\n","\n","# Set the seed for NumPy's random number generator to ensure reproducibility\n","np.random.seed(42)\n","\n","# Set the seed for Python's built-in random module to ensure reproducibility\n","random.seed(42)"],"metadata":{"id":"n5j8x2HqWs4_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eQxSrJP7WoIj"},"source":["# **Paths Definition**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"da5acb8a-7977-478d-d4e0-77f09b71fd8a","id":"detugQhiWoIk","executionInfo":{"status":"ok","timestamp":1734709422607,"user_tz":-60,"elapsed":1817,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["# Importing the 'drive' module from Google Colab to interact with Google Drive\n","from google.colab import drive\n","\n","# Mount the user's Google Drive to the Colab environment\n","# After running this, a link will appear to authorize access, and Google Drive will be mounted at '/content/gdrive'\n","drive.mount('/content/gdrive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"36ttssQ3W7cx"},"outputs":[],"source":["# Define the source ontology name\n","src_ent = \"snomed.body\"\n","\n","# Define the target ontology name\n","tgt_ent = \"fma.body\"\n","\n","# Define the task name for this ontology matching process\n","task = \"body\"\n","\n","# Define the similarity threshold for validating matches\n","thres = 0.30"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SJpvkdwVSQye"},"outputs":[],"source":["dir = \"/content/gdrive/My Drive/BioGITOM-VLDB/\"\n","\n","# Define the directory for the dataset containing source and target ontologies\n","dataset_dir = f\"{dir}/Datasets/{task}\"\n","\n","# Define the data directory for storing embeddings, adjacency matrices, and related files\n","data_dir = f\"{dir}/{task}/Data\"\n","\n","# Define the directory for storing the results\n","results_dir = f\"{dir}/{task}/Results\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eFDNSFef23er"},"outputs":[],"source":["# Load the Source ontology using the Ontology class from DeepOnto\n","# This initializes the source ontology by loading its .owl file.\n","src_onto = Ontology(f\"{dataset_dir}/{src_ent}.owl\")\n","\n","# Load the Target ontology using the Ontology class from DeepOnto\n","# This initializes the target ontology by loading its .owl file.\n","tgt_onto = Ontology(f\"{dataset_dir}/{tgt_ent}.owl\")\n","\n","# Define the file path for the Source embeddings CSV file\n","# Embeddings for the source ontology entities are stored in this file.\n","src_Emb = f\"{data_dir}/{src_ent}_Sentence_SapBERT_emb.csv\"\n","\n","# Define the file path for the Target embeddings CSV file\n","# Embeddings for the target ontology entities are stored in this file.\n","tgt_Emb = f\"{data_dir}/{tgt_ent}_Sentence_SapBERT_emb.csv\"\n","\n","# Define the file path for the Source adjacency matrix\n","# This file represents the relationships (edges) between entities in the source ontology.\n","src_Adjacence = f\"{data_dir}/{src_ent}_adjacence.csv\"\n","\n","# Define the file path for the Target adjacency matrix\n","# This file represents the relationships (edges) between entities in the target ontology.\n","tgt_Adjacence = f\"{data_dir}/{tgt_ent}_adjacence.csv\"\n","\n","# Define the file path for the JSON file containing the Source ontology class labels\n","# This file maps the source ontology entities to their labels or names.\n","src_class = f\"{data_dir}/{src_ent}_classes.json\"\n","\n","# Define the file path for the JSON file containing the Target ontology class labels\n","# This file maps the target ontology entities to their labels or names.\n","tgt_class = f\"{data_dir}/{tgt_ent}_classes.json\"\n","\n","# Define the file path for the train data\n","train_file = f\"{data_dir}/{task}_train.csv\"\n","\n","# Define the file path for the test data\n","# The test file contains reference mappings (ground truth) between the source and target ontologies.\n","test_file = f\"{dataset_dir}/refs_equiv/test.tsv\"\n","\n","# Define the file path for the candidate mappings used during testing\n","# This file includes the candidate pairs (source and target entities) for ranking and evaluation.\n","test_cands = f\"{dataset_dir}/refs_equiv/test.cands.tsv\"\n","\n","# Define the file path for the candidate mappings between Source to Target entities\n","# This file contains cleaned, combined, and encoded candidates used for predictions.\n","candidates_Prediction = f\"{data_dir}/{task}_candidates_prediction.csv\"\n","\n","# Define the file path for the candidate mappings between Source to Target entities for ranking-based metrics\n","# This file is used to compute ranking-based metrics like MRR and Hits@k.\n","candidates_Rank = f\"{data_dir}/{task}_candidates.csv\"\n","\n","# Define the path where the prediction results will be saved in TSV format\n","# This file will store the final predictions (mappings) between source and target entities.\n","prediction_path = f\"{results_dir}/{task}_matching_results.tsv\"\n","\n","# Define the path where all prediction results will be saved in TSV format\n","# This file will store detailed prediction results, including all candidate scores.\n","all_predictions_path = f\"{results_dir}/{task}_all_predictions.tsv\"\n","\n","# Define the path where all ranking prediction results will be saved in TSV format\n","# This file will store predictions sorted by rank based on their scores.\n","all_predictions_path_ranked = f\"{results_dir}/{task}_all_predictions_ranked.tsv\"\n","\n","# Define the path where formatted ranking predictions will be saved in TSV format\n","# This file will contain predictions formatted for evaluation using ranking-based metrics.\n","formatted_predictions_path = f\"{results_dir}/{task}_formatted_predictions.tsv\""]},{"cell_type":"markdown","metadata":{"id":"zqEXsgPGMVhw"},"source":["# **GIT Architecture**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A_d6XCsUMVhx"},"outputs":[],"source":["# RGIT class definition which inherits from PyTorch Geometric's MessagePassing class\n","class RGIT(MessagePassing):\n","\n","    _alpha: OptTensor  # Define _alpha as an optional tensor for storing attention weights\n","\n","    def __init__(\n","        self,\n","        nn: Callable,  # Neural network to be used in the final layer of the GNN\n","        in_channels: Union[int, Tuple[int, int]],  # Input dimension, can be a single or pair of integers\n","        out_channels: int,  # Output dimension of the GNN\n","        eps: float = 0.,  # GIN parameter: epsilon for GIN aggregation\n","        train_eps: bool = False,  # GIN parameter: whether epsilon should be learnable\n","        heads: int = 1,  # Transformer parameter: number of attention heads\n","        dropout: float = 0.,  # Dropout rate for attention weights\n","        edge_dim: Optional[int] = None,  # Dimension for edge attributes (optional)\n","        bias: bool = True,  # Whether to use bias in linear layers\n","        root_weight: bool = True,  # GIN parameter: whether to apply root weight in aggregation\n","        **kwargs,  # Additional arguments passed to the parent class\n","    ):\n","        # Set the aggregation type to 'add' and initialize the parent class with node_dim=0\n","        kwargs.setdefault('aggr', 'add')\n","        super().__init__(node_dim=0, **kwargs)\n","\n","        # Initialize input/output dimensions, neural network, and GIN/transformer parameters\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.nn = nn  # Neural network used by the GNN\n","        self.initial_eps = eps  # Initial value of epsilon for GIN\n","\n","        # Set epsilon to be learnable or fixed\n","        if train_eps:\n","            self.eps = torch.nn.Parameter(torch.empty(1))  # Learnable epsilon\n","        else:\n","            self.register_buffer('eps', torch.empty(1))  # Non-learnable epsilon (fixed)\n","\n","        # Initialize transformer-related parameters\n","        self.heads = heads\n","        self.dropout = dropout\n","        self.edge_dim = edge_dim\n","        self._alpha = None  # Placeholder for attention weights\n","\n","        # Handle case where in_channels is a single integer or a tuple\n","        if isinstance(in_channels, int):\n","            in_channels = (in_channels, in_channels)\n","\n","        # Define the linear layers for key, query, and value for the transformer mechanism\n","        self.lin_key = Linear(in_channels[0], heads * out_channels)\n","        self.lin_query = Linear(in_channels[1], heads * out_channels)\n","        self.lin_value = Linear(in_channels[0], heads * out_channels)\n","\n","        # Define linear transformation for edge embeddings if provided\n","        if edge_dim is not None:\n","            self.lin_edge = Linear(edge_dim, heads * out_channels, bias=False)\n","        else:\n","            self.lin_edge = self.register_parameter('lin_edge', None)\n","\n","        # Reset all parameters to their initial values\n","        self.reset_parameters()\n","\n","    # Function to reset model parameters\n","    def reset_parameters(self):\n","        super().reset_parameters()  # Call parent class reset method\n","        self.lin_key.reset_parameters()  # Reset key linear layer\n","        self.lin_query.reset_parameters()  # Reset query linear layer\n","        self.lin_value.reset_parameters()  # Reset value linear layer\n","        if self.edge_dim:\n","            self.lin_edge.reset_parameters()  # Reset edge linear layer if used\n","        reset(self.nn)  # Reset the neural network provided\n","        self.eps.data.fill_(self.initial_eps)  # Initialize epsilon with the starting value\n","\n","    # Forward function defining how the input data flows through the model\n","    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj,\n","                edge_attr: OptTensor = None, return_attention_weights=None):\n","        # Unpack number of heads and output channels\n","        H, C = self.heads, self.out_channels\n","\n","        # If x is a tensor, treat it as a pair of tensors (source and target embeddings)\n","        if isinstance(x, Tensor):\n","            x: PairTensor = (x, x)\n","\n","        # Extract source node embeddings\n","        x_t = x[0]\n","\n","        # Apply linear transformations and reshape query, key, and value for multi-head attention\n","        query = self.lin_query(x[1]).view(-1, H, C)\n","        key = self.lin_key(x[0]).view(-1, H, C)\n","        value = self.lin_value(x[0]).view(-1, H, C)\n","\n","        # Propagate messages through the graph using the propagate function\n","        out = self.propagate(edge_index, query=query, key=key, value=value,\n","                             edge_attr=edge_attr, size=None)\n","\n","        # Retrieve attention weights and reset them\n","        alpha = self._alpha\n","        self._alpha = None  # Reset _alpha after use\n","        out = out.mean(dim=1)  # Take the mean over all attention heads\n","\n","        # Apply GIN aggregation by adding epsilon-scaled original node embeddings\n","        out = out + (1 + self.eps) * x_t\n","        return self.nn(out)  # Pass through the neural network\n","\n","    # Message passing function which calculates attention and combines messages\n","    def message(self, query_i: Tensor, key_j: Tensor, value_j: Tensor,\n","                edge_attr: OptTensor, index: Tensor, ptr: OptTensor,\n","                size_i: Optional[int]) -> Tensor:\n","        # If edge attributes are used, apply linear transformation and add them to the key\n","        if self.lin_edge is not None:\n","            assert edge_attr is not None\n","            edge_attr = self.lin_edge(edge_attr).view(-1, self.heads, self.out_channels)\n","            key_j = key_j + edge_attr\n","\n","        # Calculate attention (alpha) using the dot product between query and key\n","        alpha = (query_i * key_j).sum(dim=-1) / math.sqrt(self.out_channels)\n","        alpha = softmax(alpha, index, ptr, size_i)  # Apply softmax to normalize attention\n","        self._alpha = alpha  # Store attention weights\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)  # Apply dropout\n","\n","        # Calculate the output message by applying attention to the value\n","        out = value_j\n","        if edge_attr is not None:\n","            out = out + edge_attr  # Add edge embeddings to the output if present\n","        out = out * alpha.view(-1, self.heads, 1)  # Scale by attention weights\n","        return out\n","\n","    # String representation function for debugging or printing\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}({self.in_channels}, '\n","                f'{self.out_channels}, heads={self.heads})')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qwFv6RgHmGCf"},"outputs":[],"source":["# Define the RGIT_mod class, a multi-layer GNN that uses both RGIT and linear layers\n","class RGIT_mod(torch.nn.Module):\n","    \"\"\"Multi-layer RGIT with optional linear layers\"\"\"\n","\n","    # Initialize the model with hidden dimension, number of RGIT layers, and number of linear layers\n","    def __init__(self, dim_h, num_layers, num_linear_layers=1):\n","        super(RGIT_mod, self).__init__()\n","        self.num_layers = num_layers  # Number of RGIT layers\n","        self.num_linear_layers = num_linear_layers  # Number of linear layers\n","        self.linears = torch.nn.ModuleList()  # List to store linear layers\n","        self.rgit_layers = torch.nn.ModuleList()  # List to store RGIT layers\n","\n","        # Create a list of Linear and PReLU layers (for encoding entity names)\n","        for _ in range(num_linear_layers):\n","            self.linears.append(Linear(dim_h, dim_h))  # Linear transformation layer\n","            self.linears.append(PReLU(num_parameters=dim_h))  # Parametric ReLU activation function\n","\n","        # Create a list of RGIT layers\n","        for _ in range(num_layers):\n","            self.rgit_layers.append(RGIT(  # Each RGIT layer contains a small MLP with Linear and PReLU\n","                Sequential(Linear(dim_h, dim_h), PReLU(num_parameters=dim_h),\n","                           Linear(dim_h, dim_h), PReLU(num_parameters=dim_h)), dim_h, dim_h))\n","\n","    # Forward pass through the model\n","    def forward(self, x, edge_index):\n","        # Apply the linear layers first to the input\n","        for layer in self.linears:\n","            x = layer(x)\n","\n","        # Then apply the RGIT layers for message passing\n","        for layer in self.rgit_layers:\n","            x = layer(x, edge_index)\n","\n","        return x  # Return the final node embeddings after all layers\n"]},{"cell_type":"markdown","metadata":{"id":"zxCn5ztKVztw"},"source":["# **Gated Network Architecture**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7MKQUv7o7zay"},"outputs":[],"source":["class GatedCombination(nn.Module):\n","    \"\"\"\n","    A neural network module for combining embeddings using a gating mechanism\n","    and evaluating their similarity. This class is particularly useful for\n","    ontology matching tasks.\n","\n","    Args:\n","        input_dim (int): Dimensionality of the input embeddings.\n","    \"\"\"\n","    def __init__(self, input_dim):\n","        super(GatedCombination, self).__init__()\n","\n","        # Fully connected layer for gating mechanism on the first embedding pair (x1, x2)\n","        self.gate_A_fc = nn.Linear(input_dim, input_dim)\n","\n","        # Fully connected layer for gating mechanism on the second embedding pair (x3, x4)\n","        self.gate_B_fc = nn.Linear(input_dim, input_dim)\n","\n","        # Fully connected layer for final similarity classification\n","        self.fc = nn.Linear(1, 1)\n","\n","    def forward(self, x1, x2, x3, x4, return_embeddings=False):\n","        \"\"\"\n","        Forward pass through the GatedCombination model.\n","\n","        Args:\n","            x1 (torch.Tensor): First set of embeddings (e.g., updated source embeddings).\n","            x2 (torch.Tensor): Second set of embeddings (e.g., original source embeddings).\n","            x3 (torch.Tensor): Third set of embeddings (e.g., updated target embeddings).\n","            x4 (torch.Tensor): Fourth set of embeddings (e.g., original target embeddings).\n","            return_embeddings (bool): Whether to return the intermediate combined embeddings (a, b).\n","\n","        Returns:\n","            torch.Tensor: Probability score for binary classification if return_embeddings is False.\n","            Tuple[torch.Tensor, torch.Tensor]: Intermediate embeddings (a, b) if return_embeddings is True.\n","        \"\"\"\n","        # Compute gating weights for the first pair of embeddings (x1, x2)\n","        gate_values1 = torch.sigmoid(self.gate_A_fc(x1))\n","\n","        # Blend x1 and x2 using the computed gating weights\n","        a = x1 * gate_values1 + x2 * (1 - gate_values1)\n","\n","        # Compute gating weights for the second pair of embeddings (x3, x4)\n","        gate_values2 = torch.sigmoid(self.gate_B_fc(x3))\n","\n","        # Blend x3 and x4 using the computed gating weights\n","        b = x3 * gate_values2 + x4 * (1 - gate_values2)\n","\n","        # If return_embeddings is True, return the intermediate blended embeddings\n","        if return_embeddings:\n","            return a, b\n","\n","        # Compute cosine similarity between the blended embeddings a and b\n","        x = torch.cosine_similarity(a, b, dim=1)\n","\n","        # Apply a fully connected layer and sigmoid activation for classification\n","        out = torch.sigmoid(self.fc(x.unsqueeze(1)))\n","        return out\n","\n"]},{"cell_type":"markdown","metadata":{"id":"aLJ5j9FNMVhy"},"source":["# **Utility functions**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k0L86DgUQjMU"},"outputs":[],"source":["def adjacency_matrix_to_undirected_edge_index(adjacency_matrix):\n","    \"\"\"\n","    Converts an adjacency matrix into an undirected edge index for use in graph-based neural networks.\n","\n","    Args:\n","        adjacency_matrix: A 2D list or array representing the adjacency matrix of a graph.\n","\n","    Returns:\n","        edge_index_undirected: A PyTorch tensor representing the undirected edges.\n","    \"\"\"\n","    # Convert each element in the adjacency matrix to an integer (from boolean or float)\n","    adjacency_matrix = [[int(element) for element in sublist] for sublist in adjacency_matrix]\n","\n","    # Convert the adjacency matrix into a PyTorch LongTensor (used for indexing)\n","    edge_index = torch.tensor(adjacency_matrix, dtype=torch.long)\n","\n","    # Transpose the edge_index tensor so that rows represent edges in the form [source, target]\n","    edge_index = edge_index.t().contiguous()\n","\n","    # Convert the directed edge_index into an undirected edge_index, meaning both directions are added (i.e., (i, j) and (j, i))\n","    edge_index_undirected = to_undirected(edge_index)\n","\n","    return edge_index_undirected  # Return the undirected edge index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YvmOxkLcpf9w"},"outputs":[],"source":["def build_indexed_dict(file_path):\n","    \"\"\"\n","    Builds a dictionary with numeric indexes for each key from a JSON file.\n","\n","    Args:\n","        file_path (str): The path to the JSON file.\n","\n","    Returns:\n","        indexed_dict (dict): A new dictionary where each key from the JSON file is assigned a numeric index.\n","    \"\"\"\n","    # Load the JSON file into a Python dictionary\n","    with open(file_path, 'r') as file:\n","        data = json.load(file)\n","\n","    # Create a new dictionary with numeric indexes as keys and the original JSON keys as values\n","    indexed_dict = {index: key for index, key in enumerate(data.keys())}\n","\n","    return indexed_dict  # Return the newly created dictionary"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QgFINoPGl9Wg"},"outputs":[],"source":["def select_rows_by_index(embedding_vector, index_vector):\n","    \"\"\"\n","    Select rows from an embedding vector using an index vector.\n","\n","    Args:\n","        embedding_vector (torch.Tensor): 2D tensor representing the embedding vector with shape [num_rows, embedding_size].\n","        index_vector (torch.Tensor): 1D tensor representing the index vector.\n","\n","    Returns:\n","        torch.Tensor: New tensor with selected rows from the embedding vector.\n","    \"\"\"\n","    # Use torch.index_select to select the desired rows\n","    new_tensor = torch.index_select(embedding_vector, 0, index_vector)\n","\n","    return new_tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a12L7vEmmCJq"},"outputs":[],"source":["def contrastive_loss(source_embeddings, target_embeddings, labels, margin=1.0):\n","    \"\"\"\n","    Computes the contrastive loss, a type of loss function used to train models in tasks like matching or similarity learning.\n","\n","    Args:\n","        source_embeddings (torch.Tensor): Embeddings of the source graphs, shape [batch_size, embedding_size].\n","        target_embeddings (torch.Tensor): Embeddings of the target graphs, shape [batch_size, embedding_size].\n","        labels (torch.Tensor): Binary labels indicating if the pairs are matched (1) or not (0), shape [batch_size].\n","        margin (float): Margin value for the contrastive loss. Defaults to 1.0.\n","\n","    Returns:\n","        torch.Tensor: The contrastive loss value.\n","    \"\"\"\n","    # Calculate the pairwise Euclidean distance between source and target embeddings\n","    distances = F.pairwise_distance(source_embeddings, target_embeddings)\n","\n","    # Compute the contrastive loss:\n","    # - For matched pairs (label == 1), the loss is the squared distance between embeddings.\n","    # - For non-matched pairs (label == 0), the loss is based on how far apart the embeddings are,\n","    #   but penalizes them only if the distance is less than the margin.\n","    loss = torch.mean(\n","        labels * 0.4 * distances.pow(2) +  # For positive pairs, minimize the distance (squared)\n","        (1 - labels) * 0.4 * torch.max(torch.zeros_like(distances), margin - distances).pow(2)  # For negative pairs, maximize the distance (up to the margin)\n","    )\n","\n","    return loss  # Return the computed contrastive loss\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZhCizXEb7D4N"},"outputs":[],"source":["def Prediction_with_candidates(model, X1_tt, X2_tt, X3_tt, X4_tt, src_entity_tensor_o, tgt_entity_tensor_o,\n","                                   indexed_dict_src, indexed_dict_tgt, all_predictions_path):\n","    \"\"\"\n","    Evaluates the GatedCombination model using the given embeddings and candidate entity pairs.\n","    Saves the predictions and evaluation results to a file.\n","\n","    Args:\n","        model: Trained GatedCombination model.\n","        X1_tt, X2_tt, X3_tt, X4_tt (torch.Tensor): Tensors of source and target entity embeddings (updated and original).\n","        src_entity_tensor_o, tgt_entity_tensor_o (torch.Tensor): Tensors of source and target entity indices.\n","        indexed_dict_src, indexed_dict_tgt (dict): Dictionaries mapping entity indices to URIs for source and target.\n","        output_file (str): Path to save the predictions and results.\n","        hits_at_k_values (list): List of k-values for which hits@k is evaluated.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    # Move the model to CPU and set it to evaluation mode\n","    model = model.to(\"cpu\")\n","    model.eval()\n","\n","    # Set batch size for evaluation\n","    batch_size_test = 32\n","\n","    # Create a DataLoader for the evaluation data\n","    test_dataset = TensorDataset(X1_tt, X2_tt, X3_tt, X4_tt)\n","    test_dataloader = DataLoader(test_dataset, batch_size=batch_size_test)\n","\n","    # Prepare for collecting predictions and results\n","    predictions = []\n","    results = []\n","    count_predictions = 0  # Counter for predictions above threshold (0.5)\n","\n","    # Measure prediction time\n","    start_time = time.time()\n","\n","    # Disable gradient computation for evaluation\n","    with torch.no_grad():\n","        # Iterate over batches and compute model predictions\n","        for batch_X1, batch_X2, batch_X3, batch_X4 in test_dataloader:\n","            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","            predictions.extend(outputs.cpu().numpy())  # Collect predictions in CPU memory\n","\n","    end_time = time.time()\n","    predicting_time = end_time - start_time\n","    print(f\"Predicting time: {predicting_time:.2f} seconds\")\n","\n","    # Convert tensors to lists for easier iteration\n","    src_indices = src_entity_tensor_o.tolist()\n","    tgt_indices = tgt_entity_tensor_o.tolist()\n","\n","    # Prepare results\n","    for i in range(len(predictions)):\n","        if predictions[i] >= 0.00:  # Consider only predictions greater than 0.5\n","            count_predictions += 1  # Increment the counter\n","\n","            # Map the source and target entity indices to their URIs\n","            src_code = src_indices[i]\n","            tgt_code = tgt_indices[i]\n","\n","            src_uri = indexed_dict_src.get(int(src_code), \"Unknown URI\")\n","            tgt_uri = indexed_dict_tgt.get(int(tgt_code), \"Unknown URI\")\n","\n","            # Get the model's predicted score for the current pair\n","            score = predictions[i]\n","\n","            # Append the results (with URIs instead of entity indices)\n","            results.append({\n","                'SrcEntity': src_uri,\n","                'TgtEntity': tgt_uri,\n","                'Score': score\n","            })\n","\n","    # Convert the results into a pandas DataFrame\n","    df_results = pd.DataFrame(results)\n","\n","    # Save the results to a TSV file\n","    df_results.to_csv(all_predictions_path, sep='\\t', index=False)\n","\n","    print(f\"Predictions saved to {all_predictions_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TslUdYHBcGVj"},"outputs":[],"source":["def filter_highest_predictions(input_file_path, output_file_path, threshold=thres):\n","    # Load the all predictions file\n","    df = pd.read_csv(input_file_path, sep='\\t')\n","\n","    # Extract the similarity score from the list in the 'Score' column\n","    df['Score'] = df['Score'].apply(lambda x: float(x.strip('[]')))\n","\n","    # Sorting the dataframe by similarity score in descending order\n","    df_sorted = df.sort_values(by='Score', ascending=False).reset_index(drop=True)\n","\n","    # Initialize variables with threshold value\n","    source_concepts = set(df_sorted['SrcEntity'])\n","    target_concepts = set(df_sorted['TgtEntity'])\n","    matched_sources = set()\n","    matched_targets = set()\n","    result = []\n","\n","    # Iterate through the sorted dataframe and find highest correspondences\n","    for _, row in df_sorted.iterrows():\n","        source, target, similarity = row['SrcEntity'], row['TgtEntity'], row['Score']\n","\n","        # Check if the source or target has already been matched and if the similarity is above the threshold\n","        if source not in matched_sources and target not in matched_targets and similarity >= threshold:\n","            # Add the match to the result list\n","            result.append((source, target, similarity))\n","            # Mark the source and target as matched\n","            matched_sources.add(source)\n","            matched_targets.add(target)\n","\n","    # Create a dataframe for the matching results with threshold applied\n","    matching_results_df_threshold = pd.DataFrame(result, columns=['SrcEntity', 'TgtEntity', 'Score'])\n","\n","    # Save the matching results with the updated column names to a new TSV file\n","    matching_results_df_threshold.to_csv(output_file_path, sep='\\t', index=False)\n","\n","    # Print the number of predictions saved\n","    print(f\"Number of Positive Predictions : {len(matching_results_df_threshold)}\")\n","\n","    return matching_results_df_threshold, len(matching_results_df_threshold)"]},{"cell_type":"code","source":["def compute_mrr_and_hits(reference_file, predicted_file, output_file, k_values=[1, 5, 10]):\n","    \"\"\"\n","    Compute MRR and Hits@k for ontology matching predictions based on a reference file.\n","\n","    Args:\n","        reference_file (str): Path to the reference file (test.cands.tsv format).\n","        predicted_file (str): Path to the predictions file with scores.\n","        output_file (str): Path to save the scored results.\n","        k_values (list): List of k values for Hits@k.\n","\n","    Returns:\n","        dict: A dictionary containing MRR and Hits@k metrics.\n","    \"\"\"\n","    # Read the reference mappings\n","    test_candidate_mappings = read_table(reference_file).values.tolist()\n","    ranking_results = []\n","\n","    # Read the predicted scores\n","    predicted_data = pd.read_csv(predicted_file, sep=\"\\t\")\n","    predicted_data[\"Score\"] = predicted_data[\"Score\"].apply(lambda x: float(x.strip(\"[]\")))\n","\n","    # Create a lookup dictionary for predicted scores\n","    score_lookup = {}\n","    for _, row in predicted_data.iterrows():\n","        score_lookup[(row[\"SrcEntity\"], row[\"TgtEntity\"])] = row[\"Score\"]\n","\n","    for src_ref_class, tgt_ref_class, tgt_cands in test_candidate_mappings:\n","        tgt_cands = eval(tgt_cands)  # Convert string to list of candidates\n","        scored_cands = []\n","        for tgt_cand in tgt_cands:\n","            # Retrieve score for each candidate, defaulting to a very low score if not found\n","            matching_score = score_lookup.get((src_ref_class, tgt_cand), -1e9)\n","            scored_cands.append((tgt_cand, matching_score))\n","\n","        # Sort candidates by score in descending order\n","        scored_cands = sorted(scored_cands, key=lambda x: x[1], reverse=True)\n","        ranking_results.append((src_ref_class, tgt_ref_class, scored_cands))\n","\n","    # Save the ranked results to a file\n","    pd.DataFrame(ranking_results, columns=[\"SrcEntity\", \"TgtEntity\", \"TgtCandidates\"]).to_csv(output_file, sep=\"\\t\", index=False)\n","\n","    # Compute MRR and Hits@k\n","    total_entities = len(ranking_results)\n","    reciprocal_ranks = []\n","    hits_at_k = {k: 0 for k in k_values}\n","\n","    for src_entity, tgt_ref_class, tgt_cands in ranking_results:\n","        ranked_candidates = [candidate[0] for candidate in tgt_cands]\n","        if tgt_ref_class in ranked_candidates:\n","            rank = ranked_candidates.index(tgt_ref_class) + 1\n","            reciprocal_ranks.append(1 / rank)\n","            for k in k_values:\n","                if rank <= k:\n","                    hits_at_k[k] += 1\n","        else:\n","            reciprocal_ranks.append(0)\n","\n","    mrr = sum(reciprocal_ranks) / total_entities\n","    hits_at_k = {k: hits / total_entities for k, hits in hits_at_k.items()}\n","\n","    return {\"MRR\": mrr, \"Hits@k\": hits_at_k}"],"metadata":{"id":"_ggVYlTiO_WA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1HyWMsw1MVhz"},"source":["# **Main Code**\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"IC37FlwGDqGM"},"source":["\n","\n","# Reading semantic node embeddings provided by the ENE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FuEfSnw5mod0"},"outputs":[],"source":["# Read the source embeddings from a CSV file into a pandas DataFrame\n","df_embbedings_src = pd.read_csv(src_Emb, index_col=0)\n","\n","# Convert the DataFrame to a NumPy array, which will remove the index and store the data as a raw matrix\n","numpy_array = df_embbedings_src.to_numpy()\n","\n","# Convert the NumPy array into a PyTorch FloatTensor, which is the format required for PyTorch operations\n","x_src = torch.FloatTensor(numpy_array)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"STUwqMUXmlG2"},"outputs":[],"source":["# Read the target embeddings from a CSV file into a pandas DataFrame\n","df_embbedings_tgt = pd.read_csv(tgt_Emb, index_col=0)\n","\n","# Convert the DataFrame to a NumPy array, which removes the index and converts the data to a raw matrix\n","numpy_array = df_embbedings_tgt.to_numpy()\n","\n","# Convert the NumPy array into a PyTorch FloatTensor, which is required for PyTorch operations\n","x_tgt = torch.FloatTensor(numpy_array)"]},{"cell_type":"markdown","metadata":{"id":"jZIu9P08DqGN"},"source":["# Reading adjacency Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pH69Up40mycz"},"outputs":[],"source":["# Read the source adjacency matrix from a CSV file into a pandas DataFrame\n","df_ma1 = pd.read_csv(src_Adjacence, index_col=0)\n","\n","# Convert the DataFrame to a list of lists (Python native list format)\n","ma1 = df_ma1.values.tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hYCmAO5Ymzpl"},"outputs":[],"source":["# Read the target adjacency matrix from a CSV file into a pandas DataFrame\n","df_ma2 = pd.read_csv(tgt_Adjacence, index_col=0)\n","\n","# Convert the DataFrame to a list of lists (Python native list format)\n","ma2 = df_ma2.values.tolist()"]},{"cell_type":"markdown","metadata":{"id":"PSyksqh3TrU-"},"source":["# Convert Adjacency matrix (in list format) to an undirected edge index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uVt-Pce5m5ll"},"outputs":[],"source":["# Convert the source adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n","edge_src = adjacency_matrix_to_undirected_edge_index(ma1)\n","\n","# Convert the target adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n","edge_tgt = adjacency_matrix_to_undirected_edge_index(ma2)"]},{"cell_type":"markdown","metadata":{"id":"H9wMTRdqT4aY"},"source":["# GIT Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eqiEKCLSMVh3"},"outputs":[],"source":["def train_model_gnn(model, x_src, edge_src, x_tgt, edge_tgt,\n","                    tensor_term1, tensor_term2, tensor_score,\n","                    learning_rate, weight_decay_value, num_epochs, print_interval=10):\n","    \"\"\"\n","    Trains a graph neural network (GNN) model using source and target embeddings and contrastive loss.\n","\n","    Args:\n","        model: The GNN model to be trained.\n","        x_src (torch.Tensor): Source node embeddings.\n","        edge_src (torch.Tensor): Source graph edges.\n","        x_tgt (torch.Tensor): Target node embeddings.\n","        edge_tgt (torch.Tensor): Target graph edges.\n","        tensor_term1 (torch.Tensor): Indices of the source nodes to be compared.\n","        tensor_term2 (torch.Tensor): Indices of the target nodes to be compared.\n","        tensor_score (torch.Tensor): Labels indicating if the pairs are matched (1) or not (0).\n","        learning_rate (float): Learning rate for the optimizer.\n","        weight_decay_value (float): Weight decay (L2 regularization) value for the optimizer.\n","        num_epochs (int): Number of epochs for training.\n","        print_interval (int): Interval at which training progress is printed (every `print_interval` epochs).\n","\n","    Returns:\n","        model: The trained GNN model.\n","    \"\"\"\n","\n","    # Step 1: Set device (GPU or CPU) for computation\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    # Step 2: Move the model and all inputs to the selected device\n","    model.to(device)\n","    x_tgt = x_tgt.to(device)               # Target node embeddings\n","    edge_tgt = edge_tgt.to(device)         # Target graph edges\n","    x_src = x_src.to(device)               # Source node embeddings\n","    edge_src = edge_src.to(device)         # Source graph edges\n","    tensor_term1 = tensor_term1.to(device) # Indices for source nodes\n","    tensor_term2 = tensor_term2.to(device) # Indices for target nodes\n","    tensor_score = tensor_score.to(device) # Ground truth labels\n","\n","    # Step 3: Define optimizer with learning rate and regularization\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay_value)\n","\n","    # Step 4: Initialize list to store training losses\n","    train_losses = []\n","\n","    # Record the start time of training\n","    start_time = time.time()\n","\n","    # Step 5: Training loop\n","    for epoch in range(num_epochs):\n","        # Zero out gradients from the previous iteration\n","        optimizer.zero_grad()\n","\n","        # Forward pass: Compute embeddings for source and target graphs\n","        out1 = model(x_src, edge_src)  # Updated source embeddings\n","        out2 = model(x_tgt, edge_tgt)  # Updated target embeddings\n","\n","        # Extract specific rows of embeddings for terms being compared\n","        src_embeddings = select_rows_by_index(out1, tensor_term1)\n","        tgt_embeddings = select_rows_by_index(out2, tensor_term2)\n","\n","        # Compute contrastive loss based on the embeddings and ground truth labels\n","        loss = contrastive_loss(src_embeddings, tgt_embeddings, tensor_score)\n","\n","        # Backward pass: Compute gradients\n","        loss.backward()\n","\n","        # Update the model's parameters\n","        optimizer.step()\n","\n","        # Append the loss for this iteration to the list\n","        train_losses.append(loss.item())\n","\n","        # Print loss every `print_interval` epochs\n","        if (epoch + 1) % print_interval == 0:\n","            print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item()}\")\n","\n","    # Step 6: Record end time of training\n","    end_time = time.time()\n","\n","    # Step 7: Plot the training loss over time\n","    plt.semilogy(range(1, num_epochs + 1), train_losses, label=\"Training Loss\", marker='o')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    # Print the total training time\n","    training_time = end_time - start_time\n","    print(f\"Training complete! Total training time: {training_time:.2f} seconds\")\n","\n","    # Step 8: Return the trained model\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6_tzUG_emtBg"},"outputs":[],"source":["# Initialize the GIT_mod model with the dimensionality of the target embeddings\n","# The first argument is the dimensionality of the target node embeddings (x_tgt.shape[1])\n","# The second argument (1) represents the number of RGIT layers in the model\n","GIT_model = RGIT_mod(x_tgt.shape[1], 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wVo-s7UQssSp"},"outputs":[],"source":["# Reading the training pairs from a CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(train_file, index_col=0)\n","\n","# Extract the 'SrcEntity' and 'TgtEntity' columns as NumPy arrays and convert them to integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)  # Source entity indices\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)  # Target entity indices\n","\n","# Extract the 'Score' column as a NumPy array and convert it to floats\n","tensor_score = df_embbedings['Score'].values.astype(float)  # Scores (labels) indicating if pairs match (1) or not (0)\n","\n","# Convert the NumPy arrays to PyTorch LongTensors (for indices) and FloatTensors (for scores)\n","tensor_term1_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)  # Source entity tensor\n","tensor_term2_o = torch.from_numpy(tensor_term2).type(torch.LongTensor)  # Target entity tensor\n","tensor_score_o = torch.from_numpy(tensor_score).type(torch.FloatTensor)  # Score tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"agHlFNesMVh3","outputId":"e887d1f5-6da1-480c-a00c-7278672e34f9","executionInfo":{"status":"ok","timestamp":1734714731448,"user_tz":-60,"elapsed":5242159,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [10/1000], Training Loss: 0.0010807407088577747\n","Epoch [20/1000], Training Loss: 0.0009215225582011044\n","Epoch [30/1000], Training Loss: 0.0007969978032633662\n","Epoch [40/1000], Training Loss: 0.0007213588105514646\n","Epoch [50/1000], Training Loss: 0.0006613766308873892\n","Epoch [60/1000], Training Loss: 0.0006100692553445697\n","Epoch [70/1000], Training Loss: 0.0005696147563867271\n","Epoch [80/1000], Training Loss: 0.0005341640207916498\n","Epoch [90/1000], Training Loss: 0.0005029486492276192\n","Epoch [100/1000], Training Loss: 0.00047573421034030616\n","Epoch [110/1000], Training Loss: 0.00045167762436904013\n","Epoch [120/1000], Training Loss: 0.00043058916344307363\n","Epoch [130/1000], Training Loss: 0.0004126144340261817\n","Epoch [140/1000], Training Loss: 0.0003971150435972959\n","Epoch [150/1000], Training Loss: 0.0003836388059426099\n","Epoch [160/1000], Training Loss: 0.0003723127883858979\n","Epoch [170/1000], Training Loss: 0.00036275957245379686\n","Epoch [180/1000], Training Loss: 0.00035465904511511326\n","Epoch [190/1000], Training Loss: 0.0003479798906482756\n","Epoch [200/1000], Training Loss: 0.0003423297603148967\n","Epoch [210/1000], Training Loss: 0.00033766234992071986\n","Epoch [220/1000], Training Loss: 0.00033363891998305917\n","Epoch [230/1000], Training Loss: 0.0003303326666355133\n","Epoch [240/1000], Training Loss: 0.0003276491188444197\n","Epoch [250/1000], Training Loss: 0.00032535786158405244\n","Epoch [260/1000], Training Loss: 0.0003234614559914917\n","Epoch [270/1000], Training Loss: 0.00032187928445637226\n","Epoch [280/1000], Training Loss: 0.0003205290122423321\n","Epoch [290/1000], Training Loss: 0.00031929253600537777\n","Epoch [300/1000], Training Loss: 0.0003182379005011171\n","Epoch [310/1000], Training Loss: 0.00031730683986097574\n","Epoch [320/1000], Training Loss: 0.00031648456933908165\n","Epoch [330/1000], Training Loss: 0.0003157555765938014\n","Epoch [340/1000], Training Loss: 0.00031510175904259086\n","Epoch [350/1000], Training Loss: 0.0003145697701256722\n","Epoch [360/1000], Training Loss: 0.00031411045347340405\n","Epoch [370/1000], Training Loss: 0.00031372063676826656\n","Epoch [380/1000], Training Loss: 0.0003133818390779197\n","Epoch [390/1000], Training Loss: 0.0003130748518742621\n","Epoch [400/1000], Training Loss: 0.00031276559457182884\n","Epoch [410/1000], Training Loss: 0.0003124802897218615\n","Epoch [420/1000], Training Loss: 0.000312142597977072\n","Epoch [430/1000], Training Loss: 0.00031177810160443187\n","Epoch [440/1000], Training Loss: 0.00031139134080149233\n","Epoch [450/1000], Training Loss: 0.0003110152902081609\n","Epoch [460/1000], Training Loss: 0.0003106617368757725\n","Epoch [470/1000], Training Loss: 0.0003103297494817525\n","Epoch [480/1000], Training Loss: 0.0003099937457591295\n","Epoch [490/1000], Training Loss: 0.0003096479340456426\n","Epoch [500/1000], Training Loss: 0.0003092505212407559\n","Epoch [510/1000], Training Loss: 0.00030879542464390397\n","Epoch [520/1000], Training Loss: 0.0003082790062762797\n","Epoch [530/1000], Training Loss: 0.00030775414779782295\n","Epoch [540/1000], Training Loss: 0.00030723068630322814\n","Epoch [550/1000], Training Loss: 0.00030673123546876013\n","Epoch [560/1000], Training Loss: 0.00030623734346590936\n","Epoch [570/1000], Training Loss: 0.0003057693538721651\n","Epoch [580/1000], Training Loss: 0.00030531652737408876\n","Epoch [590/1000], Training Loss: 0.0003048810758627951\n","Epoch [600/1000], Training Loss: 0.0003044512413907796\n","Epoch [610/1000], Training Loss: 0.0003040493174921721\n","Epoch [620/1000], Training Loss: 0.00030364026315510273\n","Epoch [630/1000], Training Loss: 0.00030324116232804954\n","Epoch [640/1000], Training Loss: 0.00030286109540611506\n","Epoch [650/1000], Training Loss: 0.00030249234987422824\n","Epoch [660/1000], Training Loss: 0.0003021212760359049\n","Epoch [670/1000], Training Loss: 0.0003017614653799683\n","Epoch [680/1000], Training Loss: 0.00030141149181872606\n","Epoch [690/1000], Training Loss: 0.00030107219936326146\n","Epoch [700/1000], Training Loss: 0.00030074457754381\n","Epoch [710/1000], Training Loss: 0.0003004187310580164\n","Epoch [720/1000], Training Loss: 0.000300083338515833\n","Epoch [730/1000], Training Loss: 0.0002997470728587359\n","Epoch [740/1000], Training Loss: 0.0002994275710079819\n","Epoch [750/1000], Training Loss: 0.0002991135115735233\n","Epoch [760/1000], Training Loss: 0.00029880082001909614\n","Epoch [770/1000], Training Loss: 0.00029849776183255017\n","Epoch [780/1000], Training Loss: 0.0002982093719765544\n","Epoch [790/1000], Training Loss: 0.0002979220589622855\n","Epoch [800/1000], Training Loss: 0.00029764100327156484\n","Epoch [810/1000], Training Loss: 0.0002973605296574533\n","Epoch [820/1000], Training Loss: 0.00029707609792239964\n","Epoch [830/1000], Training Loss: 0.0002967952750623226\n","Epoch [840/1000], Training Loss: 0.0002965113380923867\n","Epoch [850/1000], Training Loss: 0.00029624541639350355\n","Epoch [860/1000], Training Loss: 0.0002959767007268965\n","Epoch [870/1000], Training Loss: 0.00029571770573966205\n","Epoch [880/1000], Training Loss: 0.00029545981669798493\n","Epoch [890/1000], Training Loss: 0.000295209523756057\n","Epoch [900/1000], Training Loss: 0.0002949611807707697\n","Epoch [910/1000], Training Loss: 0.0002947059692814946\n","Epoch [920/1000], Training Loss: 0.0002944511652458459\n","Epoch [930/1000], Training Loss: 0.00029419976635836065\n","Epoch [940/1000], Training Loss: 0.00029395113233476877\n","Epoch [950/1000], Training Loss: 0.0002937085519079119\n","Epoch [960/1000], Training Loss: 0.00029346809606067836\n","Epoch [970/1000], Training Loss: 0.0002932291245087981\n","Epoch [980/1000], Training Loss: 0.00029299105517566204\n","Epoch [990/1000], Training Loss: 0.0002927504829131067\n","Epoch [1000/1000], Training Loss: 0.0002925179142039269\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAloAAAGwCAYAAABxbMuTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABEsElEQVR4nO3de1yUZf7/8ffMICAqKKiACYqlKR7wCJqZm1pqrZuddressN1v/jKzg7mp26Ydvma7tdtBWTtsq21WuvVNs9Y0xcp0LUmlJDyHhxIwU0DwAMzcvz9cZiMQ7oE5MfN6Ph48HnLPNfd85haZt9d13ddlMQzDEAAAANzO6usCAAAAAhVBCwAAwEMIWgAAAB5C0AIAAPAQghYAAICHELQAAAA8hKAFAADgISG+LiCYORwOHTlyRK1atZLFYvF1OQAAwATDMHTy5El16NBBVmvdfVYELR86cuSIEhISfF0GAABogMOHD6tjx451tiFo+VCrVq0knfuLioyM9HE1AADAjJKSEiUkJDg/x+tC0PKhquHCyMhIghYAAE2MmWk/TIYHAADwEIIWAACAhxC0AAAAPIQ5WgCAoGS321VRUeHrMuCnQkND6126wQyCFgAgqBiGoYKCAhUVFfm6FPgxq9WqpKQkhYaGNuo8BC0AQFCpClnt27dXREQEC0ajhqoFxfPz85WYmNionxGCFgAgaNjtdmfIiomJ8XU58GPt2rXTkSNHVFlZqWbNmjX4PEyGBwAEjao5WRERET6uBP6uasjQbrc36jwELQBA0GG4EPVx188IQ4cByO4wtCXvuI6ePKP2rcKVmhQtm5VfKgAAeBtBK8CszsnXo+/lKr/4jPNYfFS45oxL1phe8T6sDACA4MPQYQBZnZOvyUu2VQtZklRQfEaTl2zT6px8H1UGAIHF7jC0ef8Pejf7O23e/4PsDsPXJbmsc+fOevbZZ023//jjj2WxWFgWw0X0aAUIu8PQo+/lqrZ/6oYki6RH38vVFclxDCMCQCN4e+SgvrlCc+bM0SOPPOLyebOystSiRQvT7S+55BLl5+crKirK5ddyxccff6zLL79cJ06cUOvWrT36Wt5A0AoQW/KO1+jJ+jFDUn7xGW3JO64hF3JLMwA0RNXIwU//U1s1crDwlv5uD1v5+f8djVi2bJlmz56t3bt3O4+1bNnS+WfDMGS32xUSUv/He7t27VyqIzQ0VHFxcS49BwwdBoyjJ88fshrSDgCCgWEYOlVeaerr5JkKzVn59XlHDiTpkZW5OnmmwtT5DMPccGNcXJzzKyoqShaLxfn9rl271KpVK33wwQcaMGCAwsLCtHHjRu3fv1/XXHONYmNj1bJlSw0aNEjr1q2rdt6fDh1aLBb97W9/07XXXquIiAh17dpVK1eudD7+06HDxYsXq3Xr1lqzZo169Oihli1basyYMdWCYWVlpe655x61bt1aMTExmjFjhtLT0zV+/HhT7702J06c0G233aY2bdooIiJCY8eO1d69e52PHzx4UOPGjVObNm3UokUL9ezZU6tWrXI+d8KECWrXrp2aN2+url27atGiRQ2uxQx6tAJE+1bhbm0HAMHgdIVdybPXuOVchqSCkjPq/ciHptrnPjZaEaHu+RieOXOmnn76aXXp0kVt2rTR4cOHddVVV2nu3LkKCwvTP/7xD40bN067d+9WYmLiec/z6KOP6k9/+pOeeuopzZ8/XxMmTNDBgwcVHR1da/tTp07p6aef1muvvSar1apbbrlF06dP1+uvvy5J+uMf/6jXX39dixYtUo8ePfTcc89pxYoVuvzyyxv8XidOnKi9e/dq5cqVioyM1IwZM3TVVVcpNzdXzZo105QpU1ReXq4NGzaoRYsWys3Ndfb6Pfzww8rNzdUHH3ygtm3bat++fTp9+nSDazGDoBUgUpOiFR8VroLiM7X+b8siKS7q3FIPAIDA8thjj+mKK65wfh8dHa2UlBTn948//riWL1+ulStX6u677z7veSZOnKibbrpJkvTEE0/o+eef15YtWzRmzJha21dUVOiFF17QhRdeKEm6++679dhjjzkfnz9/vmbNmqVrr71WkrRgwQJn71JDVAWsTZs26ZJLLpEkvf7660pISNCKFSt044036tChQ7r++uvVu3dvSVKXLl2czz906JD69eungQMHSjrXq+dpBK0AYbNaNGdcsiYv2SaLVC1sVU2jnDMumYnwAPAjzZvZlPvYaFNtt+Qd18RFWfW2W3z7IFP/qW3ezGbqdc2oCg5VSktL9cgjj+hf//qX8vPzVVlZqdOnT+vQoUN1nqdPnz7OP7do0UKRkZE6evToedtHREQ4Q5YkxcfHO9sXFxersLBQqampzsdtNpsGDBggh8Ph0vursnPnToWEhCgtLc15LCYmRhdffLF27twpSbrnnns0efJkffjhhxo1apSuv/565/uaPHmyrr/+em3btk1XXnmlxo8f7wxsnsIcrQAyple8Ft7SX7GR1YcH46LCPTJBEwCaOovFoojQEFNfw7q2U3xUuM7331WLzt19OKxrO1Pnc+fq9D+9e3D69Olavny5nnjiCX366afKzs5W7969VV5eXud5frqnn8ViqTMU1dbe7NwzT/mf//kfffPNN7r11lu1Y8cODRw4UPPnz5ckjR07VgcPHtT999+vI0eOaOTIkZo+fbpH6yFoBZgxveK1ccZ/x75fvKW/Ns4YQcgCgEaqGjmQVCNs+dvIwaZNmzRx4kRde+216t27t+Li4nTgwAGv1hAVFaXY2FhlZf23F9But2vbtm0NPmePHj1UWVmpzz//3Hnshx9+0O7du5WcnOw8lpCQoDvvvFPvvPOOHnjgAb388svOx9q1a6f09HQtWbJEzz77rF566aUG12MGQ4cBKMRmlc1qkd1hqF9iG7/4Rw8AgaBq5OCn62jF+dkOHF27dtU777yjcePGyWKx6OGHH27wcF1jTJ06VfPmzdNFF12k7t27a/78+Tpx4oSp3rwdO3aoVatWzu8tFotSUlJ0zTXX6I477tCLL76oVq1aaebMmbrgggt0zTXXSJLuu+8+jR07Vt26ddOJEyf00UcfqUePHpKk2bNna8CAAerZs6fOnj2r999/3/mYpxC0AlRV0KpsgqsVA4A/G9MrXlckx/n1nrJ/+ctf9Jvf/EaXXHKJ2rZtqxkzZqikpMTrdcyYMUMFBQW67bbbZLPZNGnSJI0ePVo2W/3z0y677LJq39tsNlVWVmrRokW699579fOf/1zl5eW67LLLtGrVKucwpt1u15QpU/Ttt98qMjJSY8aM0TPPPCPp3Fpgs2bN0oEDB9S8eXMNGzZMS5cudf8b/xGL4evB1CBWUlKiqKgoFRcXKzIy0q3nTp69WqfK7fr0wcuVEB3h1nMDQFN15swZ5eXlKSkpSeHhLHfjbQ6HQz169NAvf/lLPf74474up051/ay48vlNj1aAqvqfFT1aAABfOXjwoD788EMNHz5cZ8+e1YIFC5SXl6ebb77Z16V5DZPhA1TIf4KW3Qdj8gAASJLVatXixYs1aNAgDR06VDt27NC6des8Pi/Kn9CjFaBs1nMZmh4tAICvJCQkaNOmTb4uw6fo0QpQVT1alXaCFgD8FNOTUR93/YwQtAKUzTl0yC8TAKhSdWfaqVOnfFwJ/F3V4q5m7pCsC0OHASrExmR4APgpm82m1q1bO7eJiYiIcOsK7QgMDodD33//vSIiIhQS0rioRNAKUPRoAUDt4uLiJKnOPfwAq9WqxMTERgdxglaAcs7R4q5DAKjGYrEoPj5e7du3V0VFha/LgZ8KDQ2V1dr4GVYErQBVddchPVoAUDubzdbo+TdAfZgMH6BCWLAUAACfI2gFKOccLZZ3AADAZwhaAYoeLQAAfI+gFaC46xAAAN8jaAWo/66jxV2HAAD4CkErQHHXIQAAvkfQCkB2h6GTp8+tDbO74CRhCwAAHyFoBZjVOfm69I/rtf1wkSTpxQ3f6NI/rtfqnHzfFgYAQBAiaAWQ1Tn5mrxkm/KLz1Q7XlB8RpOXbCNsAQDgZQStAGF3GHr0vVzVNkhYdezR93IZRgQAwIsIWgFiS97xGj1ZP2ZIyi8+oy15x71XFAAAQY6gFSCOnjx/yGpIOwAA0HgErQDRvlW4W9sBAIDGI2gFiNSkaMVHhctynsctkuKjwpWaFO3NsgAACGoErQBhs1o0Z1yyJNUIW1XfzxmX7NyaBwAAeB5BK4CM6RWvhbf0V1xU9eHBuKhwLbylv8b0ivdRZQAABCeCVoAZ0yteG2eM0LX9OkiSRifHauOMEYQsAAB8gKAVgGxWi5LatpQkRbcMY7gQAAAfIWgFqGa2c3+1lXaHjysBACB4EbQCVDPbuV6sCoIWAAA+Q9AKUFU9WhV2ttwBAMBXCFoBqipoldOjBQCAzxC0AlTV0CFztAAA8B2CVoBi6BAAAN8jaAUohg4BAPA9glaAqho6PF52Vu9mf6fN+3+Q3UHvFgAA3hTi6wLgGdmHiiRJ+46W6d6l2ZLObSo9Z1wyq8QDAOAl9GgFoHmrcvXXT/bXOJ5ffEaTl2zT6px8H1QFAEDwIWgFmFVfHdGLG/LO+7gh6dH3chlGBADACwhaAcTuMPSHd3PqbZdffEZb8o57oSIAAIIbQSuAbMk7ruNlFabaHj15xsPVAAAAglYAKSg+bbpt+1bhHqwEAABIBK2Acrys3FS7yPAQpSZFe7gaAABA0Aog0S3DTLW7fkBH2awWD1cDAAAIWgEkLtLccOCVyXEergQAAEgErYCSmhSt+Ki6w1briGYMGwIA4CUErQBis1o0Z1xynW2KTlVobW6BlyoCACC4EbQCzBXJcWod0ey8j1vEgqUAAHgLQSvAbMk7rqJT519LyxALlgIA4C0ErQBjdiFSFiwFAMDzCFoBxuxCpCxYCgCA5xG0AkzVnYfnWyXLIik+Kpw7DwEA8AKCVoD58Z2HPw1bVd/PGZfMgqUAAHgBQSsAjekVr4W39FfcT9bUiosK18Jb+mtMr3gfVQYAQHAhaAWoMb3itXHGCF3Wra0k6aZBCdo4YwQhCwAALyJoBTCb1aJO0S0kSe0iwxkuBADAywhaAS405Fy4yvmuWJv3/8BCpQAAeFGIrwuA56zOydeyrMOSpPW7jmr9rqOKjwrXnHHJDCECAOAF9GgFqNU5+Zq8ZJtKz9qrHS8oPqPJS7ZpdU6+jyoDACB4ELQCkN1h6NH3clXbIGHVMfY7BADA8whaAWhL3nHlF59/ix32OwQAwDsIWgGI/Q4BAPAPBK0AxH6HAAD4B4JWAGK/QwAA/ANBKwBV7Xd4vqnuhtjvEAAAbyBoAQAAeAhBKwBVLe9wPhaxvAMAAN5A0ApALO8AAIB/IGgFIJZ3AADAPxC0AhDLOwAA4B8IWgGoanmH+pwoK/dCNQAABC+CVgCyWS16+Ooe9bZ7/F9MiAcAwJMIWgGqTYuwetswIR4AAM8iaAUoJsQDAOB7BK0A1dZEj5Yr7QAAgOsIWoHK7O467MIDAIDHELQC1LHSs25tBwAAXEfQClAMHQIA4HsErUDF0CEAAD5H0ApQDB0CAOB7BK0AZXZ7nQPHTnm4EgAAghdBK0ClJkUrLrL++VdLsw6xOjwAAB5C0ApQNqtFN6Um1tuO1eEBAPAcglYA69y2hal2rA4PAIBnELQCmNl5WmbbAQAA1xC0GqGoqEgDBw5U37591atXL7388su+LqmaAZ3ayFrP8g1Wy7l2AADA/UJ8XUBT1qpVK23YsEEREREqKytTr169dN111ykmJsbXpUmSth48ofrmuTuMc+2GXOgfNQMAEEjo0WoEm82miIgISdLZs2dlGIYMw3/u4DM794o5WgAAeEZAB60NGzZo3Lhx6tChgywWi1asWFGjTUZGhjp37qzw8HClpaVpy5YtLr1GUVGRUlJS1LFjR/3ud79T27Zt3VR947GWFgAAvhXQQausrEwpKSnKyMio9fFly5Zp2rRpmjNnjrZt26aUlBSNHj1aR48edbapmn/1068jR45Iklq3bq0vv/xSeXl5euONN1RYWOiV92YGa2kBAOBbFsOfxro8yGKxaPny5Ro/frzzWFpamgYNGqQFCxZIkhwOhxISEjR16lTNnDnT5de46667NGLECN1www21Pn727FmdPfvfLW9KSkqUkJCg4uJiRUZGuvx6Zjy3bo+eWbe33nZv3jGYeVoAAJhQUlKiqKgoU5/fAd2jVZfy8nJt3bpVo0aNch6zWq0aNWqUNm/ebOochYWFOnnypCSpuLhYGzZs0MUXX3ze9vPmzVNUVJTzKyEhoXFvwgTW0gIAwHeCNmgdO3ZMdrtdsbGx1Y7HxsaqoKDA1DkOHjyoYcOGKSUlRcOGDdPUqVPVu3fv87afNWuWiouLnV+HDx9u1Hswg7W0AADwHZZ3aITU1FRlZ2ebbh8WFqawsPrnTLlT1VpadU3BYi0tAAA8I2h7tNq2bSubzVZj8nphYaHi4uJ8VJX7ubKWFgAAcK+gDVqhoaEaMGCAMjMzncccDocyMzM1ZMgQH1bmXmbnXq3NNTdcCgAAzAvooFVaWqrs7Gzn8F5eXp6ys7N16NAhSdK0adP08ssv69VXX9XOnTs1efJklZWV6fbbb/dh1e5ldu7Vu9lHWOIBAAA3C+g5Wl988YUuv/xy5/fTpk2TJKWnp2vx4sX61a9+pe+//16zZ89WQUGB+vbtq9WrV9eYIN+UpSZFK7pFMx0vq6iz3Q9l5dqSd5wlHgAAcKOgWUfLH7myDkdjPLoyR4v+fbDeds/8MkXX9u/osToAAAgErKOFajq2iTDVbtO+Yx6uBACA4ELQCgLRLc0tKbFu51HmaQEA4EYErSAQF2luQnzR6QptyTvu4WoAAAgeBK0gkJoUrahwc/c9FBSf9nA1AAAED4JWELBZLboi2dydlMfLyj1cDQAAwYOgFSSGdm1nqt23RfRoAQDgLgStIGF2ntZKFi4FAMBtCFpBomrh0vpULVwKAAAaj6AVJGxWi67te4Gptmb3RwQAAHUjaAWREd3NTYhv28LculsAAKBuBK1gYnFzOwAAUCeCVhA5VnrWre0AAEDdCFo+kJGRoeTkZA0aNMirr9u+lbk7D822AwAAdSNo+cCUKVOUm5urrKwsr77ugE5tZK1nWNBqOdcOAAA0HkEriGw9eEL1LZHlMM61AwAAjUfQCiJml21Ym1vg4UoAAAgOBK0gYnbu1busDg8AgFsQtIIIq8MDAOBdBK0gwurwAAB4F0EryLA6PAAA3kPQCjasDg8AgNcQtIKM2VXfM3cWergSAAACH0EryHDnIQAA3kPQCjLceQgAgPcQtIIMdx4CAOA9BK0gxJ2HAAB4B0ErGJm8ozDrAEOHAAA0BkErCJm983Dx5gNMiAcAoBEIWkHI7J2HRacqmBAPAEAjELSCUGpStKLCQ0y1LSg+7eFqAAAIXAStIGSzWnRFsrkJ8Zv2HfNwNQAABC6CVpAa2rWdqXbrdh5lnhYAAA1E0ApScZEm52mdZp4WAAANRdAKUqlJ0WrdvP4V4iUWLgUAoKEIWkHKZrUo/ZJOptqycCkAAA1D0PKBjIwMJScna9CgQT6tIzUpxlxDkwucAgCA6ghaPjBlyhTl5uYqKyvLp3UcLTE3JLgut8DDlQAAEJgIWkHseFm5qXb/t+077jwEAKABCFpBLLqlublXJWcqufMQAIAGIGgFMbNLPEisEA8AQEMQtIJYalK0WoXbTLVlhXgAAFxH0ApiNqtFN/TvaKrtqpwC5mkBAOAiglaQu7JnvKl2p8rt+mz/Dx6uBgCAwELQCnKpSdFqEWpu+HDJ5wc8WwwAAAGGoBXkbFaLLutmboPpT/f+wPAhAAAuIGhBtww2txVP6VmWeQAAwBUELWhwlxg1b2buR4FlHgAAMI+gBdmsFl3d29ykeLOryQMAAIIW/mNoV3PztL4tokcLAACzCFqQZH6V+JXZR5gQDwCASQ0KWocPH9a3337r/H7Lli2677779NJLL7mtMHhXalK0ols0q7fdD2XlTIgHAMCkBgWtm2++WR999JEkqaCgQFdccYW2bNmihx56SI899phbC4R32KwWXZPSwVRbJsQDAGBOg4JWTk6OUlNTJUn//Oc/1atXL/373//W66+/rsWLF7uzPnhRxzYRptqx7yEAAOY0KGhVVFQoLCxMkrRu3Tr94he/kCR1795d+fn57qsOXhXdMsxUu3U7jzJPCwAAExoUtHr27KkXXnhBn376qdauXasxY8ZIko4cOaKYmBi3FgjvMTshvuh0BfO0AAAwoUFB649//KNefPFF/exnP9NNN92klJQUSdLKlSudQ4poelKTohUVHmKqLfO0AACon7lP1Z/42c9+pmPHjqmkpERt2rRxHp80aZIiIszN84H/sVktuiI5Vm9v+67etixcCgBA/RrUo3X69GmdPXvWGbIOHjyoZ599Vrt371b79u3dWiC8a8iFbU21ax0R6uFKAABo+hoUtK655hr94x//kCQVFRUpLS1Nf/7znzV+/HgtXLjQrQXCu4pOmeup2ryfOw8BAKhPg4LWtm3bNGzYMEnS22+/rdjYWB08eFD/+Mc/9Pzzz7u1QHiX2TsPV+UUcOchAAD1aFDQOnXqlFq1aiVJ+vDDD3XdddfJarVq8ODBOnjwoFsLhHeZvfPwVLldn+3/wcPVAADQtDUoaF100UVasWKFDh8+rDVr1ujKK6+UJB09elSRkZFuLTAQZWRkKDk5WYMGDfJ1KTWkJkWrRajNVNslnx/wbDEAADRxDQpas2fP1vTp09W5c2elpqZqyJAhks71bvXr18+tBQaiKVOmKDc3V1lZWb4upQab1aLLurUz1fbTvT8wfAgAQB0aFLRuuOEGHTp0SF988YXWrFnjPD5y5Eg988wzbisOvnHL4E6m2pWerWThUgAA6tCgdbQkKS4uTnFxcfr2228lSR07dmSx0gAxuEuMmjez6nSFo962H36dryEXshsAAAC1aVCPlsPh0GOPPaaoqCh16tRJnTp1UuvWrfX444/L4aj/wxn+zWa16Ore8aba/t+27xg+BADgPBoUtB566CEtWLBATz75pLZv367t27friSee0Pz58/Xwww+7u0b4wNCu5uZplZxh+BAAgPNp0NDhq6++qr/97W/6xS9+4TzWp08fXXDBBbrrrrs0d+5ctxUI3zC7zIPE8CEAAOfToB6t48ePq3v37jWOd+/eXceP07sRCFKTotUq3NwyDwwfAgBQuwYFrZSUFC1YsKDG8QULFqhPnz6NLgq+Z7NadEP/jqbaMnwIAEDtGjR0+Kc//UlXX3211q1b51xDa/PmzTp8+LBWrVrl1gLhO1f2jNeif5tb6Z/hQwAAampQj9bw4cO1Z88eXXvttSoqKlJRUZGuu+46ff3113rttdfcXSN8hOFDAAAax2IYhts+Hb/88kv1799fdrvdXacMaCUlJYqKilJxcbHfbl306Moc071ab94xmF4tAEDAc+Xzu0E9WggeV/Y0t56WJBUUn/ZgJQAAND0ELdQpNSlaLcPM/ZgcKz3r4WoAAGhaCFqok81q0aUXmVu8dOuhEx6uBgCApsWluw6vu+66Oh8vKipqTC3wUxe1byV9XVhvu493fS+7w5DNavFCVQAA+D+XglZUVFS9j992222NKgj+Z8iFMVrw0b56252pdOiz/T9oaNe2XqgKAAD/51LQWrRokafqgB8b3CVGYSFWna2sf8PwJZ8fIGgBAPAfzNFCvWxWi0Z0b2+q7ad7f2A9LQAA/oOgBVNuGdzJVLvSs2zHAwBAFYIWTBncJUbNm5n7cfnw63wPVwMAQNNA0IIpNqtFV/c2t3gp2/EAAHAOQQumDe1qbj2tkjMMHwIAIBG04IK4yHDTbRk+BACAoOV2p06dUqdOnTR9+nRfl+J2qUnRahVuM9WW4UMAAAhabjd37lwNHjzY12V4hM1q0Q39O5pqy/AhAAAELbfau3evdu3apbFjx/q6FI+5sqe5CfGSVFB82oOVAADg//wiaH333Xe65ZZbFBMTo+bNm6t379764osv3Hb+DRs2aNy4cerQoYMsFotWrFhRa7uMjAx17txZ4eHhSktL05YtW1x6nenTp2vevHluqNh/pSZFq2WYuR+bjfuOebgaAAD8m8+D1okTJzR06FA1a9ZMH3zwgXJzc/XnP/9Zbdq0qbX9pk2bVFFRUeN4bm6uCgtr3/i4rKxMKSkpysjIOG8dy5Yt07Rp0zRnzhxt27ZNKSkpGj16tI4ePeps07dvX/Xq1avG15EjR/Tuu++qW7du6tatm4tXoGmxWS269CJzdx/+66t85mkBAIKaxTAMn34Szpw5U5s2bdKnn35ab1uHw6H+/fura9euWrp0qWy2cxOzd+/ereHDh2vatGl68MEH6zyHxWLR8uXLNX78+GrH09LSNGjQIC1YsMD5WgkJCZo6dapmzpxZb22zZs3SkiVLZLPZVFpaqoqKCj3wwAOaPXt2jbYZGRnKyMiQ3W7Xnj17VFxcrMjIyHpfw188vWa3qU2mJen136ax9yEAIKCUlJQoKirK1Oe3z3u0Vq5cqYEDB+rGG29U+/bt1a9fP7388su1trVarVq1apW2b9+u2267TQ6HQ/v379eIESM0fvz4ekPW+ZSXl2vr1q0aNWpUtdcaNWqUNm/ebOoc8+bN0+HDh3XgwAE9/fTTuuOOO2oNWZI0ZcoU5ebmKisrq0H1+tqQC2NMt13y+QHPFQIAgJ/zedD65ptvtHDhQnXt2lVr1qzR5MmTdc899+jVV1+ttX2HDh20fv16bdy4UTfffLNGjBihUaNGaeHChQ2u4dixY7Lb7YqNja12PDY2VgUFBQ0+b6Aa3CVGYSEWU23X5R5l+BAAELRCfF2Aw+HQwIED9cQTT0iS+vXrp5ycHL3wwgtKT0+v9TmJiYl67bXXNHz4cHXp0kWvvPKKLBZzH/zeMHHiRF+X4FE2q0WTh1+oZzPrHz6scBian7lX910R2HPXAACojc97tOLj45WcnFztWI8ePXTo0KHzPqewsFCTJk3SuHHjdOrUKd1///2NqqFt27ay2Ww1JtMXFhYqLi6uUecOVFNHdpPJPab1t43f0KsFAAhKPg9aQ4cO1e7du6sd27Nnjzp16lRr+2PHjmnkyJHq0aOH3nnnHWVmZmrZsmWNWok9NDRUAwYMUGZmpvOYw+FQZmamhgwZ0uDzBjKb1aJRyeZCaOlZO4uXAgCCks+D1v3336/PPvtMTzzxhPbt26c33nhDL730kqZMmVKjrcPh0NixY9WpUyctW7ZMISEhSk5O1tq1a7Vo0SI988wztb5GaWmpsrOzlZ2dLUnKy8tTdnZ2tV6zadOm6eWXX9arr76qnTt3avLkySorK9Ptt9/ukfcdCG4ZXHsYrg17HwIAgpHPl3eQpPfff1+zZs3S3r17lZSUpGnTpumOO+6ote3atWs1bNgwhYdX3+B4+/btateunTp2rLlFzMcff6zLL7+8xvH09HQtXrzY+f2CBQv01FNPqaCgQH379tXzzz+vtLS0xr25Orhye6g/sjsM9ZyzWmcqHPW2bd7MqpxHx8hm9Z+5dAAANIQrn99+EbSCVVMPWpL06MocLfr3QVNtWVMLABAImtQ6WmjaXNn7kDW1AADBhqCFRklNilaLMJupth/t+p67DwEAQYWghUaxWS2649IkU23PVDr02f4fPFwRAAD+g6CFRps6sptMLhSvTfu/92wxAAD4EYIWGs1mtah/pzam2n5x4ISHqwEAwH8QtOAWg5KiTbXbfqiIeVoAgKBB0IJbXHKhuWUbqvY+BAAgGBC04BaDu8QoLMTcj1PGR/vo1QIABAWCFtzCZrVoRPf2ptrSqwUACBYELbiNK3sf/m3jN/RqAQACHkELbnNu+NDcOg+lZ+3aknfcwxUBAOBbBC24jc1q0eThF5pu/+HX+R6sBgAA3yNowa2mjuymZlZzvVqvf36I4UMAQEAjaMGtbFaLbhmcaKptuZ1J8QCAwEbQgttd2TPedNsXPtlPrxYAIGARtOB2qUnRahFmM9WWjaYBAIGMoAW3s1ktuuPSJNPt2WgaABCoCFrwiKkju8lmbk48G00DAAIWQQseYbNadEVyrKm2bDQNAAhUBC14zK1DOptqx5Y8AIBARdCCx7DRNAAg2BG04DFsNA0ACHYELXiUKxtN06sFAAg0BC14lCsbTdOrBQAINAQteJSrG03/beM39GoBAAIGQQse58pG06Vn7dqSd9zDFQEA4B0ELXiczWrRlMvN92oVFJ/2YDUAAHgPQcsHMjIylJycrEGDBvm6FK+ZOrKbTE7V0sZ9xzxbDAAAXkLQ8oEpU6YoNzdXWVlZvi7Fa2xWi0aZXCl+ZfYR5mkBAAICQQtec1H7VqbacfchACBQELTgNUMujDHdljW1AACBgKAFr2FNLQBAsCFowWtcXVOLXi0AQFNH0IJXubKmFr1aAICmjqAFr3J1TS16tQAATRlBC15HrxYAIFgQtOB1rvZqvfDJfnq1AABNEkELPuFKr9aZSoc+2/+DhysCAMD9CFrwCVd7tf7x2QHPFQMAgIcQtOAzU0d2k83k/oeZOwsZPgQANDkELfiMzWrRFSb3P6x0iEnxAIAmh6AFn7p1SGfTbVnqAQDQ1BC04FNsywMACGQELfgU2/IAAAIZQQs+xwKmAIBARdCCz7EtDwAgUBG04Bfo1QIABCKCFvwC2/IAAAIRQQt+g215AACBhqAFv8G2PACAQEPQgl9xZVueD79mWx4AgH8jaMGvuLItjyHply/827MFAQDQCAQt+B1XtuXZeqhI7315xHPFAADQCAQt+B1XtuWRpAf+mc0QIgDALxG04Hdc3Zan3M66WgAA/0TQgl9yZakHiXW1AAD+iaAFv2SzWvTML1NMt2ddLQCAPyJowW/9vO8F6p8YZbr9Qyt2eLAaAABcR9CCX3vrzqGmf0gP/HCKOxABAH6FoAW/ZrNadGVPc+tqSdK0ZduZqwUA8BsELfg9V9bVqnBI97653XPFAADgAoIW/N7gLjEKb2b+R/X9Hfla9VW+BysCAMAcghb8ns1q0dPX93HpOdNYxBQA4AcIWmgSXL0D8Uylg0VMAQA+R9Bys1OnTqlTp06aPn26r0sJOG/dOVQ282uYav76vfRqAQB8iqDlZnPnztXgwYN9XUZAslktmjriItPt7Yb03No9HqwIAIC6EbTcaO/evdq1a5fGjh3r61IC1tSR3RTmQrfW/I/20asFAPAZvwpaTz75pCwWi+677z63nnfDhg0aN26cOnToIIvFohUrVtTaLiMjQ507d1Z4eLjS0tK0ZcsWl15n+vTpmjdvnhsqxvnYrBY986u+ptsbkm5cuMlj9QAAUBe/CVpZWVl68cUX1adP3XeXbdq0SRUVFTWO5+bmqrCwsNbnlJWVKSUlRRkZGec977JlyzRt2jTNmTNH27ZtU0pKikaPHq2jR4862/Tt21e9evWq8XXkyBG9++676tatm7p162byHaOhrurTQYOT2phuv+1wsR5/P9eDFQEAUDuLYRg+H1cpLS1V//799de//lX/+7//q759++rZZ5+t0c7hcKh///7q2rWrli5dKpvNJknavXu3hg8frmnTpunBBx+s87UsFouWL1+u8ePHVzuelpamQYMGacGCBc7XSkhI0NSpUzVz5sx638OsWbO0ZMkS2Ww2lZaWqqKiQg888IBmz5593ueUlJQoKipKxcXFioyMrPc18F/llQ51+8MHLj3nrzf311V94j1UEQAgWLjy+e0XPVpTpkzR1VdfrVGjRtXZzmq1atWqVdq+fbtuu+02ORwO7d+/XyNGjND48ePrDVnnU15erq1bt1Z7favVqlGjRmnz5s2mzjFv3jwdPnxYBw4c0NNPP6077rjjvCErIyNDycnJGjRoUIPqhRQaYtXVvc1vzSNJ9y5lex4AgHf5PGgtXbpU27ZtMz23qUOHDlq/fr02btyom2++WSNGjNCoUaO0cOHCBtdw7Ngx2e12xcZW/+COjY1VQUFBg897PlOmTFFubq6ysrLcfu5g8vxNA1xa7qHCYbA9DwDAq0J8+eKHDx/Wvffeq7Vr1yo8PNz08xITE/Xaa69p+PDh6tKli1555RVZLC584nrYxIkTfV1CULBZLXruV31199Js0895f0e+/lLpUGiIz/+PAQAIAj79tNm6dauOHj2q/v37KyQkRCEhIfrkk0/0/PPPKyQkRHa7vdbnFRYWatKkSRo3bpxOnTql+++/v1F1tG3bVjabrcZk+sLCQsXFxTXq3PAsV1eMl6Srn9vgoWoAAKjOp0Fr5MiR2rFjh7Kzs51fAwcO1IQJE5Sdne2c7P5jx44d08iRI9WjRw+98847yszM1LJlyxq1EntoaKgGDBigzMxM5zGHw6HMzEwNGTKkweeFd7x151C50kG19/syPfre154rCACA//Dp0GGrVq3Uq1evasdatGihmJiYGselc+Fn7Nix6tSpk5YtW6aQkBAlJydr7dq1GjFihC644IJae7dKS0u1b98+5/d5eXnKzs5WdHS0EhMTJUnTpk1Tenq6Bg4cqNTUVD377LMqKyvT7bff7uZ3DXezWS16/tf9dNcb5udfLdp0QCFWix66OtmDlQEAgp1Pg5arrFarnnjiCQ0bNkyhoaHO4ykpKVq3bp3atWtX6/O++OILXX755c7vp02bJklKT0/X4sWLJUm/+tWv9P3332v27NkqKChQ3759tXr16hoT5OGfrurTQVd9dUSrcmpfS602L3+ap34JbVjyAQDgMX6xjlawYh0t97I7DHV7aJXsLvxEh9ksyn18rGxW/7mZAgDg35rcOlqAO1TdheiKs3ZD97yxzTMFAQCCHkELAaUhdyH+K6dAj7/P5HgAgPsRtBBwXL0LUZJe2XiAsAUAcDuCFgJO1V2Irnpl4wHN/RebTwMA3IeghYB0VZ8OLu+FKJ27E3HVV/keqAgAEIwIWghYz980QGGubIb4H1Pe2Mbm0wAAtyBoIWDZrBY94+JdiJJkSBrx1Hq31wMACD4ELQS0q/p00B3DOrv8vIMnzujq5z5xf0EAgKBC0ELAe+jqnvrtpZ1dft7X+aX6+fNsQA0AaDiCFoLCwz9vWNjKOXJSt//9c/cXBAAICgQtBI2Hf95Ttw/t5PLzPtpzjLAFAGgQghaCypxxvTTi4rYuP++jPcf0sz9lcjciAMAlBC0Enb/fnqZe8S1dft6B42fU9fertOqrIx6oCgAQiAhaCErv3ztcPRsQthyS7npjux5/P8f9RQEAAg5BC0HrX/cOV+fo8AY995WNB3VtxqcMJQIA6kTQQlDLnD6iwf8Ith8u0UW/X6X3s79za00AgMBB0EJQs1ktWnCz6xtQVzEk3b00W79dzF2JAICaCFoIelf16aD/d1lSo86RueuY0uZ+qPJKh5uqAgAEAoIWIGnWVcn668395foW1P9VeLJC3f7wge5cksXcLQCAJIIW4HRVn3jte+IqdWrTsAnyVVbnHNWFv1+lv6zZReACgCBH0AJ+xGa16JMZI9WrQ6tGn+v5j/brIgIXAAQ1ghZQi/fvuUwju7dv9HkMnQtcXbk7EQCCEkELOI9XJg7S/Jv6NWreVhWHzt2dOHjuWn2653t6uAAgSFgMw+A3vo+UlJQoKipKxcXFioyM9HU5OA+7w9ANf92k7d8Wu/W816Z00B9vTFFoCP/fAYCmxJXPb4KWDxG0mpbH38/VKxvz3H7e9q3C9D+XJmni0CRCFwA0AQStJoKg1fSs+ipfU9/cJruH/tUQugDA/xG0mgiCVtNkdxia+sY2rcop8OjrtG4eojuHX6jfXNqF0AUAfoSg1UQQtJq28kqHhv9pvfJLznr8tcJDrIqPCtclF8boDz/vqeahNo+/JgCgdgStJoKgFRjezf5O9y/LljdvJLRJioxopnYtQ3Vd/470egGAFxG0mgiCVuCwOww9t3aP5n+0T776BxVqlSLCQtQyLET9E9voxoEJuuSitrJZ3bFABQCgCkGriSBoBR5vzd9yRYtmFkWGN5PValGLsBD1iI/SDQM6EsIAoIEIWk0EQStwlVc6dOsrn+nzvBO+LqVOUWFW2awW2Q0pxGpRdIswJXcgiAFAXQhaTQRBK/CVVzo08/++1PLtR3w2pNgYUeE2RTSz6mylQ3ZDslmksBCbbDarYiPDNbpnHEtRAAg6BK0mgqAVPOwOQxt3f6+Zy7/yyl2K3hZukyJCbdXCmGTUCGiSoXK7oWYhNl3YroUmXXahLu3ajp4zAE0KQauJIGgFp6perhXZR7x6p6I/ax4iNW9mqzOg/fhYqM2qcjshDoBvELSaCIJWcLM7DP177zG9tfWQNuw9pqLTlb4uKSA1NsQ1D22muCiGSQH8F0GriSBo4cfKKx16ZeN+vfjJN4QuPxZqlWJahMpsL1tVG242AAIHQauJIGjhfMorHVq06RutySnQrsKTOlXu8HVJ8IAWzSxqFRZCQAOaGIJWE0HQglk/Dl75xad04lSlzlTyTzdYne9u0J/2soU3C1HLcNZOA9yNoNVEELTQGD8NXyfP2FVKzxfq8eO108zMU2tmsyoxuoXG9GKOGlCFoNVEELTgblUT7P/5xUFtPXRCZWftslmkM5WGTlUQwtB4zSxSq/Daby6oa56aYbGyNycCBkGriSBowZt+3ANWUHJaMiTDOPchSBCDt4VapeahNlM3EtTWhmFR+BJBy4dOnTqlHj166MYbb9TTTz9dZ1uCFvxJ1aKqL2zYp/3fl6rS7qj1A6+03KFyO7824H9qm7tmJsTR8wZXEbR86KGHHtK+ffuUkJBA0ELAOl1u12Pv5+jf+46p9EyFmlnNfZidrrCr6Izd1+UDptU1VOrq8KlDFrUMC1H/xDa6cWACvXBNmCuf3yFeqiko7N27V7t27dK4ceOUk5Pj63IAj2keatO861Ia9NwfL9T69ZFinThVLrvDXG9DXR9mhDh4QoUhHT9tl1Tbz5aZY9W/LzpdqW+L8rXyq3xJ55b4iAxvpsaGOIZU/ZfPg9bChQu1cOFCHThwQJLUs2dPzZ49W2PHjnXba2zYsEFPPfWUtm7dqvz8fC1fvlzjx4+v0S4jI0NPPfWUCgoKlJKSovnz5ys1NdX060yfPl1PPfWU/v3vf7utdiDQ2KwWDbu4nYZd3M7t53Z3iKuavwZ4SlmFobKK8loecT3ESZJO26WSs9pztEzvfnlEkhQZZlVIPXeaNiTYcUeqOT4PWh07dtSTTz6prl27yjAMvfrqq7rmmmu0fft29ezZs0b7TZs2KTU1Vc2aNat2PDc3VzExMYqNja3xnLKyMqWkpOg3v/mNrrvuulrrWLZsmaZNm6YXXnhBaWlpevbZZzV69Gjt3r1b7du3lyT17dtXlZU1V+z+8MMPlZWVpW7duqlbt24ELcBHPBHiqlbs/7+t3+r7k2cb9KHEzQbwpZKzP/3Zc0/vnGTXsbIibTtcpCc+2OUcZm3IzQ1mwl9TDXZ+OUcrOjpaTz31lH77299WO+5wONS/f3917dpVS5culc1mkyTt3r1bw4cP17Rp0/Tggw/WeW6LxVJrj1ZaWpoGDRqkBQsWOF8rISFBU6dO1cyZM+utedasWVqyZIlsNptKS0tVUVGhBx54QLNnz67RNiMjQxkZGbLb7dqzZw9ztIAgcL6lNwhoQMOcbzssb2wy32Qnw9vtdr311ltKT0/X9u3blZycXKPNkSNHdNlllyktLU2vvfaa8vLydNlll2ncuHF64YUX6n2N2oJWeXm5IiIi9Pbbb1c7np6erqKiIr377rsuvY/FixcrJyeHyfAAGs3s3aA/PcawJ1BdWIhVz/26r8b0im/0uZrcZPgdO3ZoyJAhOnPmjFq2bKnly5fXGrIkqUOHDlq/fr2GDRumm2++WZs3b9aoUaO0cOHCBr/+sWPHZLfbaww7xsbGateuXQ0+LwA0ls1q0fAe7TW8R3uXn1vX2mlmhnVYygOB5GylQ3cu2aYXbunvlrBlll8ErYsvvljZ2dkqLi7W22+/rfT0dH3yySfnDVuJiYl67bXXNHz4cHXp0kWvvPKKLBb/uati4sSJvi4BABQaYtX/G36R/t/wixp8jqqwtnpHvg4eL6vz5oLzDYOeOM3enPAfj6zM1RXJcV67G9MvglZoaKguuujcL4IBAwYoKytLzz33nF588cVa2xcWFmrSpEkaN26csrKydP/992v+/PkNfv22bdvKZrOpsLCwxuvExcU1+LwA0NS5I6xJNffmPFvh2sToH7exOwz29USDFZSc0Za84xpyYYxXXs8vgtZPORwOnT17ttbHjh07ppEjR6pHjx566623tGfPHv3sZz9TWFhYvXOizic0NFQDBgxQZmamc46Ww+FQZmam7r777oa+DQDAf7grsFUxO3fNlbvb6HkLHkdPnvHaa/k8aM2aNUtjx45VYmKiTp48qTfeeEMff/yx1qxZU6Otw+HQ2LFj1alTJy1btkwhISFKTk7W2rVrNWLECF1wwQW6//77azyvtLRU+/btc36fl5en7OxsRUdHKzExUZI0bdo0paena+DAgUpNTdWzzz6rsrIy3X777Z578wCABmnM3LW6uDJU6kqwO3nWTi+cH2nfKtxrr+Xzuw5/+9vfKjMzU/n5+YqKilKfPn00Y8YMXXHFFbW2X7t2rYYNG6bw8OoXafv27WrXrp06duxY4zkff/yxLr/88hrH09PTtXjxYuf3CxYscC5Y2rdvXz3//PNKS0tr3BusA3cdAkDwON8SH+5aQJQhVXPiIsO1aeaIRs3RarLLOwQbghYAwJ1qG1JtyOKg9QW7pnxHqjvuOmxyyzsAAIDG89SQam3ON8zqiZXh3RHs3LmOlivo0fIherQAADDH7HZYrAwPJ4IWAABNjyuf301jR0YAAIAmiKAFAADgIQQtAAAADyFoAQAAeAhBCwAAwEMIWgAAAB5C0AIAAPAQghYAAICHELQAAAA8hL0OfahqUf6SkhIfVwIAAMyq+tw2s7kOQcuHTp48KUlKSEjwcSUAAMBVJ0+eVFRUVJ1t2OvQhxwOh44cOaJWrVrJYnHPRpdVSkpKlJCQoMOHD7OPogdxnb2D6+wdXGfv4Vp7h6eus2EYOnnypDp06CCrte5ZWPRo+ZDValXHjh09+hqRkZH8I/YCrrN3cJ29g+vsPVxr7/DEda6vJ6sKk+EBAAA8hKAFAADgIQStABUWFqY5c+YoLCzM16UENK6zd3CdvYPr7D1ca+/wh+vMZHgAAAAPoUcLAADAQwhaAAAAHkLQAgAA8BCCFgAAgIcQtAJQRkaGOnfurPDwcKWlpWnLli2+LqlJmTdvngYNGqRWrVqpffv2Gj9+vHbv3l2tzZkzZzRlyhTFxMSoZcuWuv7661VYWFitzaFDh3T11VcrIiJC7du31+9+9ztVVlZ68600KU8++aQsFovuu+8+5zGus3t89913uuWWWxQTE6PmzZurd+/e+uKLL5yPG4ah2bNnKz4+Xs2bN9eoUaO0d+/eauc4fvy4JkyYoMjISLVu3Vq//e1vVVpa6u234rfsdrsefvhhJSUlqXnz5rrwwgv1+OOPV9sLj+vcMBs2bNC4cePUoUMHWSwWrVixotrj7rquX331lYYNG6bw8HAlJCToT3/6k3vegIGAsnTpUiM0NNT4+9//bnz99dfGHXfcYbRu3dooLCz0dWlNxujRo41FixYZOTk5RnZ2tnHVVVcZiYmJRmlpqbPNnXfeaSQkJBiZmZnGF198YQwePNi45JJLnI9XVlYavXr1MkaNGmVs377dWLVqldG2bVtj1qxZvnhLfm/Lli1G586djT59+hj33nuv8zjXufGOHz9udOrUyZg4caLx+eefG998842xZs0aY9++fc42Tz75pBEVFWWsWLHC+PLLL41f/OIXRlJSknH69GlnmzFjxhgpKSnGZ599Znz66afGRRddZNx0002+eEt+ae7cuUZMTIzx/vvvG3l5ecZbb71ltGzZ0njuueecbbjODbNq1SrjoYceMt555x1DkrF8+fJqj7vjuhYXFxuxsbHGhAkTjJycHOPNN980mjdvbrz44ouNrp+gFWBSU1ONKVOmOL+32+1Ghw4djHnz5vmwqqbt6NGjhiTjk08+MQzDMIqKioxmzZoZb731lrPNzp07DUnG5s2bDcM494vBarUaBQUFzjYLFy40IiMjjbNnz3r3Dfi5kydPGl27djXWrl1rDB8+3Bm0uM7uMWPGDOPSSy897+MOh8OIi4sznnrqKeexoqIiIywszHjzzTcNwzCM3NxcQ5KRlZXlbPPBBx8YFovF+O677zxXfBNy9dVXG7/5zW+qHbvuuuuMCRMmGIbBdXaXnwYtd13Xv/71r0abNm2q/d6YMWOGcfHFFze6ZoYOA0h5ebm2bt2qUaNGOY9ZrVaNGjVKmzdv9mFlTVtxcbEkKTo6WpK0detWVVRUVLvO3bt3V2JiovM6b968Wb1791ZsbKyzzejRo1VSUqKvv/7ai9X7vylTpujqq6+udj0lrrO7rFy5UgMHDtSNN96o9u3bq1+/fnr55Zedj+fl5amgoKDadY6KilJaWlq169y6dWsNHDjQ2WbUqFGyWq36/PPPvfdm/Ngll1yizMxM7dmzR5L05ZdfauPGjRo7dqwkrrOnuOu6bt68WZdddplCQ0OdbUaPHq3du3frxIkTjaqRTaUDyLFjx2S326t96EhSbGysdu3a5aOqmjaHw6H77rtPQ4cOVa9evSRJBQUFCg0NVevWrau1jY2NVUFBgbNNbX8PVY/hnKVLl2rbtm3Kysqq8RjX2T2++eYbLVy4UNOmTdPvf/97ZWVl6Z577lFoaKjS09Od16m26/jj69y+fftqj4eEhCg6Oprr/B8zZ85USUmJunfvLpvNJrvdrrlz52rChAmSxHX2EHdd14KCAiUlJdU4R9Vjbdq0aXCNBC2gDlOmTFFOTo42btzo61ICzuHDh3Xvvfdq7dq1Cg8P93U5AcvhcGjgwIF64oknJEn9+vVTTk6OXnjhBaWnp/u4usDxz3/+U6+//rreeOMN9ezZU9nZ2brvvvvUoUMHrnOQY+gwgLRt21Y2m63GXVmFhYWKi4vzUVVN19133633339fH330kTp27Og8HhcXp/LychUVFVVr/+PrHBcXV+vfQ9VjODc0ePToUfXv318hISEKCQnRJ598oueff14hISGKjY3lOrtBfHy8kpOTqx3r0aOHDh06JOm/16mu3xtxcXE6evRotccrKyt1/PhxrvN//O53v9PMmTP161//Wr1799att96q+++/X/PmzZPEdfYUd11XT/4uIWgFkNDQUA0YMECZmZnOYw6HQ5mZmRoyZIgPK2taDMPQ3XffreXLl2v9+vU1upMHDBigZs2aVbvOu3fv1qFDh5zXeciQIdqxY0e1f9xr165VZGRkjQ+9YDVy5Ejt2LFD2dnZzq+BAwdqwoQJzj9znRtv6NChNZYn2bNnjzp16iRJSkpKUlxcXLXrXFJSos8//7zadS4qKtLWrVudbdavXy+Hw6G0tDQvvAv/d+rUKVmt1T9SbTabHA6HJK6zp7jrug4ZMkQbNmxQRUWFs83atWt18cUXN2rYUBLLOwSapUuXGmFhYcbixYuN3NxcY9KkSUbr1q2r3ZWFuk2ePNmIiooyPv74YyM/P9/5derUKWebO++800hMTDTWr19vfPHFF8aQIUOMIUOGOB+vWnbgyiuvNLKzs43Vq1cb7dq1Y9mBevz4rkPD4Dq7w5YtW4yQkBBj7ty5xt69e43XX3/diIiIMJYsWeJs8+STTxqtW7c23n33XeOrr74yrrnmmlpvj+/Xr5/x+eefGxs3bjS6du0a9MsO/Fh6erpxwQUXOJd3eOedd4y2bdsaDz74oLMN17lhTp48aWzfvt3Yvn27Icn4y1/+Ymzfvt04ePCgYRjuua5FRUVGbGysceuttxo5OTnG0qVLjYiICJZ3QO3mz59vJCYmGqGhoUZqaqrx2Wef+bqkJkVSrV+LFi1ytjl9+rRx1113GW3atDEiIiKMa6+91sjPz692ngMHDhhjx441mjdvbrRt29Z44IEHjIqKCi+/m6blp0GL6+we7733ntGrVy8jLCzM6N69u/HSSy9Ve9zhcBgPP/ywERsba4SFhRkjR440du/eXa3NDz/8YNx0001Gy5YtjcjISOP22283Tp486c234ddKSkqMe++910hMTDTCw8ONLl26GA899FC15QK4zg3z0Ucf1fo7OT093TAM913XL7/80rj00kuNsLAw44ILLjCefPJJt9RvMYwfLVsLAAAAt2GOFgAAgIcQtAAAADyEoAUAAOAhBC0AAAAPIWgBAAB4CEELAADAQwhaAAAAHkLQAgAA8BCCFgD4GYvFohUrVvi6DABuQNACgB+ZOHGiLBZLja8xY8b4ujQATVCIrwsAAH8zZswYLVq0qNqxsLAwH1UDoCmjRwsAfiIsLExxcXHVvtq0aSPp3LDewoULNXbsWDVv3lxdunTR22+/Xe35O3bs0IgRI9S8eXPFxMRo0qRJKi0trdbm73//u3r27KmwsDDFx8fr7rvvrvb4sWPHdO211yoiIkJdu3bVypUrPfumAXgEQQsAXPTwww/r+uuv15dffqkJEybo17/+tXbu3ClJKisr0+jRo9WmTRtlZWXprbfe0rp166oFqYULF2rKlCmaNGmSduzYoZUrV+qiiy6q9hqPPvqofvnLX+qrr77SVVddpQkTJuj48eNefZ8A3MAAADilp6cbNpvNaNGiRbWvuXPnGoZhGJKMO++8s9pz0tLSjMmTJxuGYRgvvfSS0aZNG6O0tNT5+L/+9S/DarUaBQUFhmEYRocOHYyHHnrovDVIMv7whz84vy8tLTUkGR988IHb3icA72COFgD8xOWXX66FCxdWOxYdHe3885AhQ6o9NmTIEGVnZ0uSdu7cqZSUFLVo0cL5+NChQ+VwOLR7925ZLBYdOXJEI0eOrLOGPn36OP/cokULRUZG6ujRow19SwB8hKAFAD/RokWLGkN57tK8eXNT7Zo1a1bte4vFIofD4YmSAHgQc7QAwEWfffZZje979OghSerRo4e+/PJLlZWVOR/ftGmTrFarLr74YrVq1UqdO3dWZmamV2sG4Bv0aAHAT5w9e1YFBQXVjoWEhKht27aSpLfeeksDBw7UpZdeqtdff11btmzRK6+8IkmaMGGC5syZo/T0dD3yyCP6/vvvNXXqVN16662KjY2VJD3yyCO688471b59e40dO1YnT57Upk2bNHXqVO++UQAeR9ACgJ9YvXq14uPjqx27+OKLtWvXLknn7ghcunSp7rrrLsXHx+vNN99UcnKyJCkiIkJr1qzRvffeq0GDBikiIkLXX3+9/vKXvzjPlZ6erjNnzuiZZ57R9OnT1bZtW91www3ee4MAvMZiGIbh6yIAoKmwWCxavny5xo8f7+tSADQBzNECAADwEIIWAACAhzBHCwBcwGwLAK6gRwsAAMBDCFoAAAAeQtACAADwEIIWAACAhxC0AAAAPISgBQAA4CEELQAAAA8haAEAAHjI/wfUsc59FisknAAAAABJRU5ErkJggg==\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training complete! Total training time: 5240.67 seconds\n"]}],"source":["# Train the GNN model using the provided source and target graph embeddings, edges, and training data\n","trained_model = train_model_gnn(\n","    model=GIT_model,                # The GNN model to be trained (initialized earlier)\n","    x_src=x_src,                    # Source node embeddings (tensor for source graph)\n","    edge_src=edge_src,              # Source graph edges (undirected edge index for source graph)\n","    x_tgt=x_tgt,                    # Target node embeddings (tensor for target graph)\n","    edge_tgt=edge_tgt,              # Target graph edges (undirected edge index for target graph)\n","    tensor_term1=tensor_term1_o,    # Indices of source entities for training\n","    tensor_term2=tensor_term2_o,    # Indices of target entities for training\n","    tensor_score=tensor_score_o,    # Scores (labels) indicating if pairs match (1) or not (0)\n","    learning_rate=0.0001,            # Learning rate for the Adam optimizer\n","    weight_decay_value=1e-4,        # Weight decay for L2 regularization to prevent overfitting\n","    num_epochs=1000,                # Number of training epochs\n","    print_interval=10               # Interval at which to print training progress (every 10 epochs)\n",")"]},{"cell_type":"markdown","metadata":{"id":"MYyhvjcTUaae"},"source":["# GIT Application"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BZ_VqP6tq6iD"},"outputs":[],"source":["# Determine if a GPU is available and move the computations to it; otherwise, use the CPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Assuming the model has been trained and hyperparameters (x_src, edge_src, x_tgt, edge_tgt) are set\n","\n","# Move the trained GIT_model to the device (GPU or CPU)\n","GIT_model.to(device)\n","\n","# Move the data tensors to the same device (GPU or CPU)\n","x_tgt = x_tgt.to(device)         # Target node embeddings\n","edge_tgt = edge_tgt.to(device)   # Target graph edges\n","x_src = x_src.to(device)         # Source node embeddings\n","edge_src = edge_src.to(device)   # Source graph edges\n","\n","# Set the model to evaluation mode; this disables dropout and batch normalization\n","GIT_model.eval()\n","\n","# Pass the source and target embeddings through the trained GNN model to update the embeddings\n","with torch.no_grad():  # Disable gradient computation (inference mode)\n","    embeddings_tgt = GIT_model(x_tgt, edge_tgt)  # Get updated embeddings for the target graph\n","    embeddings_src = GIT_model(x_src, edge_src)  # Get updated embeddings for the source graph\n","\n","# Detach the embeddings from the computation graph and move them back to the CPU\n","# This step is useful if you need to use the embeddings for tasks outside PyTorch (e.g., saving to disk)\n","embeddings_tgt = embeddings_tgt.detach().cpu()  # Target graph embeddings\n","embeddings_src = embeddings_src.detach().cpu()  # Source graph embeddings\n","\n","# At this point, embeddings_tgt and embeddings_src contain the updated embeddings, ready for downstream tasks"]},{"cell_type":"markdown","metadata":{"id":"Og5fdoGJrTCG"},"source":["# Selecting embedding pairs to train the Gated Network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J0nTwc-dnjLn"},"outputs":[],"source":["# Read the training pairs from a CSV file into a pandas DataFrame\n","df_embeddings = pd.read_csv(train_file, index_col=0)\n","\n","# Extract columns and convert to NumPy arrays\n","tensor_term1 = df_embeddings['SrcEntity'].values.astype(int)  # Source entity indices\n","tensor_term2 = df_embeddings['TgtEntity'].values.astype(int)  # Target entity indices\n","tensor_score = df_embeddings['Score'].values.astype(float)  # Matching scores\n","\n","# Split data into training and validation sets\n","tensor_term1_train, tensor_term1_val, tensor_term2_train, tensor_term2_val, tensor_score_train, tensor_score_val = train_test_split(\n","    tensor_term1, tensor_term2, tensor_score, test_size=0.3, random_state=42\n",")\n","\n","# Convert split data to PyTorch tensors\n","tensor_term1_train = torch.from_numpy(tensor_term1_train).type(torch.LongTensor)\n","tensor_term2_train = torch.from_numpy(tensor_term2_train).type(torch.LongTensor)\n","tensor_score_train = torch.from_numpy(tensor_score_train).type(torch.FloatTensor)\n","\n","tensor_term1_val = torch.from_numpy(tensor_term1_val).type(torch.LongTensor)\n","tensor_term2_val = torch.from_numpy(tensor_term2_val).type(torch.LongTensor)\n","tensor_score_val = torch.from_numpy(tensor_score_val).type(torch.FloatTensor)\n","\n","# Move the embeddings back to the CPU if not already there\n","x_tgt = x_tgt.cpu()  # Target node embeddings\n","x_src = x_src.cpu()  # Source node embeddings\n","\n","# Select embeddings for the training set\n","X1_train = select_rows_by_index(embeddings_src, tensor_term1_train)\n","X2_train = select_rows_by_index(x_src, tensor_term1_train)\n","X3_train = select_rows_by_index(embeddings_tgt, tensor_term2_train)\n","X4_train = select_rows_by_index(x_tgt, tensor_term2_train)\n","\n","# Select embeddings for the validation set\n","X1_val = select_rows_by_index(embeddings_src, tensor_term1_val)\n","X2_val = select_rows_by_index(x_src, tensor_term1_val)\n","X3_val = select_rows_by_index(embeddings_tgt, tensor_term2_val)\n","X4_val = select_rows_by_index(x_tgt, tensor_term2_val)\n","\n","# Now you have:\n","# - Training tensors: X1_train, X2_train, X3_train, X4_train, tensor_score_train\n","# - Validation tensors: X1_val, X2_val, X3_val, X4_val, tensor_score_val"]},{"cell_type":"markdown","metadata":{"id":"fNdCgaTMExPK"},"source":["# Gated Network Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gof1eIPIWSVU"},"outputs":[],"source":["from sklearn.metrics import f1_score\n","\n","def train_gated_combination_model(X1_t, X2_t, X3_t, X4_t, tensor_score_o,\n","                                  X1_val, X2_val, X3_val, X4_val, tensor_score_val,\n","                                  epochs=120, batch_size=32, learning_rate=0.001, weight_decay=1e-5):\n","    \"\"\"\n","    Trains the GatedCombination model with training and validation data, using ReduceLROnPlateau scheduler.\n","    Also calculates and displays F1-score during training and validation.\n","    \"\"\"\n","\n","    # Create datasets and DataLoaders\n","    train_dataset = TensorDataset(X1_t, X2_t, X3_t, X4_t, tensor_score_o)\n","    val_dataset = TensorDataset(X1_val, X2_val, X3_val, X4_val, tensor_score_val)\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = GatedCombination(X1_t.shape[1]).to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","\n","    # Use ReduceLROnPlateau scheduler\n","    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n","\n","    train_losses, val_losses = [], []\n","\n","    start_time = time.time()\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        total_train_loss = 0.0\n","        y_true_train, y_pred_train = [], []\n","\n","        for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in train_loader:\n","            batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (\n","                batch_X1.to(device),\n","                batch_X2.to(device),\n","                batch_X3.to(device),\n","                batch_X4.to(device),\n","                batch_y.to(device),\n","            )\n","            optimizer.zero_grad()\n","\n","            # Forward pass\n","            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","\n","            # Compute loss\n","            loss = F.binary_cross_entropy(outputs, batch_y.unsqueeze(1).float())\n","            loss.backward()\n","            optimizer.step()\n","            total_train_loss += loss.item()\n","\n","            # Store true labels and predictions for F1-score\n","            y_true_train.extend(batch_y.cpu().numpy())\n","            y_pred_train.extend((outputs > 0.5).float().cpu().numpy())\n","\n","        train_loss = total_train_loss / len(train_loader)\n","        train_losses.append(train_loss)\n","\n","        # Calculate F1-score for training\n","        train_f1 = f1_score(y_true_train, y_pred_train)\n","\n","        # Validation phase\n","        model.eval()\n","        total_val_loss = 0.0\n","        y_true_val, y_pred_val = [], []\n","\n","        with torch.no_grad():\n","            for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in val_loader:\n","                batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (\n","                    batch_X1.to(device),\n","                    batch_X2.to(device),\n","                    batch_X3.to(device),\n","                    batch_X4.to(device),\n","                    batch_y.to(device),\n","                )\n","                outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","\n","                # Compute loss\n","                val_loss = F.binary_cross_entropy(outputs, batch_y.unsqueeze(1).float())\n","                total_val_loss += val_loss.item()\n","\n","                # Store true labels and predictions for F1-score\n","                y_true_val.extend(batch_y.cpu().numpy())\n","                y_pred_val.extend((outputs > 0.5).float().cpu().numpy())\n","\n","        avg_val_loss = total_val_loss / len(val_loader)\n","        val_losses.append(avg_val_loss)\n","\n","        # Calculate F1-score for validation\n","        val_f1 = f1_score(y_true_val, y_pred_val)\n","\n","        # Step the scheduler with validation loss\n","        scheduler.step(avg_val_loss)\n","\n","        # Print training and validation metrics\n","        print(f\"Epoch [{epoch + 1}/{epochs}] Training Loss: {train_loss:.4f}, F1 Score: {train_f1:.4f} | \"\n","              f\"Validation Loss: {avg_val_loss:.4f}, F1 Score: {val_f1:.4f}\")\n","\n","    end_time = time.time()\n","\n","    # Plotting training and validation loss\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(train_losses, label=\"Training Loss\", marker='o')\n","    plt.plot(val_losses, label=\"Validation Loss\", marker='x')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    print(f\"Training complete! Total time: {end_time - start_time:.2f} seconds\")\n","    return model\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"l11dgb8ei69T","outputId":"3c3ec87e-b278-48ea-96c8-2304bff46fbb","executionInfo":{"status":"ok","timestamp":1734721678769,"user_tz":-60,"elapsed":649905,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/120] Training Loss: 0.1918, F1 Score: 0.0445 | Validation Loss: 0.0765, F1 Score: 0.0000\n","Epoch [2/120] Training Loss: 0.0692, F1 Score: 0.0000 | Validation Loss: 0.0690, F1 Score: 0.0000\n","Epoch [3/120] Training Loss: 0.0631, F1 Score: 0.0000 | Validation Loss: 0.0627, F1 Score: 0.0000\n","Epoch [4/120] Training Loss: 0.0566, F1 Score: 0.0000 | Validation Loss: 0.0534, F1 Score: 0.0000\n","Epoch [5/120] Training Loss: 0.0438, F1 Score: 0.0000 | Validation Loss: 0.0377, F1 Score: 0.0000\n","Epoch [6/120] Training Loss: 0.0302, F1 Score: 0.0000 | Validation Loss: 0.0252, F1 Score: 0.0000\n","Epoch [7/120] Training Loss: 0.0201, F1 Score: 0.0733 | Validation Loss: 0.0167, F1 Score: 0.4883\n","Epoch [8/120] Training Loss: 0.0138, F1 Score: 0.7348 | Validation Loss: 0.0117, F1 Score: 0.8662\n","Epoch [9/120] Training Loss: 0.0102, F1 Score: 0.8974 | Validation Loss: 0.0090, F1 Score: 0.9181\n","Epoch [10/120] Training Loss: 0.0083, F1 Score: 0.9334 | Validation Loss: 0.0076, F1 Score: 0.9333\n","Epoch [11/120] Training Loss: 0.0072, F1 Score: 0.9450 | Validation Loss: 0.0069, F1 Score: 0.9450\n","Epoch [12/120] Training Loss: 0.0067, F1 Score: 0.9499 | Validation Loss: 0.0064, F1 Score: 0.9491\n","Epoch [13/120] Training Loss: 0.0064, F1 Score: 0.9525 | Validation Loss: 0.0061, F1 Score: 0.9533\n","Epoch [14/120] Training Loss: 0.0062, F1 Score: 0.9529 | Validation Loss: 0.0059, F1 Score: 0.9525\n","Epoch [15/120] Training Loss: 0.0061, F1 Score: 0.9529 | Validation Loss: 0.0059, F1 Score: 0.9532\n","Epoch [16/120] Training Loss: 0.0060, F1 Score: 0.9528 | Validation Loss: 0.0058, F1 Score: 0.9565\n","Epoch [17/120] Training Loss: 0.0060, F1 Score: 0.9529 | Validation Loss: 0.0058, F1 Score: 0.9580\n","Epoch [18/120] Training Loss: 0.0059, F1 Score: 0.9519 | Validation Loss: 0.0058, F1 Score: 0.9549\n","Epoch [19/120] Training Loss: 0.0059, F1 Score: 0.9536 | Validation Loss: 0.0058, F1 Score: 0.9597\n","Epoch [20/120] Training Loss: 0.0059, F1 Score: 0.9540 | Validation Loss: 0.0058, F1 Score: 0.9588\n","Epoch [21/120] Training Loss: 0.0059, F1 Score: 0.9540 | Validation Loss: 0.0058, F1 Score: 0.9573\n","Epoch [22/120] Training Loss: 0.0059, F1 Score: 0.9533 | Validation Loss: 0.0058, F1 Score: 0.9572\n","Epoch [23/120] Training Loss: 0.0059, F1 Score: 0.9543 | Validation Loss: 0.0058, F1 Score: 0.9628\n","Epoch [24/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0058, F1 Score: 0.9565\n","Epoch [25/120] Training Loss: 0.0059, F1 Score: 0.9533 | Validation Loss: 0.0057, F1 Score: 0.9604\n","Epoch [26/120] Training Loss: 0.0059, F1 Score: 0.9537 | Validation Loss: 0.0057, F1 Score: 0.9508\n","Epoch [27/120] Training Loss: 0.0059, F1 Score: 0.9537 | Validation Loss: 0.0059, F1 Score: 0.9541\n","Epoch [28/120] Training Loss: 0.0059, F1 Score: 0.9529 | Validation Loss: 0.0057, F1 Score: 0.9525\n","Epoch [29/120] Training Loss: 0.0059, F1 Score: 0.9522 | Validation Loss: 0.0058, F1 Score: 0.9549\n","Epoch [30/120] Training Loss: 0.0059, F1 Score: 0.9525 | Validation Loss: 0.0058, F1 Score: 0.9580\n","Epoch [31/120] Training Loss: 0.0059, F1 Score: 0.9522 | Validation Loss: 0.0058, F1 Score: 0.9565\n","Epoch [32/120] Training Loss: 0.0059, F1 Score: 0.9540 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [33/120] Training Loss: 0.0059, F1 Score: 0.9540 | Validation Loss: 0.0057, F1 Score: 0.9604\n","Epoch [34/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0058, F1 Score: 0.9580\n","Epoch [35/120] Training Loss: 0.0059, F1 Score: 0.9541 | Validation Loss: 0.0057, F1 Score: 0.9533\n","Epoch [36/120] Training Loss: 0.0059, F1 Score: 0.9530 | Validation Loss: 0.0057, F1 Score: 0.9541\n","Epoch [37/120] Training Loss: 0.0059, F1 Score: 0.9533 | Validation Loss: 0.0058, F1 Score: 0.9596\n","Epoch [38/120] Training Loss: 0.0059, F1 Score: 0.9540 | Validation Loss: 0.0058, F1 Score: 0.9541\n","Epoch [39/120] Training Loss: 0.0059, F1 Score: 0.9533 | Validation Loss: 0.0057, F1 Score: 0.9549\n","Epoch [40/120] Training Loss: 0.0059, F1 Score: 0.9536 | Validation Loss: 0.0057, F1 Score: 0.9557\n","Epoch [41/120] Training Loss: 0.0059, F1 Score: 0.9526 | Validation Loss: 0.0058, F1 Score: 0.9580\n","Epoch [42/120] Training Loss: 0.0059, F1 Score: 0.9540 | Validation Loss: 0.0057, F1 Score: 0.9557\n","Epoch [43/120] Training Loss: 0.0059, F1 Score: 0.9540 | Validation Loss: 0.0058, F1 Score: 0.9580\n","Epoch 00044: reducing learning rate of group 0 to 1.0000e-04.\n","Epoch [44/120] Training Loss: 0.0059, F1 Score: 0.9533 | Validation Loss: 0.0058, F1 Score: 0.9517\n","Epoch [45/120] Training Loss: 0.0059, F1 Score: 0.9537 | Validation Loss: 0.0057, F1 Score: 0.9565\n","Epoch [46/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9565\n","Epoch [47/120] Training Loss: 0.0059, F1 Score: 0.9540 | Validation Loss: 0.0058, F1 Score: 0.9565\n","Epoch [48/120] Training Loss: 0.0059, F1 Score: 0.9537 | Validation Loss: 0.0057, F1 Score: 0.9565\n","Epoch [49/120] Training Loss: 0.0059, F1 Score: 0.9541 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [50/120] Training Loss: 0.0059, F1 Score: 0.9537 | Validation Loss: 0.0057, F1 Score: 0.9565\n","Epoch [51/120] Training Loss: 0.0059, F1 Score: 0.9547 | Validation Loss: 0.0057, F1 Score: 0.9557\n","Epoch [52/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9580\n","Epoch [53/120] Training Loss: 0.0059, F1 Score: 0.9540 | Validation Loss: 0.0057, F1 Score: 0.9557\n","Epoch [54/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9580\n","Epoch 00055: reducing learning rate of group 0 to 1.0000e-05.\n","Epoch [55/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [56/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [57/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [58/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [59/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [60/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [61/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [62/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [63/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [64/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [65/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch 00066: reducing learning rate of group 0 to 1.0000e-06.\n","Epoch [66/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9565\n","Epoch [67/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [68/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [69/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [70/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [71/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [72/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [73/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [74/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [75/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [76/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch 00077: reducing learning rate of group 0 to 1.0000e-07.\n","Epoch [77/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [78/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [79/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [80/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [81/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [82/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [83/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [84/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [85/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [86/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [87/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch 00088: reducing learning rate of group 0 to 1.0000e-08.\n","Epoch [88/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [89/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [90/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [91/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [92/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [93/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [94/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [95/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [96/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [97/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [98/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [99/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [100/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [101/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [102/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [103/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [104/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [105/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [106/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [107/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [108/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [109/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [110/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [111/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [112/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [113/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [114/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [115/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [116/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [117/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [118/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [119/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n","Epoch [120/120] Training Loss: 0.0059, F1 Score: 0.9544 | Validation Loss: 0.0057, F1 Score: 0.9573\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x500 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training complete! Total time: 3221.31 seconds\n"]}],"source":["# Train the GatedCombination model using training and validation data\n","trained_model = train_gated_combination_model(\n","    X1_train,          # Updated source embeddings (after applying the GNN model)\n","    X2_train,          # Original source embeddings (before applying the GNN model)\n","    X3_train,          # Updated target embeddings (after applying the GNN model)\n","    X4_train,          # Original target embeddings (before applying the GNN model)\n","    tensor_score_train, # Ground truth labels for the training set (1 for matched pairs, 0 for unmatched pairs)\n","\n","    X1_val,            # Updated source embeddings for the validation set\n","    X2_val,            # Original source embeddings for the validation set\n","    X3_val,            # Updated target embeddings for the validation set\n","    X4_val,            # Original target embeddings for the validation set\n","    tensor_score_val,  # Ground truth labels for the validation set (1 for matched pairs, 0 for unmatched pairs)\n","\n","    epochs=100,        # Number of epochs (iterations over the entire training dataset)\n","    batch_size=32,     # Number of training samples processed in one forward/backward pass\n","    learning_rate=0.001, # Learning rate for the optimizer (controls step size during optimization)\n","    weight_decay=1e-4 # Weight decay (L2 regularization) to prevent overfitting\n",")"]},{"cell_type":"markdown","metadata":{"id":"uAmLuMtGW9c2"},"source":["# **Mappings Selector**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lnFtpUAfJQHl"},"outputs":[],"source":["# Build an indexed dictionary for the source ontology classes\n","# src_class is the file path to the JSON file containing the source ontology classes\n","indexed_dict_src = build_indexed_dict(src_class)\n","\n","# Build an indexed dictionary for the target ontology classes\n","# tgt_class is the file path to the JSON file containing the target ontology classes\n","indexed_dict_tgt = build_indexed_dict(tgt_class)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"beipwavuJQHl"},"outputs":[],"source":["# Read the candidate pairs from a Candidates CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(candidates_Prediction, index_col=0)\n","\n","# Extract the 'SrcEntity' column (source entity indices) and convert it to a NumPy array of integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)\n","\n","# Extract the 'TgtEntity' column (target entity indices) and convert it to a NumPy array of integers\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)\n","\n","# Convert the source entity indices to a PyTorch LongTensor\n","src_entity_tensor_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)\n","\n","# Convert the target entity indices to a PyTorch LongTensor\n","tgt_entity_tenso_or = torch.from_numpy(tensor_term2).type(torch.LongTensor)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ECLhmxyKJQHl"},"outputs":[],"source":["# Select rows from the updated source embeddings based on the indices in src_entity_tensor_o\n","X1_tt = select_rows_by_index(embeddings_src, src_entity_tensor_o)\n","\n","# Select rows from the original source embeddings based on the indices in src_entity_tensor_o\n","X2_tt = select_rows_by_index(x_src, src_entity_tensor_o)\n","\n","# Select rows from the updated target embeddings based on the indices in tgt_entity_tenso_or\n","X3_tt = select_rows_by_index(embeddings_tgt, tgt_entity_tenso_or)\n","\n","# Select rows from the original target embeddings based on the indices in tgt_entity_tenso_or\n","X4_tt = select_rows_by_index(x_tgt, tgt_entity_tenso_or)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"17a66118-dba5-491c-d5cf-85617cb92081","id":"UFP6OQR-7D4N","executionInfo":{"status":"ok","timestamp":1734721754893,"user_tz":-60,"elapsed":60577,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting time: 24.55 seconds\n","Predictions saved to /content/gdrive/My Drive/BioGITOM-VLDB//body/Results/body_all_predictions.tsv\n"]}],"source":["# Generate predictions for candidate mappings using the trained GatedCombination model\n","Prediction_with_candidates(\n","    model=trained_model,             # The trained GatedCombination model used to evaluate similarity\n","    X1_tt=X1_tt,                     # Updated source embeddings (after applying the GIT model)\n","    X2_tt=X2_tt,                     # Original source embeddings (before applying the GIT model)\n","    X3_tt=X3_tt,                     # Updated target embeddings (after applying the GIT model)\n","    X4_tt=X4_tt,                     # Original target embeddings (before applying the GIT model)\n","    src_entity_tensor_o=src_entity_tensor_o,  # Tensor of source entity indices used for evaluation\n","    tgt_entity_tensor_o=tgt_entity_tenso_or,  # Tensor of target entity indices used for evaluation\n","    indexed_dict_src=indexed_dict_src,        # Dictionary mapping source entity indices to their URIs\n","    indexed_dict_tgt=indexed_dict_tgt,        # Dictionary mapping target entity indices to their URIs\n","    all_predictions_path=all_predictions_path # Path to save all predictions with similarity scores in TSV format\n",")"]},{"cell_type":"code","source":[],"metadata":{"id":"QYdp6EL3QDO6"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mEc12J-B7D4N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734723049758,"user_tz":-60,"elapsed":24955,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"b31b6e15-66aa-4a5e-948f-3958c7d51468"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Positive Predictions : 4542\n"]}],"source":["# Filter the highest scoring predictions from the predictions file and save the results to a new file\n","matching_results_df = filter_highest_predictions(\n","    all_predictions_path,  # Path to the file containing all predictions with scores for all candidate pairs\n","    prediction_path        # Path where the filtered predictions with highest scores will be saved\n",")"]},{"cell_type":"markdown","metadata":{"id":"BIx74lNV7D4O"},"source":["# **Evaluation**"]},{"cell_type":"markdown","source":["# Global metrics calculation"],"metadata":{"id":"Pp3IpBBfWn9m"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"bkOewzXr7D4O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734723051521,"user_tz":-60,"elapsed":1767,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"a38a7d49-7cd2-437f-8c53-5b792540d12b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Correct Predictions: 3827\n","{'P': 0.843, 'R': 0.753, 'F1': 0.796}\n"]}],"source":["# Retrieve the indices of the ignored classes (from source and target ontologies)\n","ignored_class_index = get_ignored_class_index(src_onto)  # Get ignored class indices from source ontology\n","ignored_class_index.update(get_ignored_class_index(tgt_onto))  # Update with ignored class indices from target ontology\n","\n","# Read the predicted mappings from the prediction results file\n","preds = EntityMapping.read_table_mappings(prediction_path)\n","\n","# Read the reference mappings from the ground truth test file\n","refs = ReferenceMapping.read_table_mappings(f\"{dataset_dir}/refs_equiv/test.tsv\")\n","\n","# Filter the predicted mappings to remove any mappings that involve ignored classes\n","preds = remove_ignored_mappings(preds, ignored_class_index)\n","\n","# Compute the precision, recall, and F1-score by comparing predictions with the reference mappings\n","results = AlignmentEvaluator.f1(preds, refs)\n","\n","preds2 = [p.to_tuple() for p in preds]\n","refs2 = [r.to_tuple() for r in refs]\n","\n","correct= len(set(preds2).intersection(set(refs2)))\n","\n","print(f\"Number of Correct Predictions: {correct}\")\n","\n","# Print the computed precision, recall, and F1-score metrics\n","print(results)"]},{"cell_type":"markdown","source":["# Ranked-based metrics calculation"],"metadata":{"id":"aECB6igZW04C"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-AK-jADkSbTa"},"outputs":[],"source":["# Read the candidate pairs from a Candidates CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(candidates_Rank, index_col=0)\n","\n","# Extract the 'SrcEntity' column (source entity indices) and convert it to a NumPy array of integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)\n","\n","# Extract the 'TgtEntity' column (target entity indices) and convert it to a NumPy array of integers\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)\n","\n","# Convert the source entity indices to a PyTorch LongTensor\n","src_entity_tensor_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)\n","\n","# Convert the target entity indices to a PyTorch LongTensor\n","tgt_entity_tenso_or = torch.from_numpy(tensor_term2).type(torch.LongTensor)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oyOzcLv-SbTb"},"outputs":[],"source":["# Select rows from the updated source embeddings based on the indices in src_entity_tensor_o\n","X1_tt = select_rows_by_index(embeddings_src, src_entity_tensor_o)\n","\n","# Select rows from the original source embeddings based on the indices in src_entity_tensor_o\n","X2_tt = select_rows_by_index(x_src, src_entity_tensor_o)\n","\n","# Select rows from the updated target embeddings based on the indices in tgt_entity_tenso_or\n","X3_tt = select_rows_by_index(embeddings_tgt, tgt_entity_tenso_or)\n","\n","# Select rows from the original target embeddings based on the indices in tgt_entity_tenso_or\n","X4_tt = select_rows_by_index(x_tgt, tgt_entity_tenso_or)"]},{"cell_type":"code","source":["# Perform ranking-based predictions using the trained GatedCombination model\n","# Generate predictions for candidate mappings using the trained GatedCombination model\n","Prediction_with_candidates(\n","    model=trained_model,             # The trained GatedCombination model used to evaluate similarity\n","    X1_tt=X1_tt,                     # Updated source embeddings (after applying the GIT model)\n","    X2_tt=X2_tt,                     # Original source embeddings (before applying the GIT model)\n","    X3_tt=X3_tt,                     # Updated target embeddings (after applying the GIT model)\n","    X4_tt=X4_tt,                     # Original target embeddings (before applying the GIT model)\n","    src_entity_tensor_o=src_entity_tensor_o,  # Tensor of source entity indices used for evaluation\n","    tgt_entity_tensor_o=tgt_entity_tenso_or,  # Tensor of target entity indices used for evaluation\n","    indexed_dict_src=indexed_dict_src,        # Dictionary mapping source entity indices to their URIs\n","    indexed_dict_tgt=indexed_dict_tgt,        # Dictionary mapping target entity indices to their URIs\n","    all_predictions_path=all_predictions_path_ranked, # Path where the ranked predictions will be saved in TSV format\n",")"],"metadata":{"id":"-O2f7X6cSb-m","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0aaa55e4-21dc-457e-ac77-18b28bc7e245","executionInfo":{"status":"ok","timestamp":1734721835679,"user_tz":-60,"elapsed":54410,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting time: 21.61 seconds\n","Predictions saved to /content/gdrive/My Drive/BioGITOM-VLDB//body/Results/body_all_predictions_ranked.tsv\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_402seVv7D4O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734721862791,"user_tz":-60,"elapsed":27116,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"b2dd018e-f278-4d07-a93c-862c31e15807"},"outputs":[{"output_type":"stream","name":"stdout","text":["MRR and Hits@k Results:\n","{'MRR': 0.9021500310697433, 'Hits@k': {1: 0.8440637920850561, 5: 0.9742075211655837, 10: 0.991927544792282}}\n"]}],"source":["# Compute MRR and Hits@k metrics\n","# This function evaluates the predicted rankings against the reference mappings\n","results = compute_mrr_and_hits(\n","    reference_file=test_cands,             # Reference file with true ranks\n","    predicted_file=all_predictions_path_ranked,             # File containing predicted rankings\n","    output_file=formatted_predictions_path,    # File path to save formatted predictions\n","    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",")\n","\n","# Display the computed metrics\n","print(\"MRR and Hits@k Results:\")\n","print(results)  # Output the Mean Reciprocal Rank (MRR) and Hits@k metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wStfa4eZ7D4O","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3323ca38-440e-4c10-b8a4-ae8897fc530e","executionInfo":{"status":"ok","timestamp":1734721868770,"user_tz":-60,"elapsed":5984,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Ranking Evaluation Results at K=1, 5, and 10:\n","{'MRR': 0.9021500310697433, 'Hits@1': 0.8440637920850561, 'Hits@5': 0.9742075211655837, 'Hits@10': 0.991927544792282}\n"]}],"source":["# Call the ranking evaluation function, passing the path to the formatted predictions file.\n","# Ks specifies the evaluation levels, checking if the correct target is within the top K candidates.\n","results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n","print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n","print(results)"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}