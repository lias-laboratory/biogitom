{"cells":[{"cell_type":"markdown","metadata":{"id":"MkAX88H3RNRW"},"source":["# **Package Installation**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SlL2v0xgmFJ-","outputId":"3cec0e1c-4f87-43ac-b3c6-01727c89c54f","executionInfo":{"status":"ok","timestamp":1732172573011,"user_tz":-60,"elapsed":199782,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==2.0.0\n","  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.16.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n","  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n","  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n","  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n","  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n","  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n","  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.0.0 (from torch==2.0.0)\n","  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (75.1.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.45.0)\n","Collecting cmake (from triton==2.0.0->torch==2.0.0)\n","  Downloading cmake-3.31.0.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n","Collecting lit (from triton==2.0.0->torch==2.0.0)\n","  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n","Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m583.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m552.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cmake-3.31.0.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.8/27.8 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, cmake, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.1+cpu\n","    Uninstalling torch-2.5.1+cpu:\n","      Successfully uninstalled torch-2.5.1+cpu\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.5.1+cpu requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\n","torchvision 0.20.1+cpu requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed cmake-3.31.0.1 lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 triton-2.0.0\n","Collecting torch-geometric==2.4.0\n","  Downloading torch_geometric-2.4.0-py3-none-any.whl.metadata (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (4.66.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (3.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (2.32.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (3.2.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.5.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric==2.4.0) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (2024.8.30)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.4.0) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.4.0) (3.5.0)\n","Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-geometric\n","Successfully installed torch-geometric-2.4.0\n","Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_scatter-2.1.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (494 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_sparse-0.6.18%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-cluster\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_cluster-1.6.3%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (751 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.3/751.3 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-spline-conv\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (208 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n","Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n","Installing collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster\n","Successfully installed torch-cluster-1.6.3+pt20cpu torch-scatter-2.1.2+pt20cpu torch-sparse-0.6.18+pt20cpu torch-spline-conv-1.2.2+pt20cpu\n","Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.5.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.6/66.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.9/208.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.2/319.2 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting deeponto\n","  Downloading deeponto-0.9.2-py3-none-any.whl.metadata (15 kB)\n","Collecting JPype1 (from deeponto)\n","  Downloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting yacs (from deeponto)\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deeponto) (2.0.0)\n","Collecting anytree (from deeponto)\n","  Downloading anytree-2.12.1-py3-none-any.whl.metadata (8.1 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from deeponto) (8.1.7)\n","Collecting dill (from deeponto)\n","  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from deeponto) (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deeponto) (1.26.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deeponto) (1.5.2)\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (from deeponto) (4.46.2)\n","Collecting datasets (from deeponto)\n","  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.7.5)\n","Collecting pprintpp (from deeponto)\n","  Downloading pprintpp-0.4.0-py2.py3-none-any.whl.metadata (7.9 kB)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.4.2)\n","Collecting lxml (from deeponto)\n","  Downloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n","Collecting textdistance (from deeponto)\n","  Downloading textdistance-4.6.3-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from deeponto) (7.7.1)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from deeponto) (5.5.6)\n","Collecting enlighten (from deeponto)\n","  Downloading enlighten-1.12.4-py2.py3-none-any.whl.metadata (18 kB)\n","Collecting rdflib (from deeponto)\n","  Downloading rdflib-7.1.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.9.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anytree->deeponto) (1.16.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (18.0.0)\n","Collecting dill (from deeponto)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (4.66.6)\n","Collecting xxhash (from datasets->deeponto)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets->deeponto)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->deeponto)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (3.11.6)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (0.26.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (6.0.2)\n","Collecting blessed>=1.17.7 (from enlighten->deeponto)\n","  Downloading blessed-1.20.0-py2.py3-none-any.whl.metadata (13 kB)\n","Collecting prefixed>=0.3.2 (from enlighten->deeponto)\n","  Downloading prefixed-0.9.0-py2.py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (0.2.0)\n","Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (7.34.0)\n","Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (5.7.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (6.1.12)\n","Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (6.3.3)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->deeponto) (3.6.10)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->deeponto) (3.0.13)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->deeponto) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->deeponto) (2024.11.6)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2024.2)\n","Collecting isodate<1.0.0,>=0.7.2 (from rdflib->deeponto)\n","  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib->deeponto) (3.2.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deeponto) (1.13.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deeponto) (3.5.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (0.13.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.9.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.1.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (75.1.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.4.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (1.13.1)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (2.0.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->deeponto) (0.45.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deeponto) (3.31.0.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deeponto) (18.1.8)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (0.20.3)\n","Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (1.1.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->transformers[torch]->deeponto) (5.9.5)\n","Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.7->enlighten->deeponto) (0.2.13)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (0.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.17.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (5.0.1)\n","Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->deeponto)\n","  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (5.1.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (3.0.48)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (2.18.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (4.9.0)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.2.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (2024.8.30)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->deeponto) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->deeponto) (0.1.5)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (0.20.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (7.0.5)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.5.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy->deeponto) (3.0.2)\n","Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->deeponto) (5.7.2)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->deeponto) (24.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deeponto) (1.3.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->deeponto) (0.8.4)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel->deeponto) (4.3.6)\n","Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.2.1)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (23.1.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (5.10.4)\n","Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (7.16.4)\n","Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.6.0)\n","Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.3)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.18.1)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.21.0)\n","Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.1.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel->deeponto) (0.7.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (3.0.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->deeponto) (1.14.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (0.1.2)\n","Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.2.4)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.12.3)\n","Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.2.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.7.1)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.3.0)\n","Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.0.2)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.10.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.5.1)\n","Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.4.0)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.20.0)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.23.0)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (21.2.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.5.1)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.21.0)\n","Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.24.0)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.17.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.6)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.22)\n","Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.7.1)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.2.2)\n","Downloading deeponto-0.9.2-py3-none-any.whl (89.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading anytree-2.12.1-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading enlighten-1.12.4-py2.py3-none-any.whl (41 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.8/493.8 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n","Downloading rdflib-7.1.1-py3-none-any.whl (562 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m562.4/562.4 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading textdistance-4.6.3-py3-none-any.whl (31 kB)\n","Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n","Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading prefixed-0.9.0-py2.py3-none-any.whl (13 kB)\n","Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: prefixed, pprintpp, yacs, xxhash, textdistance, lxml, JPype1, jedi, isodate, fsspec, dill, blessed, anytree, rdflib, multiprocess, enlighten, datasets, deeponto\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","Successfully installed JPype1-1.5.1 anytree-2.12.1 blessed-1.20.0 datasets-3.1.0 deeponto-0.9.2 dill-0.3.8 enlighten-1.12.4 fsspec-2024.9.0 isodate-0.7.2 jedi-0.19.2 lxml-5.3.0 multiprocess-0.70.16 pprintpp-0.4.0 prefixed-0.9.0 rdflib-7.1.1 textdistance-4.6.3 xxhash-3.5.0 yacs-0.1.8\n","/bin/bash: line 1: username: No such file or directory\n"]}],"source":["# We assume that PyTorch is already installed in the environment.\n","# If not, this command installs it.\n","!pip install torch==2.0.0\n","\n","# Install PyTorch Geometric, a library for creating graph neural networks using PyTorch.\n","!pip install torch-geometric==2.4.0\n","\n","# Import PyTorch to access its functionalities.\n","import torch\n","\n","# Install additional PyTorch Geometric dependencies for graph processing (scatter, sparse, cluster, spline-conv).\n","# These packages enable operations like sparse tensors and convolutions on graphs.\n","!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","\n","# Reinstall PyTorch Geometric to ensure all dependencies are correctly loaded.\n","!pip install torch-geometric\n","\n","# Retrieve the installed version of PyTorch to ensure compatibility with other packages.\n","torchversion = torch.__version__\n","\n","# Install the latest version of PyTorch Geometric directly from the GitHub repository.\n","# This allows access to the most recent updates and features for graph-based neural networks.\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","\n","# Install DeepOnto, a package specifically designed for ontology matching, particularly useful in biomedical applications.\n","!pip install deeponto\n","\n","# Install a custom version of DeepOnto from a GitHub repository.\n","# The '<username>' part should be replaced with the actual GitHub username of the repository maintainer.\n","!pip install git+https://github.com/<username>/deeponto.git\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HPAlAgjLMVhw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0385683a-d7a3-4263-c7eb-e530668c1b86","executionInfo":{"status":"ok","timestamp":1732173131715,"user_tz":-60,"elapsed":558719,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Please enter the maximum memory located to JVM [8g]: 8g\n","\n"]}],"source":["# Import pandas for data manipulation and analysis, such as loading, processing, and saving tabular data.\n","import pandas as pd\n","\n","# Import pickle for saving and loading serialized objects (e.g., trained models or preprocessed data).\n","import pickle\n","\n","# Import function to convert a directed graph to an undirected one, useful for certain graph algorithms.\n","from torch_geometric.utils import to_undirected\n","\n","# Import optimizer module from PyTorch for training models using gradient-based optimization techniques.\n","import torch.optim as optim\n","\n","# Import PyTorch's modules for defining neural network architectures and operations:\n","from torch.nn import (\n","    Linear,       # For linear transformations (dense layers).\n","    Sequential,   # For stacking layers sequentially.\n","    BatchNorm1d,  # For normalizing input within mini-batches.\n","    PReLU,        # Parametric ReLU activation function.\n","    Dropout       # For regularization by randomly dropping connections during training.\n",")\n","\n","# Import functional API from PyTorch for operations like activations and loss functions.\n","import torch.nn.functional as F\n","\n","# Import Matplotlib for visualizations, such as plotting training loss curves.\n","import matplotlib.pyplot as plt\n","\n","# Import PyTorch Geometric's graph convolutional layers:\n","from torch_geometric.nn import GCNConv, GINConv\n","\n","# Import pooling operations for aggregating node embeddings to graph-level representations:\n","from torch_geometric.nn import global_mean_pool, global_add_pool\n","\n","# Import NumPy for numerical operations, such as working with arrays and matrices.\n","import numpy as np\n","\n","# Import time module for measuring execution time of code blocks.\n","import time\n","\n","# Import typing module for specifying types in function arguments and return values.\n","from typing import Optional, Tuple, Union, Callable\n","\n","# Import PyTorch's DataLoader and TensorDataset for handling data batching and loading during training.\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","# Import PyTorch's Parameter class for defining learnable parameters in custom models.\n","from torch.nn import Parameter\n","\n","# Import math module for performing mathematical computations.\n","import math\n","\n","# Import Tensor type from PyTorch for defining and manipulating tensors.\n","from torch import Tensor\n","\n","# Import PyTorch's nn module for defining and building neural network architectures.\n","import torch.nn as nn\n","\n","# Import initialization utilities from PyTorch Geometric for resetting weights and biases in layers.\n","from torch_geometric.nn.inits import reset\n","\n","# Import the base class for defining message-passing layers in graph neural networks (GNNs).\n","from torch_geometric.nn.conv import MessagePassing\n","\n","# Import linear transformation utilities for creating dense representations in graph models.\n","from torch_geometric.nn.dense.linear import Linear\n","\n","# Import typing utilities for defining adjacency matrices and tensor types specific to PyTorch Geometric.\n","from torch_geometric.typing import Adj, OptTensor, PairTensor, SparseTensor\n","\n","# Import softmax function for normalizing attention scores in GNNs.\n","from torch_geometric.utils import softmax\n","\n","# Import initialization utilities for weight initialization (e.g., Glorot initialization).\n","from torch_geometric.nn.inits import glorot, zeros\n","\n","# Import F1 score metric from scikit-learn for evaluating model performance in binary/multi-class tasks.\n","from sklearn.metrics import f1_score\n","\n","# Import JSON module for reading and writing JSON files, useful for storing configuration or ontology data.\n","import json\n","\n","# Import Ontology class from DeepOnto for representing and manipulating ontologies in the pipeline.\n","from deeponto.onto import Ontology\n","\n","# Import tools from DeepOnto for handling Ontology Alignment Evaluation Initiative (OAEI) tasks.\n","from deeponto.align.oaei import *\n","\n","# Import evaluation tools from DeepOnto for assessing alignment results using metrics like precision, recall, and F1.\n","from deeponto.align.evaluation import AlignmentEvaluator\n","\n","# Import mapping utilities from DeepOnto for working with reference mappings and entity pairs.\n","from deeponto.align.mapping import ReferenceMapping, EntityMapping\n","\n","# Import utility function for reading tables (e.g., TSV, CSV) from DeepOnto.\n","from deeponto.utils import read_table\n","\n","# Importing the train_test_split function from sklearn's model_selection module.\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"-abbBHOoRdWl"},"source":["# **Paths Definition**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AVgl_Bb42naS","outputId":"d2849e99-c1d2-44f8-bf68-a0b5b224035d","executionInfo":{"status":"ok","timestamp":1732173157333,"user_tz":-60,"elapsed":25623,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# Importing the 'drive' module from Google Colab to interact with Google Drive\n","from google.colab import drive\n","\n","# Mount the user's Google Drive to the Colab environment\n","# After running this, a link will appear to authorize access, and Google Drive will be mounted at '/content/gdrive'\n","drive.mount('/content/gdrive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"36ttssQ3W7cx"},"outputs":[],"source":["# Define the source ontology name\n","src_ent = \"ncit\"\n","\n","# Define the target ontology name\n","tgt_ent = \"doid\"\n","\n","# Define the task name for this ontology matching process\n","task = \"ncit2doid\"\n","\n","# Define the weight for the training data\n","# This weight is likely used to balance the training process, giving more emphasis to certain examples.\n","# For instance, a weight of 10.0 could be applied to penalize errors in certain types of predictions more heavily.\n","weight_train = 10.0\n","\n","# Define the similarity threshold for validating matches\n","thres = 0.15"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SJpvkdwVSQye"},"outputs":[],"source":["dir = f\"/content/gdrive/My Drive/BioGITOM-VLDB/Experiments/{task}\"\n","\n","dataset=\"/content/gdrive/My Drive/BioGITOM-VLDB/\"\n","\n","# Define the directory for the dataset containing source and target ontologies\n","dataset_dir = f\"{dataset}/Datasets/{task}\"\n","\n","# Define the data directory for storing embeddings, adjacency matrices, and related files\n","data_dir = f\"{dir}/{task}/Data\"\n","\n","# Define the directory for storing the results\n","results_dir = f\"{dir}/{task}/Negative_Number_Ajdustment/Results\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eFDNSFef23er"},"outputs":[],"source":["# Load the Source ontology using the Ontology class from DeepOnto\n","# This initializes the source ontology by loading its .owl file.\n","src_onto = Ontology(f\"{dataset_dir}/{src_ent}.owl\")\n","\n","# Load the Target ontology using the Ontology class from DeepOnto\n","# This initializes the target ontology by loading its .owl file.\n","tgt_onto = Ontology(f\"{dataset_dir}/{tgt_ent}.owl\")\n","\n","# Define the file path for the Source embeddings CSV file\n","# Embeddings for the source ontology entities are stored in this file.\n","src_Emb = f\"{data_dir}/{src_ent}_emb.csv\"\n","\n","# Define the file path for the Target embeddings CSV file\n","# Embeddings for the target ontology entities are stored in this file.\n","tgt_Emb = f\"{data_dir}/{tgt_ent}_emb.csv\"\n","\n","# Define the file path for the Source adjacency matrix\n","# This file represents the relationships (edges) between entities in the source ontology.\n","src_Adjacence = f\"{data_dir}/{src_ent}_adjacence.csv\"\n","\n","# Define the file path for the Target adjacency matrix\n","# This file represents the relationships (edges) between entities in the target ontology.\n","tgt_Adjacence = f\"{data_dir}/{tgt_ent}_adjacence.csv\"\n","\n","# Define the file path for the JSON file containing the Source ontology class labels\n","# This file maps the source ontology entities to their labels or names.\n","src_class = f\"{data_dir}/{src_ent}_classes.json\"\n","\n","# Define the file path for the JSON file containing the Target ontology class labels\n","# This file maps the target ontology entities to their labels or names.\n","tgt_class = f\"{data_dir}/{tgt_ent}_classes.json\"\n","\n","# Define the file path for the train data\n","train_file = f\"{data_dir}/{task}_train_100.csv\"\n","\n","# Define the file path for the test data\n","# The test file contains reference mappings (ground truth) between the source and target ontologies.\n","test_file = f\"{dataset_dir}/refs_equiv/test.tsv\"\n","\n","# Define the file path for the candidate mappings used during testing\n","# This file includes the candidate pairs (source and target entities) for ranking and evaluation.\n","test_cands = f\"{dataset_dir}/refs_equiv/test.cands.tsv\"\n","\n","# Define the file path for the candidate mappings between Source to Target entities\n","# This file contains cleaned, combined, and encoded candidates used for predictions.\n","candidates_Prediction = f\"{data_dir}/{task}_candidates_prediction.csv\"\n","\n","# Define the file path for the candidate mappings between Source to Target entities for ranking-based metrics\n","# This file is used to compute ranking-based metrics like MRR and Hits@k.\n","candidates_Rank = f\"{data_dir}/{task}_candidates.csv\"\n","\n","# Define the path where the prediction results will be saved in TSV format\n","# This file will store the final predictions (mappings) between source and target entities.\n","prediction_path = f\"{results_dir}/{task}_matching_results.tsv\"\n","\n","# Define the path where all prediction results will be saved in TSV format\n","# This file will store detailed prediction results, including all candidate scores.\n","all_predictions_path = f\"{results_dir}/{task}_all_predictions.tsv\"\n","\n","# Define the path where all ranking prediction results will be saved in TSV format\n","# This file will store predictions sorted by rank based on their scores.\n","all_predictions_path_ranked = f\"{results_dir}/{task}_all_predictions_ranked.tsv\"\n","\n","# Define the path where formatted ranking predictions will be saved in TSV format\n","# This file will contain predictions formatted for evaluation using ranking-based metrics.\n","formatted_predictions_path = f\"{results_dir}/{task}_formatted_predictions.tsv\""]},{"cell_type":"markdown","metadata":{"id":"zqEXsgPGMVhw"},"source":["# **GIT Architecture**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A_d6XCsUMVhx"},"outputs":[],"source":["# RGIT class definition which inherits from PyTorch Geometric's MessagePassing class\n","class RGIT(MessagePassing):\n","\n","    _alpha: OptTensor  # Define _alpha as an optional tensor for storing attention weights\n","\n","    def __init__(\n","        self,\n","        nn: Callable,  # Neural network to be used in the final layer of the GNN\n","        in_channels: Union[int, Tuple[int, int]],  # Input dimension, can be a single or pair of integers\n","        out_channels: int,  # Output dimension of the GNN\n","        eps: float = 0.,  # GIN parameter: epsilon for GIN aggregation\n","        train_eps: bool = False,  # GIN parameter: whether epsilon should be learnable\n","        heads: int = 1,  # Transformer parameter: number of attention heads\n","        dropout: float = 0.,  # Dropout rate for attention weights\n","        edge_dim: Optional[int] = None,  # Dimension for edge attributes (optional)\n","        bias: bool = True,  # Whether to use bias in linear layers\n","        root_weight: bool = True,  # GIN parameter: whether to apply root weight in aggregation\n","        **kwargs,  # Additional arguments passed to the parent class\n","    ):\n","        # Set the aggregation type to 'add' and initialize the parent class with node_dim=0\n","        kwargs.setdefault('aggr', 'add')\n","        super().__init__(node_dim=0, **kwargs)\n","\n","        # Initialize input/output dimensions, neural network, and GIN/transformer parameters\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.nn = nn  # Neural network used by the GNN\n","        self.initial_eps = eps  # Initial value of epsilon for GIN\n","\n","        # Set epsilon to be learnable or fixed\n","        if train_eps:\n","            self.eps = torch.nn.Parameter(torch.empty(1))  # Learnable epsilon\n","        else:\n","            self.register_buffer('eps', torch.empty(1))  # Non-learnable epsilon (fixed)\n","\n","        # Initialize transformer-related parameters\n","        self.heads = heads\n","        self.dropout = dropout\n","        self.edge_dim = edge_dim\n","        self._alpha = None  # Placeholder for attention weights\n","\n","        # Handle case where in_channels is a single integer or a tuple\n","        if isinstance(in_channels, int):\n","            in_channels = (in_channels, in_channels)\n","\n","        # Define the linear layers for key, query, and value for the transformer mechanism\n","        self.lin_key = Linear(in_channels[0], heads * out_channels)\n","        self.lin_query = Linear(in_channels[1], heads * out_channels)\n","        self.lin_value = Linear(in_channels[0], heads * out_channels)\n","\n","        # Define linear transformation for edge embeddings if provided\n","        if edge_dim is not None:\n","            self.lin_edge = Linear(edge_dim, heads * out_channels, bias=False)\n","        else:\n","            self.lin_edge = self.register_parameter('lin_edge', None)\n","\n","        # Reset all parameters to their initial values\n","        self.reset_parameters()\n","\n","    # Function to reset model parameters\n","    def reset_parameters(self):\n","        super().reset_parameters()  # Call parent class reset method\n","        self.lin_key.reset_parameters()  # Reset key linear layer\n","        self.lin_query.reset_parameters()  # Reset query linear layer\n","        self.lin_value.reset_parameters()  # Reset value linear layer\n","        if self.edge_dim:\n","            self.lin_edge.reset_parameters()  # Reset edge linear layer if used\n","        reset(self.nn)  # Reset the neural network provided\n","        self.eps.data.fill_(self.initial_eps)  # Initialize epsilon with the starting value\n","\n","    # Forward function defining how the input data flows through the model\n","    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj,\n","                edge_attr: OptTensor = None, return_attention_weights=None):\n","        # Unpack number of heads and output channels\n","        H, C = self.heads, self.out_channels\n","\n","        # If x is a tensor, treat it as a pair of tensors (source and target embeddings)\n","        if isinstance(x, Tensor):\n","            x: PairTensor = (x, x)\n","\n","        # Extract source node embeddings\n","        x_t = x[0]\n","\n","        # Apply linear transformations and reshape query, key, and value for multi-head attention\n","        query = self.lin_query(x[1]).view(-1, H, C)\n","        key = self.lin_key(x[0]).view(-1, H, C)\n","        value = self.lin_value(x[0]).view(-1, H, C)\n","\n","        # Propagate messages through the graph using the propagate function\n","        out = self.propagate(edge_index, query=query, key=key, value=value,\n","                             edge_attr=edge_attr, size=None)\n","\n","        # Retrieve attention weights and reset them\n","        alpha = self._alpha\n","        self._alpha = None  # Reset _alpha after use\n","        out = out.mean(dim=1)  # Take the mean over all attention heads\n","\n","        # Apply GIN aggregation by adding epsilon-scaled original node embeddings\n","        out = out + (1 + self.eps) * x_t\n","        return self.nn(out)  # Pass through the neural network\n","\n","    # Message passing function which calculates attention and combines messages\n","    def message(self, query_i: Tensor, key_j: Tensor, value_j: Tensor,\n","                edge_attr: OptTensor, index: Tensor, ptr: OptTensor,\n","                size_i: Optional[int]) -> Tensor:\n","        # If edge attributes are used, apply linear transformation and add them to the key\n","        if self.lin_edge is not None:\n","            assert edge_attr is not None\n","            edge_attr = self.lin_edge(edge_attr).view(-1, self.heads, self.out_channels)\n","            key_j = key_j + edge_attr\n","\n","        # Calculate attention (alpha) using the dot product between query and key\n","        alpha = (query_i * key_j).sum(dim=-1) / math.sqrt(self.out_channels)\n","        alpha = softmax(alpha, index, ptr, size_i)  # Apply softmax to normalize attention\n","        self._alpha = alpha  # Store attention weights\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)  # Apply dropout\n","\n","        # Calculate the output message by applying attention to the value\n","        out = value_j\n","        if edge_attr is not None:\n","            out = out + edge_attr  # Add edge embeddings to the output if present\n","        out = out * alpha.view(-1, self.heads, 1)  # Scale by attention weights\n","        return out\n","\n","    # String representation function for debugging or printing\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}({self.in_channels}, '\n","                f'{self.out_channels}, heads={self.heads})')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qwFv6RgHmGCf"},"outputs":[],"source":["# Define the RGIT_mod class, a multi-layer GNN that uses both RGIT and linear layers\n","class RGIT_mod(torch.nn.Module):\n","    \"\"\"Multi-layer RGIT with optional linear layers\"\"\"\n","\n","    # Initialize the model with hidden dimension, number of RGIT layers, and number of linear layers\n","    def __init__(self, dim_h, num_layers, num_linear_layers=1):\n","        super(RGIT_mod, self).__init__()\n","        self.num_layers = num_layers  # Number of RGIT layers\n","        self.num_linear_layers = num_linear_layers  # Number of linear layers\n","        self.linears = torch.nn.ModuleList()  # List to store linear layers\n","        self.rgit_layers = torch.nn.ModuleList()  # List to store RGIT layers\n","\n","        # Create a list of Linear and PReLU layers (for encoding entity names)\n","        for _ in range(num_linear_layers):\n","            self.linears.append(Linear(dim_h, dim_h))  # Linear transformation layer\n","            self.linears.append(PReLU(num_parameters=dim_h))  # Parametric ReLU activation function\n","\n","        # Create a list of RGIT layers\n","        for _ in range(num_layers):\n","            self.rgit_layers.append(RGIT(  # Each RGIT layer contains a small MLP with Linear and PReLU\n","                Sequential(Linear(dim_h, dim_h), PReLU(num_parameters=dim_h),\n","                           Linear(dim_h, dim_h), PReLU(num_parameters=dim_h)), dim_h, dim_h))\n","\n","    # Forward pass through the model\n","    def forward(self, x, edge_index):\n","        # Apply the linear layers first to the input\n","        for layer in self.linears:\n","            x = layer(x)\n","\n","        # Then apply the RGIT layers for message passing\n","        for layer in self.rgit_layers:\n","            x = layer(x, edge_index)\n","\n","        return x  # Return the final node embeddings after all layers\n"]},{"cell_type":"markdown","metadata":{"id":"zxCn5ztKVztw"},"source":["# **Gated Network Architecture**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7MKQUv7o7zay"},"outputs":[],"source":["# Define the GatedCombination class for combining two pairs of embeddings using a gating mechanism\n","class GatedCombination(nn.Module):\n","    def __init__(self, input_dim):\n","        \"\"\"\n","        Initialize the GatedCombination model.\n","\n","        Args:\n","            input_dim (int): The dimensionality of the input embeddings (x1, x2, x3, x4).\n","        \"\"\"\n","        super(GatedCombination, self).__init__()\n","\n","        # Define a linear layer (gate) for combining embeddings x1 and x2 (first pair)\n","        self.gate_A_fc = nn.Linear(input_dim, input_dim)\n","\n","        # Define a linear layer (gate) for combining embeddings x3 and x4 (second pair)\n","        self.gate_B_fc = nn.Linear(input_dim, input_dim)\n","\n","        # A final fully connected layer that outputs a single neuron (binary classification)\n","        self.fc = nn.Linear(1, 1)\n","\n","    def forward(self, x1, x2, x3, x4):\n","        \"\"\"\n","        Forward pass through the gating mechanism and cosine similarity.\n","\n","        Args:\n","            x1 (torch.Tensor): First set of embeddings (source embeddings after update).\n","            x2 (torch.Tensor): Second set of embeddings (original source embeddings).\n","            x3 (torch.Tensor): Third set of embeddings (target embeddings after update).\n","            x4 (torch.Tensor): Fourth set of embeddings (original target embeddings).\n","\n","        Returns:\n","            torch.Tensor: Output of the model (probability score for binary classification).\n","        \"\"\"\n","        # Compute gate values for the first pair (x1 and x2) using a sigmoid activation\n","        gate_values1 = torch.sigmoid(self.gate_A_fc(x1))\n","\n","        # Combine x1 and x2 using the gate values\n","        # The result is a weighted combination of x1 and x2\n","        a = x1 * gate_values1 + x2 * (1 - gate_values1)\n","\n","        # Compute gate values for the second pair (x3 and x4) using a sigmoid activation\n","        gate_values2 = torch.sigmoid(self.gate_B_fc(x3))\n","\n","        # Combine x3 and x4 using the gate values\n","        # The result is a weighted combination of x3 and x4\n","        b = x3 * gate_values2 + x4 * (1 - gate_values2)\n","\n","        # Compute cosine similarity between the combined vectors a and b\n","        x = torch.cosine_similarity(a, b, dim=1)\n","\n","        # Pass the cosine similarity result through a fully connected layer (fc) for classification\n","        # Use a sigmoid activation to output a probability for binary classification\n","        out = torch.sigmoid(self.fc(x.unsqueeze(1)))  # unsqueeze(1) to match the input shape for the fc layer\n","        return out\n","\n"]},{"cell_type":"code","source":["class WeightedBCELoss(nn.Module):\n","    def __init__(self, pos_weight):\n","        \"\"\"\n","        Weighted Binary Cross-Entropy Loss.\n","\n","        Args:\n","            pos_weight (float): Weight for the positive class.\n","        \"\"\"\n","        super(WeightedBCELoss, self).__init__()\n","        self.pos_weight = pos_weight\n","\n","    def forward(self, outputs, targets):\n","        \"\"\"\n","        Args:\n","            outputs (torch.Tensor): Predicted probabilities from the model (after sigmoid).\n","            targets (torch.Tensor): Ground truth labels (0 or 1).\n","\n","        Returns:\n","            torch.Tensor: Computed weighted binary cross-entropy loss.\n","        \"\"\"\n","        # Compute weighted BCE loss\n","        loss = - (self.pos_weight * targets * torch.log(outputs + 1e-8) +\n","                  (1 - targets) * torch.log(1 - outputs + 1e-8))\n","        return loss.mean()"],"metadata":{"id":"PCzq6hHCD8vg"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4kO42TTCqQZ8"},"outputs":[],"source":["class FocalLoss(nn.Module):\n","    def __init__(self, alpha=0.25, gamma=2):\n","        \"\"\"\n","        Focal Loss for binary classification.\n","\n","        Args:\n","            alpha (float): Balancing factor for positive/negative classes.\n","            gamma (float): Focusing parameter for hard examples.\n","        \"\"\"\n","        super(FocalLoss, self).__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","\n","    def forward(self, outputs, targets):\n","        \"\"\"\n","        Args:\n","            outputs (torch.Tensor): Predicted probabilities from the model (after sigmoid).\n","            targets (torch.Tensor): Ground truth labels (0 or 1).\n","\n","        Returns:\n","            torch.Tensor: Computed focal loss.\n","        \"\"\"\n","        # Compute binary cross-entropy loss\n","        bce_loss = F.binary_cross_entropy(outputs, targets, reduction='none')\n","\n","        # Compute modulating factor (1 - p_t)^gamma\n","        pt = torch.where(targets == 1, outputs, 1 - outputs)  # pt = p if y==1 else 1-p\n","        modulating_factor = (1 - pt) ** self.gamma\n","\n","        # Apply alpha and modulating factor\n","        focal_loss = self.alpha * modulating_factor * bce_loss\n","        return focal_loss.mean()"]},{"cell_type":"markdown","metadata":{"id":"aLJ5j9FNMVhy"},"source":["# **Utility functions**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k0L86DgUQjMU"},"outputs":[],"source":["def adjacency_matrix_to_undirected_edge_index(adjacency_matrix):\n","    \"\"\"\n","    Converts an adjacency matrix into an undirected edge index for use in graph-based neural networks.\n","\n","    Args:\n","        adjacency_matrix: A 2D list or array representing the adjacency matrix of a graph.\n","\n","    Returns:\n","        edge_index_undirected: A PyTorch tensor representing the undirected edges.\n","    \"\"\"\n","    # Convert each element in the adjacency matrix to an integer (from boolean or float)\n","    adjacency_matrix = [[int(element) for element in sublist] for sublist in adjacency_matrix]\n","\n","    # Convert the adjacency matrix into a PyTorch LongTensor (used for indexing)\n","    edge_index = torch.tensor(adjacency_matrix, dtype=torch.long)\n","\n","    # Transpose the edge_index tensor so that rows represent edges in the form [source, target]\n","    edge_index = edge_index.t().contiguous()\n","\n","    # Convert the directed edge_index into an undirected edge_index, meaning both directions are added (i.e., (i, j) and (j, i))\n","    edge_index_undirected = to_undirected(edge_index)\n","\n","    return edge_index_undirected  # Return the undirected edge index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YvmOxkLcpf9w"},"outputs":[],"source":["def build_indexed_dict(file_path):\n","    \"\"\"\n","    Builds a dictionary with numeric indexes for each key from a JSON file.\n","\n","    Args:\n","        file_path (str): The path to the JSON file.\n","\n","    Returns:\n","        indexed_dict (dict): A new dictionary where each key from the JSON file is assigned a numeric index.\n","    \"\"\"\n","    # Load the JSON file into a Python dictionary\n","    with open(file_path, 'r') as file:\n","        data = json.load(file)\n","\n","    # Create a new dictionary with numeric indexes as keys and the original JSON keys as values\n","    indexed_dict = {index: key for index, key in enumerate(data.keys())}\n","\n","    return indexed_dict  # Return the newly created dictionary"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QgFINoPGl9Wg"},"outputs":[],"source":["def select_rows_by_index(embedding_vector, index_vector):\n","    \"\"\"\n","    Select rows from an embedding vector using an index vector.\n","\n","    Args:\n","        embedding_vector (torch.Tensor): 2D tensor representing the embedding vector with shape [num_rows, embedding_size].\n","        index_vector (torch.Tensor): 1D tensor representing the index vector.\n","\n","    Returns:\n","        torch.Tensor: New tensor with selected rows from the embedding vector.\n","    \"\"\"\n","    # Use torch.index_select to select the desired rows\n","    new_tensor = torch.index_select(embedding_vector, 0, index_vector)\n","\n","    return new_tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a12L7vEmmCJq"},"outputs":[],"source":["def contrastive_loss(source_embeddings, target_embeddings, labels, margin=1.0):\n","    \"\"\"\n","    Computes the contrastive loss, a type of loss function used to train models in tasks like matching or similarity learning.\n","\n","    Args:\n","        source_embeddings (torch.Tensor): Embeddings of the source graphs, shape [batch_size, embedding_size].\n","        target_embeddings (torch.Tensor): Embeddings of the target graphs, shape [batch_size, embedding_size].\n","        labels (torch.Tensor): Binary labels indicating if the pairs are matched (1) or not (0), shape [batch_size].\n","        margin (float): Margin value for the contrastive loss. Defaults to 1.0.\n","\n","    Returns:\n","        torch.Tensor: The contrastive loss value.\n","    \"\"\"\n","    # Calculate the pairwise Euclidean distance between source and target embeddings\n","    distances = F.pairwise_distance(source_embeddings, target_embeddings)\n","\n","    # Compute the contrastive loss:\n","    # - For matched pairs (label == 1), the loss is the squared distance between embeddings.\n","    # - For non-matched pairs (label == 0), the loss is based on how far apart the embeddings are,\n","    #   but penalizes them only if the distance is less than the margin.\n","    loss = torch.mean(\n","        labels * 0.4 * distances.pow(2) +  # For positive pairs, minimize the distance (squared)\n","        (1 - labels) * 0.4 * torch.max(torch.zeros_like(distances), margin - distances).pow(2)  # For negative pairs, maximize the distance (up to the margin)\n","    )\n","\n","    return loss  # Return the computed contrastive loss\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZhCizXEb7D4N"},"outputs":[],"source":["def Prediction_with_candidates(model, X1_tt, X2_tt, X3_tt, X4_tt, src_entity_tensor_o, tgt_entity_tensor_o,\n","                                   indexed_dict_src, indexed_dict_tgt, all_predictions_path):\n","    \"\"\"\n","    Evaluates the GatedCombination model using the given embeddings and candidate entity pairs.\n","    Saves the predictions and evaluation results to a file.\n","\n","    Args:\n","        model: Trained GatedCombination model.\n","        X1_tt, X2_tt, X3_tt, X4_tt (torch.Tensor): Tensors of source and target entity embeddings (updated and original).\n","        src_entity_tensor_o, tgt_entity_tensor_o (torch.Tensor): Tensors of source and target entity indices.\n","        indexed_dict_src, indexed_dict_tgt (dict): Dictionaries mapping entity indices to URIs for source and target.\n","        output_file (str): Path to save the predictions and results.\n","        hits_at_k_values (list): List of k-values for which hits@k is evaluated.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    # Move the model to CPU and set it to evaluation mode\n","    model = model.to(\"cpu\")\n","    model.eval()\n","\n","    # Set batch size for evaluation\n","    batch_size_test = 32\n","\n","    # Create a DataLoader for the evaluation data\n","    test_dataset = TensorDataset(X1_tt, X2_tt, X3_tt, X4_tt)\n","    test_dataloader = DataLoader(test_dataset, batch_size=batch_size_test)\n","\n","    # Prepare for collecting predictions and results\n","    predictions = []\n","    results = []\n","    count_predictions = 0  # Counter for predictions above threshold (0.5)\n","\n","    # Measure prediction time\n","    start_time = time.time()\n","\n","    # Disable gradient computation for evaluation\n","    with torch.no_grad():\n","        # Iterate over batches and compute model predictions\n","        for batch_X1, batch_X2, batch_X3, batch_X4 in test_dataloader:\n","            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","            predictions.extend(outputs.cpu().numpy())  # Collect predictions in CPU memory\n","\n","    end_time = time.time()\n","    predicting_time = end_time - start_time\n","    print(f\"Predicting time: {predicting_time:.2f} seconds\")\n","\n","    # Convert tensors to lists for easier iteration\n","    src_indices = src_entity_tensor_o.tolist()\n","    tgt_indices = tgt_entity_tensor_o.tolist()\n","\n","    # Prepare results\n","    for i in range(len(predictions)):\n","        if predictions[i] >= 0.00:  # Consider only predictions greater than 0.5\n","            count_predictions += 1  # Increment the counter\n","\n","            # Map the source and target entity indices to their URIs\n","            src_code = src_indices[i]\n","            tgt_code = tgt_indices[i]\n","\n","            src_uri = indexed_dict_src.get(int(src_code), \"Unknown URI\")\n","            tgt_uri = indexed_dict_tgt.get(int(tgt_code), \"Unknown URI\")\n","\n","            # Get the model's predicted score for the current pair\n","            score = predictions[i]\n","\n","            # Append the results (with URIs instead of entity indices)\n","            results.append({\n","                'SrcEntity': src_uri,\n","                'TgtEntity': tgt_uri,\n","                'Score': score\n","            })\n","\n","    # Convert the results into a pandas DataFrame\n","    df_results = pd.DataFrame(results)\n","\n","    # Save the results to a TSV file\n","    df_results.to_csv(all_predictions_path, sep='\\t', index=False)\n","\n","    print(f\"Predictions saved to {all_predictions_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TslUdYHBcGVj"},"outputs":[],"source":["def filter_highest_predictions(input_file_path, output_file_path, threshold=thres):\n","    # Load the all predictions file\n","    df = pd.read_csv(input_file_path, sep='\\t')\n","\n","    # Extract the similarity score from the list in the 'Score' column\n","    df['Score'] = df['Score'].apply(lambda x: float(x.strip('[]')))\n","\n","    # Sorting the dataframe by similarity score in descending order\n","    df_sorted = df.sort_values(by='Score', ascending=False).reset_index(drop=True)\n","\n","    # Initialize variables with threshold value\n","    source_concepts = set(df_sorted['SrcEntity'])\n","    target_concepts = set(df_sorted['TgtEntity'])\n","    matched_sources = set()\n","    matched_targets = set()\n","    result = []\n","\n","    # Iterate through the sorted dataframe and find highest correspondences\n","    for _, row in df_sorted.iterrows():\n","        source, target, similarity = row['SrcEntity'], row['TgtEntity'], row['Score']\n","\n","        # Check if the source or target has already been matched and if the similarity is above the threshold\n","        if source not in matched_sources and target not in matched_targets and similarity >= threshold:\n","            # Add the match to the result list\n","            result.append((source, target, similarity))\n","            # Mark the source and target as matched\n","            matched_sources.add(source)\n","            matched_targets.add(target)\n","\n","    # Create a dataframe for the matching results with threshold applied\n","    matching_results_df_threshold = pd.DataFrame(result, columns=['SrcEntity', 'TgtEntity', 'Score'])\n","\n","    # Save the matching results with the updated column names to a new TSV file\n","    matching_results_df_threshold.to_csv(output_file_path, sep='\\t', index=False)\n","\n","    # Print the number of predictions saved\n","    print(f\"Number of Positive predictions: {len(matching_results_df_threshold)}\")\n","\n","    return matching_results_df_threshold, len(matching_results_df_threshold)"]},{"cell_type":"code","source":["def compute_mrr_and_hits(reference_file, predicted_file, output_file, k_values=[1, 5, 10]):\n","    \"\"\"\n","    Compute MRR and Hits@k for ontology matching predictions based on a reference file.\n","\n","    Args:\n","        reference_file (str): Path to the reference file (test.cands.tsv format).\n","        predicted_file (str): Path to the predictions file with scores.\n","        output_file (str): Path to save the scored results.\n","        k_values (list): List of k values for Hits@k.\n","\n","    Returns:\n","        dict: A dictionary containing MRR and Hits@k metrics.\n","    \"\"\"\n","    # Read the reference mappings\n","    test_candidate_mappings = read_table(reference_file).values.tolist()\n","    ranking_results = []\n","\n","    # Read the predicted scores\n","    predicted_data = pd.read_csv(predicted_file, sep=\"\\t\")\n","    predicted_data[\"Score\"] = predicted_data[\"Score\"].apply(lambda x: float(x.strip(\"[]\")))\n","\n","    # Create a lookup dictionary for predicted scores\n","    score_lookup = {}\n","    for _, row in predicted_data.iterrows():\n","        score_lookup[(row[\"SrcEntity\"], row[\"TgtEntity\"])] = row[\"Score\"]\n","\n","    for src_ref_class, tgt_ref_class, tgt_cands in test_candidate_mappings:\n","        tgt_cands = eval(tgt_cands)  # Convert string to list of candidates\n","        scored_cands = []\n","        for tgt_cand in tgt_cands:\n","            # Retrieve score for each candidate, defaulting to a very low score if not found\n","            matching_score = score_lookup.get((src_ref_class, tgt_cand), -1e9)\n","            scored_cands.append((tgt_cand, matching_score))\n","\n","        # Sort candidates by score in descending order\n","        scored_cands = sorted(scored_cands, key=lambda x: x[1], reverse=True)\n","        ranking_results.append((src_ref_class, tgt_ref_class, scored_cands))\n","\n","    # Save the ranked results to a file\n","    pd.DataFrame(ranking_results, columns=[\"SrcEntity\", \"TgtEntity\", \"TgtCandidates\"]).to_csv(output_file, sep=\"\\t\", index=False)\n","\n","    # Compute MRR and Hits@k\n","    total_entities = len(ranking_results)\n","    reciprocal_ranks = []\n","    hits_at_k = {k: 0 for k in k_values}\n","\n","    for src_entity, tgt_ref_class, tgt_cands in ranking_results:\n","        ranked_candidates = [candidate[0] for candidate in tgt_cands]\n","        if tgt_ref_class in ranked_candidates:\n","            rank = ranked_candidates.index(tgt_ref_class) + 1\n","            reciprocal_ranks.append(1 / rank)\n","            for k in k_values:\n","                if rank <= k:\n","                    hits_at_k[k] += 1\n","        else:\n","            reciprocal_ranks.append(0)\n","\n","    mrr = sum(reciprocal_ranks) / total_entities\n","    hits_at_k = {k: hits / total_entities for k, hits in hits_at_k.items()}\n","\n","    return {\"MRR\": mrr, \"Hits@k\": hits_at_k}"],"metadata":{"id":"_ggVYlTiO_WA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1HyWMsw1MVhz"},"source":["# **Main Code**\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"IC37FlwGDqGM"},"source":["\n","\n","# Reading semantic node embeddings provided by the ENE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FuEfSnw5mod0"},"outputs":[],"source":["# Read the source embeddings from a CSV file into a pandas DataFrame\n","df_embbedings_src = pd.read_csv(src_Emb, index_col=0)\n","\n","# Convert the DataFrame to a NumPy array, which will remove the index and store the data as a raw matrix\n","numpy_array = df_embbedings_src.to_numpy()\n","\n","# Convert the NumPy array into a PyTorch FloatTensor, which is the format required for PyTorch operations\n","x_src = torch.FloatTensor(numpy_array)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"STUwqMUXmlG2"},"outputs":[],"source":["# Read the target embeddings from a CSV file into a pandas DataFrame\n","df_embbedings_tgt = pd.read_csv(tgt_Emb, index_col=0)\n","\n","# Convert the DataFrame to a NumPy array, which removes the index and converts the data to a raw matrix\n","numpy_array = df_embbedings_tgt.to_numpy()\n","\n","# Convert the NumPy array into a PyTorch FloatTensor, which is required for PyTorch operations\n","x_tgt = torch.FloatTensor(numpy_array)"]},{"cell_type":"markdown","metadata":{"id":"jZIu9P08DqGN"},"source":["# Reading adjacency Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pH69Up40mycz"},"outputs":[],"source":["# Read the source adjacency matrix from a CSV file into a pandas DataFrame\n","df_ma1 = pd.read_csv(src_Adjacence, index_col=0)\n","\n","# Convert the DataFrame to a list of lists (Python native list format)\n","ma1 = df_ma1.values.tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hYCmAO5Ymzpl"},"outputs":[],"source":["# Read the target adjacency matrix from a CSV file into a pandas DataFrame\n","df_ma2 = pd.read_csv(tgt_Adjacence, index_col=0)\n","\n","# Convert the DataFrame to a list of lists (Python native list format)\n","ma2 = df_ma2.values.tolist()"]},{"cell_type":"markdown","metadata":{"id":"PSyksqh3TrU-"},"source":["# Convert Adjacency matrix (in list format) to an undirected edge index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uVt-Pce5m5ll"},"outputs":[],"source":["# Convert the source adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n","edge_src = adjacency_matrix_to_undirected_edge_index(ma1)\n","\n","# Convert the target adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n","edge_tgt = adjacency_matrix_to_undirected_edge_index(ma2)"]},{"cell_type":"markdown","metadata":{"id":"H9wMTRdqT4aY"},"source":["# GIT Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eqiEKCLSMVh3"},"outputs":[],"source":["def train_model_gnn(model, x_src, edge_src, x_tgt, edge_tgt,\n","                    tensor_term1, tensor_term2, tensor_score,\n","                    learning_rate, weight_decay_value, num_epochs, print_interval=10):\n","    \"\"\"\n","    Trains a graph neural network (GNN) model using source and target embeddings and contrastive loss.\n","\n","    Args:\n","        model: The GNN model to be trained.\n","        x_src (torch.Tensor): Source node embeddings.\n","        edge_src (torch.Tensor): Source graph edges.\n","        x_tgt (torch.Tensor): Target node embeddings.\n","        edge_tgt (torch.Tensor): Target graph edges.\n","        tensor_term1 (torch.Tensor): Indices of the source nodes to be compared.\n","        tensor_term2 (torch.Tensor): Indices of the target nodes to be compared.\n","        tensor_score (torch.Tensor): Labels indicating if the pairs are matched (1) or not (0).\n","        learning_rate (float): Learning rate for the optimizer.\n","        weight_decay_value (float): Weight decay (L2 regularization) value for the optimizer.\n","        num_epochs (int): Number of epochs for training.\n","        print_interval (int): Interval at which training progress is printed (every `print_interval` epochs).\n","\n","    Returns:\n","        model: The trained GNN model.\n","    \"\"\"\n","\n","    # Step 1: Set device (GPU or CPU) for computation\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    # Step 2: Move the model and all inputs to the selected device\n","    model.to(device)\n","    x_tgt = x_tgt.to(device)               # Target node embeddings\n","    edge_tgt = edge_tgt.to(device)         # Target graph edges\n","    x_src = x_src.to(device)               # Source node embeddings\n","    edge_src = edge_src.to(device)         # Source graph edges\n","    tensor_term1 = tensor_term1.to(device) # Indices for source nodes\n","    tensor_term2 = tensor_term2.to(device) # Indices for target nodes\n","    tensor_score = tensor_score.to(device) # Ground truth labels\n","\n","    # Step 3: Define optimizer with learning rate and regularization\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay_value)\n","\n","    # Step 4: Initialize list to store training losses\n","    train_losses = []\n","\n","    # Record the start time of training\n","    start_time = time.time()\n","\n","    # Step 5: Training loop\n","    for epoch in range(num_epochs):\n","        # Zero out gradients from the previous iteration\n","        optimizer.zero_grad()\n","\n","        # Forward pass: Compute embeddings for source and target graphs\n","        out1 = model(x_src, edge_src)  # Updated source embeddings\n","        out2 = model(x_tgt, edge_tgt)  # Updated target embeddings\n","\n","        # Extract specific rows of embeddings for terms being compared\n","        src_embeddings = select_rows_by_index(out1, tensor_term1)\n","        tgt_embeddings = select_rows_by_index(out2, tensor_term2)\n","\n","        # Compute contrastive loss based on the embeddings and ground truth labels\n","        loss = contrastive_loss(src_embeddings, tgt_embeddings, tensor_score)\n","\n","        # Backward pass: Compute gradients\n","        loss.backward()\n","\n","        # Update the model's parameters\n","        optimizer.step()\n","\n","        # Append the loss for this iteration to the list\n","        train_losses.append(loss.item())\n","\n","        # Print loss every `print_interval` epochs\n","        if (epoch + 1) % print_interval == 0:\n","            print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item()}\")\n","\n","    # Step 6: Record end time of training\n","    end_time = time.time()\n","\n","    # Step 7: Plot the training loss over time\n","    plt.semilogy(range(1, num_epochs + 1), train_losses, label=\"Training Loss\", marker='o')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    # Print the total training time\n","    training_time = end_time - start_time\n","    print(f\"Training complete! Total training time: {training_time:.2f} seconds\")\n","\n","    # Step 8: Return the trained model\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6_tzUG_emtBg"},"outputs":[],"source":["# Initialize the GIT_mod model with the dimensionality of the target embeddings\n","# The first argument is the dimensionality of the target node embeddings (x_tgt.shape[1])\n","# The second argument (1) represents the number of RGIT layers in the model\n","GIT_model = RGIT_mod(x_tgt.shape[1], 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wVo-s7UQssSp"},"outputs":[],"source":["# Reading the training pairs from a CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(train_file, index_col=0)\n","\n","# Extract the 'SrcEntity' and 'TgtEntity' columns as NumPy arrays and convert them to integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)  # Source entity indices\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)  # Target entity indices\n","\n","# Extract the 'Score' column as a NumPy array and convert it to floats\n","tensor_score = df_embbedings['Score'].values.astype(float)  # Scores (labels) indicating if pairs match (1) or not (0)\n","\n","# Convert the NumPy arrays to PyTorch LongTensors (for indices) and FloatTensors (for scores)\n","tensor_term1_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)  # Source entity tensor\n","tensor_term2_o = torch.from_numpy(tensor_term2).type(torch.LongTensor)  # Target entity tensor\n","tensor_score_o = torch.from_numpy(tensor_score).type(torch.FloatTensor)  # Score tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"agHlFNesMVh3","outputId":"36d021de-b570-4a7e-c590-3c866fd09926","executionInfo":{"status":"ok","timestamp":1732174248980,"user_tz":-60,"elapsed":1067355,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [10/1000], Training Loss: 0.0019168693106621504\n","Epoch [20/1000], Training Loss: 0.0015770301688462496\n","Epoch [30/1000], Training Loss: 0.0013953093439340591\n","Epoch [40/1000], Training Loss: 0.0012595407897606492\n","Epoch [50/1000], Training Loss: 0.0011618233984336257\n","Epoch [60/1000], Training Loss: 0.0010848595993593335\n","Epoch [70/1000], Training Loss: 0.001019802177324891\n","Epoch [80/1000], Training Loss: 0.0009652438457123935\n","Epoch [90/1000], Training Loss: 0.0009189524571411312\n","Epoch [100/1000], Training Loss: 0.000878648366779089\n","Epoch [110/1000], Training Loss: 0.0008431444293819368\n","Epoch [120/1000], Training Loss: 0.0008114778902381659\n","Epoch [130/1000], Training Loss: 0.000783558702096343\n","Epoch [140/1000], Training Loss: 0.0007582730613648891\n","Epoch [150/1000], Training Loss: 0.0007357277791015804\n","Epoch [160/1000], Training Loss: 0.0007157697691582143\n","Epoch [170/1000], Training Loss: 0.0006976604927331209\n","Epoch [180/1000], Training Loss: 0.0006817171233706176\n","Epoch [190/1000], Training Loss: 0.0006672165472991765\n","Epoch [200/1000], Training Loss: 0.0006540775648318231\n","Epoch [210/1000], Training Loss: 0.0006423836457543075\n","Epoch [220/1000], Training Loss: 0.0006320294342003763\n","Epoch [230/1000], Training Loss: 0.0006225692923180759\n","Epoch [240/1000], Training Loss: 0.0006138652097433805\n","Epoch [250/1000], Training Loss: 0.0006061250460334122\n","Epoch [260/1000], Training Loss: 0.0005990249919705093\n","Epoch [270/1000], Training Loss: 0.0005925517762079835\n","Epoch [280/1000], Training Loss: 0.0005865799612365663\n","Epoch [290/1000], Training Loss: 0.0005811068112961948\n","Epoch [300/1000], Training Loss: 0.000576185411773622\n","Epoch [310/1000], Training Loss: 0.000571642944123596\n","Epoch [320/1000], Training Loss: 0.0005674715503118932\n","Epoch [330/1000], Training Loss: 0.0005635709967464209\n","Epoch [340/1000], Training Loss: 0.0005599213764071465\n","Epoch [350/1000], Training Loss: 0.0005565239116549492\n","Epoch [360/1000], Training Loss: 0.0005532712675631046\n","Epoch [370/1000], Training Loss: 0.0005501785199157894\n","Epoch [380/1000], Training Loss: 0.0005472413613460958\n","Epoch [390/1000], Training Loss: 0.0005443535628728569\n","Epoch [400/1000], Training Loss: 0.0005415792111307383\n","Epoch [410/1000], Training Loss: 0.0005389243015088141\n","Epoch [420/1000], Training Loss: 0.0005363066447898746\n","Epoch [430/1000], Training Loss: 0.0005337760667316616\n","Epoch [440/1000], Training Loss: 0.0005312688299454749\n","Epoch [450/1000], Training Loss: 0.0005288316169753671\n","Epoch [460/1000], Training Loss: 0.0005264177452772856\n","Epoch [470/1000], Training Loss: 0.0005240298924036324\n","Epoch [480/1000], Training Loss: 0.0005217131692916155\n","Epoch [490/1000], Training Loss: 0.0005194330005906522\n","Epoch [500/1000], Training Loss: 0.0005171950906515121\n","Epoch [510/1000], Training Loss: 0.0005149361677467823\n","Epoch [520/1000], Training Loss: 0.0005127089680172503\n","Epoch [530/1000], Training Loss: 0.0005104630836285651\n","Epoch [540/1000], Training Loss: 0.0005081798299215734\n","Epoch [550/1000], Training Loss: 0.0005059242248535156\n","Epoch [560/1000], Training Loss: 0.0005036881193518639\n","Epoch [570/1000], Training Loss: 0.000501458125654608\n","Epoch [580/1000], Training Loss: 0.0004992341855540872\n","Epoch [590/1000], Training Loss: 0.0004970130394212902\n","Epoch [600/1000], Training Loss: 0.0004947682027705014\n","Epoch [610/1000], Training Loss: 0.0004924742388539016\n","Epoch [620/1000], Training Loss: 0.0004901571082882583\n","Epoch [630/1000], Training Loss: 0.0004878294712398201\n","Epoch [640/1000], Training Loss: 0.00048552447697147727\n","Epoch [650/1000], Training Loss: 0.0004832409031223506\n","Epoch [660/1000], Training Loss: 0.00048099327250383794\n","Epoch [670/1000], Training Loss: 0.0004788142105098814\n","Epoch [680/1000], Training Loss: 0.00047663075383752584\n","Epoch [690/1000], Training Loss: 0.0004744769830722362\n","Epoch [700/1000], Training Loss: 0.00047233368968591094\n","Epoch [710/1000], Training Loss: 0.0004702093137893826\n","Epoch [720/1000], Training Loss: 0.0004681085410993546\n","Epoch [730/1000], Training Loss: 0.0004660288104787469\n","Epoch [740/1000], Training Loss: 0.0004639668040908873\n","Epoch [750/1000], Training Loss: 0.00046192327863536775\n","Epoch [760/1000], Training Loss: 0.0004599046369548887\n","Epoch [770/1000], Training Loss: 0.000457876012660563\n","Epoch [780/1000], Training Loss: 0.0004558260552585125\n","Epoch [790/1000], Training Loss: 0.00045373482862487435\n","Epoch [800/1000], Training Loss: 0.00045160678564570844\n","Epoch [810/1000], Training Loss: 0.00044946291018277407\n","Epoch [820/1000], Training Loss: 0.00044730619993060827\n","Epoch [830/1000], Training Loss: 0.0004451785353012383\n","Epoch [840/1000], Training Loss: 0.0004430857952684164\n","Epoch [850/1000], Training Loss: 0.000441004172898829\n","Epoch [860/1000], Training Loss: 0.0004389228706713766\n","Epoch [870/1000], Training Loss: 0.0004368616209831089\n","Epoch [880/1000], Training Loss: 0.0004348376241978258\n","Epoch [890/1000], Training Loss: 0.00043276665383018553\n","Epoch [900/1000], Training Loss: 0.00043070028186775744\n","Epoch [910/1000], Training Loss: 0.00042864744318649173\n","Epoch [920/1000], Training Loss: 0.0004265975148882717\n","Epoch [930/1000], Training Loss: 0.00042457348899915814\n","Epoch [940/1000], Training Loss: 0.00042262967326678336\n","Epoch [950/1000], Training Loss: 0.00042072092765010893\n","Epoch [960/1000], Training Loss: 0.0004188838938716799\n","Epoch [970/1000], Training Loss: 0.0004170974134467542\n","Epoch [980/1000], Training Loss: 0.0004153313930146396\n","Epoch [990/1000], Training Loss: 0.0004136227071285248\n","Epoch [1000/1000], Training Loss: 0.0004119685327168554\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training complete! Total training time: 1066.45 seconds\n"]}],"source":["# Train the GNN model using the provided source and target graph embeddings, edges, and training data\n","trained_model = train_model_gnn(\n","    model=GIT_model,                # The GNN model to be trained (initialized earlier)\n","    x_src=x_src,                    # Source node embeddings (tensor for source graph)\n","    edge_src=edge_src,              # Source graph edges (undirected edge index for source graph)\n","    x_tgt=x_tgt,                    # Target node embeddings (tensor for target graph)\n","    edge_tgt=edge_tgt,              # Target graph edges (undirected edge index for target graph)\n","    tensor_term1=tensor_term1_o,    # Indices of source entities for training\n","    tensor_term2=tensor_term2_o,    # Indices of target entities for training\n","    tensor_score=tensor_score_o,    # Scores (labels) indicating if pairs match (1) or not (0)\n","    learning_rate=0.0001,            # Learning rate for the Adam optimizer\n","    weight_decay_value=1e-4,        # Weight decay for L2 regularization to prevent overfitting\n","    num_epochs=1000,                # Number of training epochs\n","    print_interval=10               # Interval at which to print training progress (every 10 epochs)\n",")"]},{"cell_type":"markdown","metadata":{"id":"MYyhvjcTUaae"},"source":["# GIT Application"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BZ_VqP6tq6iD"},"outputs":[],"source":["# Determine if a GPU is available and move the computations to it; otherwise, use the CPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Assuming the model has been trained and hyperparameters (x_src, edge_src, x_tgt, edge_tgt) are set\n","\n","# Move the trained GIT_model to the device (GPU or CPU)\n","GIT_model.to(device)\n","\n","# Move the data tensors to the same device (GPU or CPU)\n","x_tgt = x_tgt.to(device)         # Target node embeddings\n","edge_tgt = edge_tgt.to(device)   # Target graph edges\n","x_src = x_src.to(device)         # Source node embeddings\n","edge_src = edge_src.to(device)   # Source graph edges\n","\n","# Set the model to evaluation mode; this disables dropout and batch normalization\n","GIT_model.eval()\n","\n","# Pass the source and target embeddings through the trained GNN model to update the embeddings\n","with torch.no_grad():  # Disable gradient computation (inference mode)\n","    embeddings_tgt = GIT_model(x_tgt, edge_tgt)  # Get updated embeddings for the target graph\n","    embeddings_src = GIT_model(x_src, edge_src)  # Get updated embeddings for the source graph\n","\n","# Detach the embeddings from the computation graph and move them back to the CPU\n","# This step is useful if you need to use the embeddings for tasks outside PyTorch (e.g., saving to disk)\n","embeddings_tgt = embeddings_tgt.detach().cpu()  # Target graph embeddings\n","embeddings_src = embeddings_src.detach().cpu()  # Source graph embeddings\n","\n","# At this point, embeddings_tgt and embeddings_src contain the updated embeddings, ready for downstream tasks"]},{"cell_type":"markdown","metadata":{"id":"Og5fdoGJrTCG"},"source":["# Selecting embedding pairs to train the Gated Network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J0nTwc-dnjLn"},"outputs":[],"source":["# Read the training pairs from a CSV file into a pandas DataFrame\n","df_embeddings = pd.read_csv(train_file, index_col=0)\n","\n","# Extract columns and convert to NumPy arrays\n","tensor_term1 = df_embeddings['SrcEntity'].values.astype(int)  # Source entity indices\n","tensor_term2 = df_embeddings['TgtEntity'].values.astype(int)  # Target entity indices\n","tensor_score = df_embeddings['Score'].values.astype(float)  # Matching scores\n","\n","# Split data into training and validation sets\n","tensor_term1_train, tensor_term1_val, tensor_term2_train, tensor_term2_val, tensor_score_train, tensor_score_val = train_test_split(\n","    tensor_term1, tensor_term2, tensor_score, test_size=0.3, random_state=42\n",")\n","\n","# Convert split data to PyTorch tensors\n","tensor_term1_train = torch.from_numpy(tensor_term1_train).type(torch.LongTensor)\n","tensor_term2_train = torch.from_numpy(tensor_term2_train).type(torch.LongTensor)\n","tensor_score_train = torch.from_numpy(tensor_score_train).type(torch.FloatTensor)\n","\n","tensor_term1_val = torch.from_numpy(tensor_term1_val).type(torch.LongTensor)\n","tensor_term2_val = torch.from_numpy(tensor_term2_val).type(torch.LongTensor)\n","tensor_score_val = torch.from_numpy(tensor_score_val).type(torch.FloatTensor)\n","\n","# Move the embeddings back to the CPU if not already there\n","x_tgt = x_tgt.cpu()  # Target node embeddings\n","x_src = x_src.cpu()  # Source node embeddings\n","\n","# Select embeddings for the training set\n","X1_train = select_rows_by_index(embeddings_src, tensor_term1_train)\n","X2_train = select_rows_by_index(x_src, tensor_term1_train)\n","X3_train = select_rows_by_index(embeddings_tgt, tensor_term2_train)\n","X4_train = select_rows_by_index(x_tgt, tensor_term2_train)\n","\n","# Select embeddings for the validation set\n","X1_val = select_rows_by_index(embeddings_src, tensor_term1_val)\n","X2_val = select_rows_by_index(x_src, tensor_term1_val)\n","X3_val = select_rows_by_index(embeddings_tgt, tensor_term2_val)\n","X4_val = select_rows_by_index(x_tgt, tensor_term2_val)\n","\n","# Now you have:\n","# - Training tensors: X1_train, X2_train, X3_train, X4_train, tensor_score_train\n","# - Validation tensors: X1_val, X2_val, X3_val, X4_val, tensor_score_val"]},{"cell_type":"code","source":["positive_weight = len(tensor_score_train) / (weight_train * tensor_score_train.sum())"],"metadata":{"id":"wR3PbrbBETJA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fNdCgaTMExPK"},"source":["# Gated Network Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gof1eIPIWSVU"},"outputs":[],"source":["def train_gated_combination_model(X1_t, X2_t, X3_t, X4_t, tensor_score_o,\n","                                  X1_val, X2_val, X3_val, X4_val, tensor_score_val,\n","                                  epochs=120, batch_size=32, learning_rate=0.001, weight_decay=1e-5):\n","    \"\"\"\n","    Trains the GatedCombination model with training and validation data, using ReduceLROnPlateau scheduler.\n","    \"\"\"\n","\n","    # Create datasets and DataLoaders\n","    train_dataset = TensorDataset(X1_t, X2_t, X3_t, X4_t, tensor_score_o)\n","    val_dataset = TensorDataset(X1_val, X2_val, X3_val, X4_val, tensor_score_val)\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = GatedCombination(X1_t.shape[1]).to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","\n","    # Use ReduceLROnPlateau scheduler\n","    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n","\n","    criterion = WeightedBCELoss(pos_weight=positive_weight).to(device)\n","\n","    train_losses, val_losses = [], []\n","\n","    start_time = time.time()\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        total_train_loss, y_true_train, y_pred_train = 0.0, [], []\n","\n","        for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in train_loader:\n","            batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (batch_X1.to(device), batch_X2.to(device),\n","                                                               batch_X3.to(device), batch_X4.to(device), batch_y.to(device))\n","            optimizer.zero_grad()\n","            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","            loss = criterion(outputs, batch_y.unsqueeze(1).float())\n","            loss.backward()\n","            optimizer.step()\n","            total_train_loss += loss.item()\n","            y_true_train.extend(batch_y.cpu().numpy())\n","            y_pred_train.extend((outputs > 0.2).float().cpu().numpy())\n","\n","        train_f1 = f1_score(y_true_train, y_pred_train)\n","        train_loss = total_train_loss / len(train_loader)\n","        train_losses.append(train_loss)\n","\n","        # Validation phase\n","        model.eval()\n","        total_val_loss, y_true_val, y_pred_val = 0.0, [], []\n","        with torch.no_grad():\n","            for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in val_loader:\n","                batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (batch_X1.to(device), batch_X2.to(device),\n","                                                                   batch_X3.to(device), batch_X4.to(device), batch_y.to(device))\n","                outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","                val_loss = criterion(outputs, batch_y.unsqueeze(1).float())\n","                total_val_loss += val_loss.item()\n","                y_true_val.extend(batch_y.cpu().numpy())\n","                y_pred_val.extend((outputs > 0.4).float().cpu().numpy())\n","\n","        val_f1 = f1_score(y_true_val, y_pred_val)\n","        avg_val_loss = total_val_loss / len(val_loader)\n","        val_losses.append(avg_val_loss)\n","\n","        # Step the scheduler with validation loss\n","        scheduler.step(avg_val_loss)\n","\n","        # Print training and validation metrics\n","        print(f\"Epoch [{epoch + 1}/{epochs}] Training Loss: {train_loss:.4f}, F1 Score: {train_f1:.4f} | \"\n","              f\"Validation Loss: {avg_val_loss:.4f}, F1 Score: {val_f1:.4f}\")\n","\n","    end_time = time.time()\n","\n","    # Plotting\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(train_losses, label=\"Training Loss\", marker='o')\n","    plt.plot(val_losses, label=\"Validation Loss\", marker='x')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    print(f\"Training complete! Total time: {end_time - start_time:.2f} seconds\")\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"l11dgb8ei69T","outputId":"f5d955e0-a45c-4995-9b45-669dd9b4a888","executionInfo":{"status":"ok","timestamp":1732175971324,"user_tz":-60,"elapsed":1721495,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/100] Training Loss: 0.4498, F1 Score: 0.0263 | Validation Loss: 0.2686, F1 Score: 0.5191\n","Epoch [2/100] Training Loss: 0.2092, F1 Score: 0.5398 | Validation Loss: 0.1774, F1 Score: 0.7837\n","Epoch [3/100] Training Loss: 0.1508, F1 Score: 0.7338 | Validation Loss: 0.1344, F1 Score: 0.8961\n","Epoch [4/100] Training Loss: 0.1168, F1 Score: 0.7028 | Validation Loss: 0.1052, F1 Score: 0.9238\n","Epoch [5/100] Training Loss: 0.0933, F1 Score: 0.6877 | Validation Loss: 0.0840, F1 Score: 0.9257\n","Epoch [6/100] Training Loss: 0.0765, F1 Score: 0.6930 | Validation Loss: 0.0703, F1 Score: 0.9244\n","Epoch [7/100] Training Loss: 0.0647, F1 Score: 0.6803 | Validation Loss: 0.0606, F1 Score: 0.9199\n","Epoch [8/100] Training Loss: 0.0564, F1 Score: 0.6894 | Validation Loss: 0.0519, F1 Score: 0.9114\n","Epoch [9/100] Training Loss: 0.0503, F1 Score: 0.6950 | Validation Loss: 0.0482, F1 Score: 0.9058\n","Epoch [10/100] Training Loss: 0.0455, F1 Score: 0.6947 | Validation Loss: 0.0433, F1 Score: 0.9099\n","Epoch [11/100] Training Loss: 0.0419, F1 Score: 0.7041 | Validation Loss: 0.0393, F1 Score: 0.9070\n","Epoch [12/100] Training Loss: 0.0392, F1 Score: 0.7041 | Validation Loss: 0.0378, F1 Score: 0.9083\n","Epoch [13/100] Training Loss: 0.0368, F1 Score: 0.7140 | Validation Loss: 0.0367, F1 Score: 0.8938\n","Epoch [14/100] Training Loss: 0.0349, F1 Score: 0.7113 | Validation Loss: 0.0348, F1 Score: 0.9163\n","Epoch [15/100] Training Loss: 0.0336, F1 Score: 0.7159 | Validation Loss: 0.0317, F1 Score: 0.8917\n","Epoch [16/100] Training Loss: 0.0322, F1 Score: 0.7165 | Validation Loss: 0.0307, F1 Score: 0.9005\n","Epoch [17/100] Training Loss: 0.0311, F1 Score: 0.7255 | Validation Loss: 0.0313, F1 Score: 0.8935\n","Epoch [18/100] Training Loss: 0.0298, F1 Score: 0.7262 | Validation Loss: 0.0305, F1 Score: 0.9093\n","Epoch [19/100] Training Loss: 0.0291, F1 Score: 0.7280 | Validation Loss: 0.0291, F1 Score: 0.9041\n","Epoch [20/100] Training Loss: 0.0285, F1 Score: 0.7251 | Validation Loss: 0.0282, F1 Score: 0.9183\n","Epoch [21/100] Training Loss: 0.0280, F1 Score: 0.7325 | Validation Loss: 0.0277, F1 Score: 0.8857\n","Epoch [22/100] Training Loss: 0.0270, F1 Score: 0.7342 | Validation Loss: 0.0261, F1 Score: 0.8958\n","Epoch [23/100] Training Loss: 0.0267, F1 Score: 0.7351 | Validation Loss: 0.0260, F1 Score: 0.8725\n","Epoch [24/100] Training Loss: 0.0263, F1 Score: 0.7332 | Validation Loss: 0.0261, F1 Score: 0.8900\n","Epoch [25/100] Training Loss: 0.0261, F1 Score: 0.7373 | Validation Loss: 0.0257, F1 Score: 0.8930\n","Epoch [26/100] Training Loss: 0.0254, F1 Score: 0.7340 | Validation Loss: 0.0249, F1 Score: 0.8984\n","Epoch [27/100] Training Loss: 0.0252, F1 Score: 0.7429 | Validation Loss: 0.0258, F1 Score: 0.8864\n","Epoch [28/100] Training Loss: 0.0247, F1 Score: 0.7332 | Validation Loss: 0.0242, F1 Score: 0.9070\n","Epoch [29/100] Training Loss: 0.0246, F1 Score: 0.7433 | Validation Loss: 0.0246, F1 Score: 0.9087\n","Epoch [30/100] Training Loss: 0.0240, F1 Score: 0.7390 | Validation Loss: 0.0246, F1 Score: 0.8854\n","Epoch [31/100] Training Loss: 0.0244, F1 Score: 0.7365 | Validation Loss: 0.0235, F1 Score: 0.8891\n","Epoch [32/100] Training Loss: 0.0241, F1 Score: 0.7443 | Validation Loss: 0.0243, F1 Score: 0.9049\n","Epoch [33/100] Training Loss: 0.0238, F1 Score: 0.7471 | Validation Loss: 0.0239, F1 Score: 0.8731\n","Epoch [34/100] Training Loss: 0.0231, F1 Score: 0.7541 | Validation Loss: 0.0245, F1 Score: 0.8949\n","Epoch [35/100] Training Loss: 0.0231, F1 Score: 0.7484 | Validation Loss: 0.0230, F1 Score: 0.8875\n","Epoch [36/100] Training Loss: 0.0230, F1 Score: 0.7514 | Validation Loss: 0.0231, F1 Score: 0.9053\n","Epoch [37/100] Training Loss: 0.0221, F1 Score: 0.7563 | Validation Loss: 0.0251, F1 Score: 0.8358\n","Epoch [38/100] Training Loss: 0.0227, F1 Score: 0.7560 | Validation Loss: 0.0245, F1 Score: 0.8971\n","Epoch [39/100] Training Loss: 0.0217, F1 Score: 0.7511 | Validation Loss: 0.0231, F1 Score: 0.8658\n","Epoch [40/100] Training Loss: 0.0224, F1 Score: 0.7526 | Validation Loss: 0.0222, F1 Score: 0.8816\n","Epoch [41/100] Training Loss: 0.0222, F1 Score: 0.7545 | Validation Loss: 0.0223, F1 Score: 0.8760\n","Epoch [42/100] Training Loss: 0.0214, F1 Score: 0.7540 | Validation Loss: 0.0237, F1 Score: 0.8490\n","Epoch [43/100] Training Loss: 0.0218, F1 Score: 0.7587 | Validation Loss: 0.0231, F1 Score: 0.9030\n","Epoch [44/100] Training Loss: 0.0217, F1 Score: 0.7570 | Validation Loss: 0.0231, F1 Score: 0.9018\n","Epoch [45/100] Training Loss: 0.0217, F1 Score: 0.7556 | Validation Loss: 0.0220, F1 Score: 0.8877\n","Epoch [46/100] Training Loss: 0.0215, F1 Score: 0.7578 | Validation Loss: 0.0217, F1 Score: 0.8811\n","Epoch [47/100] Training Loss: 0.0212, F1 Score: 0.7532 | Validation Loss: 0.0217, F1 Score: 0.9020\n","Epoch [48/100] Training Loss: 0.0211, F1 Score: 0.7570 | Validation Loss: 0.0216, F1 Score: 0.8986\n","Epoch [49/100] Training Loss: 0.0210, F1 Score: 0.7540 | Validation Loss: 0.0212, F1 Score: 0.8728\n","Epoch [50/100] Training Loss: 0.0207, F1 Score: 0.7546 | Validation Loss: 0.0220, F1 Score: 0.8873\n","Epoch [51/100] Training Loss: 0.0207, F1 Score: 0.7604 | Validation Loss: 0.0236, F1 Score: 0.8834\n","Epoch [52/100] Training Loss: 0.0210, F1 Score: 0.7502 | Validation Loss: 0.0228, F1 Score: 0.9056\n","Epoch [53/100] Training Loss: 0.0206, F1 Score: 0.7582 | Validation Loss: 0.0214, F1 Score: 0.8834\n","Epoch [54/100] Training Loss: 0.0205, F1 Score: 0.7552 | Validation Loss: 0.0208, F1 Score: 0.8968\n","Epoch [55/100] Training Loss: 0.0204, F1 Score: 0.7587 | Validation Loss: 0.0220, F1 Score: 0.8722\n","Epoch [56/100] Training Loss: 0.0210, F1 Score: 0.7535 | Validation Loss: 0.0212, F1 Score: 0.8958\n","Epoch [57/100] Training Loss: 0.0206, F1 Score: 0.7601 | Validation Loss: 0.0221, F1 Score: 0.9077\n","Epoch [58/100] Training Loss: 0.0200, F1 Score: 0.7614 | Validation Loss: 0.0226, F1 Score: 0.8956\n","Epoch [59/100] Training Loss: 0.0193, F1 Score: 0.7609 | Validation Loss: 0.0217, F1 Score: 0.8893\n","Epoch [60/100] Training Loss: 0.0207, F1 Score: 0.7557 | Validation Loss: 0.0214, F1 Score: 0.8986\n","Epoch [61/100] Training Loss: 0.0201, F1 Score: 0.7590 | Validation Loss: 0.0218, F1 Score: 0.9128\n","Epoch [62/100] Training Loss: 0.0201, F1 Score: 0.7620 | Validation Loss: 0.0205, F1 Score: 0.9022\n","Epoch [63/100] Training Loss: 0.0205, F1 Score: 0.7642 | Validation Loss: 0.0211, F1 Score: 0.8711\n","Epoch [64/100] Training Loss: 0.0200, F1 Score: 0.7626 | Validation Loss: 0.0204, F1 Score: 0.8893\n","Epoch [65/100] Training Loss: 0.0199, F1 Score: 0.7691 | Validation Loss: 0.0215, F1 Score: 0.8919\n","Epoch [66/100] Training Loss: 0.0202, F1 Score: 0.7652 | Validation Loss: 0.0217, F1 Score: 0.9083\n","Epoch [67/100] Training Loss: 0.0191, F1 Score: 0.7636 | Validation Loss: 0.0221, F1 Score: 0.9056\n","Epoch [68/100] Training Loss: 0.0197, F1 Score: 0.7593 | Validation Loss: 0.0207, F1 Score: 0.9136\n","Epoch [69/100] Training Loss: 0.0194, F1 Score: 0.7681 | Validation Loss: 0.0205, F1 Score: 0.8947\n","Epoch [70/100] Training Loss: 0.0202, F1 Score: 0.7595 | Validation Loss: 0.0218, F1 Score: 0.8635\n","Epoch [71/100] Training Loss: 0.0192, F1 Score: 0.7591 | Validation Loss: 0.0221, F1 Score: 0.9211\n","Epoch [72/100] Training Loss: 0.0200, F1 Score: 0.7651 | Validation Loss: 0.0206, F1 Score: 0.8935\n","Epoch [73/100] Training Loss: 0.0194, F1 Score: 0.7648 | Validation Loss: 0.0219, F1 Score: 0.8304\n","Epoch [74/100] Training Loss: 0.0196, F1 Score: 0.7627 | Validation Loss: 0.0209, F1 Score: 0.8652\n","Epoch 00075: reducing learning rate of group 0 to 1.0000e-04.\n","Epoch [75/100] Training Loss: 0.0192, F1 Score: 0.7568 | Validation Loss: 0.0205, F1 Score: 0.8758\n","Epoch [76/100] Training Loss: 0.0157, F1 Score: 0.7765 | Validation Loss: 0.0199, F1 Score: 0.8958\n","Epoch [77/100] Training Loss: 0.0151, F1 Score: 0.7914 | Validation Loss: 0.0201, F1 Score: 0.9136\n","Epoch [78/100] Training Loss: 0.0148, F1 Score: 0.8039 | Validation Loss: 0.0197, F1 Score: 0.8977\n","Epoch [79/100] Training Loss: 0.0145, F1 Score: 0.7943 | Validation Loss: 0.0198, F1 Score: 0.9077\n","Epoch [80/100] Training Loss: 0.0144, F1 Score: 0.7973 | Validation Loss: 0.0197, F1 Score: 0.9077\n","Epoch [81/100] Training Loss: 0.0143, F1 Score: 0.8017 | Validation Loss: 0.0196, F1 Score: 0.9079\n","Epoch [82/100] Training Loss: 0.0141, F1 Score: 0.7993 | Validation Loss: 0.0197, F1 Score: 0.9077\n","Epoch [83/100] Training Loss: 0.0143, F1 Score: 0.7990 | Validation Loss: 0.0196, F1 Score: 0.9068\n","Epoch [84/100] Training Loss: 0.0139, F1 Score: 0.7998 | Validation Loss: 0.0196, F1 Score: 0.9058\n","Epoch [85/100] Training Loss: 0.0140, F1 Score: 0.8051 | Validation Loss: 0.0195, F1 Score: 0.9032\n","Epoch [86/100] Training Loss: 0.0139, F1 Score: 0.8027 | Validation Loss: 0.0196, F1 Score: 0.9077\n","Epoch [87/100] Training Loss: 0.0140, F1 Score: 0.7995 | Validation Loss: 0.0197, F1 Score: 0.9097\n","Epoch [89/100] Training Loss: 0.0137, F1 Score: 0.8062 | Validation Loss: 0.0198, F1 Score: 0.9136\n","Epoch [90/100] Training Loss: 0.0138, F1 Score: 0.8129 | Validation Loss: 0.0194, F1 Score: 0.8996\n","Epoch [91/100] Training Loss: 0.0137, F1 Score: 0.8052 | Validation Loss: 0.0194, F1 Score: 0.8984\n","Epoch [92/100] Training Loss: 0.0136, F1 Score: 0.8035 | Validation Loss: 0.0197, F1 Score: 0.9106\n","Epoch [93/100] Training Loss: 0.0137, F1 Score: 0.8084 | Validation Loss: 0.0197, F1 Score: 0.9116\n","Epoch [94/100] Training Loss: 0.0136, F1 Score: 0.8079 | Validation Loss: 0.0196, F1 Score: 0.9106\n","Epoch [95/100] Training Loss: 0.0136, F1 Score: 0.8137 | Validation Loss: 0.0193, F1 Score: 0.9015\n","Epoch [96/100] Training Loss: 0.0135, F1 Score: 0.8052 | Validation Loss: 0.0195, F1 Score: 0.9097\n","Epoch [97/100] Training Loss: 0.0134, F1 Score: 0.8076 | Validation Loss: 0.0196, F1 Score: 0.9106\n","Epoch [98/100] Training Loss: 0.0134, F1 Score: 0.8081 | Validation Loss: 0.0196, F1 Score: 0.9116\n","Epoch [99/100] Training Loss: 0.0135, F1 Score: 0.8062 | Validation Loss: 0.0196, F1 Score: 0.9145\n","Epoch [100/100] Training Loss: 0.0134, F1 Score: 0.8120 | Validation Loss: 0.0194, F1 Score: 0.9068\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x500 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training complete! Total time: 1721.20 seconds\n"]}],"source":["# Train the GatedCombination model using training and validation data\n","trained_model = train_gated_combination_model(\n","    X1_train,          # Updated source embeddings (after applying the GNN model)\n","    X2_train,          # Original source embeddings (before applying the GNN model)\n","    X3_train,          # Updated target embeddings (after applying the GNN model)\n","    X4_train,          # Original target embeddings (before applying the GNN model)\n","    tensor_score_train, # Ground truth labels for the training set (1 for matched pairs, 0 for unmatched pairs)\n","\n","    X1_val,            # Updated source embeddings for the validation set\n","    X2_val,            # Original source embeddings for the validation set\n","    X3_val,            # Updated target embeddings for the validation set\n","    X4_val,            # Original target embeddings for the validation set\n","    tensor_score_val,  # Ground truth labels for the validation set (1 for matched pairs, 0 for unmatched pairs)\n","\n","    epochs=100,        # Number of epochs (iterations over the entire training dataset)\n","    batch_size=32,     # Number of training samples processed in one forward/backward pass\n","    learning_rate=0.001, # Learning rate for the optimizer (controls step size during optimization)\n","    weight_decay=1e-5  # Weight decay (L2 regularization) to prevent overfitting\n",")"]},{"cell_type":"markdown","metadata":{"id":"uAmLuMtGW9c2"},"source":["# **Mappings Selector**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lnFtpUAfJQHl"},"outputs":[],"source":["# Build an indexed dictionary for the source ontology classes\n","# src_class is the file path to the JSON file containing the source ontology classes\n","indexed_dict_src = build_indexed_dict(src_class)\n","\n","# Build an indexed dictionary for the target ontology classes\n","# tgt_class is the file path to the JSON file containing the target ontology classes\n","indexed_dict_tgt = build_indexed_dict(tgt_class)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"beipwavuJQHl"},"outputs":[],"source":["# Read the candidate pairs from a Candidates CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(candidates_Prediction, index_col=0)\n","\n","# Extract the 'SrcEntity' column (source entity indices) and convert it to a NumPy array of integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)\n","\n","# Extract the 'TgtEntity' column (target entity indices) and convert it to a NumPy array of integers\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)\n","\n","# Convert the source entity indices to a PyTorch LongTensor\n","src_entity_tensor_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)\n","\n","# Convert the target entity indices to a PyTorch LongTensor\n","tgt_entity_tenso_or = torch.from_numpy(tensor_term2).type(torch.LongTensor)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ECLhmxyKJQHl"},"outputs":[],"source":["# Select rows from the updated source embeddings based on the indices in src_entity_tensor_o\n","X1_tt = select_rows_by_index(embeddings_src, src_entity_tensor_o)\n","\n","# Select rows from the original source embeddings based on the indices in src_entity_tensor_o\n","X2_tt = select_rows_by_index(x_src, src_entity_tensor_o)\n","\n","# Select rows from the updated target embeddings based on the indices in tgt_entity_tenso_or\n","X3_tt = select_rows_by_index(embeddings_tgt, tgt_entity_tenso_or)\n","\n","# Select rows from the original target embeddings based on the indices in tgt_entity_tenso_or\n","X4_tt = select_rows_by_index(x_tgt, tgt_entity_tenso_or)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b6cb7b1c-13d7-455b-c064-7c70bc313a45","id":"UFP6OQR-7D4N","executionInfo":{"status":"ok","timestamp":1732177524877,"user_tz":-60,"elapsed":37366,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting time: 15.21 seconds\n","Predictions saved to /content/gdrive/My Drive/BioGITOM-VLDB/Experiments/Negative_Number_Ajdustment//ncit2doid/Results/ncit2doid_all_predictions.tsv\n"]}],"source":["# Generate predictions for candidate mappings using the trained GatedCombination model\n","Prediction_with_candidates(\n","    model=trained_model,             # The trained GatedCombination model used to evaluate similarity\n","    X1_tt=X1_tt,                     # Updated source embeddings (after applying the GIT model)\n","    X2_tt=X2_tt,                     # Original source embeddings (before applying the GIT model)\n","    X3_tt=X3_tt,                     # Updated target embeddings (after applying the GIT model)\n","    X4_tt=X4_tt,                     # Original target embeddings (before applying the GIT model)\n","    src_entity_tensor_o=src_entity_tensor_o,  # Tensor of source entity indices used for evaluation\n","    tgt_entity_tensor_o=tgt_entity_tenso_or,  # Tensor of target entity indices used for evaluation\n","    indexed_dict_src=indexed_dict_src,        # Dictionary mapping source entity indices to their URIs\n","    indexed_dict_tgt=indexed_dict_tgt,        # Dictionary mapping target entity indices to their URIs\n","    all_predictions_path=all_predictions_path # Path to save all predictions with similarity scores in TSV format\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mEc12J-B7D4N","colab":{"base_uri":"https://localhost:8080/"},"outputId":"504f2f00-0e13-4565-c2db-fdccd8254152","executionInfo":{"status":"ok","timestamp":1732177613734,"user_tz":-60,"elapsed":15053,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Positive predictions: 3228\n"]}],"source":["# Filter the highest scoring predictions from the predictions file and save the results to a new file\n","matching_results_df = filter_highest_predictions(\n","    all_predictions_path,  # Path to the file containing all predictions with scores for all candidate pairs\n","    prediction_path        # Path where the filtered predictions with highest scores will be saved\n",")"]},{"cell_type":"markdown","metadata":{"id":"BIx74lNV7D4O"},"source":["# **Evaluation**"]},{"cell_type":"markdown","source":["# Global metrics calculation"],"metadata":{"id":"Pp3IpBBfWn9m"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bkOewzXr7D4O","outputId":"e247a257-fdcb-496e-98dd-54f0fb74402d","executionInfo":{"status":"ok","timestamp":1732177614101,"user_tz":-60,"elapsed":369,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Correct Predictions: 2859\n","{'P': 0.886, 'R': 0.872, 'F1': 0.879}\n"]}],"source":["# Retrieve the indices of the ignored classes (from source and target ontologies)\n","ignored_class_index = get_ignored_class_index(src_onto)  # Get ignored class indices from source ontology\n","ignored_class_index.update(get_ignored_class_index(tgt_onto))  # Update with ignored class indices from target ontology\n","\n","# Read the predicted mappings from the prediction results file\n","preds = EntityMapping.read_table_mappings(prediction_path)\n","\n","# Read the reference mappings from the ground truth test file\n","refs = ReferenceMapping.read_table_mappings(f\"{dataset_dir}/refs_equiv/test.tsv\")\n","\n","# Filter the predicted mappings to remove any mappings that involve ignored classes\n","preds = remove_ignored_mappings(preds, ignored_class_index)\n","\n","# Compute the precision, recall, and F1-score by comparing predictions with the reference mappings\n","results = AlignmentEvaluator.f1(preds, refs)\n","\n","preds2 = [p.to_tuple() for p in preds]\n","refs2 = [r.to_tuple() for r in refs]\n","\n","correct= len(set(preds2).intersection(set(refs2)))\n","\n","print(f\"Number of Correct Predictions: {correct}\")\n","\n","# Print the computed precision, recall, and F1-score metrics\n","print(results)"]},{"cell_type":"markdown","source":["# Ranked-based metrics calculation"],"metadata":{"id":"aECB6igZW04C"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-AK-jADkSbTa"},"outputs":[],"source":["# Read the candidate pairs from a Candidates CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(candidates_Rank, index_col=0)\n","\n","# Extract the 'SrcEntity' column (source entity indices) and convert it to a NumPy array of integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)\n","\n","# Extract the 'TgtEntity' column (target entity indices) and convert it to a NumPy array of integers\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)\n","\n","# Convert the source entity indices to a PyTorch LongTensor\n","src_entity_tensor_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)\n","\n","# Convert the target entity indices to a PyTorch LongTensor\n","tgt_entity_tenso_or = torch.from_numpy(tensor_term2).type(torch.LongTensor)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oyOzcLv-SbTb"},"outputs":[],"source":["# Select rows from the updated source embeddings based on the indices in src_entity_tensor_o\n","X1_tt = select_rows_by_index(embeddings_src, src_entity_tensor_o)\n","\n","# Select rows from the original source embeddings based on the indices in src_entity_tensor_o\n","X2_tt = select_rows_by_index(x_src, src_entity_tensor_o)\n","\n","# Select rows from the updated target embeddings based on the indices in tgt_entity_tenso_or\n","X3_tt = select_rows_by_index(embeddings_tgt, tgt_entity_tenso_or)\n","\n","# Select rows from the original target embeddings based on the indices in tgt_entity_tenso_or\n","X4_tt = select_rows_by_index(x_tgt, tgt_entity_tenso_or)"]},{"cell_type":"code","source":["# Perform ranking-based predictions using the trained GatedCombination model\n","# Generate predictions for candidate mappings using the trained GatedCombination model\n","Prediction_with_candidates(\n","    model=trained_model,             # The trained GatedCombination model used to evaluate similarity\n","    X1_tt=X1_tt,                     # Updated source embeddings (after applying the GIT model)\n","    X2_tt=X2_tt,                     # Original source embeddings (before applying the GIT model)\n","    X3_tt=X3_tt,                     # Updated target embeddings (after applying the GIT model)\n","    X4_tt=X4_tt,                     # Original target embeddings (before applying the GIT model)\n","    src_entity_tensor_o=src_entity_tensor_o,  # Tensor of source entity indices used for evaluation\n","    tgt_entity_tensor_o=tgt_entity_tenso_or,  # Tensor of target entity indices used for evaluation\n","    indexed_dict_src=indexed_dict_src,        # Dictionary mapping source entity indices to their URIs\n","    indexed_dict_tgt=indexed_dict_tgt,        # Dictionary mapping target entity indices to their URIs\n","    all_predictions_path=all_predictions_path_ranked, # Path where the ranked predictions will be saved in TSV format\n",")"],"metadata":{"id":"-O2f7X6cSb-m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732176052639,"user_tz":-60,"elapsed":29764,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"989a0d59-9883-4483-e9af-1d580c2d4510"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting time: 14.04 seconds\n","Predictions saved to /content/gdrive/My Drive/BioGITOM-VLDB/Experiments/Negative_Number_Ajdustment//ncit2doid/Results/ncit2doid_all_predictions_ranked.tsv\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_402seVv7D4O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732176069738,"user_tz":-60,"elapsed":17108,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"79347806-c0cc-4b88-f0e9-a1570c7530d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["MRR and Hits@k Results:\n","{'MRR': 0.9041838122020249, 'Hits@k': {1: 0.8536585365853658, 5: 0.9685975609756098, 10: 0.9853658536585366}}\n"]}],"source":["# Compute MRR and Hits@k metrics\n","# This function evaluates the predicted rankings against the reference mappings\n","results = compute_mrr_and_hits(\n","    reference_file=test_cands,             # Reference file with true ranks\n","    predicted_file=all_predictions_path_ranked,             # File containing predicted rankings\n","    output_file=formatted_predictions_path,    # File path to save formatted predictions\n","    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",")\n","\n","# Display the computed metrics\n","print(\"MRR and Hits@k Results:\")\n","print(results)  # Output the Mean Reciprocal Rank (MRR) and Hits@k metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wStfa4eZ7D4O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732176073365,"user_tz":-60,"elapsed":3639,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"de4cbc85-dd3f-4e0d-ff27-53ae4f63b8b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ranking Evaluation Results at K=1, 5, and 10:\n","{'MRR': 0.9041838122020249, 'Hits@1': 0.8536585365853658, 'Hits@5': 0.9685975609756098, 'Hits@10': 0.9853658536585366}\n"]}],"source":["# Call the ranking evaluation function, passing the path to the formatted predictions file.\n","# Ks specifies the evaluation levels, checking if the correct target is within the top K candidates.\n","results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n","print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n","print(results)"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}