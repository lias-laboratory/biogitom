{"cells":[{"cell_type":"markdown","metadata":{"id":"MkAX88H3RNRW"},"source":["# **Package Installation**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SlL2v0xgmFJ-","outputId":"24721a7a-da2f-488c-b840-e9884d89d762","executionInfo":{"status":"ok","timestamp":1732180704675,"user_tz":-60,"elapsed":202133,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==2.0.0\n","  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.16.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n","  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n","  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n","  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n","  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n","  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n","  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.0.0 (from torch==2.0.0)\n","  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (75.1.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.45.0)\n","Collecting cmake (from triton==2.0.0->torch==2.0.0)\n","  Downloading cmake-3.31.0.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n","Collecting lit (from triton==2.0.0->torch==2.0.0)\n","  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n","Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m542.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m625.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cmake-3.31.0.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.8/27.8 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, cmake, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.1+cpu\n","    Uninstalling torch-2.5.1+cpu:\n","      Successfully uninstalled torch-2.5.1+cpu\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.5.1+cpu requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\n","torchvision 0.20.1+cpu requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed cmake-3.31.0.1 lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 triton-2.0.0\n","Collecting torch-geometric==2.4.0\n","  Downloading torch_geometric-2.4.0-py3-none-any.whl.metadata (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (4.66.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (3.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (2.32.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (3.2.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.5.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric==2.4.0) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (2024.8.30)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.4.0) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.4.0) (3.5.0)\n","Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-geometric\n","Successfully installed torch-geometric-2.4.0\n","Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_scatter-2.1.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (494 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_sparse-0.6.18%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-cluster\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_cluster-1.6.3%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (751 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.3/751.3 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-spline-conv\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (208 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n","Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n","Installing collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster\n","Successfully installed torch-cluster-1.6.3+pt20cpu torch-scatter-2.1.2+pt20cpu torch-sparse-0.6.18+pt20cpu torch-spline-conv-1.2.2+pt20cpu\n","Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.5.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.6/66.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.9/208.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.2/319.2 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting deeponto\n","  Downloading deeponto-0.9.2-py3-none-any.whl.metadata (15 kB)\n","Collecting JPype1 (from deeponto)\n","  Downloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting yacs (from deeponto)\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deeponto) (2.0.0)\n","Collecting anytree (from deeponto)\n","  Downloading anytree-2.12.1-py3-none-any.whl.metadata (8.1 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from deeponto) (8.1.7)\n","Collecting dill (from deeponto)\n","  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from deeponto) (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deeponto) (1.26.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deeponto) (1.5.2)\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (from deeponto) (4.46.2)\n","Collecting datasets (from deeponto)\n","  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.7.5)\n","Collecting pprintpp (from deeponto)\n","  Downloading pprintpp-0.4.0-py2.py3-none-any.whl.metadata (7.9 kB)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.4.2)\n","Collecting lxml (from deeponto)\n","  Downloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n","Collecting textdistance (from deeponto)\n","  Downloading textdistance-4.6.3-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from deeponto) (7.7.1)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from deeponto) (5.5.6)\n","Collecting enlighten (from deeponto)\n","  Downloading enlighten-1.12.4-py2.py3-none-any.whl.metadata (18 kB)\n","Collecting rdflib (from deeponto)\n","  Downloading rdflib-7.1.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.9.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anytree->deeponto) (1.16.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (18.0.0)\n","Collecting dill (from deeponto)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (4.66.6)\n","Collecting xxhash (from datasets->deeponto)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets->deeponto)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->deeponto)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (3.11.6)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (0.26.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (6.0.2)\n","Collecting blessed>=1.17.7 (from enlighten->deeponto)\n","  Downloading blessed-1.20.0-py2.py3-none-any.whl.metadata (13 kB)\n","Collecting prefixed>=0.3.2 (from enlighten->deeponto)\n","  Downloading prefixed-0.9.0-py2.py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (0.2.0)\n","Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (7.34.0)\n","Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (5.7.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (6.1.12)\n","Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (6.3.3)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->deeponto) (3.6.10)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->deeponto) (3.0.13)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->deeponto) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->deeponto) (2024.11.6)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2024.2)\n","Collecting isodate<1.0.0,>=0.7.2 (from rdflib->deeponto)\n","  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib->deeponto) (3.2.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deeponto) (1.13.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deeponto) (3.5.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (0.13.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.9.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.1.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (75.1.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.4.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (1.13.1)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (2.0.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->deeponto) (0.45.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deeponto) (3.31.0.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deeponto) (18.1.8)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (0.20.3)\n","Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (1.1.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->transformers[torch]->deeponto) (5.9.5)\n","Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.7->enlighten->deeponto) (0.2.13)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (0.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.17.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (5.0.1)\n","Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->deeponto)\n","  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (5.1.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (3.0.48)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (2.18.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (4.9.0)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.2.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (2024.8.30)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->deeponto) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->deeponto) (0.1.5)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (0.20.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (7.0.5)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.5.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy->deeponto) (3.0.2)\n","Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->deeponto) (5.7.2)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->deeponto) (24.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deeponto) (1.3.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->deeponto) (0.8.4)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel->deeponto) (4.3.6)\n","Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.2.1)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (23.1.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (5.10.4)\n","Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (7.16.4)\n","Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.6.0)\n","Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.3)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.18.1)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.21.0)\n","Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.1.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel->deeponto) (0.7.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (3.0.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->deeponto) (1.14.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (0.1.2)\n","Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.2.4)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.12.3)\n","Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.2.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.7.1)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.3.0)\n","Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.0.2)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.10.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.5.1)\n","Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.4.0)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.20.0)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.23.0)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (21.2.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.5.1)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.21.0)\n","Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.24.0)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.17.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.6)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.22)\n","Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.7.1)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.2.2)\n","Downloading deeponto-0.9.2-py3-none-any.whl (89.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading anytree-2.12.1-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading enlighten-1.12.4-py2.py3-none-any.whl (41 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.8/493.8 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n","Downloading rdflib-7.1.1-py3-none-any.whl (562 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m562.4/562.4 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading textdistance-4.6.3-py3-none-any.whl (31 kB)\n","Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n","Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading prefixed-0.9.0-py2.py3-none-any.whl (13 kB)\n","Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: prefixed, pprintpp, yacs, xxhash, textdistance, lxml, JPype1, jedi, isodate, fsspec, dill, blessed, anytree, rdflib, multiprocess, enlighten, datasets, deeponto\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","Successfully installed JPype1-1.5.1 anytree-2.12.1 blessed-1.20.0 datasets-3.1.0 deeponto-0.9.2 dill-0.3.8 enlighten-1.12.4 fsspec-2024.9.0 isodate-0.7.2 jedi-0.19.2 lxml-5.3.0 multiprocess-0.70.16 pprintpp-0.4.0 prefixed-0.9.0 rdflib-7.1.1 textdistance-4.6.3 xxhash-3.5.0 yacs-0.1.8\n","/bin/bash: line 1: username: No such file or directory\n"]}],"source":["# We assume that PyTorch is already installed in the environment.\n","# If not, this command installs it.\n","!pip install torch==2.0.0\n","\n","# Install PyTorch Geometric, a library for creating graph neural networks using PyTorch.\n","!pip install torch-geometric==2.4.0\n","\n","# Import PyTorch to access its functionalities.\n","import torch\n","\n","# Install additional PyTorch Geometric dependencies for graph processing (scatter, sparse, cluster, spline-conv).\n","# These packages enable operations like sparse tensors and convolutions on graphs.\n","!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","\n","# Reinstall PyTorch Geometric to ensure all dependencies are correctly loaded.\n","!pip install torch-geometric\n","\n","# Retrieve the installed version of PyTorch to ensure compatibility with other packages.\n","torchversion = torch.__version__\n","\n","# Install the latest version of PyTorch Geometric directly from the GitHub repository.\n","# This allows access to the most recent updates and features for graph-based neural networks.\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","\n","# Install DeepOnto, a package specifically designed for ontology matching, particularly useful in biomedical applications.\n","!pip install deeponto\n","\n","# Install a custom version of DeepOnto from a GitHub repository.\n","# The '<username>' part should be replaced with the actual GitHub username of the repository maintainer.\n","!pip install git+https://github.com/<username>/deeponto.git\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HPAlAgjLMVhw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9167b708-9ad8-4bf2-d6fc-906662907272","executionInfo":{"status":"ok","timestamp":1732180842933,"user_tz":-60,"elapsed":138261,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Please enter the maximum memory located to JVM [8g]: 8g\n","\n"]}],"source":["# Import pandas for data manipulation and analysis, such as loading, processing, and saving tabular data.\n","import pandas as pd\n","\n","# Import pickle for saving and loading serialized objects (e.g., trained models or preprocessed data).\n","import pickle\n","\n","# Import function to convert a directed graph to an undirected one, useful for certain graph algorithms.\n","from torch_geometric.utils import to_undirected\n","\n","# Import optimizer module from PyTorch for training models using gradient-based optimization techniques.\n","import torch.optim as optim\n","\n","# Import PyTorch's modules for defining neural network architectures and operations:\n","from torch.nn import (\n","    Linear,       # For linear transformations (dense layers).\n","    Sequential,   # For stacking layers sequentially.\n","    BatchNorm1d,  # For normalizing input within mini-batches.\n","    PReLU,        # Parametric ReLU activation function.\n","    Dropout       # For regularization by randomly dropping connections during training.\n",")\n","\n","# Import functional API from PyTorch for operations like activations and loss functions.\n","import torch.nn.functional as F\n","\n","# Import Matplotlib for visualizations, such as plotting training loss curves.\n","import matplotlib.pyplot as plt\n","\n","# Import PyTorch Geometric's graph convolutional layers:\n","from torch_geometric.nn import GCNConv, GINConv\n","\n","# Import pooling operations for aggregating node embeddings to graph-level representations:\n","from torch_geometric.nn import global_mean_pool, global_add_pool\n","\n","# Import NumPy for numerical operations, such as working with arrays and matrices.\n","import numpy as np\n","\n","# Import time module for measuring execution time of code blocks.\n","import time\n","\n","# Import typing module for specifying types in function arguments and return values.\n","from typing import Optional, Tuple, Union, Callable\n","\n","# Import PyTorch's DataLoader and TensorDataset for handling data batching and loading during training.\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","# Import PyTorch's Parameter class for defining learnable parameters in custom models.\n","from torch.nn import Parameter\n","\n","# Import math module for performing mathematical computations.\n","import math\n","\n","# Import Tensor type from PyTorch for defining and manipulating tensors.\n","from torch import Tensor\n","\n","# Import PyTorch's nn module for defining and building neural network architectures.\n","import torch.nn as nn\n","\n","# Import initialization utilities from PyTorch Geometric for resetting weights and biases in layers.\n","from torch_geometric.nn.inits import reset\n","\n","# Import the base class for defining message-passing layers in graph neural networks (GNNs).\n","from torch_geometric.nn.conv import MessagePassing\n","\n","# Import linear transformation utilities for creating dense representations in graph models.\n","from torch_geometric.nn.dense.linear import Linear\n","\n","# Import typing utilities for defining adjacency matrices and tensor types specific to PyTorch Geometric.\n","from torch_geometric.typing import Adj, OptTensor, PairTensor, SparseTensor\n","\n","# Import softmax function for normalizing attention scores in GNNs.\n","from torch_geometric.utils import softmax\n","\n","# Import initialization utilities for weight initialization (e.g., Glorot initialization).\n","from torch_geometric.nn.inits import glorot, zeros\n","\n","# Import F1 score metric from scikit-learn for evaluating model performance in binary/multi-class tasks.\n","from sklearn.metrics import f1_score\n","\n","# Import JSON module for reading and writing JSON files, useful for storing configuration or ontology data.\n","import json\n","\n","# Import Ontology class from DeepOnto for representing and manipulating ontologies in the pipeline.\n","from deeponto.onto import Ontology\n","\n","# Import tools from DeepOnto for handling Ontology Alignment Evaluation Initiative (OAEI) tasks.\n","from deeponto.align.oaei import *\n","\n","# Import evaluation tools from DeepOnto for assessing alignment results using metrics like precision, recall, and F1.\n","from deeponto.align.evaluation import AlignmentEvaluator\n","\n","# Import mapping utilities from DeepOnto for working with reference mappings and entity pairs.\n","from deeponto.align.mapping import ReferenceMapping, EntityMapping\n","\n","# Import utility function for reading tables (e.g., TSV, CSV) from DeepOnto.\n","from deeponto.utils import read_table\n","\n","# Importing the train_test_split function from sklearn's model_selection module.\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"-abbBHOoRdWl"},"source":["# **Paths Definition**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AVgl_Bb42naS","outputId":"3163cc83-9180-4a1a-e1b9-1064f278184c","executionInfo":{"status":"ok","timestamp":1732180863800,"user_tz":-60,"elapsed":20872,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# Importing the 'drive' module from Google Colab to interact with Google Drive\n","from google.colab import drive\n","\n","# Mount the user's Google Drive to the Colab environment\n","# After running this, a link will appear to authorize access, and Google Drive will be mounted at '/content/gdrive'\n","drive.mount('/content/gdrive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"36ttssQ3W7cx"},"outputs":[],"source":["# Define the source ontology name\n","src_ent = \"ncit\"\n","\n","# Define the target ontology name\n","tgt_ent = \"doid\"\n","\n","# Define the task name for this ontology matching process\n","task = \"ncit2doid\"\n","\n","# Define the weight for the training data\n","# This weight is likely used to balance the training process, giving more emphasis to certain examples.\n","# For instance, a weight of 10.0 could be applied to penalize errors in certain types of predictions more heavily.\n","weight_train = 10.0\n","\n","# Define the similarity threshold for validating matches\n","thres = 0.20"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SJpvkdwVSQye"},"outputs":[],"source":["dir = f\"/content/gdrive/My Drive/BioGITOM-VLDB/Experiments/{task}\"\n","\n","dataset=\"/content/gdrive/My Drive/BioGITOM-VLDB/\"\n","\n","# Define the directory for the dataset containing source and target ontologies\n","dataset_dir = f\"{dataset}/Datasets/{task}\"\n","\n","# Define the data directory for storing embeddings, adjacency matrices, and related files\n","data_dir = f\"{dir}/{task}/Data\"\n","\n","# Define the directory for storing the results\n","results_dir = f\"{dir}/{task}/Negative_Number_Ajdustment/Results\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eFDNSFef23er"},"outputs":[],"source":["# Load the Source ontology using the Ontology class from DeepOnto\n","# This initializes the source ontology by loading its .owl file.\n","src_onto = Ontology(f\"{dataset_dir}/{src_ent}.owl\")\n","\n","# Load the Target ontology using the Ontology class from DeepOnto\n","# This initializes the target ontology by loading its .owl file.\n","tgt_onto = Ontology(f\"{dataset_dir}/{tgt_ent}.owl\")\n","\n","# Define the file path for the Source embeddings CSV file\n","# Embeddings for the source ontology entities are stored in this file.\n","src_Emb = f\"{data_dir}/{src_ent}_emb.csv\"\n","\n","# Define the file path for the Target embeddings CSV file\n","# Embeddings for the target ontology entities are stored in this file.\n","tgt_Emb = f\"{data_dir}/{tgt_ent}_emb.csv\"\n","\n","# Define the file path for the Source adjacency matrix\n","# This file represents the relationships (edges) between entities in the source ontology.\n","src_Adjacence = f\"{data_dir}/{src_ent}_adjacence.csv\"\n","\n","# Define the file path for the Target adjacency matrix\n","# This file represents the relationships (edges) between entities in the target ontology.\n","tgt_Adjacence = f\"{data_dir}/{tgt_ent}_adjacence.csv\"\n","\n","# Define the file path for the JSON file containing the Source ontology class labels\n","# This file maps the source ontology entities to their labels or names.\n","src_class = f\"{data_dir}/{src_ent}_classes.json\"\n","\n","# Define the file path for the JSON file containing the Target ontology class labels\n","# This file maps the target ontology entities to their labels or names.\n","tgt_class = f\"{data_dir}/{tgt_ent}_classes.json\"\n","\n","# Define the file path for the train data\n","train_file = f\"{data_dir}/{task}_train_50.csv\"\n","\n","# Define the file path for the test data\n","# The test file contains reference mappings (ground truth) between the source and target ontologies.\n","test_file = f\"{dataset_dir}/refs_equiv/test.tsv\"\n","\n","# Define the file path for the candidate mappings used during testing\n","# This file includes the candidate pairs (source and target entities) for ranking and evaluation.\n","test_cands = f\"{dataset_dir}/refs_equiv/test.cands.tsv\"\n","\n","# Define the file path for the candidate mappings between Source to Target entities\n","# This file contains cleaned, combined, and encoded candidates used for predictions.\n","candidates_Prediction = f\"{data_dir}/{task}_candidates_prediction.csv\"\n","\n","# Define the file path for the candidate mappings between Source to Target entities for ranking-based metrics\n","# This file is used to compute ranking-based metrics like MRR and Hits@k.\n","candidates_Rank = f\"{data_dir}/{task}_candidates.csv\"\n","\n","# Define the path where the prediction results will be saved in TSV format\n","# This file will store the final predictions (mappings) between source and target entities.\n","prediction_path = f\"{results_dir}/{task}_matching_results.tsv\"\n","\n","# Define the path where all prediction results will be saved in TSV format\n","# This file will store detailed prediction results, including all candidate scores.\n","all_predictions_path = f\"{results_dir}/{task}_all_predictions.tsv\"\n","\n","# Define the path where all ranking prediction results will be saved in TSV format\n","# This file will store predictions sorted by rank based on their scores.\n","all_predictions_path_ranked = f\"{results_dir}/{task}_all_predictions_ranked.tsv\"\n","\n","# Define the path where formatted ranking predictions will be saved in TSV format\n","# This file will contain predictions formatted for evaluation using ranking-based metrics.\n","formatted_predictions_path = f\"{results_dir}/{task}_formatted_predictions.tsv\""]},{"cell_type":"markdown","metadata":{"id":"zqEXsgPGMVhw"},"source":["# **GIT Architecture**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A_d6XCsUMVhx"},"outputs":[],"source":["# RGIT class definition which inherits from PyTorch Geometric's MessagePassing class\n","class RGIT(MessagePassing):\n","\n","    _alpha: OptTensor  # Define _alpha as an optional tensor for storing attention weights\n","\n","    def __init__(\n","        self,\n","        nn: Callable,  # Neural network to be used in the final layer of the GNN\n","        in_channels: Union[int, Tuple[int, int]],  # Input dimension, can be a single or pair of integers\n","        out_channels: int,  # Output dimension of the GNN\n","        eps: float = 0.,  # GIN parameter: epsilon for GIN aggregation\n","        train_eps: bool = False,  # GIN parameter: whether epsilon should be learnable\n","        heads: int = 1,  # Transformer parameter: number of attention heads\n","        dropout: float = 0.,  # Dropout rate for attention weights\n","        edge_dim: Optional[int] = None,  # Dimension for edge attributes (optional)\n","        bias: bool = True,  # Whether to use bias in linear layers\n","        root_weight: bool = True,  # GIN parameter: whether to apply root weight in aggregation\n","        **kwargs,  # Additional arguments passed to the parent class\n","    ):\n","        # Set the aggregation type to 'add' and initialize the parent class with node_dim=0\n","        kwargs.setdefault('aggr', 'add')\n","        super().__init__(node_dim=0, **kwargs)\n","\n","        # Initialize input/output dimensions, neural network, and GIN/transformer parameters\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.nn = nn  # Neural network used by the GNN\n","        self.initial_eps = eps  # Initial value of epsilon for GIN\n","\n","        # Set epsilon to be learnable or fixed\n","        if train_eps:\n","            self.eps = torch.nn.Parameter(torch.empty(1))  # Learnable epsilon\n","        else:\n","            self.register_buffer('eps', torch.empty(1))  # Non-learnable epsilon (fixed)\n","\n","        # Initialize transformer-related parameters\n","        self.heads = heads\n","        self.dropout = dropout\n","        self.edge_dim = edge_dim\n","        self._alpha = None  # Placeholder for attention weights\n","\n","        # Handle case where in_channels is a single integer or a tuple\n","        if isinstance(in_channels, int):\n","            in_channels = (in_channels, in_channels)\n","\n","        # Define the linear layers for key, query, and value for the transformer mechanism\n","        self.lin_key = Linear(in_channels[0], heads * out_channels)\n","        self.lin_query = Linear(in_channels[1], heads * out_channels)\n","        self.lin_value = Linear(in_channels[0], heads * out_channels)\n","\n","        # Define linear transformation for edge embeddings if provided\n","        if edge_dim is not None:\n","            self.lin_edge = Linear(edge_dim, heads * out_channels, bias=False)\n","        else:\n","            self.lin_edge = self.register_parameter('lin_edge', None)\n","\n","        # Reset all parameters to their initial values\n","        self.reset_parameters()\n","\n","    # Function to reset model parameters\n","    def reset_parameters(self):\n","        super().reset_parameters()  # Call parent class reset method\n","        self.lin_key.reset_parameters()  # Reset key linear layer\n","        self.lin_query.reset_parameters()  # Reset query linear layer\n","        self.lin_value.reset_parameters()  # Reset value linear layer\n","        if self.edge_dim:\n","            self.lin_edge.reset_parameters()  # Reset edge linear layer if used\n","        reset(self.nn)  # Reset the neural network provided\n","        self.eps.data.fill_(self.initial_eps)  # Initialize epsilon with the starting value\n","\n","    # Forward function defining how the input data flows through the model\n","    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj,\n","                edge_attr: OptTensor = None, return_attention_weights=None):\n","        # Unpack number of heads and output channels\n","        H, C = self.heads, self.out_channels\n","\n","        # If x is a tensor, treat it as a pair of tensors (source and target embeddings)\n","        if isinstance(x, Tensor):\n","            x: PairTensor = (x, x)\n","\n","        # Extract source node embeddings\n","        x_t = x[0]\n","\n","        # Apply linear transformations and reshape query, key, and value for multi-head attention\n","        query = self.lin_query(x[1]).view(-1, H, C)\n","        key = self.lin_key(x[0]).view(-1, H, C)\n","        value = self.lin_value(x[0]).view(-1, H, C)\n","\n","        # Propagate messages through the graph using the propagate function\n","        out = self.propagate(edge_index, query=query, key=key, value=value,\n","                             edge_attr=edge_attr, size=None)\n","\n","        # Retrieve attention weights and reset them\n","        alpha = self._alpha\n","        self._alpha = None  # Reset _alpha after use\n","        out = out.mean(dim=1)  # Take the mean over all attention heads\n","\n","        # Apply GIN aggregation by adding epsilon-scaled original node embeddings\n","        out = out + (1 + self.eps) * x_t\n","        return self.nn(out)  # Pass through the neural network\n","\n","    # Message passing function which calculates attention and combines messages\n","    def message(self, query_i: Tensor, key_j: Tensor, value_j: Tensor,\n","                edge_attr: OptTensor, index: Tensor, ptr: OptTensor,\n","                size_i: Optional[int]) -> Tensor:\n","        # If edge attributes are used, apply linear transformation and add them to the key\n","        if self.lin_edge is not None:\n","            assert edge_attr is not None\n","            edge_attr = self.lin_edge(edge_attr).view(-1, self.heads, self.out_channels)\n","            key_j = key_j + edge_attr\n","\n","        # Calculate attention (alpha) using the dot product between query and key\n","        alpha = (query_i * key_j).sum(dim=-1) / math.sqrt(self.out_channels)\n","        alpha = softmax(alpha, index, ptr, size_i)  # Apply softmax to normalize attention\n","        self._alpha = alpha  # Store attention weights\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)  # Apply dropout\n","\n","        # Calculate the output message by applying attention to the value\n","        out = value_j\n","        if edge_attr is not None:\n","            out = out + edge_attr  # Add edge embeddings to the output if present\n","        out = out * alpha.view(-1, self.heads, 1)  # Scale by attention weights\n","        return out\n","\n","    # String representation function for debugging or printing\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}({self.in_channels}, '\n","                f'{self.out_channels}, heads={self.heads})')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qwFv6RgHmGCf"},"outputs":[],"source":["# Define the RGIT_mod class, a multi-layer GNN that uses both RGIT and linear layers\n","class RGIT_mod(torch.nn.Module):\n","    \"\"\"Multi-layer RGIT with optional linear layers\"\"\"\n","\n","    # Initialize the model with hidden dimension, number of RGIT layers, and number of linear layers\n","    def __init__(self, dim_h, num_layers, num_linear_layers=1):\n","        super(RGIT_mod, self).__init__()\n","        self.num_layers = num_layers  # Number of RGIT layers\n","        self.num_linear_layers = num_linear_layers  # Number of linear layers\n","        self.linears = torch.nn.ModuleList()  # List to store linear layers\n","        self.rgit_layers = torch.nn.ModuleList()  # List to store RGIT layers\n","\n","        # Create a list of Linear and PReLU layers (for encoding entity names)\n","        for _ in range(num_linear_layers):\n","            self.linears.append(Linear(dim_h, dim_h))  # Linear transformation layer\n","            self.linears.append(PReLU(num_parameters=dim_h))  # Parametric ReLU activation function\n","\n","        # Create a list of RGIT layers\n","        for _ in range(num_layers):\n","            self.rgit_layers.append(RGIT(  # Each RGIT layer contains a small MLP with Linear and PReLU\n","                Sequential(Linear(dim_h, dim_h), PReLU(num_parameters=dim_h),\n","                           Linear(dim_h, dim_h), PReLU(num_parameters=dim_h)), dim_h, dim_h))\n","\n","    # Forward pass through the model\n","    def forward(self, x, edge_index):\n","        # Apply the linear layers first to the input\n","        for layer in self.linears:\n","            x = layer(x)\n","\n","        # Then apply the RGIT layers for message passing\n","        for layer in self.rgit_layers:\n","            x = layer(x, edge_index)\n","\n","        return x  # Return the final node embeddings after all layers\n"]},{"cell_type":"markdown","metadata":{"id":"zxCn5ztKVztw"},"source":["# **Gated Network Architecture**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7MKQUv7o7zay"},"outputs":[],"source":["# Define the GatedCombination class for combining two pairs of embeddings using a gating mechanism\n","class GatedCombination(nn.Module):\n","    def __init__(self, input_dim):\n","        \"\"\"\n","        Initialize the GatedCombination model.\n","\n","        Args:\n","            input_dim (int): The dimensionality of the input embeddings (x1, x2, x3, x4).\n","        \"\"\"\n","        super(GatedCombination, self).__init__()\n","\n","        # Define a linear layer (gate) for combining embeddings x1 and x2 (first pair)\n","        self.gate_A_fc = nn.Linear(input_dim, input_dim)\n","\n","        # Define a linear layer (gate) for combining embeddings x3 and x4 (second pair)\n","        self.gate_B_fc = nn.Linear(input_dim, input_dim)\n","\n","        # A final fully connected layer that outputs a single neuron (binary classification)\n","        self.fc = nn.Linear(1, 1)\n","\n","    def forward(self, x1, x2, x3, x4):\n","        \"\"\"\n","        Forward pass through the gating mechanism and cosine similarity.\n","\n","        Args:\n","            x1 (torch.Tensor): First set of embeddings (source embeddings after update).\n","            x2 (torch.Tensor): Second set of embeddings (original source embeddings).\n","            x3 (torch.Tensor): Third set of embeddings (target embeddings after update).\n","            x4 (torch.Tensor): Fourth set of embeddings (original target embeddings).\n","\n","        Returns:\n","            torch.Tensor: Output of the model (probability score for binary classification).\n","        \"\"\"\n","        # Compute gate values for the first pair (x1 and x2) using a sigmoid activation\n","        gate_values1 = torch.sigmoid(self.gate_A_fc(x1))\n","\n","        # Combine x1 and x2 using the gate values\n","        # The result is a weighted combination of x1 and x2\n","        a = x1 * gate_values1 + x2 * (1 - gate_values1)\n","\n","        # Compute gate values for the second pair (x3 and x4) using a sigmoid activation\n","        gate_values2 = torch.sigmoid(self.gate_B_fc(x3))\n","\n","        # Combine x3 and x4 using the gate values\n","        # The result is a weighted combination of x3 and x4\n","        b = x3 * gate_values2 + x4 * (1 - gate_values2)\n","\n","        # Compute cosine similarity between the combined vectors a and b\n","        x = torch.cosine_similarity(a, b, dim=1)\n","\n","        # Pass the cosine similarity result through a fully connected layer (fc) for classification\n","        # Use a sigmoid activation to output a probability for binary classification\n","        out = torch.sigmoid(self.fc(x.unsqueeze(1)))  # unsqueeze(1) to match the input shape for the fc layer\n","        return out\n","\n"]},{"cell_type":"code","source":["class WeightedBCELoss(nn.Module):\n","    def __init__(self, pos_weight):\n","        \"\"\"\n","        Weighted Binary Cross-Entropy Loss.\n","\n","        Args:\n","            pos_weight (float): Weight for the positive class.\n","        \"\"\"\n","        super(WeightedBCELoss, self).__init__()\n","        self.pos_weight = pos_weight\n","\n","    def forward(self, outputs, targets):\n","        \"\"\"\n","        Args:\n","            outputs (torch.Tensor): Predicted probabilities from the model (after sigmoid).\n","            targets (torch.Tensor): Ground truth labels (0 or 1).\n","\n","        Returns:\n","            torch.Tensor: Computed weighted binary cross-entropy loss.\n","        \"\"\"\n","        # Compute weighted BCE loss\n","        loss = - (self.pos_weight * targets * torch.log(outputs + 1e-8) +\n","                  (1 - targets) * torch.log(1 - outputs + 1e-8))\n","        return loss.mean()"],"metadata":{"id":"PCzq6hHCD8vg"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4kO42TTCqQZ8"},"outputs":[],"source":["class FocalLoss(nn.Module):\n","    def __init__(self, alpha=0.25, gamma=2):\n","        \"\"\"\n","        Focal Loss for binary classification.\n","\n","        Args:\n","            alpha (float): Balancing factor for positive/negative classes.\n","            gamma (float): Focusing parameter for hard examples.\n","        \"\"\"\n","        super(FocalLoss, self).__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","\n","    def forward(self, outputs, targets):\n","        \"\"\"\n","        Args:\n","            outputs (torch.Tensor): Predicted probabilities from the model (after sigmoid).\n","            targets (torch.Tensor): Ground truth labels (0 or 1).\n","\n","        Returns:\n","            torch.Tensor: Computed focal loss.\n","        \"\"\"\n","        # Compute binary cross-entropy loss\n","        bce_loss = F.binary_cross_entropy(outputs, targets, reduction='none')\n","\n","        # Compute modulating factor (1 - p_t)^gamma\n","        pt = torch.where(targets == 1, outputs, 1 - outputs)  # pt = p if y==1 else 1-p\n","        modulating_factor = (1 - pt) ** self.gamma\n","\n","        # Apply alpha and modulating factor\n","        focal_loss = self.alpha * modulating_factor * bce_loss\n","        return focal_loss.mean()"]},{"cell_type":"markdown","metadata":{"id":"aLJ5j9FNMVhy"},"source":["# **Utility functions**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k0L86DgUQjMU"},"outputs":[],"source":["def adjacency_matrix_to_undirected_edge_index(adjacency_matrix):\n","    \"\"\"\n","    Converts an adjacency matrix into an undirected edge index for use in graph-based neural networks.\n","\n","    Args:\n","        adjacency_matrix: A 2D list or array representing the adjacency matrix of a graph.\n","\n","    Returns:\n","        edge_index_undirected: A PyTorch tensor representing the undirected edges.\n","    \"\"\"\n","    # Convert each element in the adjacency matrix to an integer (from boolean or float)\n","    adjacency_matrix = [[int(element) for element in sublist] for sublist in adjacency_matrix]\n","\n","    # Convert the adjacency matrix into a PyTorch LongTensor (used for indexing)\n","    edge_index = torch.tensor(adjacency_matrix, dtype=torch.long)\n","\n","    # Transpose the edge_index tensor so that rows represent edges in the form [source, target]\n","    edge_index = edge_index.t().contiguous()\n","\n","    # Convert the directed edge_index into an undirected edge_index, meaning both directions are added (i.e., (i, j) and (j, i))\n","    edge_index_undirected = to_undirected(edge_index)\n","\n","    return edge_index_undirected  # Return the undirected edge index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YvmOxkLcpf9w"},"outputs":[],"source":["def build_indexed_dict(file_path):\n","    \"\"\"\n","    Builds a dictionary with numeric indexes for each key from a JSON file.\n","\n","    Args:\n","        file_path (str): The path to the JSON file.\n","\n","    Returns:\n","        indexed_dict (dict): A new dictionary where each key from the JSON file is assigned a numeric index.\n","    \"\"\"\n","    # Load the JSON file into a Python dictionary\n","    with open(file_path, 'r') as file:\n","        data = json.load(file)\n","\n","    # Create a new dictionary with numeric indexes as keys and the original JSON keys as values\n","    indexed_dict = {index: key for index, key in enumerate(data.keys())}\n","\n","    return indexed_dict  # Return the newly created dictionary"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QgFINoPGl9Wg"},"outputs":[],"source":["def select_rows_by_index(embedding_vector, index_vector):\n","    \"\"\"\n","    Select rows from an embedding vector using an index vector.\n","\n","    Args:\n","        embedding_vector (torch.Tensor): 2D tensor representing the embedding vector with shape [num_rows, embedding_size].\n","        index_vector (torch.Tensor): 1D tensor representing the index vector.\n","\n","    Returns:\n","        torch.Tensor: New tensor with selected rows from the embedding vector.\n","    \"\"\"\n","    # Use torch.index_select to select the desired rows\n","    new_tensor = torch.index_select(embedding_vector, 0, index_vector)\n","\n","    return new_tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a12L7vEmmCJq"},"outputs":[],"source":["def contrastive_loss(source_embeddings, target_embeddings, labels, margin=1.0):\n","    \"\"\"\n","    Computes the contrastive loss, a type of loss function used to train models in tasks like matching or similarity learning.\n","\n","    Args:\n","        source_embeddings (torch.Tensor): Embeddings of the source graphs, shape [batch_size, embedding_size].\n","        target_embeddings (torch.Tensor): Embeddings of the target graphs, shape [batch_size, embedding_size].\n","        labels (torch.Tensor): Binary labels indicating if the pairs are matched (1) or not (0), shape [batch_size].\n","        margin (float): Margin value for the contrastive loss. Defaults to 1.0.\n","\n","    Returns:\n","        torch.Tensor: The contrastive loss value.\n","    \"\"\"\n","    # Calculate the pairwise Euclidean distance between source and target embeddings\n","    distances = F.pairwise_distance(source_embeddings, target_embeddings)\n","\n","    # Compute the contrastive loss:\n","    # - For matched pairs (label == 1), the loss is the squared distance between embeddings.\n","    # - For non-matched pairs (label == 0), the loss is based on how far apart the embeddings are,\n","    #   but penalizes them only if the distance is less than the margin.\n","    loss = torch.mean(\n","        labels * 0.4 * distances.pow(2) +  # For positive pairs, minimize the distance (squared)\n","        (1 - labels) * 0.4 * torch.max(torch.zeros_like(distances), margin - distances).pow(2)  # For negative pairs, maximize the distance (up to the margin)\n","    )\n","\n","    return loss  # Return the computed contrastive loss\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZhCizXEb7D4N"},"outputs":[],"source":["def Prediction_with_candidates(model, X1_tt, X2_tt, X3_tt, X4_tt, src_entity_tensor_o, tgt_entity_tensor_o,\n","                                   indexed_dict_src, indexed_dict_tgt, all_predictions_path):\n","    \"\"\"\n","    Evaluates the GatedCombination model using the given embeddings and candidate entity pairs.\n","    Saves the predictions and evaluation results to a file.\n","\n","    Args:\n","        model: Trained GatedCombination model.\n","        X1_tt, X2_tt, X3_tt, X4_tt (torch.Tensor): Tensors of source and target entity embeddings (updated and original).\n","        src_entity_tensor_o, tgt_entity_tensor_o (torch.Tensor): Tensors of source and target entity indices.\n","        indexed_dict_src, indexed_dict_tgt (dict): Dictionaries mapping entity indices to URIs for source and target.\n","        output_file (str): Path to save the predictions and results.\n","        hits_at_k_values (list): List of k-values for which hits@k is evaluated.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    # Move the model to CPU and set it to evaluation mode\n","    model = model.to(\"cpu\")\n","    model.eval()\n","\n","    # Set batch size for evaluation\n","    batch_size_test = 32\n","\n","    # Create a DataLoader for the evaluation data\n","    test_dataset = TensorDataset(X1_tt, X2_tt, X3_tt, X4_tt)\n","    test_dataloader = DataLoader(test_dataset, batch_size=batch_size_test)\n","\n","    # Prepare for collecting predictions and results\n","    predictions = []\n","    results = []\n","    count_predictions = 0  # Counter for predictions above threshold (0.5)\n","\n","    # Measure prediction time\n","    start_time = time.time()\n","\n","    # Disable gradient computation for evaluation\n","    with torch.no_grad():\n","        # Iterate over batches and compute model predictions\n","        for batch_X1, batch_X2, batch_X3, batch_X4 in test_dataloader:\n","            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","            predictions.extend(outputs.cpu().numpy())  # Collect predictions in CPU memory\n","\n","    end_time = time.time()\n","    predicting_time = end_time - start_time\n","    print(f\"Predicting time: {predicting_time:.2f} seconds\")\n","\n","    # Convert tensors to lists for easier iteration\n","    src_indices = src_entity_tensor_o.tolist()\n","    tgt_indices = tgt_entity_tensor_o.tolist()\n","\n","    # Prepare results\n","    for i in range(len(predictions)):\n","        if predictions[i] >= 0.00:  # Consider only predictions greater than 0.5\n","            count_predictions += 1  # Increment the counter\n","\n","            # Map the source and target entity indices to their URIs\n","            src_code = src_indices[i]\n","            tgt_code = tgt_indices[i]\n","\n","            src_uri = indexed_dict_src.get(int(src_code), \"Unknown URI\")\n","            tgt_uri = indexed_dict_tgt.get(int(tgt_code), \"Unknown URI\")\n","\n","            # Get the model's predicted score for the current pair\n","            score = predictions[i]\n","\n","            # Append the results (with URIs instead of entity indices)\n","            results.append({\n","                'SrcEntity': src_uri,\n","                'TgtEntity': tgt_uri,\n","                'Score': score\n","            })\n","\n","    # Convert the results into a pandas DataFrame\n","    df_results = pd.DataFrame(results)\n","\n","    # Save the results to a TSV file\n","    df_results.to_csv(all_predictions_path, sep='\\t', index=False)\n","\n","    print(f\"Predictions saved to {all_predictions_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TslUdYHBcGVj"},"outputs":[],"source":["def filter_highest_predictions(input_file_path, output_file_path, threshold=thres):\n","    # Load the all predictions file\n","    df = pd.read_csv(input_file_path, sep='\\t')\n","\n","    # Extract the similarity score from the list in the 'Score' column\n","    df['Score'] = df['Score'].apply(lambda x: float(x.strip('[]')))\n","\n","    # Sorting the dataframe by similarity score in descending order\n","    df_sorted = df.sort_values(by='Score', ascending=False).reset_index(drop=True)\n","\n","    # Initialize variables with threshold value\n","    source_concepts = set(df_sorted['SrcEntity'])\n","    target_concepts = set(df_sorted['TgtEntity'])\n","    matched_sources = set()\n","    matched_targets = set()\n","    result = []\n","\n","    # Iterate through the sorted dataframe and find highest correspondences\n","    for _, row in df_sorted.iterrows():\n","        source, target, similarity = row['SrcEntity'], row['TgtEntity'], row['Score']\n","\n","        # Check if the source or target has already been matched and if the similarity is above the threshold\n","        if source not in matched_sources and target not in matched_targets and similarity >= threshold:\n","            # Add the match to the result list\n","            result.append((source, target, similarity))\n","            # Mark the source and target as matched\n","            matched_sources.add(source)\n","            matched_targets.add(target)\n","\n","    # Create a dataframe for the matching results with threshold applied\n","    matching_results_df_threshold = pd.DataFrame(result, columns=['SrcEntity', 'TgtEntity', 'Score'])\n","\n","    # Save the matching results with the updated column names to a new TSV file\n","    matching_results_df_threshold.to_csv(output_file_path, sep='\\t', index=False)\n","\n","    # Print the number of predictions saved\n","    print(f\"Number of Positive predictions: {len(matching_results_df_threshold)}\")\n","\n","    return matching_results_df_threshold, len(matching_results_df_threshold)"]},{"cell_type":"code","source":["def compute_mrr_and_hits(reference_file, predicted_file, output_file, k_values=[1, 5, 10]):\n","    \"\"\"\n","    Compute MRR and Hits@k for ontology matching predictions based on a reference file.\n","\n","    Args:\n","        reference_file (str): Path to the reference file (test.cands.tsv format).\n","        predicted_file (str): Path to the predictions file with scores.\n","        output_file (str): Path to save the scored results.\n","        k_values (list): List of k values for Hits@k.\n","\n","    Returns:\n","        dict: A dictionary containing MRR and Hits@k metrics.\n","    \"\"\"\n","    # Read the reference mappings\n","    test_candidate_mappings = read_table(reference_file).values.tolist()\n","    ranking_results = []\n","\n","    # Read the predicted scores\n","    predicted_data = pd.read_csv(predicted_file, sep=\"\\t\")\n","    predicted_data[\"Score\"] = predicted_data[\"Score\"].apply(lambda x: float(x.strip(\"[]\")))\n","\n","    # Create a lookup dictionary for predicted scores\n","    score_lookup = {}\n","    for _, row in predicted_data.iterrows():\n","        score_lookup[(row[\"SrcEntity\"], row[\"TgtEntity\"])] = row[\"Score\"]\n","\n","    for src_ref_class, tgt_ref_class, tgt_cands in test_candidate_mappings:\n","        tgt_cands = eval(tgt_cands)  # Convert string to list of candidates\n","        scored_cands = []\n","        for tgt_cand in tgt_cands:\n","            # Retrieve score for each candidate, defaulting to a very low score if not found\n","            matching_score = score_lookup.get((src_ref_class, tgt_cand), -1e9)\n","            scored_cands.append((tgt_cand, matching_score))\n","\n","        # Sort candidates by score in descending order\n","        scored_cands = sorted(scored_cands, key=lambda x: x[1], reverse=True)\n","        ranking_results.append((src_ref_class, tgt_ref_class, scored_cands))\n","\n","    # Save the ranked results to a file\n","    pd.DataFrame(ranking_results, columns=[\"SrcEntity\", \"TgtEntity\", \"TgtCandidates\"]).to_csv(output_file, sep=\"\\t\", index=False)\n","\n","    # Compute MRR and Hits@k\n","    total_entities = len(ranking_results)\n","    reciprocal_ranks = []\n","    hits_at_k = {k: 0 for k in k_values}\n","\n","    for src_entity, tgt_ref_class, tgt_cands in ranking_results:\n","        ranked_candidates = [candidate[0] for candidate in tgt_cands]\n","        if tgt_ref_class in ranked_candidates:\n","            rank = ranked_candidates.index(tgt_ref_class) + 1\n","            reciprocal_ranks.append(1 / rank)\n","            for k in k_values:\n","                if rank <= k:\n","                    hits_at_k[k] += 1\n","        else:\n","            reciprocal_ranks.append(0)\n","\n","    mrr = sum(reciprocal_ranks) / total_entities\n","    hits_at_k = {k: hits / total_entities for k, hits in hits_at_k.items()}\n","\n","    return {\"MRR\": mrr, \"Hits@k\": hits_at_k}"],"metadata":{"id":"_ggVYlTiO_WA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1HyWMsw1MVhz"},"source":["# **Main Code**\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"IC37FlwGDqGM"},"source":["\n","\n","# Reading semantic node embeddings provided by the ENE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FuEfSnw5mod0"},"outputs":[],"source":["# Read the source embeddings from a CSV file into a pandas DataFrame\n","df_embbedings_src = pd.read_csv(src_Emb, index_col=0)\n","\n","# Convert the DataFrame to a NumPy array, which will remove the index and store the data as a raw matrix\n","numpy_array = df_embbedings_src.to_numpy()\n","\n","# Convert the NumPy array into a PyTorch FloatTensor, which is the format required for PyTorch operations\n","x_src = torch.FloatTensor(numpy_array)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"STUwqMUXmlG2"},"outputs":[],"source":["# Read the target embeddings from a CSV file into a pandas DataFrame\n","df_embbedings_tgt = pd.read_csv(tgt_Emb, index_col=0)\n","\n","# Convert the DataFrame to a NumPy array, which removes the index and converts the data to a raw matrix\n","numpy_array = df_embbedings_tgt.to_numpy()\n","\n","# Convert the NumPy array into a PyTorch FloatTensor, which is required for PyTorch operations\n","x_tgt = torch.FloatTensor(numpy_array)"]},{"cell_type":"markdown","metadata":{"id":"jZIu9P08DqGN"},"source":["# Reading adjacency Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pH69Up40mycz"},"outputs":[],"source":["# Read the source adjacency matrix from a CSV file into a pandas DataFrame\n","df_ma1 = pd.read_csv(src_Adjacence, index_col=0)\n","\n","# Convert the DataFrame to a list of lists (Python native list format)\n","ma1 = df_ma1.values.tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hYCmAO5Ymzpl"},"outputs":[],"source":["# Read the target adjacency matrix from a CSV file into a pandas DataFrame\n","df_ma2 = pd.read_csv(tgt_Adjacence, index_col=0)\n","\n","# Convert the DataFrame to a list of lists (Python native list format)\n","ma2 = df_ma2.values.tolist()"]},{"cell_type":"markdown","metadata":{"id":"PSyksqh3TrU-"},"source":["# Convert Adjacency matrix (in list format) to an undirected edge index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uVt-Pce5m5ll"},"outputs":[],"source":["# Convert the source adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n","edge_src = adjacency_matrix_to_undirected_edge_index(ma1)\n","\n","# Convert the target adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n","edge_tgt = adjacency_matrix_to_undirected_edge_index(ma2)"]},{"cell_type":"markdown","metadata":{"id":"H9wMTRdqT4aY"},"source":["# GIT Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eqiEKCLSMVh3"},"outputs":[],"source":["def train_model_gnn(model, x_src, edge_src, x_tgt, edge_tgt,\n","                    tensor_term1, tensor_term2, tensor_score,\n","                    learning_rate, weight_decay_value, num_epochs, print_interval=10):\n","    \"\"\"\n","    Trains a graph neural network (GNN) model using source and target embeddings and contrastive loss.\n","\n","    Args:\n","        model: The GNN model to be trained.\n","        x_src (torch.Tensor): Source node embeddings.\n","        edge_src (torch.Tensor): Source graph edges.\n","        x_tgt (torch.Tensor): Target node embeddings.\n","        edge_tgt (torch.Tensor): Target graph edges.\n","        tensor_term1 (torch.Tensor): Indices of the source nodes to be compared.\n","        tensor_term2 (torch.Tensor): Indices of the target nodes to be compared.\n","        tensor_score (torch.Tensor): Labels indicating if the pairs are matched (1) or not (0).\n","        learning_rate (float): Learning rate for the optimizer.\n","        weight_decay_value (float): Weight decay (L2 regularization) value for the optimizer.\n","        num_epochs (int): Number of epochs for training.\n","        print_interval (int): Interval at which training progress is printed (every `print_interval` epochs).\n","\n","    Returns:\n","        model: The trained GNN model.\n","    \"\"\"\n","\n","    # Step 1: Set device (GPU or CPU) for computation\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    # Step 2: Move the model and all inputs to the selected device\n","    model.to(device)\n","    x_tgt = x_tgt.to(device)               # Target node embeddings\n","    edge_tgt = edge_tgt.to(device)         # Target graph edges\n","    x_src = x_src.to(device)               # Source node embeddings\n","    edge_src = edge_src.to(device)         # Source graph edges\n","    tensor_term1 = tensor_term1.to(device) # Indices for source nodes\n","    tensor_term2 = tensor_term2.to(device) # Indices for target nodes\n","    tensor_score = tensor_score.to(device) # Ground truth labels\n","\n","    # Step 3: Define optimizer with learning rate and regularization\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay_value)\n","\n","    # Step 4: Initialize list to store training losses\n","    train_losses = []\n","\n","    # Record the start time of training\n","    start_time = time.time()\n","\n","    # Step 5: Training loop\n","    for epoch in range(num_epochs):\n","        # Zero out gradients from the previous iteration\n","        optimizer.zero_grad()\n","\n","        # Forward pass: Compute embeddings for source and target graphs\n","        out1 = model(x_src, edge_src)  # Updated source embeddings\n","        out2 = model(x_tgt, edge_tgt)  # Updated target embeddings\n","\n","        # Extract specific rows of embeddings for terms being compared\n","        src_embeddings = select_rows_by_index(out1, tensor_term1)\n","        tgt_embeddings = select_rows_by_index(out2, tensor_term2)\n","\n","        # Compute contrastive loss based on the embeddings and ground truth labels\n","        loss = contrastive_loss(src_embeddings, tgt_embeddings, tensor_score)\n","\n","        # Backward pass: Compute gradients\n","        loss.backward()\n","\n","        # Update the model's parameters\n","        optimizer.step()\n","\n","        # Append the loss for this iteration to the list\n","        train_losses.append(loss.item())\n","\n","        # Print loss every `print_interval` epochs\n","        if (epoch + 1) % print_interval == 0:\n","            print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item()}\")\n","\n","    # Step 6: Record end time of training\n","    end_time = time.time()\n","\n","    # Step 7: Plot the training loss over time\n","    plt.semilogy(range(1, num_epochs + 1), train_losses, label=\"Training Loss\", marker='o')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    # Print the total training time\n","    training_time = end_time - start_time\n","    print(f\"Training complete! Total training time: {training_time:.2f} seconds\")\n","\n","    # Step 8: Return the trained model\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6_tzUG_emtBg"},"outputs":[],"source":["# Initialize the GIT_mod model with the dimensionality of the target embeddings\n","# The first argument is the dimensionality of the target node embeddings (x_tgt.shape[1])\n","# The second argument (1) represents the number of RGIT layers in the model\n","GIT_model = RGIT_mod(x_tgt.shape[1], 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wVo-s7UQssSp"},"outputs":[],"source":["# Reading the training pairs from a CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(train_file, index_col=0)\n","\n","# Extract the 'SrcEntity' and 'TgtEntity' columns as NumPy arrays and convert them to integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)  # Source entity indices\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)  # Target entity indices\n","\n","# Extract the 'Score' column as a NumPy array and convert it to floats\n","tensor_score = df_embbedings['Score'].values.astype(float)  # Scores (labels) indicating if pairs match (1) or not (0)\n","\n","# Convert the NumPy arrays to PyTorch LongTensors (for indices) and FloatTensors (for scores)\n","tensor_term1_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)  # Source entity tensor\n","tensor_term2_o = torch.from_numpy(tensor_term2).type(torch.LongTensor)  # Target entity tensor\n","tensor_score_o = torch.from_numpy(tensor_score).type(torch.FloatTensor)  # Score tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"agHlFNesMVh3","outputId":"646c6b0d-927a-4b57-9271-379fbaaf21fc","executionInfo":{"status":"ok","timestamp":1732182267213,"user_tz":-60,"elapsed":741261,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [10/1000], Training Loss: 0.003478609025478363\n","Epoch [20/1000], Training Loss: 0.002747512888163328\n","Epoch [30/1000], Training Loss: 0.0023310179822146893\n","Epoch [40/1000], Training Loss: 0.0020463226828724146\n","Epoch [50/1000], Training Loss: 0.0018415150698274374\n","Epoch [60/1000], Training Loss: 0.001684603514149785\n","Epoch [70/1000], Training Loss: 0.001558701042085886\n","Epoch [80/1000], Training Loss: 0.0014551278436556458\n","Epoch [90/1000], Training Loss: 0.0013674425426870584\n","Epoch [100/1000], Training Loss: 0.0012919725850224495\n","Epoch [110/1000], Training Loss: 0.0012266209814697504\n","Epoch [120/1000], Training Loss: 0.0011691704858094454\n","Epoch [130/1000], Training Loss: 0.0011182371526956558\n","Epoch [140/1000], Training Loss: 0.0010725586907938123\n","Epoch [150/1000], Training Loss: 0.0010312001686543226\n","Epoch [160/1000], Training Loss: 0.000993514433503151\n","Epoch [170/1000], Training Loss: 0.0009590606205165386\n","Epoch [180/1000], Training Loss: 0.0009274150943383574\n","Epoch [190/1000], Training Loss: 0.0008980886777862906\n","Epoch [200/1000], Training Loss: 0.0008707968518137932\n","Epoch [210/1000], Training Loss: 0.0008452916517853737\n","Epoch [220/1000], Training Loss: 0.0008213014807552099\n","Epoch [230/1000], Training Loss: 0.0007988128927536309\n","Epoch [240/1000], Training Loss: 0.0007775290869176388\n","Epoch [250/1000], Training Loss: 0.000757272879127413\n","Epoch [260/1000], Training Loss: 0.0007379474118351936\n","Epoch [270/1000], Training Loss: 0.0007195762009359896\n","Epoch [280/1000], Training Loss: 0.0007018126198090613\n","Epoch [290/1000], Training Loss: 0.0006848266930319369\n","Epoch [300/1000], Training Loss: 0.0006685377447865903\n","Epoch [310/1000], Training Loss: 0.0006528965895995498\n","Epoch [320/1000], Training Loss: 0.0006378578837029636\n","Epoch [330/1000], Training Loss: 0.000623374420683831\n","Epoch [340/1000], Training Loss: 0.0006093213451094925\n","Epoch [350/1000], Training Loss: 0.0005956963286735117\n","Epoch [360/1000], Training Loss: 0.0005825267871841788\n","Epoch [370/1000], Training Loss: 0.0005698757013306022\n","Epoch [380/1000], Training Loss: 0.0005576772382482886\n","Epoch [390/1000], Training Loss: 0.0005459676613099873\n","Epoch [400/1000], Training Loss: 0.0005346164107322693\n","Epoch [410/1000], Training Loss: 0.0005235641729086637\n","Epoch [420/1000], Training Loss: 0.0005128771299496293\n","Epoch [430/1000], Training Loss: 0.0005026046419516206\n","Epoch [440/1000], Training Loss: 0.0004927567788399756\n","Epoch [450/1000], Training Loss: 0.00048329238779842854\n","Epoch [460/1000], Training Loss: 0.0004742260498460382\n","Epoch [470/1000], Training Loss: 0.0004655307566281408\n","Epoch [480/1000], Training Loss: 0.00045719274203293025\n","Epoch [490/1000], Training Loss: 0.0004491778090596199\n","Epoch [500/1000], Training Loss: 0.00044147862354293466\n","Epoch [510/1000], Training Loss: 0.0004340304876677692\n","Epoch [520/1000], Training Loss: 0.00042678232421167195\n","Epoch [530/1000], Training Loss: 0.00041975831845775247\n","Epoch [540/1000], Training Loss: 0.00041291717207059264\n","Epoch [550/1000], Training Loss: 0.0004062275984324515\n","Epoch [560/1000], Training Loss: 0.00039969789213500917\n","Epoch [570/1000], Training Loss: 0.00039324071258306503\n","Epoch [580/1000], Training Loss: 0.00038681254955008626\n","Epoch [590/1000], Training Loss: 0.00038113229675218463\n","Epoch [600/1000], Training Loss: 0.0003753339406102896\n","Epoch [610/1000], Training Loss: 0.0003684921539388597\n","Epoch [620/1000], Training Loss: 0.0003618708869908005\n","Epoch [630/1000], Training Loss: 0.0003556159499567002\n","Epoch [640/1000], Training Loss: 0.0003507870133034885\n","Epoch [650/1000], Training Loss: 0.0003458172141108662\n","Epoch [660/1000], Training Loss: 0.0003395909152459353\n","Epoch [670/1000], Training Loss: 0.0003329773317091167\n","Epoch [680/1000], Training Loss: 0.0003268746077083051\n","Epoch [690/1000], Training Loss: 0.0003217697376385331\n","Epoch [700/1000], Training Loss: 0.0003177962207701057\n","Epoch [710/1000], Training Loss: 0.00031407628557644784\n","Epoch [720/1000], Training Loss: 0.0003080712049268186\n","Epoch [730/1000], Training Loss: 0.00030185963260009885\n","Epoch [740/1000], Training Loss: 0.00029611249919980764\n","Epoch [750/1000], Training Loss: 0.000292114244075492\n","Epoch [760/1000], Training Loss: 0.0002893267082981765\n","Epoch [770/1000], Training Loss: 0.00028564580134116113\n","Epoch [780/1000], Training Loss: 0.00027975006378255785\n","Epoch [790/1000], Training Loss: 0.0002740957716014236\n","Epoch [800/1000], Training Loss: 0.000269975425908342\n","Epoch [810/1000], Training Loss: 0.0002682682825252414\n","Epoch [820/1000], Training Loss: 0.0002655584830790758\n","Epoch [830/1000], Training Loss: 0.0002608546637929976\n","Epoch [840/1000], Training Loss: 0.00025574088795110583\n","Epoch [850/1000], Training Loss: 0.00025207639555446804\n","Epoch [860/1000], Training Loss: 0.00025131067377515137\n","Epoch [870/1000], Training Loss: 0.0002495295484550297\n","Epoch [880/1000], Training Loss: 0.0002452193293720484\n","Epoch [890/1000], Training Loss: 0.00024108862271532416\n","Epoch [900/1000], Training Loss: 0.0002388755528954789\n","Epoch [910/1000], Training Loss: 0.00023975843214429915\n","Epoch [920/1000], Training Loss: 0.00023558942484669387\n","Epoch [930/1000], Training Loss: 0.00023125504958443344\n","Epoch [940/1000], Training Loss: 0.00022975775937084109\n","Epoch [950/1000], Training Loss: 0.0002281893976032734\n","Epoch [960/1000], Training Loss: 0.00022698611428495497\n","Epoch [970/1000], Training Loss: 0.00022241414990276098\n","Epoch [980/1000], Training Loss: 0.0002181507006753236\n","Epoch [990/1000], Training Loss: 0.00021757054491899908\n","Epoch [1000/1000], Training Loss: 0.0002165194455301389\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAkIAAAGwCAYAAABFFQqPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9RUlEQVR4nO3deXxU1f3/8ffMhKxkJWSTAGERCPsSkE1FUTZREW1VtGitfkVELNUvLkVcfi6trQuQYrWKtaJU+xWKiAsiiiACCkEiq8imJCBLEraQZOb+/qCZEiFkJrkzd5bX8/Hg8TAzZ+6cuYDz5pzPOcdmGIYhAACAMGS3ugMAAABWIQgBAICwRRACAABhiyAEAADCFkEIAACELYIQAAAIWwQhAAAQtiKs7kCgc7lc2rNnj+Lj42Wz2azuDgAA8IBhGDp8+LCysrJkt9c+7kMQqsOePXuUnZ1tdTcAAEA97N69W82aNav1eYJQHeLj4yWdvJEJCQkW9wYAAHiirKxM2dnZ7u/x2hCE6lA9HZaQkEAQAgAgyNRV1kKxNAAACFsEIQAAELYIQgAAIGxRI1SL/Px85efny+l0Wt0VAAhLTqdTlZWVVncDAapRo0ZyOBwNvo7NMAzDhP6ErLKyMiUmJqq0tJRiaQDwA8MwVFxcrJKSEqu7ggCXlJSkjIyMMxZEe/r9zYgQACCgVIegtLQ0xcbGspktTmMYho4dO6Z9+/ZJkjIzM+t9LYIQACBgOJ1Odwhq0qSJ1d1BAIuJiZEk7du3T2lpafWeJqNYGgAQMKprgmJjYy3uCYJB9Z+ThtSSEYQAAAGH6TB4wow/J0yNWcDpMrRq+0HtO1yutPho9c5JkcPOX3oAAPyNIORnHxQW6ZF3N6iotNz9WGZitKaOzNXQTvUv9gIAAN5jasyPPigs0rjX19QIQZJUXFquca+v0QeFRRb1DABCi9NlaMW2A/p3wY9ase2AnK7g2ymmZcuWeu655zxu/+mnn8pms7HtgJcYEfITp8vQI+9u0Jn+KhqSbJIeeXeDLsnNYJoMABrA3yPvddWpTJ06VQ8//LDX1129erXi4uI8bt+vXz8VFRUpMTHR6/fyxqeffqpBgwbp0KFDSkpK8ul7+QNByE9WbT942kjQqQxJRaXlWrX9oPq2ZskoANRH9cj7z//RWT3yPvOGHqaHoaKi/47m//Of/9RDDz2kzZs3ux9r3Lix+78Nw5DT6VRERN1fv02bNvWqH5GRkcrIyPDqNWBqzG/2Ha49BNWnHQCEC8MwdKyiqs5fh8srNXX+t7WOvEvSw/M36HB5pUfX8/TghYyMDPevxMRE2Ww298+bNm1SfHy83n//ffXs2VNRUVFatmyZtm3bpiuuuELp6elq3Lix8vLy9PHHH9e47s+nxmw2m/72t79p1KhRio2NVdu2bTV//nz38z+fGnv11VeVlJSkDz/8UB06dFDjxo01dOjQGsGtqqpKd911l5KSktSkSRNNnjxZY8eO1ZVXXunRZz+TQ4cO6Ve/+pWSk5MVGxurYcOGaevWre7nd+7cqZEjRyo5OVlxcXHq2LGjFi5c6H7tmDFj1LRpU8XExKht27aaNWtWvfviCUaE/CQtPtrUdgAQLo5XOpX70IcNvo4hqbisXJ0f/sij9hseHaLYSHO+Ju+77z796U9/UqtWrZScnKzdu3dr+PDhevzxxxUVFaXXXntNI0eO1ObNm9W8efNar/PII4/oj3/8o55++mlNnz5dY8aM0c6dO5WSknLG9seOHdOf/vQn/eMf/5DdbtcNN9yge+65R7Nnz5Yk/eEPf9Ds2bM1a9YsdejQQc8//7zmzZunQYMG1fuz3nTTTdq6davmz5+vhIQETZ48WcOHD9eGDRvUqFEjjR8/XhUVFVq6dKni4uK0YcMG96jZlClTtGHDBr3//vtKTU3Vd999p+PHj9e7L54gCPlJ75wUZSZGq7i0/Iz/WrFJykg8uZQeABBaHn30UV1yySXun1NSUtS1a1f3z4899pjmzp2r+fPn684776z1OjfddJOuu+46SdITTzyhadOmadWqVRo6dOgZ21dWVuqFF15Q69atJUl33nmnHn30Uffz06dP1/33369Ro0ZJkmbMmOEenamP6gC0fPly9evXT5I0e/ZsZWdna968ebrmmmu0a9cujR49Wp07d5YktWrVyv36Xbt2qXv37urVq5ekk6NivkYQ8hOH3aapI3M17vU1skk1wlB1md3UkbkUSgPAz8Q0cmjDo0PqbLdq+0HdNGt1ne1evTnPo390xjRq+Mnm1aq/2KsdOXJEDz/8sN577z0VFRWpqqpKx48f165du856nS5durj/Oy4uTgkJCe7zts4kNjbWHYKkk2dyVbcvLS3V3r171bt3b/fzDodDPXv2lMvl8urzVdu4caMiIiLUp08f92NNmjRRu3bttHHjRknSXXfdpXHjxumjjz7S4MGDNXr0aPfnGjdunEaPHq01a9bo0ksv1ZVXXukOVL5CjVAt8vPzlZubq7y8PNOuObRTpmbe0EMZiTWnvzISo31SwAcAocBmsyk2MqLOXwPbNlVmYrRq++ekTSdXjw1s29Sj65m5u/XPV3/dc889mjt3rp544gl9/vnnKigoUOfOnVVRUXHW6zRq1KjmZ7LZzhpaztTe09onX/nNb36j77//XjfeeKPWr1+vXr16afr06ZKkYcOGaefOnfrtb3+rPXv26OKLL9Y999zj0/4QhGoxfvx4bdiwQatX1/2vC28M7ZSpZZMvUnbyycPiHhjeQcsmX0QIAoAGqh55l3RaGAq0kffly5frpptu0qhRo9S5c2dlZGRox44dfu1DYmKi0tPTa3zPOZ1OrVmzpt7X7NChg6qqqrRy5Ur3YwcOHNDmzZuVm5vrfiw7O1u333673nnnHf3ud7/TSy+95H6uadOmGjt2rF5//XU999xzevHFF+vdH08wNWYBh92mhJhG0qHjOje9cUD8pQSAUFA98v7zfYQyAmwH/7Zt2+qdd97RyJEjZbPZNGXKlHpPRzXEhAkT9OSTT6pNmzZq3769pk+frkOHDnk0GrZ+/XrFx8e7f7bZbOratauuuOIK3XrrrfrrX/+q+Ph43XfffTrnnHN0xRVXSJLuvvtuDRs2TOeee64OHTqkJUuWqEOHDpKkhx56SD179lTHjh114sQJLViwwP2crxCELBLhODkYF4y7nQJAIBvaKVOX5GYE9JmOzzzzjH7961+rX79+Sk1N1eTJk1VWVub3fkyePFnFxcX61a9+JYfDodtuu01DhgyRw1F3fdT5559f42eHw6GqqirNmjVLEydO1GWXXaaKigqdf/75WrhwoXuazul0avz48frhhx+UkJCgoUOH6tlnn5V0ci+k+++/Xzt27FBMTIwGDhyoOXPmmP/BT2EzrJ4sDHBlZWVKTExUaWmpEhISTLvu6Jlf6Oudh/TXG3tqSEc2wAIASSovL9f27duVk5Oj6Gi2E/E3l8ulDh066Be/+IUee+wxq7tTp7P9efH0+5sRIYtU/8uEESEAgFV27typjz76SBdccIFOnDihGTNmaPv27br++uut7prfUCxtkYj/BKFKp//nhAEAkCS73a5XX31VeXl56t+/v9avX6+PP/7Y53U5gYQRIYswIgQAsFp2draWL19udTcsxYiQRRr9p1i6iiAEAKehfBWeMOPPCUHIIowIAcDpqlcWHTt2zOKeIBhU/zn5+caR3mBqzCLVNUJV1AgBgJvD4VBSUpL7GIjY2FhTd3hGaDAMQ8eOHdO+ffuUlJTk0XL/2hCELFI9IsTUGADUlJFxckuRs52hBUhSUlKS+89LfRGELNKIDRUB4IxsNpsyMzOVlpamyspKq7uDANWoUaMGjQRVIwhZhBEhADg7h8NhyhcdcDYUS1skgmJpAAAsRxCyiIMNFQEAsBxByCKMCAEAYD2CkEUi2FARAADLEYRqkZ+fr9zcXOXl5fnk+v8ZENLm4sNase0AI0MAAFjAZrCP+VmVlZUpMTFRpaWlSkhIMOWaHxQW6Xdvr9PRE073Y5mJ0Zo6MldDO2Wa8h4AAIQzT7+/GRHysw8KizTu9TU1QpAkFZeWa9zra/RBYZFFPQMAIPwQhPzI6TL0yLsbdKYhuOrHHnl3A9NkAAD4CUHIj1ZtP6ii0vJanzckFZWWa9X2g/7rFAAAYYwg5Ef7DtcegurTDgAANAxByI/S4qNNbQcAABqGIORHvXNSlJkYLVstz9t0cvVY75wUf3YLAICwRRDyI4fdpqkjc8/4XHU4mjoy1338BgAA8C2CkJ8N7ZSpmTf0UFJsoxqPZyRGa+YNPdhHCAAAP4qwugPhaGinTNll022vf60WKbF6anQX9c5JYSQIAAA/IwhZJDrSIUmKjYpQ39ZNLO4NAADhiakxizT6z+jPgSMnOGsMAACLEIQs8EFhke58c60kad/hE7rupS814A+fcLwGAAB+RhDys+qzxg4crajxOGeNAQDgfwQhP+KsMQAAAgtByI84awwAgMBCEPIjzhoDACCwEIT8KLVxlKntAABAwxCE/MnD0p/VTI0BAOAXBCE/2n/0hEftXl2xg4JpAAD8gCDkR2nx0R61KzlWScE0AAB+QBDyo945KUqKaVR3Q1EwDQCAPxCEapGfn6/c3Fzl5eWZdk2H3aab+7f0qK2no0cAAKD+bIZhUIxyFmVlZUpMTFRpaakSEhIafD2ny1DP/7dIJccqa22TmRitZZMv4jR6AADqydPvb0aE/Mxht+mXvZqdtc3lXTMJQQAA+AFByM+cLkPz1539PLH564pYNQYAgB8QhPysrmM2JI7ZAADAXwhCfubparBFG4p93BMAAEAQ8jNPV4O99dUPTI8BAOBjBCE/652TouTYiDrbHTlRpS+3HfBDjwAACF8EIT9z2G3q26qJR21fX7nDt50BACDMEYQs0KppvEftPt96gOkxAAB8iCBkgb6tPRsROnKiitVjAAD4EEHIAue1aqLYSIdHbTlzDAAA3yEIWcBht+nWgTketU2Ni/JxbwAACF8EIYv0zvFsekyctAEAgM8QhCyy/8gJj9ot3rjXxz0BACB8EYQs4unGiv8u2MPKMQAAfIQgZJHeOSlKiWtUZ7sDRytYOQYAgI8QhCzisNs0qts5HrVl5RgAAL5BELLQRe3TPWrHyjEAAHyDIGQlT1eEsXIMAACfIAhZiJVjAABYiyBkIVaOAQBgLYKQhVg5BgCAtQhCFmLlGAAA1iIIWYyVYwAAWIcgZDGX4Vntj6ftAACA5whCFlu5/YBH7d5YtdPHPQEAIPwQhCzn2SZBn289wMoxAABMRhCqRX5+vnJzc5WXl+fT9+nbuolH7Y6cqGLlGAAAJiMI1WL8+PHasGGDVq9e7dP3Oa9VE8U08uy3obj0uE/7AgBAuCEIWcxht2lE50yP2i7/br+PewMAQHghCAWA/m2betTu4437qBMCAMBEBKEAkJHg2VEbJccrqRMCAMBEBKEA0DsnRYnRER61pU4IAADzEIQCgMNu0yW5nu0wTZ0QAADmIQgFCOqEAADwP4JQgKBOCAAA/yMIBQjqhAAA8D+CUICgTggAAP8jCAUQ6oQAAPAvglAAoU4IAAD/IggFEG/qhD76tsjHvQEAIPQRhAKIN3VC/7fmR6bHAABoIIJQgPG0TqisvIrpMQAAGoggFGA8rROSWEYPAEBDEYQCTO+cFMVHOzxqe/BohY97AwBAaCMIBRiH3aarup/jUdtdB4/5uDcAAIQ2glAAap4S51G7uWspmAYAoCEIQgEopXGUR+0omAYAoGEIQgHIm4Jp9hMCAKD+CEIByJuC6TmrdzM9BgBAPRGEApDDbtPVPZp51PZ4pUtfbjvg4x4BABCaCEIB6tKOmR63fX3lDt91BACAEEYQClC9c1IUF+XZ9NiSTT8xPQYAQD0QhAKUw27TrQNyPGpbXsX0GAAA9UEQCmATLj5XjTz8HWJ6DAAA7xGEApjDbtPg3AyP2jI9BgCA9whCAe6G81p41I7pMQAAvEcQCnDntWqiSIfNo7bLt/3k494AABBaCEIBzmG3qVt2kkdtv9pxyLedAQAgxBCEgkBeTopH7dbuKqFOCAAALxCEgkC/1qketat0GZq+eKuPewMAQOggCAWB81o1UVSEZ79V+Uu+Y1QIAAAPEYSCgMNu00Xt0zxqy6gQAACeIwgFCU+X0UvS35Z9z6gQAAAeIAgFiZPTY54toz9ywqlV2w/6uEcAAAQ/glCQcNhtGndBa4/bf/RtkQ97AwBAaCAIBZGTZ495Nio0e+UupscAAKgDQSiIOOw23XBec4/aVjgpmgYAoC4EoVrk5+crNzdXeXl5Vnelhks7Znrc9oXPtjEqBADAWRCEajF+/Hht2LBBq1evtrorNfTOSVFclMOjthzECgDA2RGEgozDbtOtA3I8bv/alzt81xkAAIIcQSgITbj4XHl4IL0Wb9zL9BgAALUgCAUhh92mS3LTPWpb5RJF0wAA1IIgFKRu7NvS47acPwYAwJkRhIKUNztNc/4YAABnRhAKUt7uNM2oEAAApyMIBTFvdppmVAgAgNMRhIKYw27T+EGejwpN/2Qro0IAAJyCIBTkvBkVchrSxDfX+rhHAAAED4JQkPN2VGjB+iJVVLl82CMAAIIHQSgEeDMqJEn3v/OND3sDAEDwIAiFAG9Hhd5Z8yO1QgAAiCAUMrw5dsMQtUIAAEgEoZDhsNs0/kLvaoUWflPkwx4BABD4CEIhZOIl7TweFZKkSW8VMEUGAAhrBKEQ4rDbNOGiNh63L69ysckiACCsEYRCjLcryDh6AwAQzghCIcbbFWQcvQEACGcEoRA04eJzFeVFsdAMjt4AAIQpglAIcthtevaX3TxuX8XRGwCAMEUQClHDu2SpW3aCx+1ZTg8ACEcEoRB275AOXrW/6801TJEBAMIKQSiEndeqieIiPf8trjKkX7zwhQ97BABAYCEIhTCH3aanr+7q1Wu+3lWid9ft8VGPAAAILAShEDe8S5ZGdE736jV3z1nLFBkAICwQhMLAtOt6erWc3mlIE95Y48MeAQAQGAhCYcDb5fSStLCwmFVkAICQRxAKE8O7ZOmWAS28eg2ryAAAoY4gFEamXNZJbZvGedyeVWQAgFBHEAoz700836v2rCIDAIQyglCYiYywe72K7K43WUUGAAhNBKEwNO26norw4nfekHT1X5b7rD8AAFiFIBSGHHabpl3b3avXrP2hVI+8+62PegQAgDUIQmGqPqvIZi3foccWEIYAAKGDIBTGvF1FJkkvL9uhx9/b4KMeAQDgXwShMOftKjJJeunz7Wy2CAAICQShMBcZYfd6ikySfvtPVpIBAIIfQQiaclkn5aTGePWaE05Dd3EeGQAgyBGEIEn6eNIgr5bUS9J7hcUUTwMAghpBCJLqt6ReOlk8TRgCAAQrghDchnfJ0q0DW3r9OlaSAQCCVb2C0O7du/XDDz+4f161apXuvvtuvfjii6Z1DNZ4cERHDe/k3REcEivJAADBqV5B6Prrr9eSJUskScXFxbrkkku0atUqPfjgg3r00UdN7SD8b/r1PRXlsHn9uvFvrGElGQAgqNQrCBUWFqp3796SpLfeekudOnXSF198odmzZ+vVV181s3+wgMNu07O/7Ob16wxJFz39ien9AQDAV+oVhCorKxUVFSVJ+vjjj3X55ZdLktq3b6+iIqZHQkF964V2HirXiOc/M79DAAD4QL2CUMeOHfXCCy/o888/16JFizR06FBJ0p49e9SkSRNTOwjrPDiio24Z0NLr131bdESXTVtqfocAADBZvYLQH/7wB/31r3/VhRdeqOuuu05du3aVJM2fP989ZYbQMOWy+oWhwj2H9etZq8zvEAAAJrIZhlGv6lan06mysjIlJye7H9uxY4diY2OVlpZmWgetVlZWpsTERJWWliohIcHq7ljmkXcLNWv5Tq9fd3P/lpo6sqMPegQAQO08/f6u14jQ8ePHdeLECXcI2rlzp5577jlt3rw5pEIQ/mvqyE66qF2q16+btXyHHnm30Ac9AgCg4eoVhK644gq99tprkqSSkhL16dNHf/7zn3XllVdq5syZpnYQgeOVm/uoU2Zjr183a/lO/XrWSh/0CACAhqlXEFqzZo0GDhwoSfrXv/6l9PR07dy5U6+99pqmTZtmagcRWBZMvEAd6xGGPtm8XyMpoAYABJh6BaFjx44pPj5ekvTRRx/pqquukt1u13nnnaedO72vI0FweW/iBWqZEu3169bvOaybX2FkCAAQOOoVhNq0aaN58+Zp9+7d+vDDD3XppZdKkvbt2xfWBcXhZPE9F9XrD8+SLfsJQwCAgFGvIPTQQw/pnnvuUcuWLdW7d2/17dtX0snRoe7dvT/BHMHHYbdpxvX1+71esmW/LmPTRQBAAKj38vni4mIVFRWpa9eusttP5qlVq1YpISFB7du3N7WTVmL5/Nk9/t63eunzHfV6bW5GnBbefaGp/QEAQPL8+7veQaha9Sn0zZo1a8hlAhZBqG6PLfhWLy/bUa/XNkuK0rL7BpvbIQBA2PPpPkIul0uPPvqoEhMT1aJFC7Vo0UJJSUl67LHH5HK56t1pBKcpl3XUrQNz6vXaH0pOqNdjH3FqPQDAEvUKQg8++KBmzJihp556SmvXrtXatWv1xBNPaPr06ZoyZYrZfUQQeHBErmZcW7+aof1HK9X2gYVa+M0ek3sFAMDZ1WtqLCsrSy+88IL71Plq//73v3XHHXfoxx9/NK2DVmNqzDsLCvbozjlr6/36Wwe21IMjOJIDANAwPp0aO3jw4BkLotu3b6+DBw/W55IIEZd1y9L/nF+/aTJJeulzjuQAAPhPvYJQ165dNWPGjNMenzFjhrp06dLgTiG43T88V3+5vods9Xw9R3IAAPylXlNjn332mUaMGKHmzZu79xBasWKFdu/erYULF7qP3wgEJSUlGjx4sKqqqlRVVaWJEyfq1ltv9fj1TI3Vn9NlaNAfF2tXyYl6vb5lSrQW33ORHPb6RioAQLjy6dTYBRdcoC1btmjUqFEqKSlRSUmJrrrqKn377bf6xz/+Ue9O+0J8fLyWLl2qgoICrVy5Uk888YQOHDhgdbfCgsNu09L7BqtZUlS9Xr/jYDlF1AAAn2rwPkKnWrdunXr06CGn02nWJU118OBB9ejRQ1999ZVSU1M9eg0jQuYY8NTH+qGeI0OSdMuAFppyWScTewQACGU+HREy09KlSzVy5EhlZWXJZrNp3rx5p7XJz89Xy5YtFR0drT59+mjVqlVevUdJSYm6du2qZs2a6d577/U4BME8y+4brI5Z8fV+/cvLqBsCAJjP8iB09OhRde3aVfn5+Wd8/p///KcmTZqkqVOnas2aNeratauGDBmiffv2udt069ZNnTp1Ou3Xnj0np1SSkpK0bt06bd++XW+88Yb27t3rl8+Gmt6763wNOrf+IfSTzft14R8Xs/kiAMA0ATU1ZrPZNHfuXF155ZXux/r06aO8vDz3KjWXy6Xs7GxNmDBB9913n9fvcccdd+iiiy7S1VdffcbnT5w4oRMn/juFU1ZWpuzsbKbGTPTrWav0yeaf6v16u6QZ13fX8C5Z5nUKABBSPJ0ai/DmolddddVZny8pKfHmcnWqqKjQ119/rfvvv9/9mN1u1+DBg7VixQqPrrF3717FxsYqPj5epaWlWrp0qcaNG1dr+yeffFKPPPJIg/uO2r1yc2/95u+r9fHGfXU3PgOXpDveWKtbdh2kbggA0CBeBaHExMQ6n//Vr37VoA6dav/+/XI6nUpPT6/xeHp6ujZt2uTRNXbu3KnbbrtNhmHIMAxNmDBBnTt3rrX9/fffr0mTJrl/rh4Rgrn+NjZP767bowlv1n8X6peX7dSanYf0r3EDWGIPAKgXr4LQrFmzfNUPn+ndu7cKCgo8bh8VFaWoqPot94Z3RnbN0vDOmbro6U+081B5va6xdneZ2j6wkKkyAEC9WF4sfTapqalyOBynFTfv3btXGRkZFvUKZnLYbfps8sXq1IAVZdVTZY8t4GgOAIB3AjoIRUZGqmfPnlq8eLH7MZfLpcWLF7t3tEZoWHDX+bq4fVqDrvHysp0a/OclqqhymdQrAECoszwIHTlyRAUFBe7pq+3bt6ugoEC7du2SJE2aNEkvvfSS/v73v2vjxo0aN26cjh49qptvvtnCXsMXXr4pT9Ov696ga3z30zGd+/v39ci7603qFQAglJm6fL4+Pv30Uw0aNOi0x8eOHatXX31V0snDXJ9++mkVFxerW7dumjZtmvr06eOX/rGztP85XUaD6oaqNW3cSF8+cAmF1AAQhjz9/rY8CAU6gpB1Lpu2VIV7Djf4OjOu7abLup1jQo8AAMEiaI7YAGpjRt2QJN05p0BX5X/OjtQAgNMQhBDQzKgbkqQ1u8vU5oGFWlDwowm9AgCECoJQLfLz85Wbm6u8vDyruxL2RnbN0rYnhqtlSkyDrmOI0SEAQE3UCNWBGqHAcsurq7V4U/2O5vi5ab/oqst7NDPlWgCAwEKNEEJS9VSZGQvB7nprnS58mtPsASCcEYQQdEZ2zdLWx4dreKeG7y6+40C5Wj+wUM98uIlABABhiKmxOjA1FtgqqlzK+38fqbTc2eBr2W3StF+y1B4AQgFTYwgLkRF2rXt4qC5q37TB13IZFFMDQLghCCEkvHJTb1OW2UsstQeAcEIQQsioXmaf0yS2wdeqXmo/itEhAAhpBCGEFIfdpiX3DtItA3JMud7a3WUUUwNACKNYug4USweviiqXRkxbqq37jppyPYqpASB4UCyNsBcZYdeiSReaVjtUXUzNdBkAhA6CEEJede1Q9+xEU67HdBkAhA6CUC04ayy0OOw2zR0/wLRdqSVp2pJtakMgAoCgRo1QHagRCj1Ol6EJb6zRwsJi065plzTtWuqHACBQUCME1MJht+kvN/TUX67voUYmDQ+5dLJ+6JI/L1FFlcuUawIAfI8ghLA1vEumNv2/YbprUBvTrrn1p2M69/fv65F315t2TQCA7zA1VgemxsKD02Vo8J8/1fYDx0y7ZmK0Q6t/f6kiI/j3BgD4G1NjgBeqN2J8/tpuphVTl5Y7de7v39cvX/iC6TIACFCMCNWBEaHw43QZen7RFk1b8p2p1x3aKU351/eSw6ykBQColaff3wShOhCEwpcvpssk6a5BrTXxknYEIgDwIYKQSQhC+HfBj/rtPwtk9lZBV3XL0lNXd6WGCAB8gCBkEoIQpP9Ol01f8p3M/gszvFO6pl/fkxEiADARQcgkBCGcyhebMVZjygwAzEMQMglBCGdSUeXSjS9/qZXbD5l6XXaoBgBzEIRMQhDC2VRUudT78UUqOV5l6nXbNo3VexMvoH4IAOqJfYQaiENX4YnICLsKpg7Rr/u3NPW61TtUswcRAPgWI0J1YEQInvLVdJkk9WmZrH/85jxGiADAQ0yNmYQgBG9VVLl0wR8/UVHZCdOvTSACAM8wNQZYJDLCrhUPDDb1uI5qK3cc0rm/f1+3v75aTrM3NgKAMEQQAnzkim7naOvjw3XXoDamB6IPCvep9QML9cyHmwhEANAATI3VgakxmKF6Q8YZn35n+g7VkjThwta6+1L2IAKAatQImYQgBDP5codqiU0ZAaAaQcgkBCH4gi93qJY4xwwACEImIQjBl3y55F7iHDMA4YsgZBKCEPyhosqlEdOWauu+oz65PlNmAMINy+eBIBIZYdeiSRdq+nXd1chhfliZtmSb2rDKDABOw4hQHRgRgr85XYa+2LpfDy8o1Lafjpl+fZukCYwQAQhxTI2ZhCAEK/lyl2qJZfcAQhdTY0AI8OUu1ZI0/dNtbMwIIKwxIlQHRoQQKHy9B5HEsnsAoYOpMZMQhBBonC5Dz320WTM+3eazQMSyewDBjiDUQPn5+crPz5fT6dSWLVsIQgg4vj62Q2KECEDwIgiZhBEhBDp/BKI+LZP1j9+cRyACEDQIQiYhCCFY+KOGiEAEIFgQhExCEEKw8fU5ZpKU1zJJs3/Tl0AEIGARhExCEEKwqqhy6b7/W6e5a/f4bISodWqcHr68o/q1SaWwGkBAIQiZhCCEYOePKTObpDvZnBFAACEImYQghFDhj2X3Ege8AggMBCGTEIQQavyxykzi+A4A1iIImYQghFDlr0DEXkQArEAQMglBCKHOX4GoQ3pjvTN+gGIiHb57EwD4D4KQSQhCCBfVgSj/s+/kdPnufTLiI/X0Nd1YaQbApwhCJiEIIdw4XYa+2LpfDy8o1LafjvnsfWySRjFtBsBHCEImIQghnFVUuTRi2lJt3XfUp+/DjtUAzEYQMglBCJCOVzg16i/LtKn4iE/fhzoiAGYhCJmEIAT8V/Vu1e+s3ePT96GOCEBDEYRMQhACTuevzRmpIwJQXwQhkxCEgNr54/iOatQRAfAGQcgkBCGgbtUjRPmfbfPpXkSSlBYfpd8MyNFN/XMIRQBqRRBqoPz8fOXn58vpdGrLli0EIcAD/lp6X41RIgC1IQiZhBEhoH4qqly64W8rtGpHic/fi9VmAH6OIGQSghDQMNUrzeau3ePzOqLEaIfGD2rLtBkAgpBZCEKAOfx1hEe1rIQoPTm6iwa0bcoSfCAMEYRMQhACzOXvOiJJuool+EDYIQiZhCAE+I4/64gkqVVqrB65vBMbNQJhgCBkEoIQ4Hv+rCOqltciSXddfC6hCAhRBCGTEIQA//F3HZHE7tVAqCIImYQgBPifFXVEktQ6NU4PX96RUSIgBBCETEIQAqxVPW02r2CPz3etrsYoERD8CEImIQgBgcGqUSKW4QPBiSBkEoIQEHj8vdqsGgXWQPAgCJmEIAQErooql2Yt/14vf75d+45U+PW9R3XN0h+uYeoMCFQEIZMQhIDgUFHl0v/+q0D/Lijy2xJ8SUqKaaQLzm2qq3s2Y6QICCAEIZMQhIDgUl1LdM//FWhvmX9HiSiyBgIHQcgkBCEgeB2vcOrW11Zr+XcH/DpKJFFkDViNIGQSghAQ/KxacVaNImvA/whCJiEIAaHFygJriSJrwF8IQiYhCAGhq6LKpRtf/lIrtx/y+3unxUfpNwNydFP/HEIR4AMEIZMQhIDQZ/UoUVJMhC44N42VZ4CJCEImIQgB4cWqZfjVbJLuvLC17r60HYEIaACCkEkIQkB4qi6wfv6TLfpqZ4klfWiVGqtr85ozfQbUA0GogfLz85Wfny+n06ktW7YQhIAw5nQZWrb5J9039xsVlZ2wpA95LZM0+zd9CUSAhwhCJmFECMCprK4nim1kV/fmSbrt/NbsUQScBUHIJAQhALWxOhTZJE0Y1FoTL6GeCPg5gpBJCEIAPGF1kXVKbCMNaJOqa3pls/IMEEHINAQhAN4IhCLrRnbp2V9002XdzrHk/YFAQBAyCUEIQH1ZXWQd7bDp0o4ZjBIhLBGETEIQAmCG6nqi/CXbVFZe5ff3d9ik8RdST4TwQRAyCUEIgNmOVzj16IJCfbxhr346Uun3989MiFLvnCbsZI2QRhAyCUEIgC85XYae+2iz8j/bJpcF/zemngihiiBkEoIQAH+oLrJ+++td+njTPh2rcPn1/aMdNnU8J1FDOmawkzVCAkHIJAQhAFY4XuHUqL8s06biI5a8/839m2vqyM6WvDdgBoKQSQhCAKxUXWQ9Z9UubT9w3K/vbZPUskms+rVuot9f1lExkQ6/vj/QEAQhkxCEAAQKp8vQ84u2KP+z7+T078yZJKlHdoLeHjeA4moEBYKQSQhCAAJNdT3RW1/t1LJtB3TomH+X4yfFRKhjVgLnnSGgEYRMQhACEOicLkMT3lijhYXFfn9vu02a9ktWnSHwEIRMQhACECwqqlx6edk2/f2LHSou8+8hsA6blJkYrR7Nk9nJGgGBIGQSghCAYGTlKJEkRTlsevaX3TS8S5Yl7w8QhExCEAIQzKpXnX1YWKzNew/rqJ/3J0qKidAF56axizX8jiBkEoIQgFCy8JsiTXqrQOVV/l92xi7W8CeCkEkIQgBCzam7WG8oKtP3+4/59XiPRjYpPTFa6QnR7GQNnyEImYQgBCAcPPrut3pl+Q7L3v+WAS005bJOlr0/Qg9ByCQEIQDh4tR6osKiMlVU+ffrIcIudW2WxCgRTEEQMglBCEC4enfdHk16q0CVTmu+Jm4d2FIPjuhoyXsj+BGETEIQAhDOTq0nWrn9oPYe9u/+RBE2KTU+Sq2bxrGTNbxCEDIJQQgA/svq/Yki7NK0a7uzPxHqRBAyCUEIAE5XXU/0wfoibSw+rHI/1xNFR9iUm5mooZ2oJ8KZEYRMQhACgLot/KZIE+esVaU/1+GfglVn+DmCkEkIQgDgGafL0LLNP+mFpd/p26IylZU7/fr+dkmtm8YpNyuRnaxBEDILQQgA6sfpMnTNzC+0ZneJJe8faZfuGNRGOU0bKy0+Wr1zUghGYYQg1ED5+fnKz8+X0+nUli1bCEIAUE/HK5x6dEGhvvhuvw4cqdARP593Vi0qwqb/GdhKEy9pRyAKAwQhkzAiBADm+qCwSJPeWqdjFf6dOqtmk9S7ZbISYyOV1zJFY/u1pNg6BBGETEIQAgDznbo/0dKt+1VyvMrS/lBsHXoIQiYhCAGA7y38pkiT3ipQeZU102aS1DjSpqzkOCVER+jSXJblBzuCkEkIQgDgH6eOEm0oKtOe0nIds6ieqBrHfAQvgpBJCEIAYJ1AGCly2KTMxGj1aJ6sa3plsyw/SBCETEIQAgBrVY8UvfXVTn2965CKyypk0b6NkqQoh03P/rIbx3wEOIKQSQhCABB4HluwQS8v225pH6IcUvMUNnAMVAQhkxCEACAwVVS59PKybfq/r3/QroPHVeG09uuskU0a2S1TR064FBfp0FU9CEdWIgiZhCAEAMHB6vPOzoRpNOsQhExCEAKA4HHqeWff7z+qA0crZGGdtVtStENpidHqkME0mr8QhExCEAKA4BYI9UQ/F+2Q/ufCNnK6DEk29W3dROe1akI4MhFByCQEIQAIfhVVLs1a/r0++nav9pQeV3HpCQXal19cpF1PX92VaTSTEIRMQhACgNDjdBma8MYaLSwstrorp2kcaVNMZISyk+M0tBM7XNcXQcgkBCEACF0VVS79/YvtWr3jkEqOntDa3aUBVWxdbWy/bDVLitPqHYdYkeYhgpBJCEIAED5OPebj2z2l+rGkXOVVgfk1yYq0syMImYQgBADhLRCO+TibmAibmjSOUnpCtIZ0ZCqtGkHIJAQhAMDPj/nYf6TS8g0czyaveYJKyp06XF6l1k3jdNv5rTWgbdOwmkojCJmEIAQAOJNA3MDxbBw2adyFrfTDoXIdq3Aqr2WKxvZrGbKjRwQhkxCEAAC1OXUDx+0HjqmsvFLHKgJzCq02twxooQeGd9Sq7Qe173C50uKj1TsnJehHjwhCJiEIAQC88e66Pbr3X+tUXhlcgehUjaMcempUZ13W7Ryru1JvBCGTEIQAAN5yugx9ue2AVny/X5JN2346rPcL91rdLa81bRyh5LhoJURH6NLc4CrEJgiZhCAEADBD9e7WHxYWq7jsuMorXTp4rMrqbnnt5v7N1SwpTjsPHlOLlFjd2Dcw64wIQiYhCAEAfCWQd7j2xi0DWmjKZZ2s7kYNBCGTEIQAAL5WUeXSP1bscI+y/HDouGZ9scPqbnmlcaRNmUmxstmkDhmJurqntbtfE4RMQhACAFihosqll5dt0/99/YMOHK2UYRgqOR5cU2lRDpueHt1FPx2t8PtUGkHIJAQhAECg+HmdUenxKh0NsuX6kn+m0ghCJiEIAQACWaAfAVKbxpE2ZSXH+WxFGkHIJAQhAECgO/Ww2E17jyghOkLZybFaWFisE0ESkGySbjs/R/cPzzXlegQhkxCEAADB6tQz0tbsLpHTJZVXOgO61uh/TApDBCGTEIQAAKEmkHe/ttukTY8Na/A0maff3xENehcAABB0RnbN0vDOmTV2v46w2/Ti59ssPyvNZUj/WLFDtwxs5Zf3IwgBABCGHHab+rdNVf+2qe7HJlzcVl9s3a9/rdmtH0vKZZOhgt2lqnT5d/Jo58FjfnsvghAAAJB0MhwNbNdUA9s1dT92aiH2hqIyHa906qfDFapw+i4ctUiJ9dm1f44gBAAAanWmcCRJjy3YoJeXbTf9/ew26ca+LU2/bm0IQgAAwGtTLsvV5KHtNWv591q0YZ8kQ9nJsXr3myJVNWAq7daB/j3hnlVjdWDVGAAAnnO6DC3b/JNeWPqdtv10RMcrXTp8wunRa81aOi+xagwAAFjAYbfpgg5puqBDmvuxDwqLNOmtdTpWcXogskka1S1LT13d1a8jQdUIQgAAwKeGdsrUJbkZNVakNUuO0ege1p5QLxGEAACAH9RWdG01/49BBYn8/Hzl5uYqLy/P6q4AAAAfoVi6DhRLAwAQfDz9/mZECAAAhC2CEAAACFsEIQAAELYIQgAAIGwRhAAAQNgiCAEAgLBFEAIAAGGLnaXrUL3NUllZmcU9AQAAnqr+3q5ru0SCUB0OHz4sScrOzra4JwAAwFuHDx9WYmJirc+zs3QdXC6X9uzZo/j4eNls5h0KV1ZWpuzsbO3evZsdq32I++wf3Gf/4D77D/faP3x5nw3D0OHDh5WVlSW7vfZKIEaE6mC329WsWTOfXT8hIYG/ZH7AffYP7rN/cJ/9h3vtH766z2cbCapGsTQAAAhbBCEAABC2CEIWiYqK0tSpUxUVFWV1V0Ia99k/uM/+wX32H+61fwTCfaZYGgAAhC1GhAAAQNgiCAEAgLBFEAIAAGGLIAQAAMIWQcgC+fn5atmypaKjo9WnTx+tWrXK6i4FlSeffFJ5eXmKj49XWlqarrzySm3evLlGm/Lyco0fP15NmjRR48aNNXr0aO3du7dGm127dmnEiBGKjY1VWlqa7r33XlVVVfnzowSVp556SjabTXfffbf7Me6zOX788UfdcMMNatKkiWJiYtS5c2d99dVX7ucNw9BDDz2kzMxMxcTEaPDgwdq6dWuNaxw8eFBjxoxRQkKCkpKSdMstt+jIkSP+/igBzel0asqUKcrJyVFMTIxat26txx57rMZZVNxr7y1dulQjR45UVlaWbDab5s2bV+N5s+7pN998o4EDByo6OlrZ2dn64x//aM4HMOBXc+bMMSIjI41XXnnF+Pbbb41bb73VSEpKMvbu3Wt114LGkCFDjFmzZhmFhYVGQUGBMXz4cKN58+bGkSNH3G1uv/12Izs721i8eLHx1VdfGeedd57Rr18/9/NVVVVGp06djMGDBxtr1641Fi5caKSmphr333+/FR8p4K1atcpo2bKl0aVLF2PixInux7nPDXfw4EGjRYsWxk033WSsXLnS+P77740PP/zQ+O6779xtnnrqKSMxMdGYN2+esW7dOuPyyy83cnJyjOPHj7vbDB061Ojatavx5ZdfGp9//rnRpk0b47rrrrPiIwWsxx9/3GjSpImxYMECY/v27cbbb79tNG7c2Hj++efdbbjX3lu4cKHx4IMPGu+8844hyZg7d26N5824p6WlpUZ6eroxZswYo7Cw0HjzzTeNmJgY469//WuD+08Q8rPevXsb48ePd//sdDqNrKws48knn7SwV8Ft3759hiTjs88+MwzDMEpKSoxGjRoZb7/9trvNxo0bDUnGihUrDMM4+RfXbrcbxcXF7jYzZ840EhISjBMnTvj3AwS4w4cPG23btjUWLVpkXHDBBe4gxH02x+TJk40BAwbU+rzL5TIyMjKMp59+2v1YSUmJERUVZbz55puGYRjGhg0bDEnG6tWr3W3ef/99w2azGT/++KPvOh9kRowYYfz617+u8dhVV11ljBkzxjAM7rUZfh6EzLqnf/nLX4zk5OQa/9+YPHmy0a5duwb3makxP6qoqNDXX3+twYMHux+z2+0aPHiwVqxYYWHPgltpaakkKSUlRZL09ddfq7KyssZ9bt++vZo3b+6+zytWrFDnzp2Vnp7ubjNkyBCVlZXp22+/9WPvA9/48eM1YsSIGvdT4j6bZf78+erVq5euueYapaWlqXv37nrppZfcz2/fvl3FxcU17nNiYqL69OlT4z4nJSWpV69e7jaDBw+W3W7XypUr/fdhAly/fv20ePFibdmyRZK0bt06LVu2TMOGDZPEvfYFs+7pihUrdP755ysyMtLdZsiQIdq8ebMOHTrUoD5y6Kof7d+/X06ns8aXgiSlp6dr06ZNFvUquLlcLt19993q37+/OnXqJEkqLi5WZGSkkpKSarRNT09XcXGxu82Zfh+qn8NJc+bM0Zo1a7R69erTnuM+m+P777/XzJkzNWnSJD3wwANavXq17rrrLkVGRmrs2LHu+3Sm+3jqfU5LS6vxfEREhFJSUrjPp7jvvvtUVlam9u3by+FwyOl06vHHH9eYMWMkiXvtA2bd0+LiYuXk5Jx2jernkpOT691HghCC2vjx41VYWKhly5ZZ3ZWQs3v3bk2cOFGLFi1SdHS01d0JWS6XS7169dITTzwhSerevbsKCwv1wgsvaOzYsRb3LrS89dZbmj17tt544w117NhRBQUFuvvuu5WVlcW9DmNMjflRamqqHA7Haatq9u7dq4yMDIt6FbzuvPNOLViwQEuWLFGzZs3cj2dkZKiiokIlJSU12p96nzMyMs74+1D9HE5Ofe3bt089evRQRESEIiIi9Nlnn2natGmKiIhQeno699kEmZmZys3NrfFYhw4dtGvXLkn/vU9n+/9GRkaG9u3bV+P5qqoqHTx4kPt8invvvVf33Xefrr32WnXu3Fk33nijfvvb3+rJJ5+UxL32BbPuqS//X0IQ8qPIyEj17NlTixcvdj/mcrm0ePFi9e3b18KeBRfDMHTnnXdq7ty5+uSTT04bLu3Zs6caNWpU4z5v3rxZu3btct/nvn37av369TX+8i1atEgJCQmnfSmFq4svvljr169XQUGB+1evXr00ZswY939znxuuf//+p23/sGXLFrVo0UKSlJOTo4yMjBr3uaysTCtXrqxxn0tKSvT111+723zyySdyuVzq06ePHz5FcDh27Jjs9ppfew6HQy6XSxL32hfMuqd9+/bV0qVLVVlZ6W6zaNEitWvXrkHTYpJYPu9vc+bMMaKiooxXX33V2LBhg3HbbbcZSUlJNVbV4OzGjRtnJCYmGp9++qlRVFTk/nXs2DF3m9tvv91o3ry58cknnxhfffWV0bdvX6Nv377u56uXdV966aVGQUGB8cEHHxhNmzZlWXcdTl01ZhjcZzOsWrXKiIiIMB5//HFj69atxuzZs43Y2Fjj9ddfd7d56qmnjKSkJOPf//638c033xhXXHHFGZcfd+/e3Vi5cqWxbNkyo23btmG9pPtMxo4da5xzzjnu5fPvvPOOkZqaavzv//6vuw332nuHDx821q5da6xdu9aQZDzzzDPG2rVrjZ07dxqGYc49LSkpMdLT040bb7zRKCwsNObMmWPExsayfD5YTZ8+3WjevLkRGRlp9O7d2/jyyy+t7lJQkXTGX7NmzXK3OX78uHHHHXcYycnJRmxsrDFq1CijqKioxnV27NhhDBs2zIiJiTFSU1ON3/3ud0ZlZaWfP01w+XkQ4j6b49133zU6depkREVFGe3btzdefPHFGs+7XC5jypQpRnp6uhEVFWVcfPHFxubNm2u0OXDggHHdddcZjRs3NhISEoybb77ZOHz4sD8/RsArKyszJk6caDRv3tyIjo42WrVqZTz44IM1lmRzr723ZMmSM/4/eezYsYZhmHdP161bZwwYMMCIiooyzjnnHOOpp54ypf82wzhlS00AAIAwQo0QAAAIWwQhAAAQtghCAAAgbBGEAABA2CIIAQCAsEUQAgAAYYsgBAAAwhZBCAAAhC2CEAB4yWazad68eVZ3A4AJCEIAgspNN90km8122q+hQ4da3TUAQSjC6g4AgLeGDh2qWbNm1XgsKirKot4ACGaMCAEIOlFRUcrIyKjxKzk5WdLJaauZM2dq2LBhiomJUatWrfSvf/2rxuvXr1+viy66SDExMWrSpIluu+02HTlypEabV155RR07dlRUVJQyMzN155131nh+//79GjVqlGJjY9W2bVvNnz/ftx8agE8QhACEnClTpmj06NFat26dxowZo2uvvVYbN26UJB09elRDhgxRcnKyVq9erbffflsff/xxjaAzc+ZMjR8/XrfddpvWr1+v+fPnq02bNjXe45FHHtEvfvELffPNNxo+fLjGjBmjgwcP+vVzAjCBKWfYA4CfjB071nA4HEZcXFyNX48//rhhGIYhybj99ttrvKZPnz7GuHHjDMMwjBdffNFITk42jhw54n7+vffeM+x2u1FcXGwYhmFkZWUZDz74YK19kGT8/ve/d/985MgRQ5Lx/vvvm/Y5AfgHNUIAgs6gQYM0c+bMGo+lpKS4/7tv3741nuvbt68KCgokSRs3blTXrl0VFxfnfr5///5yuVzavHmzbDab9uzZo4svvvisfejSpYv7v+Pi4pSQkKB9+/bV9yMBsAhBCEDQiYuLO22qyiwxMTEetWvUqFGNn202m1wuly+6BMCHqBECEHK+/PLL037u0KGDJKlDhw5at26djh496n5++fLlstvtateuneLj49WyZUstXrzYr30GYA1GhAAEnRMnTqi4uLjGYxEREUpNTZUkvf322+rVq5cGDBig2bNna9WqVXr55ZclSWPGjNHUqVM1duxYPfzww/rpp580YcIE3XjjjUpPT5ckPfzww7r99tuVlpamYcOG6fDhw1q+fLkmTJjg3w8KwOcIQgCCzgcffKDMzMwaj7Vr106bNm2SdHJF15w5c3THHXcoMzNTb775pnJzcyVJsbGx+vDDDzVx4kTl5eUpNjZWo0eP1jPPPOO+1tixY1VeXq5nn31W99xzj1JTU3X11Vf77wMC8BubYRiG1Z0AALPYbDbNnTtXV155pdVdARAEqBECAABhiyAEAADCFjVCAEIKs/0AvMGIEAAACFsEIQAAELYIQgAAIGwRhAAAQNgiCAEAgLBFEAIAAGGLIAQAAMIWQQgAAISt/w8cO7ScdWphUQAAAABJRU5ErkJggg==\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training complete! Total training time: 740.59 seconds\n"]}],"source":["# Train the GNN model using the provided source and target graph embeddings, edges, and training data\n","trained_model = train_model_gnn(\n","    model=GIT_model,                # The GNN model to be trained (initialized earlier)\n","    x_src=x_src,                    # Source node embeddings (tensor for source graph)\n","    edge_src=edge_src,              # Source graph edges (undirected edge index for source graph)\n","    x_tgt=x_tgt,                    # Target node embeddings (tensor for target graph)\n","    edge_tgt=edge_tgt,              # Target graph edges (undirected edge index for target graph)\n","    tensor_term1=tensor_term1_o,    # Indices of source entities for training\n","    tensor_term2=tensor_term2_o,    # Indices of target entities for training\n","    tensor_score=tensor_score_o,    # Scores (labels) indicating if pairs match (1) or not (0)\n","    learning_rate=0.0001,            # Learning rate for the Adam optimizer\n","    weight_decay_value=1e-4,        # Weight decay for L2 regularization to prevent overfitting\n","    num_epochs=1000,                # Number of training epochs\n","    print_interval=10               # Interval at which to print training progress (every 10 epochs)\n",")"]},{"cell_type":"markdown","metadata":{"id":"MYyhvjcTUaae"},"source":["# GIT Application"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BZ_VqP6tq6iD"},"outputs":[],"source":["# Determine if a GPU is available and move the computations to it; otherwise, use the CPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Assuming the model has been trained and hyperparameters (x_src, edge_src, x_tgt, edge_tgt) are set\n","\n","# Move the trained GIT_model to the device (GPU or CPU)\n","GIT_model.to(device)\n","\n","# Move the data tensors to the same device (GPU or CPU)\n","x_tgt = x_tgt.to(device)         # Target node embeddings\n","edge_tgt = edge_tgt.to(device)   # Target graph edges\n","x_src = x_src.to(device)         # Source node embeddings\n","edge_src = edge_src.to(device)   # Source graph edges\n","\n","# Set the model to evaluation mode; this disables dropout and batch normalization\n","GIT_model.eval()\n","\n","# Pass the source and target embeddings through the trained GNN model to update the embeddings\n","with torch.no_grad():  # Disable gradient computation (inference mode)\n","    embeddings_tgt = GIT_model(x_tgt, edge_tgt)  # Get updated embeddings for the target graph\n","    embeddings_src = GIT_model(x_src, edge_src)  # Get updated embeddings for the source graph\n","\n","# Detach the embeddings from the computation graph and move them back to the CPU\n","# This step is useful if you need to use the embeddings for tasks outside PyTorch (e.g., saving to disk)\n","embeddings_tgt = embeddings_tgt.detach().cpu()  # Target graph embeddings\n","embeddings_src = embeddings_src.detach().cpu()  # Source graph embeddings\n","\n","# At this point, embeddings_tgt and embeddings_src contain the updated embeddings, ready for downstream tasks"]},{"cell_type":"markdown","metadata":{"id":"Og5fdoGJrTCG"},"source":["# Selecting embedding pairs to train the Gated Network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J0nTwc-dnjLn"},"outputs":[],"source":["# Read the training pairs from a CSV file into a pandas DataFrame\n","df_embeddings = pd.read_csv(train_file, index_col=0)\n","\n","# Extract columns and convert to NumPy arrays\n","tensor_term1 = df_embeddings['SrcEntity'].values.astype(int)  # Source entity indices\n","tensor_term2 = df_embeddings['TgtEntity'].values.astype(int)  # Target entity indices\n","tensor_score = df_embeddings['Score'].values.astype(float)  # Matching scores\n","\n","# Split data into training and validation sets\n","tensor_term1_train, tensor_term1_val, tensor_term2_train, tensor_term2_val, tensor_score_train, tensor_score_val = train_test_split(\n","    tensor_term1, tensor_term2, tensor_score, test_size=0.3, random_state=42\n",")\n","\n","# Convert split data to PyTorch tensors\n","tensor_term1_train = torch.from_numpy(tensor_term1_train).type(torch.LongTensor)\n","tensor_term2_train = torch.from_numpy(tensor_term2_train).type(torch.LongTensor)\n","tensor_score_train = torch.from_numpy(tensor_score_train).type(torch.FloatTensor)\n","\n","tensor_term1_val = torch.from_numpy(tensor_term1_val).type(torch.LongTensor)\n","tensor_term2_val = torch.from_numpy(tensor_term2_val).type(torch.LongTensor)\n","tensor_score_val = torch.from_numpy(tensor_score_val).type(torch.FloatTensor)\n","\n","# Move the embeddings back to the CPU if not already there\n","x_tgt = x_tgt.cpu()  # Target node embeddings\n","x_src = x_src.cpu()  # Source node embeddings\n","\n","# Select embeddings for the training set\n","X1_train = select_rows_by_index(embeddings_src, tensor_term1_train)\n","X2_train = select_rows_by_index(x_src, tensor_term1_train)\n","X3_train = select_rows_by_index(embeddings_tgt, tensor_term2_train)\n","X4_train = select_rows_by_index(x_tgt, tensor_term2_train)\n","\n","# Select embeddings for the validation set\n","X1_val = select_rows_by_index(embeddings_src, tensor_term1_val)\n","X2_val = select_rows_by_index(x_src, tensor_term1_val)\n","X3_val = select_rows_by_index(embeddings_tgt, tensor_term2_val)\n","X4_val = select_rows_by_index(x_tgt, tensor_term2_val)\n","\n","# Now you have:\n","# - Training tensors: X1_train, X2_train, X3_train, X4_train, tensor_score_train\n","# - Validation tensors: X1_val, X2_val, X3_val, X4_val, tensor_score_val"]},{"cell_type":"code","source":["positive_weight = len(tensor_score_train) / (weight_train * tensor_score_train.sum())"],"metadata":{"id":"wR3PbrbBETJA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fNdCgaTMExPK"},"source":["# Gated Network Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gof1eIPIWSVU"},"outputs":[],"source":["def train_gated_combination_model(X1_t, X2_t, X3_t, X4_t, tensor_score_o,\n","                                  X1_val, X2_val, X3_val, X4_val, tensor_score_val,\n","                                  epochs=120, batch_size=32, learning_rate=0.001, weight_decay=1e-5):\n","    \"\"\"\n","    Trains the GatedCombination model with training and validation data, using ReduceLROnPlateau scheduler.\n","    \"\"\"\n","\n","    # Create datasets and DataLoaders\n","    train_dataset = TensorDataset(X1_t, X2_t, X3_t, X4_t, tensor_score_o)\n","    val_dataset = TensorDataset(X1_val, X2_val, X3_val, X4_val, tensor_score_val)\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = GatedCombination(X1_t.shape[1]).to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","\n","    # Use ReduceLROnPlateau scheduler\n","    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n","\n","    criterion = WeightedBCELoss(pos_weight=positive_weight).to(device)\n","\n","    train_losses, val_losses = [], []\n","\n","    start_time = time.time()\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        total_train_loss, y_true_train, y_pred_train = 0.0, [], []\n","\n","        for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in train_loader:\n","            batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (batch_X1.to(device), batch_X2.to(device),\n","                                                               batch_X3.to(device), batch_X4.to(device), batch_y.to(device))\n","            optimizer.zero_grad()\n","            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","            loss = criterion(outputs, batch_y.unsqueeze(1).float())\n","            loss.backward()\n","            optimizer.step()\n","            total_train_loss += loss.item()\n","            y_true_train.extend(batch_y.cpu().numpy())\n","            y_pred_train.extend((outputs > 0.2).float().cpu().numpy())\n","\n","        train_f1 = f1_score(y_true_train, y_pred_train)\n","        train_loss = total_train_loss / len(train_loader)\n","        train_losses.append(train_loss)\n","\n","        # Validation phase\n","        model.eval()\n","        total_val_loss, y_true_val, y_pred_val = 0.0, [], []\n","        with torch.no_grad():\n","            for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in val_loader:\n","                batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (batch_X1.to(device), batch_X2.to(device),\n","                                                                   batch_X3.to(device), batch_X4.to(device), batch_y.to(device))\n","                outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","                val_loss = criterion(outputs, batch_y.unsqueeze(1).float())\n","                total_val_loss += val_loss.item()\n","                y_true_val.extend(batch_y.cpu().numpy())\n","                y_pred_val.extend((outputs > 0.4).float().cpu().numpy())\n","\n","        val_f1 = f1_score(y_true_val, y_pred_val)\n","        avg_val_loss = total_val_loss / len(val_loader)\n","        val_losses.append(avg_val_loss)\n","\n","        # Step the scheduler with validation loss\n","        scheduler.step(avg_val_loss)\n","\n","        # Print training and validation metrics\n","        print(f\"Epoch [{epoch + 1}/{epochs}] Training Loss: {train_loss:.4f}, F1 Score: {train_f1:.4f} | \"\n","              f\"Validation Loss: {avg_val_loss:.4f}, F1 Score: {val_f1:.4f}\")\n","\n","    end_time = time.time()\n","\n","    # Plotting\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(train_losses, label=\"Training Loss\", marker='o')\n","    plt.plot(val_losses, label=\"Validation Loss\", marker='x')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    print(f\"Training complete! Total time: {end_time - start_time:.2f} seconds\")\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"l11dgb8ei69T","outputId":"31704b90-1cfb-410c-80f3-d48c81fa744d","executionInfo":{"status":"ok","timestamp":1732183504524,"user_tz":-60,"elapsed":839115,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/100] Training Loss: 0.3466, F1 Score: 0.0924 | Validation Loss: 0.2912, F1 Score: 0.0000\n","Epoch [2/100] Training Loss: 0.2581, F1 Score: 0.9314 | Validation Loss: 0.2347, F1 Score: 0.0000\n","Epoch [3/100] Training Loss: 0.2118, F1 Score: 0.9259 | Validation Loss: 0.1949, F1 Score: 0.4505\n","Epoch [4/100] Training Loss: 0.1766, F1 Score: 0.9020 | Validation Loss: 0.1631, F1 Score: 0.7677\n","Epoch [5/100] Training Loss: 0.1488, F1 Score: 0.8698 | Validation Loss: 0.1381, F1 Score: 0.8645\n","Epoch [6/100] Training Loss: 0.1263, F1 Score: 0.8488 | Validation Loss: 0.1182, F1 Score: 0.9140\n","Epoch [7/100] Training Loss: 0.1082, F1 Score: 0.8400 | Validation Loss: 0.1018, F1 Score: 0.9281\n","Epoch [8/100] Training Loss: 0.0936, F1 Score: 0.8261 | Validation Loss: 0.0889, F1 Score: 0.9291\n","Epoch [9/100] Training Loss: 0.0820, F1 Score: 0.8261 | Validation Loss: 0.0783, F1 Score: 0.9305\n","Epoch [10/100] Training Loss: 0.0725, F1 Score: 0.8270 | Validation Loss: 0.0701, F1 Score: 0.9335\n","Epoch [11/100] Training Loss: 0.0649, F1 Score: 0.8293 | Validation Loss: 0.0636, F1 Score: 0.9329\n","Epoch [12/100] Training Loss: 0.0586, F1 Score: 0.8330 | Validation Loss: 0.0580, F1 Score: 0.9287\n","Epoch [13/100] Training Loss: 0.0535, F1 Score: 0.8266 | Validation Loss: 0.0535, F1 Score: 0.9309\n","Epoch [14/100] Training Loss: 0.0494, F1 Score: 0.8341 | Validation Loss: 0.0500, F1 Score: 0.9255\n","Epoch [15/100] Training Loss: 0.0460, F1 Score: 0.8338 | Validation Loss: 0.0468, F1 Score: 0.9319\n","Epoch [16/100] Training Loss: 0.0429, F1 Score: 0.8370 | Validation Loss: 0.0444, F1 Score: 0.9289\n","Epoch [17/100] Training Loss: 0.0405, F1 Score: 0.8370 | Validation Loss: 0.0415, F1 Score: 0.9289\n","Epoch [18/100] Training Loss: 0.0384, F1 Score: 0.8440 | Validation Loss: 0.0403, F1 Score: 0.9194\n","Epoch [19/100] Training Loss: 0.0364, F1 Score: 0.8441 | Validation Loss: 0.0384, F1 Score: 0.9333\n","Epoch [20/100] Training Loss: 0.0352, F1 Score: 0.8473 | Validation Loss: 0.0374, F1 Score: 0.9259\n","Epoch [21/100] Training Loss: 0.0337, F1 Score: 0.8450 | Validation Loss: 0.0362, F1 Score: 0.9210\n","Epoch [22/100] Training Loss: 0.0325, F1 Score: 0.8455 | Validation Loss: 0.0353, F1 Score: 0.9215\n","Epoch [23/100] Training Loss: 0.0313, F1 Score: 0.8478 | Validation Loss: 0.0351, F1 Score: 0.9177\n","Epoch [24/100] Training Loss: 0.0303, F1 Score: 0.8460 | Validation Loss: 0.0335, F1 Score: 0.9300\n","Epoch [25/100] Training Loss: 0.0296, F1 Score: 0.8529 | Validation Loss: 0.0337, F1 Score: 0.9194\n","Epoch [26/100] Training Loss: 0.0287, F1 Score: 0.8544 | Validation Loss: 0.0320, F1 Score: 0.9156\n","Epoch [27/100] Training Loss: 0.0280, F1 Score: 0.8531 | Validation Loss: 0.0318, F1 Score: 0.9175\n","Epoch [28/100] Training Loss: 0.0273, F1 Score: 0.8573 | Validation Loss: 0.0307, F1 Score: 0.9196\n","Epoch [29/100] Training Loss: 0.0266, F1 Score: 0.8566 | Validation Loss: 0.0313, F1 Score: 0.9250\n","Epoch [30/100] Training Loss: 0.0263, F1 Score: 0.8542 | Validation Loss: 0.0298, F1 Score: 0.9169\n","Epoch [31/100] Training Loss: 0.0258, F1 Score: 0.8552 | Validation Loss: 0.0318, F1 Score: 0.9065\n","Epoch [32/100] Training Loss: 0.0253, F1 Score: 0.8599 | Validation Loss: 0.0300, F1 Score: 0.9162\n","Epoch [33/100] Training Loss: 0.0248, F1 Score: 0.8610 | Validation Loss: 0.0294, F1 Score: 0.9193\n","Epoch [34/100] Training Loss: 0.0243, F1 Score: 0.8541 | Validation Loss: 0.0295, F1 Score: 0.9254\n","Epoch [35/100] Training Loss: 0.0243, F1 Score: 0.8557 | Validation Loss: 0.0290, F1 Score: 0.9212\n","Epoch [36/100] Training Loss: 0.0236, F1 Score: 0.8611 | Validation Loss: 0.0287, F1 Score: 0.9200\n","Epoch [37/100] Training Loss: 0.0234, F1 Score: 0.8630 | Validation Loss: 0.0289, F1 Score: 0.9160\n","Epoch [38/100] Training Loss: 0.0231, F1 Score: 0.8592 | Validation Loss: 0.0279, F1 Score: 0.9247\n","Epoch [39/100] Training Loss: 0.0229, F1 Score: 0.8629 | Validation Loss: 0.0280, F1 Score: 0.9280\n","Epoch [40/100] Training Loss: 0.0228, F1 Score: 0.8650 | Validation Loss: 0.0278, F1 Score: 0.9219\n","Epoch [41/100] Training Loss: 0.0222, F1 Score: 0.8610 | Validation Loss: 0.0277, F1 Score: 0.9280\n","Epoch [42/100] Training Loss: 0.0223, F1 Score: 0.8619 | Validation Loss: 0.0274, F1 Score: 0.9226\n","Epoch [43/100] Training Loss: 0.0218, F1 Score: 0.8616 | Validation Loss: 0.0270, F1 Score: 0.9200\n","Epoch [44/100] Training Loss: 0.0216, F1 Score: 0.8628 | Validation Loss: 0.0280, F1 Score: 0.9179\n","Epoch [45/100] Training Loss: 0.0213, F1 Score: 0.8627 | Validation Loss: 0.0271, F1 Score: 0.9198\n","Epoch [46/100] Training Loss: 0.0211, F1 Score: 0.8664 | Validation Loss: 0.0273, F1 Score: 0.9196\n","Epoch [47/100] Training Loss: 0.0210, F1 Score: 0.8588 | Validation Loss: 0.0265, F1 Score: 0.9217\n","Epoch [48/100] Training Loss: 0.0208, F1 Score: 0.8656 | Validation Loss: 0.0265, F1 Score: 0.9181\n","Epoch [49/100] Training Loss: 0.0209, F1 Score: 0.8712 | Validation Loss: 0.0258, F1 Score: 0.9210\n","Epoch [50/100] Training Loss: 0.0206, F1 Score: 0.8686 | Validation Loss: 0.0261, F1 Score: 0.9158\n","Epoch [51/100] Training Loss: 0.0199, F1 Score: 0.8688 | Validation Loss: 0.0277, F1 Score: 0.9277\n","Epoch [52/100] Training Loss: 0.0204, F1 Score: 0.8657 | Validation Loss: 0.0267, F1 Score: 0.9240\n","Epoch [53/100] Training Loss: 0.0203, F1 Score: 0.8700 | Validation Loss: 0.0272, F1 Score: 0.9160\n","Epoch [54/100] Training Loss: 0.0198, F1 Score: 0.8660 | Validation Loss: 0.0255, F1 Score: 0.9189\n","Epoch [55/100] Training Loss: 0.0201, F1 Score: 0.8626 | Validation Loss: 0.0260, F1 Score: 0.9107\n","Epoch [56/100] Training Loss: 0.0194, F1 Score: 0.8684 | Validation Loss: 0.0255, F1 Score: 0.9231\n","Epoch [57/100] Training Loss: 0.0197, F1 Score: 0.8707 | Validation Loss: 0.0267, F1 Score: 0.9280\n","Epoch [58/100] Training Loss: 0.0193, F1 Score: 0.8705 | Validation Loss: 0.0269, F1 Score: 0.9261\n","Epoch [59/100] Training Loss: 0.0191, F1 Score: 0.8717 | Validation Loss: 0.0254, F1 Score: 0.9172\n","Epoch [60/100] Training Loss: 0.0195, F1 Score: 0.8689 | Validation Loss: 0.0260, F1 Score: 0.9129\n","Epoch [61/100] Training Loss: 0.0185, F1 Score: 0.8693 | Validation Loss: 0.0258, F1 Score: 0.9250\n","Epoch [62/100] Training Loss: 0.0190, F1 Score: 0.8726 | Validation Loss: 0.0259, F1 Score: 0.9087\n","Epoch [63/100] Training Loss: 0.0188, F1 Score: 0.8708 | Validation Loss: 0.0263, F1 Score: 0.9254\n","Epoch [64/100] Training Loss: 0.0188, F1 Score: 0.8752 | Validation Loss: 0.0260, F1 Score: 0.9201\n","Epoch [65/100] Training Loss: 0.0188, F1 Score: 0.8738 | Validation Loss: 0.0269, F1 Score: 0.9250\n","Epoch [66/100] Training Loss: 0.0184, F1 Score: 0.8764 | Validation Loss: 0.0256, F1 Score: 0.9224\n","Epoch [67/100] Training Loss: 0.0186, F1 Score: 0.8687 | Validation Loss: 0.0263, F1 Score: 0.9304\n","Epoch [68/100] Training Loss: 0.0183, F1 Score: 0.8771 | Validation Loss: 0.0247, F1 Score: 0.9198\n","Epoch [69/100] Training Loss: 0.0184, F1 Score: 0.8725 | Validation Loss: 0.0252, F1 Score: 0.9203\n","Epoch [70/100] Training Loss: 0.0183, F1 Score: 0.8705 | Validation Loss: 0.0261, F1 Score: 0.9208\n","Epoch [71/100] Training Loss: 0.0183, F1 Score: 0.8691 | Validation Loss: 0.0265, F1 Score: 0.9227\n","Epoch [72/100] Training Loss: 0.0184, F1 Score: 0.8750 | Validation Loss: 0.0257, F1 Score: 0.9169\n","Epoch [73/100] Training Loss: 0.0175, F1 Score: 0.8729 | Validation Loss: 0.0248, F1 Score: 0.9203\n","Epoch [74/100] Training Loss: 0.0179, F1 Score: 0.8748 | Validation Loss: 0.0261, F1 Score: 0.9309\n","Epoch [75/100] Training Loss: 0.0177, F1 Score: 0.8762 | Validation Loss: 0.0242, F1 Score: 0.9206\n","Epoch [76/100] Training Loss: 0.0180, F1 Score: 0.8771 | Validation Loss: 0.0247, F1 Score: 0.9219\n","Epoch [77/100] Training Loss: 0.0176, F1 Score: 0.8794 | Validation Loss: 0.0252, F1 Score: 0.9303\n","Epoch [78/100] Training Loss: 0.0176, F1 Score: 0.8766 | Validation Loss: 0.0248, F1 Score: 0.9264\n","Epoch [79/100] Training Loss: 0.0177, F1 Score: 0.8731 | Validation Loss: 0.0245, F1 Score: 0.9240\n","Epoch [80/100] Training Loss: 0.0177, F1 Score: 0.8795 | Validation Loss: 0.0245, F1 Score: 0.9220\n","Epoch [81/100] Training Loss: 0.0177, F1 Score: 0.8809 | Validation Loss: 0.0241, F1 Score: 0.9140\n","Epoch [82/100] Training Loss: 0.0177, F1 Score: 0.8818 | Validation Loss: 0.0251, F1 Score: 0.9183\n","Epoch [83/100] Training Loss: 0.0169, F1 Score: 0.8747 | Validation Loss: 0.0250, F1 Score: 0.9241\n","Epoch [84/100] Training Loss: 0.0173, F1 Score: 0.8810 | Validation Loss: 0.0248, F1 Score: 0.9131\n","Epoch [85/100] Training Loss: 0.0172, F1 Score: 0.8739 | Validation Loss: 0.0244, F1 Score: 0.9189\n","Epoch [86/100] Training Loss: 0.0172, F1 Score: 0.8818 | Validation Loss: 0.0249, F1 Score: 0.9147\n","Epoch [87/100] Training Loss: 0.0168, F1 Score: 0.8798 | Validation Loss: 0.0244, F1 Score: 0.9224\n","Epoch [88/100] Training Loss: 0.0173, F1 Score: 0.8823 | Validation Loss: 0.0250, F1 Score: 0.9172\n","Epoch [89/100] Training Loss: 0.0169, F1 Score: 0.8769 | Validation Loss: 0.0249, F1 Score: 0.9075\n","Epoch [90/100] Training Loss: 0.0172, F1 Score: 0.8785 | Validation Loss: 0.0245, F1 Score: 0.9166\n","Epoch [91/100] Training Loss: 0.0167, F1 Score: 0.8786 | Validation Loss: 0.0250, F1 Score: 0.9125\n","Epoch 00092: reducing learning rate of group 0 to 1.0000e-04.\n","Epoch [92/100] Training Loss: 0.0165, F1 Score: 0.8802 | Validation Loss: 0.0245, F1 Score: 0.9264\n","Epoch [93/100] Training Loss: 0.0141, F1 Score: 0.8897 | Validation Loss: 0.0238, F1 Score: 0.9243\n","Epoch [94/100] Training Loss: 0.0138, F1 Score: 0.8935 | Validation Loss: 0.0236, F1 Score: 0.9234\n","Epoch [95/100] Training Loss: 0.0136, F1 Score: 0.8926 | Validation Loss: 0.0237, F1 Score: 0.9224\n","Epoch [96/100] Training Loss: 0.0134, F1 Score: 0.8946 | Validation Loss: 0.0238, F1 Score: 0.9231\n","Epoch [97/100] Training Loss: 0.0134, F1 Score: 0.9012 | Validation Loss: 0.0237, F1 Score: 0.9226\n","Epoch [98/100] Training Loss: 0.0133, F1 Score: 0.8942 | Validation Loss: 0.0237, F1 Score: 0.9234\n","Epoch [99/100] Training Loss: 0.0133, F1 Score: 0.8966 | Validation Loss: 0.0237, F1 Score: 0.9212\n","Epoch [100/100] Training Loss: 0.0131, F1 Score: 0.8976 | Validation Loss: 0.0238, F1 Score: 0.9243\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x500 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training complete! Total time: 838.53 seconds\n"]}],"source":["# Train the GatedCombination model using training and validation data\n","trained_model = train_gated_combination_model(\n","    X1_train,          # Updated source embeddings (after applying the GNN model)\n","    X2_train,          # Original source embeddings (before applying the GNN model)\n","    X3_train,          # Updated target embeddings (after applying the GNN model)\n","    X4_train,          # Original target embeddings (before applying the GNN model)\n","    tensor_score_train, # Ground truth labels for the training set (1 for matched pairs, 0 for unmatched pairs)\n","\n","    X1_val,            # Updated source embeddings for the validation set\n","    X2_val,            # Original source embeddings for the validation set\n","    X3_val,            # Updated target embeddings for the validation set\n","    X4_val,            # Original target embeddings for the validation set\n","    tensor_score_val,  # Ground truth labels for the validation set (1 for matched pairs, 0 for unmatched pairs)\n","\n","    epochs=100,        # Number of epochs (iterations over the entire training dataset)\n","    batch_size=32,     # Number of training samples processed in one forward/backward pass\n","    learning_rate=0.001, # Learning rate for the optimizer (controls step size during optimization)\n","    weight_decay=1e-5  # Weight decay (L2 regularization) to prevent overfitting\n",")"]},{"cell_type":"markdown","metadata":{"id":"uAmLuMtGW9c2"},"source":["# **Mappings Selector**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lnFtpUAfJQHl"},"outputs":[],"source":["# Build an indexed dictionary for the source ontology classes\n","# src_class is the file path to the JSON file containing the source ontology classes\n","indexed_dict_src = build_indexed_dict(src_class)\n","\n","# Build an indexed dictionary for the target ontology classes\n","# tgt_class is the file path to the JSON file containing the target ontology classes\n","indexed_dict_tgt = build_indexed_dict(tgt_class)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"beipwavuJQHl"},"outputs":[],"source":["# Read the candidate pairs from a Candidates CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(candidates_Prediction, index_col=0)\n","\n","# Extract the 'SrcEntity' column (source entity indices) and convert it to a NumPy array of integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)\n","\n","# Extract the 'TgtEntity' column (target entity indices) and convert it to a NumPy array of integers\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)\n","\n","# Convert the source entity indices to a PyTorch LongTensor\n","src_entity_tensor_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)\n","\n","# Convert the target entity indices to a PyTorch LongTensor\n","tgt_entity_tenso_or = torch.from_numpy(tensor_term2).type(torch.LongTensor)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ECLhmxyKJQHl"},"outputs":[],"source":["# Select rows from the updated source embeddings based on the indices in src_entity_tensor_o\n","X1_tt = select_rows_by_index(embeddings_src, src_entity_tensor_o)\n","\n","# Select rows from the original source embeddings based on the indices in src_entity_tensor_o\n","X2_tt = select_rows_by_index(x_src, src_entity_tensor_o)\n","\n","# Select rows from the updated target embeddings based on the indices in tgt_entity_tenso_or\n","X3_tt = select_rows_by_index(embeddings_tgt, tgt_entity_tenso_or)\n","\n","# Select rows from the original target embeddings based on the indices in tgt_entity_tenso_or\n","X4_tt = select_rows_by_index(x_tgt, tgt_entity_tenso_or)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4d3f6c09-30f6-4c08-f81d-58a4b9711e8d","id":"UFP6OQR-7D4N","executionInfo":{"status":"ok","timestamp":1732183587842,"user_tz":-60,"elapsed":38692,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting time: 14.54 seconds\n","Predictions saved to /content/gdrive/My Drive/BioGITOM-VLDB/ncit2doid/Results/ncit2doid_all_predictions.tsv\n"]}],"source":["# Generate predictions for candidate mappings using the trained GatedCombination model\n","Prediction_with_candidates(\n","    model=trained_model,             # The trained GatedCombination model used to evaluate similarity\n","    X1_tt=X1_tt,                     # Updated source embeddings (after applying the GIT model)\n","    X2_tt=X2_tt,                     # Original source embeddings (before applying the GIT model)\n","    X3_tt=X3_tt,                     # Updated target embeddings (after applying the GIT model)\n","    X4_tt=X4_tt,                     # Original target embeddings (before applying the GIT model)\n","    src_entity_tensor_o=src_entity_tensor_o,  # Tensor of source entity indices used for evaluation\n","    tgt_entity_tensor_o=tgt_entity_tenso_or,  # Tensor of target entity indices used for evaluation\n","    indexed_dict_src=indexed_dict_src,        # Dictionary mapping source entity indices to their URIs\n","    indexed_dict_tgt=indexed_dict_tgt,        # Dictionary mapping target entity indices to their URIs\n","    all_predictions_path=all_predictions_path # Path to save all predictions with similarity scores in TSV format\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mEc12J-B7D4N","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ecc691f6-0e83-4870-c6fd-c37bc896b0c0","executionInfo":{"status":"ok","timestamp":1732183603980,"user_tz":-60,"elapsed":16140,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Positive predictions: 3228\n"]}],"source":["# Filter the highest scoring predictions from the predictions file and save the results to a new file\n","matching_results_df = filter_highest_predictions(\n","    all_predictions_path,  # Path to the file containing all predictions with scores for all candidate pairs\n","    prediction_path        # Path where the filtered predictions with highest scores will be saved\n",")"]},{"cell_type":"markdown","metadata":{"id":"BIx74lNV7D4O"},"source":["# **Evaluation**"]},{"cell_type":"markdown","source":["# Global metrics calculation"],"metadata":{"id":"Pp3IpBBfWn9m"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bkOewzXr7D4O","outputId":"2e61642a-e8cc-4149-95b3-2b0923cef889","executionInfo":{"status":"ok","timestamp":1732183604945,"user_tz":-60,"elapsed":968,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Correct Predictions: 2847\n","{'P': 0.882, 'R': 0.868, 'F1': 0.875}\n"]}],"source":["# Retrieve the indices of the ignored classes (from source and target ontologies)\n","ignored_class_index = get_ignored_class_index(src_onto)  # Get ignored class indices from source ontology\n","ignored_class_index.update(get_ignored_class_index(tgt_onto))  # Update with ignored class indices from target ontology\n","\n","# Read the predicted mappings from the prediction results file\n","preds = EntityMapping.read_table_mappings(prediction_path)\n","\n","# Read the reference mappings from the ground truth test file\n","refs = ReferenceMapping.read_table_mappings(f\"{dataset_dir}/refs_equiv/test.tsv\")\n","\n","# Filter the predicted mappings to remove any mappings that involve ignored classes\n","preds = remove_ignored_mappings(preds, ignored_class_index)\n","\n","# Compute the precision, recall, and F1-score by comparing predictions with the reference mappings\n","results = AlignmentEvaluator.f1(preds, refs)\n","\n","preds2 = [p.to_tuple() for p in preds]\n","refs2 = [r.to_tuple() for r in refs]\n","\n","correct= len(set(preds2).intersection(set(refs2)))\n","\n","print(f\"Number of Correct Predictions: {correct}\")\n","\n","# Print the computed precision, recall, and F1-score metrics\n","print(results)"]},{"cell_type":"markdown","source":["# Ranked-based metrics calculation"],"metadata":{"id":"aECB6igZW04C"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-AK-jADkSbTa"},"outputs":[],"source":["# Read the candidate pairs from a Candidates CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(candidates_Rank, index_col=0)\n","\n","# Extract the 'SrcEntity' column (source entity indices) and convert it to a NumPy array of integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)\n","\n","# Extract the 'TgtEntity' column (target entity indices) and convert it to a NumPy array of integers\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)\n","\n","# Convert the source entity indices to a PyTorch LongTensor\n","src_entity_tensor_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)\n","\n","# Convert the target entity indices to a PyTorch LongTensor\n","tgt_entity_tenso_or = torch.from_numpy(tensor_term2).type(torch.LongTensor)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oyOzcLv-SbTb"},"outputs":[],"source":["# Select rows from the updated source embeddings based on the indices in src_entity_tensor_o\n","X1_tt = select_rows_by_index(embeddings_src, src_entity_tensor_o)\n","\n","# Select rows from the original source embeddings based on the indices in src_entity_tensor_o\n","X2_tt = select_rows_by_index(x_src, src_entity_tensor_o)\n","\n","# Select rows from the updated target embeddings based on the indices in tgt_entity_tenso_or\n","X3_tt = select_rows_by_index(embeddings_tgt, tgt_entity_tenso_or)\n","\n","# Select rows from the original target embeddings based on the indices in tgt_entity_tenso_or\n","X4_tt = select_rows_by_index(x_tgt, tgt_entity_tenso_or)"]},{"cell_type":"code","source":["# Perform ranking-based predictions using the trained GatedCombination model\n","# Generate predictions for candidate mappings using the trained GatedCombination model\n","Prediction_with_candidates(\n","    model=trained_model,             # The trained GatedCombination model used to evaluate similarity\n","    X1_tt=X1_tt,                     # Updated source embeddings (after applying the GIT model)\n","    X2_tt=X2_tt,                     # Original source embeddings (before applying the GIT model)\n","    X3_tt=X3_tt,                     # Updated target embeddings (after applying the GIT model)\n","    X4_tt=X4_tt,                     # Original target embeddings (before applying the GIT model)\n","    src_entity_tensor_o=src_entity_tensor_o,  # Tensor of source entity indices used for evaluation\n","    tgt_entity_tensor_o=tgt_entity_tenso_or,  # Tensor of target entity indices used for evaluation\n","    indexed_dict_src=indexed_dict_src,        # Dictionary mapping source entity indices to their URIs\n","    indexed_dict_tgt=indexed_dict_tgt,        # Dictionary mapping target entity indices to their URIs\n","    all_predictions_path=all_predictions_path_ranked, # Path where the ranked predictions will be saved in TSV format\n",")"],"metadata":{"id":"-O2f7X6cSb-m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732184683010,"user_tz":-60,"elapsed":37454,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"749649b0-4c58-4e9b-d949-c2fc3e2389c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting time: 13.93 seconds\n","Predictions saved to /content/gdrive/My Drive/BioGITOM-VLDB/ncit2doid/Results/ncit2doid_all_predictions_ranked.tsv\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_402seVv7D4O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732184702062,"user_tz":-60,"elapsed":19055,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"a9b7da67-239f-4f41-fedf-e3bcd720998d"},"outputs":[{"output_type":"stream","name":"stdout","text":["MRR and Hits@k Results:\n","{'MRR': 0.9020788874521052, 'Hits@k': {1: 0.849390243902439, 5: 0.9679878048780488, 10: 0.9850609756097561}}\n"]}],"source":["# Compute MRR and Hits@k metrics\n","# This function evaluates the predicted rankings against the reference mappings\n","results = compute_mrr_and_hits(\n","    reference_file=test_cands,             # Reference file with true ranks\n","    predicted_file=all_predictions_path_ranked,             # File containing predicted rankings\n","    output_file=formatted_predictions_path,    # File path to save formatted predictions\n","    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",")\n","\n","# Display the computed metrics\n","print(\"MRR and Hits@k Results:\")\n","print(results)  # Output the Mean Reciprocal Rank (MRR) and Hits@k metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wStfa4eZ7D4O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732184705726,"user_tz":-60,"elapsed":3667,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"cbd65c07-bb57-49df-d1a2-c9fc76e3c5cb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ranking Evaluation Results at K=1, 5, and 10:\n","{'MRR': 0.9020788874521052, 'Hits@1': 0.849390243902439, 'Hits@5': 0.9679878048780488, 'Hits@10': 0.9850609756097561}\n"]}],"source":["# Call the ranking evaluation function, passing the path to the formatted predictions file.\n","# Ks specifies the evaluation levels, checking if the correct target is within the top K candidates.\n","results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n","print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n","print(results)"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}