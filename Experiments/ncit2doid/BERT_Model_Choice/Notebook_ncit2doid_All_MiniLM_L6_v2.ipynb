{"cells":[{"cell_type":"markdown","metadata":{"id":"MkAX88H3RNRW"},"source":["# **Package Installation**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SlL2v0xgmFJ-","outputId":"c3a424d1-afb2-433c-c435-b97c9e92d0db","executionInfo":{"status":"ok","timestamp":1732210750182,"user_tz":-60,"elapsed":205566,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==2.0.0\n","  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.16.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n","  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n","  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n","  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n","  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n","  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n","  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.0.0 (from torch==2.0.0)\n","  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (75.1.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.45.0)\n","Collecting cmake (from triton==2.0.0->torch==2.0.0)\n","  Downloading cmake-3.31.0.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n","Collecting lit (from triton==2.0.0->torch==2.0.0)\n","  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n","Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m575.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m568.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cmake-3.31.0.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.8/27.8 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, cmake, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.1+cpu\n","    Uninstalling torch-2.5.1+cpu:\n","      Successfully uninstalled torch-2.5.1+cpu\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.5.1+cpu requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\n","torchvision 0.20.1+cpu requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed cmake-3.31.0.1 lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 triton-2.0.0\n","Collecting torch-geometric==2.4.0\n","  Downloading torch_geometric-2.4.0-py3-none-any.whl.metadata (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (4.66.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (3.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (2.32.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (3.2.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.5.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric==2.4.0) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (2024.8.30)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.4.0) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.4.0) (3.5.0)\n","Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-geometric\n","Successfully installed torch-geometric-2.4.0\n","Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_scatter-2.1.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (494 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_sparse-0.6.18%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-cluster\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_cluster-1.6.3%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (751 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.3/751.3 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-spline-conv\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (208 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n","Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n","Installing collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster\n","Successfully installed torch-cluster-1.6.3+pt20cpu torch-scatter-2.1.2+pt20cpu torch-sparse-0.6.18+pt20cpu torch-spline-conv-1.2.2+pt20cpu\n","Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.5.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.9/208.9 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.4/319.4 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting deeponto\n","  Downloading deeponto-0.9.2-py3-none-any.whl.metadata (15 kB)\n","Collecting JPype1 (from deeponto)\n","  Downloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting yacs (from deeponto)\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deeponto) (2.0.0)\n","Collecting anytree (from deeponto)\n","  Downloading anytree-2.12.1-py3-none-any.whl.metadata (8.1 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from deeponto) (8.1.7)\n","Collecting dill (from deeponto)\n","  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from deeponto) (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deeponto) (1.26.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deeponto) (1.5.2)\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (from deeponto) (4.46.2)\n","Collecting datasets (from deeponto)\n","  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.7.5)\n","Collecting pprintpp (from deeponto)\n","  Downloading pprintpp-0.4.0-py2.py3-none-any.whl.metadata (7.9 kB)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.4.2)\n","Collecting lxml (from deeponto)\n","  Downloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n","Collecting textdistance (from deeponto)\n","  Downloading textdistance-4.6.3-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from deeponto) (7.7.1)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from deeponto) (5.5.6)\n","Collecting enlighten (from deeponto)\n","  Downloading enlighten-1.12.4-py2.py3-none-any.whl.metadata (18 kB)\n","Collecting rdflib (from deeponto)\n","  Downloading rdflib-7.1.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.9.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anytree->deeponto) (1.16.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (18.0.0)\n","Collecting dill (from deeponto)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (4.66.6)\n","Collecting xxhash (from datasets->deeponto)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets->deeponto)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->deeponto)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (3.11.7)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (0.26.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (6.0.2)\n","Collecting blessed>=1.17.7 (from enlighten->deeponto)\n","  Downloading blessed-1.20.0-py2.py3-none-any.whl.metadata (13 kB)\n","Collecting prefixed>=0.3.2 (from enlighten->deeponto)\n","  Downloading prefixed-0.9.0-py2.py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (0.2.0)\n","Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (7.34.0)\n","Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (5.7.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (6.1.12)\n","Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (6.3.3)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->deeponto) (3.6.10)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->deeponto) (3.0.13)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->deeponto) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->deeponto) (2024.11.6)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2024.2)\n","Collecting isodate<1.0.0,>=0.7.2 (from rdflib->deeponto)\n","  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib->deeponto) (3.2.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deeponto) (1.13.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deeponto) (3.5.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (0.13.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.9.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.1.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (75.1.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.4.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (1.13.1)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (2.0.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->deeponto) (0.45.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deeponto) (3.31.0.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deeponto) (18.1.8)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (0.20.3)\n","Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (1.1.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->transformers[torch]->deeponto) (5.9.5)\n","Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.7->enlighten->deeponto) (0.2.13)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.3.1)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (5.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (0.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.18.0)\n","Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->deeponto)\n","  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (5.1.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (3.0.48)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (2.18.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (4.9.0)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.2.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (2024.8.30)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->deeponto) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->deeponto) (0.1.5)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (0.20.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (7.0.5)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.5.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy->deeponto) (3.0.2)\n","Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->deeponto) (5.7.2)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->deeponto) (24.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deeponto) (1.3.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->deeponto) (0.8.4)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel->deeponto) (4.3.6)\n","Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.2.1)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (23.1.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (5.10.4)\n","Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (7.16.4)\n","Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.6.0)\n","Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.3)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.18.1)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.21.0)\n","Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.1.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel->deeponto) (0.7.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (3.0.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->deeponto) (1.14.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (0.1.2)\n","Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.2.4)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.12.3)\n","Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.2.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.7.1)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.3.0)\n","Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.0.2)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.10.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.5.1)\n","Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.4.0)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.20.0)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.23.0)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (21.2.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.5.1)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.21.0)\n","Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.24.0)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.17.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.6)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.22)\n","Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.7.1)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.2.2)\n","Downloading deeponto-0.9.2-py3-none-any.whl (89.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading anytree-2.12.1-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading enlighten-1.12.4-py2.py3-none-any.whl (41 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.8/493.8 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n","Downloading rdflib-7.1.1-py3-none-any.whl (562 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m562.4/562.4 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading textdistance-4.6.3-py3-none-any.whl (31 kB)\n","Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n","Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading prefixed-0.9.0-py2.py3-none-any.whl (13 kB)\n","Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: prefixed, pprintpp, yacs, xxhash, textdistance, lxml, JPype1, jedi, isodate, fsspec, dill, blessed, anytree, rdflib, multiprocess, enlighten, datasets, deeponto\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","Successfully installed JPype1-1.5.1 anytree-2.12.1 blessed-1.20.0 datasets-3.1.0 deeponto-0.9.2 dill-0.3.8 enlighten-1.12.4 fsspec-2024.9.0 isodate-0.7.2 jedi-0.19.2 lxml-5.3.0 multiprocess-0.70.16 pprintpp-0.4.0 prefixed-0.9.0 rdflib-7.1.1 textdistance-4.6.3 xxhash-3.5.0 yacs-0.1.8\n","/bin/bash: line 1: username: No such file or directory\n"]}],"source":["# We assume that PyTorch is already installed in the environment.\n","# If not, this command installs it.\n","!pip install torch==2.0.0\n","\n","# Install PyTorch Geometric, a library for creating graph neural networks using PyTorch.\n","!pip install torch-geometric==2.4.0\n","\n","# Import PyTorch to access its functionalities.\n","import torch\n","\n","# Install additional PyTorch Geometric dependencies for graph processing (scatter, sparse, cluster, spline-conv).\n","# These packages enable operations like sparse tensors and convolutions on graphs.\n","!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","\n","# Reinstall PyTorch Geometric to ensure all dependencies are correctly loaded.\n","!pip install torch-geometric\n","\n","# Retrieve the installed version of PyTorch to ensure compatibility with other packages.\n","torchversion = torch.__version__\n","\n","# Install the latest version of PyTorch Geometric directly from the GitHub repository.\n","# This allows access to the most recent updates and features for graph-based neural networks.\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","\n","# Install DeepOnto, a package specifically designed for ontology matching, particularly useful in biomedical applications.\n","!pip install deeponto\n","\n","# Install a custom version of DeepOnto from a GitHub repository.\n","# The '<username>' part should be replaced with the actual GitHub username of the repository maintainer.\n","!pip install git+https://github.com/<username>/deeponto.git\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HPAlAgjLMVhw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"08334ce7-b871-4946-f58e-46d90b57f134","executionInfo":{"status":"ok","timestamp":1732210874008,"user_tz":-60,"elapsed":123845,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Please enter the maximum memory located to JVM [8g]: 8g\n","\n"]}],"source":["# Import pandas for data manipulation and analysis, such as loading, processing, and saving tabular data.\n","import pandas as pd\n","\n","# Import pickle for saving and loading serialized objects (e.g., trained models or preprocessed data).\n","import pickle\n","\n","# Import function to convert a directed graph to an undirected one, useful for certain graph algorithms.\n","from torch_geometric.utils import to_undirected\n","\n","# Import optimizer module from PyTorch for training models using gradient-based optimization techniques.\n","import torch.optim as optim\n","\n","# Import PyTorch's modules for defining neural network architectures and operations:\n","from torch.nn import (\n","    Linear,       # For linear transformations (dense layers).\n","    Sequential,   # For stacking layers sequentially.\n","    BatchNorm1d,  # For normalizing input within mini-batches.\n","    PReLU,        # Parametric ReLU activation function.\n","    Dropout       # For regularization by randomly dropping connections during training.\n",")\n","\n","# Import functional API from PyTorch for operations like activations and loss functions.\n","import torch.nn.functional as F\n","\n","# Import Matplotlib for visualizations, such as plotting training loss curves.\n","import matplotlib.pyplot as plt\n","\n","# Import PyTorch Geometric's graph convolutional layers:\n","from torch_geometric.nn import GCNConv, GINConv\n","\n","# Import pooling operations for aggregating node embeddings to graph-level representations:\n","from torch_geometric.nn import global_mean_pool, global_add_pool\n","\n","# Import NumPy for numerical operations, such as working with arrays and matrices.\n","import numpy as np\n","\n","# Import time module for measuring execution time of code blocks.\n","import time\n","\n","# Import typing module for specifying types in function arguments and return values.\n","from typing import Optional, Tuple, Union, Callable\n","\n","# Import PyTorch's DataLoader and TensorDataset for handling data batching and loading during training.\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","# Import PyTorch's Parameter class for defining learnable parameters in custom models.\n","from torch.nn import Parameter\n","\n","# Import math module for performing mathematical computations.\n","import math\n","\n","# Import Tensor type from PyTorch for defining and manipulating tensors.\n","from torch import Tensor\n","\n","# Import PyTorch's nn module for defining and building neural network architectures.\n","import torch.nn as nn\n","\n","# Import initialization utilities from PyTorch Geometric for resetting weights and biases in layers.\n","from torch_geometric.nn.inits import reset\n","\n","# Import the base class for defining message-passing layers in graph neural networks (GNNs).\n","from torch_geometric.nn.conv import MessagePassing\n","\n","# Import linear transformation utilities for creating dense representations in graph models.\n","from torch_geometric.nn.dense.linear import Linear\n","\n","# Import typing utilities for defining adjacency matrices and tensor types specific to PyTorch Geometric.\n","from torch_geometric.typing import Adj, OptTensor, PairTensor, SparseTensor\n","\n","# Import softmax function for normalizing attention scores in GNNs.\n","from torch_geometric.utils import softmax\n","\n","# Import initialization utilities for weight initialization (e.g., Glorot initialization).\n","from torch_geometric.nn.inits import glorot, zeros\n","\n","# Import F1 score metric from scikit-learn for evaluating model performance in binary/multi-class tasks.\n","from sklearn.metrics import f1_score\n","\n","# Import JSON module for reading and writing JSON files, useful for storing configuration or ontology data.\n","import json\n","\n","# Import Ontology class from DeepOnto for representing and manipulating ontologies in the pipeline.\n","from deeponto.onto import Ontology\n","\n","# Import tools from DeepOnto for handling Ontology Alignment Evaluation Initiative (OAEI) tasks.\n","from deeponto.align.oaei import *\n","\n","# Import evaluation tools from DeepOnto for assessing alignment results using metrics like precision, recall, and F1.\n","from deeponto.align.evaluation import AlignmentEvaluator\n","\n","# Import mapping utilities from DeepOnto for working with reference mappings and entity pairs.\n","from deeponto.align.mapping import ReferenceMapping, EntityMapping\n","\n","# Import utility function for reading tables (e.g., TSV, CSV) from DeepOnto.\n","from deeponto.utils import read_table\n","\n","# Importing the train_test_split function from sklearn's model_selection module.\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"-abbBHOoRdWl"},"source":["# **Paths Definition**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AVgl_Bb42naS","outputId":"4cc63680-4844-427d-aa30-7da6cc374019","executionInfo":{"status":"ok","timestamp":1732210904008,"user_tz":-60,"elapsed":30005,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# Importing the 'drive' module from Google Colab to interact with Google Drive\n","from google.colab import drive\n","\n","# Mount the user's Google Drive to the Colab environment\n","# After running this, a link will appear to authorize access, and Google Drive will be mounted at '/content/gdrive'\n","drive.mount('/content/gdrive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"36ttssQ3W7cx"},"outputs":[],"source":["# Define the source ontology name\n","src_ent = \"ncit\"\n","\n","# Define the target ontology name\n","tgt_ent = \"doid\"\n","\n","# Define the task name for this ontology matching process\n","task = \"ncit2doid\"\n","\n","# Define the weight for the training data\n","# This weight is likely used to balance the training process, giving more emphasis to certain examples.\n","# For instance, a weight of 10.0 could be applied to penalize errors in certain types of predictions more heavily.\n","weight_train = 10.0\n","\n","# Define the similarity threshold for validating matches\n","thres = 0.2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SJpvkdwVSQye"},"outputs":[],"source":["dir = f\"/content/gdrive/My Drive/BioGITOM-VLDB/Experiments/{task}\"\n","\n","dataset=\"/content/gdrive/My Drive/BioGITOM-VLDB/\"\n","\n","# Define the directory for the dataset containing source and target ontologies\n","dataset_dir = f\"{dataset}/Datasets/{task}\"\n","\n","# Define the data directory for storing embeddings, adjacency matrices, and related files\n","data_dir = f\"{dir}/Data\"\n","\n","\n","# Define the directory for storing the results\n","results_dir = f\"{dir}/BERT_Model_Choice/Results\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eFDNSFef23er"},"outputs":[],"source":["# Load the Source ontology using the Ontology class from DeepOnto\n","# This initializes the source ontology by loading its .owl file.\n","src_onto = Ontology(f\"{dataset_dir}/{src_ent}.owl\")\n","\n","# Load the Target ontology using the Ontology class from DeepOnto\n","# This initializes the target ontology by loading its .owl file.\n","tgt_onto = Ontology(f\"{dataset_dir}/{tgt_ent}.owl\")\n","\n","# Define the file path for the Source embeddings CSV file\n","# Embeddings for the source ontology entities are stored in this file.\n","src_Emb = f\"{data_dir}/{src_ent}_All_Mini_emb.csv\"\n","\n","# Define the file path for the Target embeddings CSV file\n","# Embeddings for the target ontology entities are stored in this file.\n","tgt_Emb = f\"{data_dir}/{tgt_ent}_All_Mini_emb.csv\"\n","\n","# Define the file path for the Source adjacency matrix\n","# This file represents the relationships (edges) between entities in the source ontology.\n","src_Adjacence = f\"{data_dir}/{src_ent}_adjacence.csv\"\n","\n","# Define the file path for the Target adjacency matrix\n","# This file represents the relationships (edges) between entities in the target ontology.\n","tgt_Adjacence = f\"{data_dir}/{tgt_ent}_adjacence.csv\"\n","\n","# Define the file path for the JSON file containing the Source ontology class labels\n","# This file maps the source ontology entities to their labels or names.\n","src_class = f\"{data_dir}/{src_ent}_classes.json\"\n","\n","# Define the file path for the JSON file containing the Target ontology class labels\n","# This file maps the target ontology entities to their labels or names.\n","tgt_class = f\"{data_dir}/{tgt_ent}_classes.json\"\n","\n","# Define the file path for the train data\n","train_file = f\"{data_dir}/{task}_train_100.csv\"\n","\n","# Define the file path for the test data\n","# The test file contains reference mappings (ground truth) between the source and target ontologies.\n","test_file = f\"{dataset_dir}/refs_equiv/test.tsv\"\n","\n","# Define the file path for the candidate mappings used during testing\n","# This file includes the candidate pairs (source and target entities) for ranking and evaluation.\n","test_cands = f\"{dataset_dir}/refs_equiv/test.cands.tsv\"\n","\n","# Define the file path for the candidate mappings between Source to Target entities\n","# This file contains cleaned, combined, and encoded candidates used for predictions.\n","candidates_Prediction = f\"{data_dir}/{task}_candidates_prediction.csv\"\n","\n","# Define the file path for the candidate mappings between Source to Target entities for ranking-based metrics\n","# This file is used to compute ranking-based metrics like MRR and Hits@k.\n","candidates_Rank = f\"{data_dir}/{task}_candidates.csv\"\n","\n","# Define the path where the prediction results will be saved in TSV format\n","# This file will store the final predictions (mappings) between source and target entities.\n","prediction_path = f\"{results_dir}/{task}_matching_results_All_Mini.tsv\"\n","\n","# Define the path where all prediction results will be saved in TSV format\n","# This file will store detailed prediction results, including all candidate scores.\n","all_predictions_path = f\"{results_dir}/{task}_all_predictions_Mini.tsv\"\n","\n","# Define the path where all ranking prediction results will be saved in TSV format\n","# This file will store predictions sorted by rank based on their scores.\n","all_predictions_path_ranked = f\"{results_dir}/{task}_all_predictions_ranked_All_Mini.tsv\"\n","\n","# Define the path where formatted ranking predictions will be saved in TSV format\n","# This file will contain predictions formatted for evaluation using ranking-based metrics.\n","formatted_predictions_path = f\"{results_dir}/{task}_formatted_predictions_All_Mini.tsv\""]},{"cell_type":"markdown","metadata":{"id":"zqEXsgPGMVhw"},"source":["# **GIT Architecture**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A_d6XCsUMVhx"},"outputs":[],"source":["# RGIT class definition which inherits from PyTorch Geometric's MessagePassing class\n","class RGIT(MessagePassing):\n","\n","    _alpha: OptTensor  # Define _alpha as an optional tensor for storing attention weights\n","\n","    def __init__(\n","        self,\n","        nn: Callable,  # Neural network to be used in the final layer of the GNN\n","        in_channels: Union[int, Tuple[int, int]],  # Input dimension, can be a single or pair of integers\n","        out_channels: int,  # Output dimension of the GNN\n","        eps: float = 0.,  # GIN parameter: epsilon for GIN aggregation\n","        train_eps: bool = False,  # GIN parameter: whether epsilon should be learnable\n","        heads: int = 1,  # Transformer parameter: number of attention heads\n","        dropout: float = 0.,  # Dropout rate for attention weights\n","        edge_dim: Optional[int] = None,  # Dimension for edge attributes (optional)\n","        bias: bool = True,  # Whether to use bias in linear layers\n","        root_weight: bool = True,  # GIN parameter: whether to apply root weight in aggregation\n","        **kwargs,  # Additional arguments passed to the parent class\n","    ):\n","        # Set the aggregation type to 'add' and initialize the parent class with node_dim=0\n","        kwargs.setdefault('aggr', 'add')\n","        super().__init__(node_dim=0, **kwargs)\n","\n","        # Initialize input/output dimensions, neural network, and GIN/transformer parameters\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.nn = nn  # Neural network used by the GNN\n","        self.initial_eps = eps  # Initial value of epsilon for GIN\n","\n","        # Set epsilon to be learnable or fixed\n","        if train_eps:\n","            self.eps = torch.nn.Parameter(torch.empty(1))  # Learnable epsilon\n","        else:\n","            self.register_buffer('eps', torch.empty(1))  # Non-learnable epsilon (fixed)\n","\n","        # Initialize transformer-related parameters\n","        self.heads = heads\n","        self.dropout = dropout\n","        self.edge_dim = edge_dim\n","        self._alpha = None  # Placeholder for attention weights\n","\n","        # Handle case where in_channels is a single integer or a tuple\n","        if isinstance(in_channels, int):\n","            in_channels = (in_channels, in_channels)\n","\n","        # Define the linear layers for key, query, and value for the transformer mechanism\n","        self.lin_key = Linear(in_channels[0], heads * out_channels)\n","        self.lin_query = Linear(in_channels[1], heads * out_channels)\n","        self.lin_value = Linear(in_channels[0], heads * out_channels)\n","\n","        # Define linear transformation for edge embeddings if provided\n","        if edge_dim is not None:\n","            self.lin_edge = Linear(edge_dim, heads * out_channels, bias=False)\n","        else:\n","            self.lin_edge = self.register_parameter('lin_edge', None)\n","\n","        # Reset all parameters to their initial values\n","        self.reset_parameters()\n","\n","    # Function to reset model parameters\n","    def reset_parameters(self):\n","        super().reset_parameters()  # Call parent class reset method\n","        self.lin_key.reset_parameters()  # Reset key linear layer\n","        self.lin_query.reset_parameters()  # Reset query linear layer\n","        self.lin_value.reset_parameters()  # Reset value linear layer\n","        if self.edge_dim:\n","            self.lin_edge.reset_parameters()  # Reset edge linear layer if used\n","        reset(self.nn)  # Reset the neural network provided\n","        self.eps.data.fill_(self.initial_eps)  # Initialize epsilon with the starting value\n","\n","    # Forward function defining how the input data flows through the model\n","    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj,\n","                edge_attr: OptTensor = None, return_attention_weights=None):\n","        # Unpack number of heads and output channels\n","        H, C = self.heads, self.out_channels\n","\n","        # If x is a tensor, treat it as a pair of tensors (source and target embeddings)\n","        if isinstance(x, Tensor):\n","            x: PairTensor = (x, x)\n","\n","        # Extract source node embeddings\n","        x_t = x[0]\n","\n","        # Apply linear transformations and reshape query, key, and value for multi-head attention\n","        query = self.lin_query(x[1]).view(-1, H, C)\n","        key = self.lin_key(x[0]).view(-1, H, C)\n","        value = self.lin_value(x[0]).view(-1, H, C)\n","\n","        # Propagate messages through the graph using the propagate function\n","        out = self.propagate(edge_index, query=query, key=key, value=value,\n","                             edge_attr=edge_attr, size=None)\n","\n","        # Retrieve attention weights and reset them\n","        alpha = self._alpha\n","        self._alpha = None  # Reset _alpha after use\n","        out = out.mean(dim=1)  # Take the mean over all attention heads\n","\n","        # Apply GIN aggregation by adding epsilon-scaled original node embeddings\n","        out = out + (1 + self.eps) * x_t\n","        return self.nn(out)  # Pass through the neural network\n","\n","    # Message passing function which calculates attention and combines messages\n","    def message(self, query_i: Tensor, key_j: Tensor, value_j: Tensor,\n","                edge_attr: OptTensor, index: Tensor, ptr: OptTensor,\n","                size_i: Optional[int]) -> Tensor:\n","        # If edge attributes are used, apply linear transformation and add them to the key\n","        if self.lin_edge is not None:\n","            assert edge_attr is not None\n","            edge_attr = self.lin_edge(edge_attr).view(-1, self.heads, self.out_channels)\n","            key_j = key_j + edge_attr\n","\n","        # Calculate attention (alpha) using the dot product between query and key\n","        alpha = (query_i * key_j).sum(dim=-1) / math.sqrt(self.out_channels)\n","        alpha = softmax(alpha, index, ptr, size_i)  # Apply softmax to normalize attention\n","        self._alpha = alpha  # Store attention weights\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)  # Apply dropout\n","\n","        # Calculate the output message by applying attention to the value\n","        out = value_j\n","        if edge_attr is not None:\n","            out = out + edge_attr  # Add edge embeddings to the output if present\n","        out = out * alpha.view(-1, self.heads, 1)  # Scale by attention weights\n","        return out\n","\n","    # String representation function for debugging or printing\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}({self.in_channels}, '\n","                f'{self.out_channels}, heads={self.heads})')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qwFv6RgHmGCf"},"outputs":[],"source":["# Define the RGIT_mod class, a multi-layer GNN that uses both RGIT and linear layers\n","class RGIT_mod(torch.nn.Module):\n","    \"\"\"Multi-layer RGIT with optional linear layers\"\"\"\n","\n","    # Initialize the model with hidden dimension, number of RGIT layers, and number of linear layers\n","    def __init__(self, dim_h, num_layers, num_linear_layers=1):\n","        super(RGIT_mod, self).__init__()\n","        self.num_layers = num_layers  # Number of RGIT layers\n","        self.num_linear_layers = num_linear_layers  # Number of linear layers\n","        self.linears = torch.nn.ModuleList()  # List to store linear layers\n","        self.rgit_layers = torch.nn.ModuleList()  # List to store RGIT layers\n","\n","        # Create a list of Linear and PReLU layers (for encoding entity names)\n","        for _ in range(num_linear_layers):\n","            self.linears.append(Linear(dim_h, dim_h))  # Linear transformation layer\n","            self.linears.append(PReLU(num_parameters=dim_h))  # Parametric ReLU activation function\n","\n","        # Create a list of RGIT layers\n","        for _ in range(num_layers):\n","            self.rgit_layers.append(RGIT(  # Each RGIT layer contains a small MLP with Linear and PReLU\n","                Sequential(Linear(dim_h, dim_h), PReLU(num_parameters=dim_h),\n","                           Linear(dim_h, dim_h), PReLU(num_parameters=dim_h)), dim_h, dim_h))\n","\n","    # Forward pass through the model\n","    def forward(self, x, edge_index):\n","        # Apply the linear layers first to the input\n","        for layer in self.linears:\n","            x = layer(x)\n","\n","        # Then apply the RGIT layers for message passing\n","        for layer in self.rgit_layers:\n","            x = layer(x, edge_index)\n","\n","        return x  # Return the final node embeddings after all layers\n"]},{"cell_type":"markdown","metadata":{"id":"zxCn5ztKVztw"},"source":["# **Gated Network Architecture**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7MKQUv7o7zay"},"outputs":[],"source":["# Define the GatedCombination class for combining two pairs of embeddings using a gating mechanism\n","class GatedCombination(nn.Module):\n","    def __init__(self, input_dim):\n","        \"\"\"\n","        Initialize the GatedCombination model.\n","\n","        Args:\n","            input_dim (int): The dimensionality of the input embeddings (x1, x2, x3, x4).\n","        \"\"\"\n","        super(GatedCombination, self).__init__()\n","\n","        # Define a linear layer (gate) for combining embeddings x1 and x2 (first pair)\n","        self.gate_A_fc = nn.Linear(input_dim, input_dim)\n","\n","        # Define a linear layer (gate) for combining embeddings x3 and x4 (second pair)\n","        self.gate_B_fc = nn.Linear(input_dim, input_dim)\n","\n","        # A final fully connected layer that outputs a single neuron (binary classification)\n","        self.fc = nn.Linear(1, 1)\n","\n","    def forward(self, x1, x2, x3, x4):\n","        \"\"\"\n","        Forward pass through the gating mechanism and cosine similarity.\n","\n","        Args:\n","            x1 (torch.Tensor): First set of embeddings (source embeddings after update).\n","            x2 (torch.Tensor): Second set of embeddings (original source embeddings).\n","            x3 (torch.Tensor): Third set of embeddings (target embeddings after update).\n","            x4 (torch.Tensor): Fourth set of embeddings (original target embeddings).\n","\n","        Returns:\n","            torch.Tensor: Output of the model (probability score for binary classification).\n","        \"\"\"\n","        # Compute gate values for the first pair (x1 and x2) using a sigmoid activation\n","        gate_values1 = torch.sigmoid(self.gate_A_fc(x1))\n","\n","        # Combine x1 and x2 using the gate values\n","        # The result is a weighted combination of x1 and x2\n","        a = x1 * gate_values1 + x2 * (1 - gate_values1)\n","\n","        # Compute gate values for the second pair (x3 and x4) using a sigmoid activation\n","        gate_values2 = torch.sigmoid(self.gate_B_fc(x3))\n","\n","        # Combine x3 and x4 using the gate values\n","        # The result is a weighted combination of x3 and x4\n","        b = x3 * gate_values2 + x4 * (1 - gate_values2)\n","\n","        # Compute cosine similarity between the combined vectors a and b\n","        x = torch.cosine_similarity(a, b, dim=1)\n","\n","        # Pass the cosine similarity result through a fully connected layer (fc) for classification\n","        # Use a sigmoid activation to output a probability for binary classification\n","        out = torch.sigmoid(self.fc(x.unsqueeze(1)))  # unsqueeze(1) to match the input shape for the fc layer\n","        return out\n","\n"]},{"cell_type":"code","source":["class WeightedBCELoss(nn.Module):\n","    def __init__(self, pos_weight):\n","        \"\"\"\n","        Weighted Binary Cross-Entropy Loss.\n","\n","        Args:\n","            pos_weight (float): Weight for the positive class.\n","        \"\"\"\n","        super(WeightedBCELoss, self).__init__()\n","        self.pos_weight = pos_weight\n","\n","    def forward(self, outputs, targets):\n","        \"\"\"\n","        Args:\n","            outputs (torch.Tensor): Predicted probabilities from the model (after sigmoid).\n","            targets (torch.Tensor): Ground truth labels (0 or 1).\n","\n","        Returns:\n","            torch.Tensor: Computed weighted binary cross-entropy loss.\n","        \"\"\"\n","        # Compute weighted BCE loss\n","        loss = - (self.pos_weight * targets * torch.log(outputs + 1e-8) +\n","                  (1 - targets) * torch.log(1 - outputs + 1e-8))\n","        return loss.mean()"],"metadata":{"id":"PCzq6hHCD8vg"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4kO42TTCqQZ8"},"outputs":[],"source":["class FocalLoss(nn.Module):\n","    def __init__(self, alpha=0.25, gamma=2):\n","        \"\"\"\n","        Focal Loss for binary classification.\n","\n","        Args:\n","            alpha (float): Balancing factor for positive/negative classes.\n","            gamma (float): Focusing parameter for hard examples.\n","        \"\"\"\n","        super(FocalLoss, self).__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","\n","    def forward(self, outputs, targets):\n","        \"\"\"\n","        Args:\n","            outputs (torch.Tensor): Predicted probabilities from the model (after sigmoid).\n","            targets (torch.Tensor): Ground truth labels (0 or 1).\n","\n","        Returns:\n","            torch.Tensor: Computed focal loss.\n","        \"\"\"\n","        # Compute binary cross-entropy loss\n","        bce_loss = F.binary_cross_entropy(outputs, targets, reduction='none')\n","\n","        # Compute modulating factor (1 - p_t)^gamma\n","        pt = torch.where(targets == 1, outputs, 1 - outputs)  # pt = p if y==1 else 1-p\n","        modulating_factor = (1 - pt) ** self.gamma\n","\n","        # Apply alpha and modulating factor\n","        focal_loss = self.alpha * modulating_factor * bce_loss\n","        return focal_loss.mean()"]},{"cell_type":"markdown","metadata":{"id":"aLJ5j9FNMVhy"},"source":["# **Utility functions**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k0L86DgUQjMU"},"outputs":[],"source":["def adjacency_matrix_to_undirected_edge_index(adjacency_matrix):\n","    \"\"\"\n","    Converts an adjacency matrix into an undirected edge index for use in graph-based neural networks.\n","\n","    Args:\n","        adjacency_matrix: A 2D list or array representing the adjacency matrix of a graph.\n","\n","    Returns:\n","        edge_index_undirected: A PyTorch tensor representing the undirected edges.\n","    \"\"\"\n","    # Convert each element in the adjacency matrix to an integer (from boolean or float)\n","    adjacency_matrix = [[int(element) for element in sublist] for sublist in adjacency_matrix]\n","\n","    # Convert the adjacency matrix into a PyTorch LongTensor (used for indexing)\n","    edge_index = torch.tensor(adjacency_matrix, dtype=torch.long)\n","\n","    # Transpose the edge_index tensor so that rows represent edges in the form [source, target]\n","    edge_index = edge_index.t().contiguous()\n","\n","    # Convert the directed edge_index into an undirected edge_index, meaning both directions are added (i.e., (i, j) and (j, i))\n","    edge_index_undirected = to_undirected(edge_index)\n","\n","    return edge_index_undirected  # Return the undirected edge index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YvmOxkLcpf9w"},"outputs":[],"source":["def build_indexed_dict(file_path):\n","    \"\"\"\n","    Builds a dictionary with numeric indexes for each key from a JSON file.\n","\n","    Args:\n","        file_path (str): The path to the JSON file.\n","\n","    Returns:\n","        indexed_dict (dict): A new dictionary where each key from the JSON file is assigned a numeric index.\n","    \"\"\"\n","    # Load the JSON file into a Python dictionary\n","    with open(file_path, 'r') as file:\n","        data = json.load(file)\n","\n","    # Create a new dictionary with numeric indexes as keys and the original JSON keys as values\n","    indexed_dict = {index: key for index, key in enumerate(data.keys())}\n","\n","    return indexed_dict  # Return the newly created dictionary"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QgFINoPGl9Wg"},"outputs":[],"source":["def select_rows_by_index(embedding_vector, index_vector):\n","    \"\"\"\n","    Select rows from an embedding vector using an index vector.\n","\n","    Args:\n","        embedding_vector (torch.Tensor): 2D tensor representing the embedding vector with shape [num_rows, embedding_size].\n","        index_vector (torch.Tensor): 1D tensor representing the index vector.\n","\n","    Returns:\n","        torch.Tensor: New tensor with selected rows from the embedding vector.\n","    \"\"\"\n","    # Use torch.index_select to select the desired rows\n","    new_tensor = torch.index_select(embedding_vector, 0, index_vector)\n","\n","    return new_tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a12L7vEmmCJq"},"outputs":[],"source":["def contrastive_loss(source_embeddings, target_embeddings, labels, margin=1.0):\n","    \"\"\"\n","    Computes the contrastive loss, a type of loss function used to train models in tasks like matching or similarity learning.\n","\n","    Args:\n","        source_embeddings (torch.Tensor): Embeddings of the source graphs, shape [batch_size, embedding_size].\n","        target_embeddings (torch.Tensor): Embeddings of the target graphs, shape [batch_size, embedding_size].\n","        labels (torch.Tensor): Binary labels indicating if the pairs are matched (1) or not (0), shape [batch_size].\n","        margin (float): Margin value for the contrastive loss. Defaults to 1.0.\n","\n","    Returns:\n","        torch.Tensor: The contrastive loss value.\n","    \"\"\"\n","    # Calculate the pairwise Euclidean distance between source and target embeddings\n","    distances = F.pairwise_distance(source_embeddings, target_embeddings)\n","\n","    # Compute the contrastive loss:\n","    # - For matched pairs (label == 1), the loss is the squared distance between embeddings.\n","    # - For non-matched pairs (label == 0), the loss is based on how far apart the embeddings are,\n","    #   but penalizes them only if the distance is less than the margin.\n","    loss = torch.mean(\n","        labels * 0.4 * distances.pow(2) +  # For positive pairs, minimize the distance (squared)\n","        (1 - labels) * 0.4 * torch.max(torch.zeros_like(distances), margin - distances).pow(2)  # For negative pairs, maximize the distance (up to the margin)\n","    )\n","\n","    return loss  # Return the computed contrastive loss\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZhCizXEb7D4N"},"outputs":[],"source":["def Prediction_with_candidates(model, X1_tt, X2_tt, X3_tt, X4_tt, src_entity_tensor_o, tgt_entity_tensor_o,\n","                                   indexed_dict_src, indexed_dict_tgt, all_predictions_path):\n","    \"\"\"\n","    Evaluates the GatedCombination model using the given embeddings and candidate entity pairs.\n","    Saves the predictions and evaluation results to a file.\n","\n","    Args:\n","        model: Trained GatedCombination model.\n","        X1_tt, X2_tt, X3_tt, X4_tt (torch.Tensor): Tensors of source and target entity embeddings (updated and original).\n","        src_entity_tensor_o, tgt_entity_tensor_o (torch.Tensor): Tensors of source and target entity indices.\n","        indexed_dict_src, indexed_dict_tgt (dict): Dictionaries mapping entity indices to URIs for source and target.\n","        output_file (str): Path to save the predictions and results.\n","        hits_at_k_values (list): List of k-values for which hits@k is evaluated.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    # Move the model to CPU and set it to evaluation mode\n","    model = model.to(\"cpu\")\n","    model.eval()\n","\n","    # Set batch size for evaluation\n","    batch_size_test = 32\n","\n","    # Create a DataLoader for the evaluation data\n","    test_dataset = TensorDataset(X1_tt, X2_tt, X3_tt, X4_tt)\n","    test_dataloader = DataLoader(test_dataset, batch_size=batch_size_test)\n","\n","    # Prepare for collecting predictions and results\n","    predictions = []\n","    results = []\n","    count_predictions = 0  # Counter for predictions above threshold (0.5)\n","\n","    # Measure prediction time\n","    start_time = time.time()\n","\n","    # Disable gradient computation for evaluation\n","    with torch.no_grad():\n","        # Iterate over batches and compute model predictions\n","        for batch_X1, batch_X2, batch_X3, batch_X4 in test_dataloader:\n","            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","            predictions.extend(outputs.cpu().numpy())  # Collect predictions in CPU memory\n","\n","    end_time = time.time()\n","    predicting_time = end_time - start_time\n","    print(f\"Predicting time: {predicting_time:.2f} seconds\")\n","\n","    # Convert tensors to lists for easier iteration\n","    src_indices = src_entity_tensor_o.tolist()\n","    tgt_indices = tgt_entity_tensor_o.tolist()\n","\n","    # Prepare results\n","    for i in range(len(predictions)):\n","        if predictions[i] >= 0.00:  # Consider only predictions greater than 0.5\n","            count_predictions += 1  # Increment the counter\n","\n","            # Map the source and target entity indices to their URIs\n","            src_code = src_indices[i]\n","            tgt_code = tgt_indices[i]\n","\n","            src_uri = indexed_dict_src.get(int(src_code), \"Unknown URI\")\n","            tgt_uri = indexed_dict_tgt.get(int(tgt_code), \"Unknown URI\")\n","\n","            # Get the model's predicted score for the current pair\n","            score = predictions[i]\n","\n","            # Append the results (with URIs instead of entity indices)\n","            results.append({\n","                'SrcEntity': src_uri,\n","                'TgtEntity': tgt_uri,\n","                'Score': score\n","            })\n","\n","    # Convert the results into a pandas DataFrame\n","    df_results = pd.DataFrame(results)\n","\n","    # Save the results to a TSV file\n","    df_results.to_csv(all_predictions_path, sep='\\t', index=False)\n","\n","    print(f\"Predictions saved to {all_predictions_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TslUdYHBcGVj"},"outputs":[],"source":["def filter_highest_predictions(input_file_path, output_file_path, threshold=thres):\n","    # Load the all predictions file\n","    df = pd.read_csv(input_file_path, sep='\\t')\n","\n","    # Extract the similarity score from the list in the 'Score' column\n","    df['Score'] = df['Score'].apply(lambda x: float(x.strip('[]')))\n","\n","    # Sorting the dataframe by similarity score in descending order\n","    df_sorted = df.sort_values(by='Score', ascending=False).reset_index(drop=True)\n","\n","    # Initialize variables with threshold value\n","    source_concepts = set(df_sorted['SrcEntity'])\n","    target_concepts = set(df_sorted['TgtEntity'])\n","    matched_sources = set()\n","    matched_targets = set()\n","    result = []\n","\n","    # Iterate through the sorted dataframe and find highest correspondences\n","    for _, row in df_sorted.iterrows():\n","        source, target, similarity = row['SrcEntity'], row['TgtEntity'], row['Score']\n","\n","        # Check if the source or target has already been matched and if the similarity is above the threshold\n","        if source not in matched_sources and target not in matched_targets and similarity >= threshold:\n","            # Add the match to the result list\n","            result.append((source, target, similarity))\n","            # Mark the source and target as matched\n","            matched_sources.add(source)\n","            matched_targets.add(target)\n","\n","    # Create a dataframe for the matching results with threshold applied\n","    matching_results_df_threshold = pd.DataFrame(result, columns=['SrcEntity', 'TgtEntity', 'Score'])\n","\n","    # Save the matching results with the updated column names to a new TSV file\n","    matching_results_df_threshold.to_csv(output_file_path, sep='\\t', index=False)\n","\n","    # Print the number of predictions saved\n","    print(f\"Number of Positive predictions: {len(matching_results_df_threshold)}\")\n","\n","    return matching_results_df_threshold, len(matching_results_df_threshold)"]},{"cell_type":"code","source":["def compute_mrr_and_hits(reference_file, predicted_file, output_file, k_values=[1, 5, 10]):\n","    \"\"\"\n","    Compute MRR and Hits@k for ontology matching predictions based on a reference file.\n","\n","    Args:\n","        reference_file (str): Path to the reference file (test.cands.tsv format).\n","        predicted_file (str): Path to the predictions file with scores.\n","        output_file (str): Path to save the scored results.\n","        k_values (list): List of k values for Hits@k.\n","\n","    Returns:\n","        dict: A dictionary containing MRR and Hits@k metrics.\n","    \"\"\"\n","    # Read the reference mappings\n","    test_candidate_mappings = read_table(reference_file).values.tolist()\n","    ranking_results = []\n","\n","    # Read the predicted scores\n","    predicted_data = pd.read_csv(predicted_file, sep=\"\\t\")\n","    predicted_data[\"Score\"] = predicted_data[\"Score\"].apply(lambda x: float(x.strip(\"[]\")))\n","\n","    # Create a lookup dictionary for predicted scores\n","    score_lookup = {}\n","    for _, row in predicted_data.iterrows():\n","        score_lookup[(row[\"SrcEntity\"], row[\"TgtEntity\"])] = row[\"Score\"]\n","\n","    for src_ref_class, tgt_ref_class, tgt_cands in test_candidate_mappings:\n","        tgt_cands = eval(tgt_cands)  # Convert string to list of candidates\n","        scored_cands = []\n","        for tgt_cand in tgt_cands:\n","            # Retrieve score for each candidate, defaulting to a very low score if not found\n","            matching_score = score_lookup.get((src_ref_class, tgt_cand), -1e9)\n","            scored_cands.append((tgt_cand, matching_score))\n","\n","        # Sort candidates by score in descending order\n","        scored_cands = sorted(scored_cands, key=lambda x: x[1], reverse=True)\n","        ranking_results.append((src_ref_class, tgt_ref_class, scored_cands))\n","\n","    # Save the ranked results to a file\n","    pd.DataFrame(ranking_results, columns=[\"SrcEntity\", \"TgtEntity\", \"TgtCandidates\"]).to_csv(output_file, sep=\"\\t\", index=False)\n","\n","    # Compute MRR and Hits@k\n","    total_entities = len(ranking_results)\n","    reciprocal_ranks = []\n","    hits_at_k = {k: 0 for k in k_values}\n","\n","    for src_entity, tgt_ref_class, tgt_cands in ranking_results:\n","        ranked_candidates = [candidate[0] for candidate in tgt_cands]\n","        if tgt_ref_class in ranked_candidates:\n","            rank = ranked_candidates.index(tgt_ref_class) + 1\n","            reciprocal_ranks.append(1 / rank)\n","            for k in k_values:\n","                if rank <= k:\n","                    hits_at_k[k] += 1\n","        else:\n","            reciprocal_ranks.append(0)\n","\n","    mrr = sum(reciprocal_ranks) / total_entities\n","    hits_at_k = {k: hits / total_entities for k, hits in hits_at_k.items()}\n","\n","    return {\"MRR\": mrr, \"Hits@k\": hits_at_k}"],"metadata":{"id":"_ggVYlTiO_WA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1HyWMsw1MVhz"},"source":["# **Main Code**\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"IC37FlwGDqGM"},"source":["\n","\n","# Reading semantic node embeddings provided by the ENE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FuEfSnw5mod0"},"outputs":[],"source":["# Read the source embeddings from a CSV file into a pandas DataFrame\n","df_embbedings_src = pd.read_csv(src_Emb, index_col=0)\n","\n","# Convert the DataFrame to a NumPy array, which will remove the index and store the data as a raw matrix\n","numpy_array = df_embbedings_src.to_numpy()\n","\n","# Convert the NumPy array into a PyTorch FloatTensor, which is the format required for PyTorch operations\n","x_src = torch.FloatTensor(numpy_array)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"STUwqMUXmlG2"},"outputs":[],"source":["# Read the target embeddings from a CSV file into a pandas DataFrame\n","df_embbedings_tgt = pd.read_csv(tgt_Emb, index_col=0)\n","\n","# Convert the DataFrame to a NumPy array, which removes the index and converts the data to a raw matrix\n","numpy_array = df_embbedings_tgt.to_numpy()\n","\n","# Convert the NumPy array into a PyTorch FloatTensor, which is required for PyTorch operations\n","x_tgt = torch.FloatTensor(numpy_array)"]},{"cell_type":"markdown","metadata":{"id":"jZIu9P08DqGN"},"source":["# Reading adjacency Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pH69Up40mycz"},"outputs":[],"source":["# Read the source adjacency matrix from a CSV file into a pandas DataFrame\n","df_ma1 = pd.read_csv(src_Adjacence, index_col=0)\n","\n","# Convert the DataFrame to a list of lists (Python native list format)\n","ma1 = df_ma1.values.tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hYCmAO5Ymzpl"},"outputs":[],"source":["# Read the target adjacency matrix from a CSV file into a pandas DataFrame\n","df_ma2 = pd.read_csv(tgt_Adjacence, index_col=0)\n","\n","# Convert the DataFrame to a list of lists (Python native list format)\n","ma2 = df_ma2.values.tolist()"]},{"cell_type":"markdown","metadata":{"id":"PSyksqh3TrU-"},"source":["# Convert Adjacency matrix (in list format) to an undirected edge index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uVt-Pce5m5ll"},"outputs":[],"source":["# Convert the source adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n","edge_src = adjacency_matrix_to_undirected_edge_index(ma1)\n","\n","# Convert the target adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n","edge_tgt = adjacency_matrix_to_undirected_edge_index(ma2)"]},{"cell_type":"markdown","metadata":{"id":"H9wMTRdqT4aY"},"source":["# GIT Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eqiEKCLSMVh3"},"outputs":[],"source":["def train_model_gnn(model, x_src, edge_src, x_tgt, edge_tgt,\n","                    tensor_term1, tensor_term2, tensor_score,\n","                    learning_rate, weight_decay_value, num_epochs, print_interval=10):\n","    \"\"\"\n","    Trains a graph neural network (GNN) model using source and target embeddings and contrastive loss.\n","\n","    Args:\n","        model: The GNN model to be trained.\n","        x_src (torch.Tensor): Source node embeddings.\n","        edge_src (torch.Tensor): Source graph edges.\n","        x_tgt (torch.Tensor): Target node embeddings.\n","        edge_tgt (torch.Tensor): Target graph edges.\n","        tensor_term1 (torch.Tensor): Indices of the source nodes to be compared.\n","        tensor_term2 (torch.Tensor): Indices of the target nodes to be compared.\n","        tensor_score (torch.Tensor): Labels indicating if the pairs are matched (1) or not (0).\n","        learning_rate (float): Learning rate for the optimizer.\n","        weight_decay_value (float): Weight decay (L2 regularization) value for the optimizer.\n","        num_epochs (int): Number of epochs for training.\n","        print_interval (int): Interval at which training progress is printed (every `print_interval` epochs).\n","\n","    Returns:\n","        model: The trained GNN model.\n","    \"\"\"\n","\n","    # Step 1: Set device (GPU or CPU) for computation\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    # Step 2: Move the model and all inputs to the selected device\n","    model.to(device)\n","    x_tgt = x_tgt.to(device)               # Target node embeddings\n","    edge_tgt = edge_tgt.to(device)         # Target graph edges\n","    x_src = x_src.to(device)               # Source node embeddings\n","    edge_src = edge_src.to(device)         # Source graph edges\n","    tensor_term1 = tensor_term1.to(device) # Indices for source nodes\n","    tensor_term2 = tensor_term2.to(device) # Indices for target nodes\n","    tensor_score = tensor_score.to(device) # Ground truth labels\n","\n","    # Step 3: Define optimizer with learning rate and regularization\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay_value)\n","\n","    # Step 4: Initialize list to store training losses\n","    train_losses = []\n","\n","    # Record the start time of training\n","    start_time = time.time()\n","\n","    # Step 5: Training loop\n","    for epoch in range(num_epochs):\n","        # Zero out gradients from the previous iteration\n","        optimizer.zero_grad()\n","\n","        # Forward pass: Compute embeddings for source and target graphs\n","        out1 = model(x_src, edge_src)  # Updated source embeddings\n","        out2 = model(x_tgt, edge_tgt)  # Updated target embeddings\n","\n","        # Extract specific rows of embeddings for terms being compared\n","        src_embeddings = select_rows_by_index(out1, tensor_term1)\n","        tgt_embeddings = select_rows_by_index(out2, tensor_term2)\n","\n","        # Compute contrastive loss based on the embeddings and ground truth labels\n","        loss = contrastive_loss(src_embeddings, tgt_embeddings, tensor_score)\n","\n","        # Backward pass: Compute gradients\n","        loss.backward()\n","\n","        # Update the model's parameters\n","        optimizer.step()\n","\n","        # Append the loss for this iteration to the list\n","        train_losses.append(loss.item())\n","\n","        # Print loss every `print_interval` epochs\n","        if (epoch + 1) % print_interval == 0:\n","            print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item()}\")\n","\n","    # Step 6: Record end time of training\n","    end_time = time.time()\n","\n","    # Step 7: Plot the training loss over time\n","    plt.semilogy(range(1, num_epochs + 1), train_losses, label=\"Training Loss\", marker='o')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    # Print the total training time\n","    training_time = end_time - start_time\n","    print(f\"Training complete! Total training time: {training_time:.2f} seconds\")\n","\n","    # Step 8: Return the trained model\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6_tzUG_emtBg"},"outputs":[],"source":["# Initialize the GIT_mod model with the dimensionality of the target embeddings\n","# The first argument is the dimensionality of the target node embeddings (x_tgt.shape[1])\n","# The second argument (1) represents the number of RGIT layers in the model\n","GIT_model = RGIT_mod(x_tgt.shape[1], 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wVo-s7UQssSp"},"outputs":[],"source":["# Reading the training pairs from a CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(train_file, index_col=0)\n","\n","# Extract the 'SrcEntity' and 'TgtEntity' columns as NumPy arrays and convert them to integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)  # Source entity indices\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)  # Target entity indices\n","\n","# Extract the 'Score' column as a NumPy array and convert it to floats\n","tensor_score = df_embbedings['Score'].values.astype(float)  # Scores (labels) indicating if pairs match (1) or not (0)\n","\n","# Convert the NumPy arrays to PyTorch LongTensors (for indices) and FloatTensors (for scores)\n","tensor_term1_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)  # Source entity tensor\n","tensor_term2_o = torch.from_numpy(tensor_term2).type(torch.LongTensor)  # Target entity tensor\n","tensor_score_o = torch.from_numpy(tensor_score).type(torch.FloatTensor)  # Score tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"agHlFNesMVh3","outputId":"d6c35f2f-f952-4ae7-caac-52c21181b0db","executionInfo":{"status":"ok","timestamp":1732211476928,"user_tz":-60,"elapsed":552295,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [10/1000], Training Loss: 0.2252236157655716\n","Epoch [20/1000], Training Loss: 0.14085645973682404\n","Epoch [30/1000], Training Loss: 0.1068200170993805\n","Epoch [40/1000], Training Loss: 0.06792325526475906\n","Epoch [50/1000], Training Loss: 0.03979305550456047\n","Epoch [60/1000], Training Loss: 0.026576461270451546\n","Epoch [70/1000], Training Loss: 0.02017463743686676\n","Epoch [80/1000], Training Loss: 0.016415530815720558\n","Epoch [90/1000], Training Loss: 0.013973511755466461\n","Epoch [100/1000], Training Loss: 0.012440629303455353\n","Epoch [110/1000], Training Loss: 0.011415989138185978\n","Epoch [120/1000], Training Loss: 0.010654780082404613\n","Epoch [130/1000], Training Loss: 0.01003291830420494\n","Epoch [140/1000], Training Loss: 0.009497642517089844\n","Epoch [150/1000], Training Loss: 0.009031875059008598\n","Epoch [160/1000], Training Loss: 0.008616243489086628\n","Epoch [170/1000], Training Loss: 0.008237217552959919\n","Epoch [180/1000], Training Loss: 0.00788889080286026\n","Epoch [190/1000], Training Loss: 0.007564446423202753\n","Epoch [200/1000], Training Loss: 0.007259676232933998\n","Epoch [210/1000], Training Loss: 0.006975474301725626\n","Epoch [220/1000], Training Loss: 0.006713316310197115\n","Epoch [230/1000], Training Loss: 0.006471811328083277\n","Epoch [240/1000], Training Loss: 0.0062488061375916\n","Epoch [250/1000], Training Loss: 0.0060419305227696896\n","Epoch [260/1000], Training Loss: 0.005848503205925226\n","Epoch [270/1000], Training Loss: 0.005665799602866173\n","Epoch [280/1000], Training Loss: 0.005493548698723316\n","Epoch [290/1000], Training Loss: 0.005329904146492481\n","Epoch [300/1000], Training Loss: 0.0051741572096943855\n","Epoch [310/1000], Training Loss: 0.005025433376431465\n","Epoch [320/1000], Training Loss: 0.004883304238319397\n","Epoch [330/1000], Training Loss: 0.004748057574033737\n","Epoch [340/1000], Training Loss: 0.004620514810085297\n","Epoch [350/1000], Training Loss: 0.004502132069319487\n","Epoch [360/1000], Training Loss: 0.004392161499708891\n","Epoch [370/1000], Training Loss: 0.004291012417525053\n","Epoch [380/1000], Training Loss: 0.004199133720248938\n","Epoch [390/1000], Training Loss: 0.004116033669561148\n","Epoch [400/1000], Training Loss: 0.004041040316224098\n","Epoch [410/1000], Training Loss: 0.003973265178501606\n","Epoch [420/1000], Training Loss: 0.003911703359335661\n","Epoch [430/1000], Training Loss: 0.0038557201623916626\n","Epoch [440/1000], Training Loss: 0.003804706037044525\n","Epoch [450/1000], Training Loss: 0.003757739206776023\n","Epoch [460/1000], Training Loss: 0.0037139367777854204\n","Epoch [470/1000], Training Loss: 0.0036730251740664244\n","Epoch [480/1000], Training Loss: 0.0036346009001135826\n","Epoch [490/1000], Training Loss: 0.0035983340349048376\n","Epoch [500/1000], Training Loss: 0.0035639747511595488\n","Epoch [510/1000], Training Loss: 0.0035312583204358816\n","Epoch [520/1000], Training Loss: 0.0034999402705579996\n","Epoch [530/1000], Training Loss: 0.0034699158277362585\n","Epoch [540/1000], Training Loss: 0.0034410494845360518\n","Epoch [550/1000], Training Loss: 0.0034131144639104605\n","Epoch [560/1000], Training Loss: 0.0033859163522720337\n","Epoch [570/1000], Training Loss: 0.003359399037435651\n","Epoch [580/1000], Training Loss: 0.0033334684558212757\n","Epoch [590/1000], Training Loss: 0.0033080605790019035\n","Epoch [600/1000], Training Loss: 0.0032831209246069193\n","Epoch [610/1000], Training Loss: 0.003258613171055913\n","Epoch [620/1000], Training Loss: 0.003234485164284706\n","Epoch [630/1000], Training Loss: 0.0032107389997690916\n","Epoch [640/1000], Training Loss: 0.003187311114743352\n","Epoch [650/1000], Training Loss: 0.003164171939715743\n","Epoch [660/1000], Training Loss: 0.0031412607058882713\n","Epoch [670/1000], Training Loss: 0.003118570428341627\n","Epoch [680/1000], Training Loss: 0.0030960312578827143\n","Epoch [690/1000], Training Loss: 0.0030736522749066353\n","Epoch [700/1000], Training Loss: 0.0030513980891555548\n","Epoch [710/1000], Training Loss: 0.0030293576419353485\n","Epoch [720/1000], Training Loss: 0.0030075411777943373\n","Epoch [730/1000], Training Loss: 0.002985937986522913\n","Epoch [740/1000], Training Loss: 0.0029645010363310575\n","Epoch [750/1000], Training Loss: 0.0029431956354528666\n","Epoch [760/1000], Training Loss: 0.0029220578726381063\n","Epoch [770/1000], Training Loss: 0.0029011652804911137\n","Epoch [780/1000], Training Loss: 0.00288051157258451\n","Epoch [790/1000], Training Loss: 0.002860092790797353\n","Epoch [800/1000], Training Loss: 0.0028399068396538496\n","Epoch [810/1000], Training Loss: 0.0028198841027915478\n","Epoch [820/1000], Training Loss: 0.0028001139871776104\n","Epoch [830/1000], Training Loss: 0.002780629089102149\n","Epoch [840/1000], Training Loss: 0.0027614543214440346\n","Epoch [850/1000], Training Loss: 0.0027426332235336304\n","Epoch [860/1000], Training Loss: 0.0027242216747254133\n","Epoch [870/1000], Training Loss: 0.0027061502914875746\n","Epoch [880/1000], Training Loss: 0.0026884169783443213\n","Epoch [890/1000], Training Loss: 0.0026709481608122587\n","Epoch [900/1000], Training Loss: 0.0026538397651165724\n","Epoch [910/1000], Training Loss: 0.002636993769556284\n","Epoch [920/1000], Training Loss: 0.0026204469613730907\n","Epoch [930/1000], Training Loss: 0.00260419980622828\n","Epoch [940/1000], Training Loss: 0.002588235540315509\n","Epoch [950/1000], Training Loss: 0.0025725311134010553\n","Epoch [960/1000], Training Loss: 0.0025570911820977926\n","Epoch [970/1000], Training Loss: 0.0025419422890990973\n","Epoch [980/1000], Training Loss: 0.0025270599871873856\n","Epoch [990/1000], Training Loss: 0.0025123634841293097\n","Epoch [1000/1000], Training Loss: 0.0024978534784168005\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training complete! Total training time: 551.36 seconds\n"]}],"source":["# Train the GNN model using the provided source and target graph embeddings, edges, and training data\n","trained_model = train_model_gnn(\n","    model=GIT_model,                # The GNN model to be trained (initialized earlier)\n","    x_src=x_src,                    # Source node embeddings (tensor for source graph)\n","    edge_src=edge_src,              # Source graph edges (undirected edge index for source graph)\n","    x_tgt=x_tgt,                    # Target node embeddings (tensor for target graph)\n","    edge_tgt=edge_tgt,              # Target graph edges (undirected edge index for target graph)\n","    tensor_term1=tensor_term1_o,    # Indices of source entities for training\n","    tensor_term2=tensor_term2_o,    # Indices of target entities for training\n","    tensor_score=tensor_score_o,    # Scores (labels) indicating if pairs match (1) or not (0)\n","    learning_rate=0.0001,            # Learning rate for the Adam optimizer\n","    weight_decay_value=1e-4,        # Weight decay for L2 regularization to prevent overfitting\n","    num_epochs=1000,                # Number of training epochs\n","    print_interval=10               # Interval at which to print training progress (every 10 epochs)\n",")"]},{"cell_type":"markdown","metadata":{"id":"MYyhvjcTUaae"},"source":["# GIT Application"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BZ_VqP6tq6iD"},"outputs":[],"source":["# Determine if a GPU is available and move the computations to it; otherwise, use the CPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Assuming the model has been trained and hyperparameters (x_src, edge_src, x_tgt, edge_tgt) are set\n","\n","# Move the trained GIT_model to the device (GPU or CPU)\n","GIT_model.to(device)\n","\n","# Move the data tensors to the same device (GPU or CPU)\n","x_tgt = x_tgt.to(device)         # Target node embeddings\n","edge_tgt = edge_tgt.to(device)   # Target graph edges\n","x_src = x_src.to(device)         # Source node embeddings\n","edge_src = edge_src.to(device)   # Source graph edges\n","\n","# Set the model to evaluation mode; this disables dropout and batch normalization\n","GIT_model.eval()\n","\n","# Pass the source and target embeddings through the trained GNN model to update the embeddings\n","with torch.no_grad():  # Disable gradient computation (inference mode)\n","    embeddings_tgt = GIT_model(x_tgt, edge_tgt)  # Get updated embeddings for the target graph\n","    embeddings_src = GIT_model(x_src, edge_src)  # Get updated embeddings for the source graph\n","\n","# Detach the embeddings from the computation graph and move them back to the CPU\n","# This step is useful if you need to use the embeddings for tasks outside PyTorch (e.g., saving to disk)\n","embeddings_tgt = embeddings_tgt.detach().cpu()  # Target graph embeddings\n","embeddings_src = embeddings_src.detach().cpu()  # Source graph embeddings\n","\n","# At this point, embeddings_tgt and embeddings_src contain the updated embeddings, ready for downstream tasks"]},{"cell_type":"markdown","metadata":{"id":"Og5fdoGJrTCG"},"source":["# Selecting embedding pairs to train the Gated Network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J0nTwc-dnjLn"},"outputs":[],"source":["# Read the training pairs from a CSV file into a pandas DataFrame\n","df_embeddings = pd.read_csv(train_file, index_col=0)\n","\n","# Extract columns and convert to NumPy arrays\n","tensor_term1 = df_embeddings['SrcEntity'].values.astype(int)  # Source entity indices\n","tensor_term2 = df_embeddings['TgtEntity'].values.astype(int)  # Target entity indices\n","tensor_score = df_embeddings['Score'].values.astype(float)  # Matching scores\n","\n","# Split data into training and validation sets\n","tensor_term1_train, tensor_term1_val, tensor_term2_train, tensor_term2_val, tensor_score_train, tensor_score_val = train_test_split(\n","    tensor_term1, tensor_term2, tensor_score, test_size=0.3, random_state=42\n",")\n","\n","# Convert split data to PyTorch tensors\n","tensor_term1_train = torch.from_numpy(tensor_term1_train).type(torch.LongTensor)\n","tensor_term2_train = torch.from_numpy(tensor_term2_train).type(torch.LongTensor)\n","tensor_score_train = torch.from_numpy(tensor_score_train).type(torch.FloatTensor)\n","\n","tensor_term1_val = torch.from_numpy(tensor_term1_val).type(torch.LongTensor)\n","tensor_term2_val = torch.from_numpy(tensor_term2_val).type(torch.LongTensor)\n","tensor_score_val = torch.from_numpy(tensor_score_val).type(torch.FloatTensor)\n","\n","# Move the embeddings back to the CPU if not already there\n","x_tgt = x_tgt.cpu()  # Target node embeddings\n","x_src = x_src.cpu()  # Source node embeddings\n","\n","# Select embeddings for the training set\n","X1_train = select_rows_by_index(embeddings_src, tensor_term1_train)\n","X2_train = select_rows_by_index(x_src, tensor_term1_train)\n","X3_train = select_rows_by_index(embeddings_tgt, tensor_term2_train)\n","X4_train = select_rows_by_index(x_tgt, tensor_term2_train)\n","\n","# Select embeddings for the validation set\n","X1_val = select_rows_by_index(embeddings_src, tensor_term1_val)\n","X2_val = select_rows_by_index(x_src, tensor_term1_val)\n","X3_val = select_rows_by_index(embeddings_tgt, tensor_term2_val)\n","X4_val = select_rows_by_index(x_tgt, tensor_term2_val)\n","\n","# Now you have:\n","# - Training tensors: X1_train, X2_train, X3_train, X4_train, tensor_score_train\n","# - Validation tensors: X1_val, X2_val, X3_val, X4_val, tensor_score_val"]},{"cell_type":"code","source":["positive_weight = len(tensor_score_train) / (weight_train * tensor_score_train.sum())"],"metadata":{"id":"wR3PbrbBETJA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fNdCgaTMExPK"},"source":["# Gated Network Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gof1eIPIWSVU"},"outputs":[],"source":["def train_gated_combination_model(X1_t, X2_t, X3_t, X4_t, tensor_score_o,\n","                                  X1_val, X2_val, X3_val, X4_val, tensor_score_val,\n","                                  epochs=120, batch_size=32, learning_rate=0.001, weight_decay=1e-5):\n","    \"\"\"\n","    Trains the GatedCombination model with training and validation data, using ReduceLROnPlateau scheduler.\n","    \"\"\"\n","\n","    # Create datasets and DataLoaders\n","    train_dataset = TensorDataset(X1_t, X2_t, X3_t, X4_t, tensor_score_o)\n","    val_dataset = TensorDataset(X1_val, X2_val, X3_val, X4_val, tensor_score_val)\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = GatedCombination(X1_t.shape[1]).to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","\n","    # Use ReduceLROnPlateau scheduler\n","    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n","\n","    criterion = WeightedBCELoss(pos_weight=positive_weight).to(device)\n","\n","    train_losses, val_losses = [], []\n","\n","    start_time = time.time()\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        total_train_loss, y_true_train, y_pred_train = 0.0, [], []\n","\n","        for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in train_loader:\n","            batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (batch_X1.to(device), batch_X2.to(device),\n","                                                               batch_X3.to(device), batch_X4.to(device), batch_y.to(device))\n","            optimizer.zero_grad()\n","            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","            loss = criterion(outputs, batch_y.unsqueeze(1).float())\n","            loss.backward()\n","            optimizer.step()\n","            total_train_loss += loss.item()\n","            y_true_train.extend(batch_y.cpu().numpy())\n","            y_pred_train.extend((outputs > 0.2).float().cpu().numpy())\n","\n","        train_f1 = f1_score(y_true_train, y_pred_train)\n","        train_loss = total_train_loss / len(train_loader)\n","        train_losses.append(train_loss)\n","\n","        # Validation phase\n","        model.eval()\n","        total_val_loss, y_true_val, y_pred_val = 0.0, [], []\n","        with torch.no_grad():\n","            for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in val_loader:\n","                batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (batch_X1.to(device), batch_X2.to(device),\n","                                                                   batch_X3.to(device), batch_X4.to(device), batch_y.to(device))\n","                outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","                val_loss = criterion(outputs, batch_y.unsqueeze(1).float())\n","                total_val_loss += val_loss.item()\n","                y_true_val.extend(batch_y.cpu().numpy())\n","                y_pred_val.extend((outputs > 0.4).float().cpu().numpy())\n","\n","        val_f1 = f1_score(y_true_val, y_pred_val)\n","        avg_val_loss = total_val_loss / len(val_loader)\n","        val_losses.append(avg_val_loss)\n","\n","        # Step the scheduler with validation loss\n","        scheduler.step(avg_val_loss)\n","\n","        # Print training and validation metrics\n","        print(f\"Epoch [{epoch + 1}/{epochs}] Training Loss: {train_loss:.4f}, F1 Score: {train_f1:.4f} | \"\n","              f\"Validation Loss: {avg_val_loss:.4f}, F1 Score: {val_f1:.4f}\")\n","\n","    end_time = time.time()\n","\n","    # Plotting\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(train_losses, label=\"Training Loss\", marker='o')\n","    plt.plot(val_losses, label=\"Validation Loss\", marker='x')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    print(f\"Training complete! Total time: {end_time - start_time:.2f} seconds\")\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"l11dgb8ei69T","outputId":"f0b6fbc2-20e6-436c-b273-3a3cfc657a8a","executionInfo":{"status":"ok","timestamp":1732212992323,"user_tz":-60,"elapsed":1514251,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/100] Training Loss: 0.4946, F1 Score: 0.0249 | Validation Loss: 0.2697, F1 Score: 0.5808\n","Epoch [2/100] Training Loss: 0.1966, F1 Score: 0.3554 | Validation Loss: 0.1559, F1 Score: 0.8715\n","Epoch [3/100] Training Loss: 0.1267, F1 Score: 0.6203 | Validation Loss: 0.1111, F1 Score: 0.8871\n","Epoch [4/100] Training Loss: 0.0948, F1 Score: 0.6948 | Validation Loss: 0.0868, F1 Score: 0.8978\n","Epoch [5/100] Training Loss: 0.0764, F1 Score: 0.7215 | Validation Loss: 0.0714, F1 Score: 0.9111\n","Epoch [6/100] Training Loss: 0.0641, F1 Score: 0.7212 | Validation Loss: 0.0630, F1 Score: 0.9025\n","Epoch [7/100] Training Loss: 0.0554, F1 Score: 0.7299 | Validation Loss: 0.0527, F1 Score: 0.9085\n","Epoch [8/100] Training Loss: 0.0491, F1 Score: 0.7235 | Validation Loss: 0.0465, F1 Score: 0.9052\n","Epoch [9/100] Training Loss: 0.0445, F1 Score: 0.7346 | Validation Loss: 0.0425, F1 Score: 0.9043\n","Epoch [10/100] Training Loss: 0.0408, F1 Score: 0.7442 | Validation Loss: 0.0403, F1 Score: 0.8980\n","Epoch [11/100] Training Loss: 0.0378, F1 Score: 0.7420 | Validation Loss: 0.0371, F1 Score: 0.8926\n","Epoch [12/100] Training Loss: 0.0355, F1 Score: 0.7418 | Validation Loss: 0.0357, F1 Score: 0.8976\n","Epoch [13/100] Training Loss: 0.0338, F1 Score: 0.7525 | Validation Loss: 0.0325, F1 Score: 0.8891\n","Epoch [14/100] Training Loss: 0.0322, F1 Score: 0.7497 | Validation Loss: 0.0335, F1 Score: 0.9050\n","Epoch [15/100] Training Loss: 0.0310, F1 Score: 0.7559 | Validation Loss: 0.0307, F1 Score: 0.8789\n","Epoch [16/100] Training Loss: 0.0295, F1 Score: 0.7571 | Validation Loss: 0.0294, F1 Score: 0.8933\n","Epoch [17/100] Training Loss: 0.0288, F1 Score: 0.7565 | Validation Loss: 0.0305, F1 Score: 0.9008\n","Epoch [18/100] Training Loss: 0.0280, F1 Score: 0.7599 | Validation Loss: 0.0276, F1 Score: 0.8942\n","Epoch [19/100] Training Loss: 0.0272, F1 Score: 0.7597 | Validation Loss: 0.0276, F1 Score: 0.8959\n","Epoch [20/100] Training Loss: 0.0265, F1 Score: 0.7644 | Validation Loss: 0.0265, F1 Score: 0.8868\n","Epoch [21/100] Training Loss: 0.0260, F1 Score: 0.7654 | Validation Loss: 0.0265, F1 Score: 0.9045\n","Epoch [22/100] Training Loss: 0.0254, F1 Score: 0.7685 | Validation Loss: 0.0250, F1 Score: 0.8933\n","Epoch [23/100] Training Loss: 0.0251, F1 Score: 0.7684 | Validation Loss: 0.0255, F1 Score: 0.8905\n","Epoch [24/100] Training Loss: 0.0246, F1 Score: 0.7674 | Validation Loss: 0.0255, F1 Score: 0.8945\n","Epoch [25/100] Training Loss: 0.0241, F1 Score: 0.7703 | Validation Loss: 0.0238, F1 Score: 0.8889\n","Epoch [26/100] Training Loss: 0.0236, F1 Score: 0.7693 | Validation Loss: 0.0279, F1 Score: 0.9012\n","Epoch [27/100] Training Loss: 0.0232, F1 Score: 0.7694 | Validation Loss: 0.0237, F1 Score: 0.8914\n","Epoch [28/100] Training Loss: 0.0228, F1 Score: 0.7753 | Validation Loss: 0.0231, F1 Score: 0.8931\n","Epoch [29/100] Training Loss: 0.0227, F1 Score: 0.7769 | Validation Loss: 0.0239, F1 Score: 0.8898\n","Epoch [30/100] Training Loss: 0.0223, F1 Score: 0.7749 | Validation Loss: 0.0252, F1 Score: 0.8898\n","Epoch [31/100] Training Loss: 0.0222, F1 Score: 0.7759 | Validation Loss: 0.0232, F1 Score: 0.8845\n","Epoch [32/100] Training Loss: 0.0220, F1 Score: 0.7798 | Validation Loss: 0.0245, F1 Score: 0.8859\n","Epoch [33/100] Training Loss: 0.0217, F1 Score: 0.7761 | Validation Loss: 0.0224, F1 Score: 0.8986\n","Epoch [34/100] Training Loss: 0.0213, F1 Score: 0.7793 | Validation Loss: 0.0220, F1 Score: 0.8793\n","Epoch [35/100] Training Loss: 0.0210, F1 Score: 0.7766 | Validation Loss: 0.0259, F1 Score: 0.8997\n","Epoch [36/100] Training Loss: 0.0210, F1 Score: 0.7757 | Validation Loss: 0.0219, F1 Score: 0.9032\n","Epoch [37/100] Training Loss: 0.0209, F1 Score: 0.7838 | Validation Loss: 0.0241, F1 Score: 0.8961\n","Epoch [38/100] Training Loss: 0.0207, F1 Score: 0.7838 | Validation Loss: 0.0226, F1 Score: 0.8850\n","Epoch [39/100] Training Loss: 0.0201, F1 Score: 0.7871 | Validation Loss: 0.0209, F1 Score: 0.8760\n","Epoch [40/100] Training Loss: 0.0207, F1 Score: 0.7790 | Validation Loss: 0.0229, F1 Score: 0.8841\n","Epoch [41/100] Training Loss: 0.0204, F1 Score: 0.7812 | Validation Loss: 0.0212, F1 Score: 0.9013\n","Epoch [42/100] Training Loss: 0.0199, F1 Score: 0.7878 | Validation Loss: 0.0225, F1 Score: 0.9056\n","Epoch [43/100] Training Loss: 0.0201, F1 Score: 0.7840 | Validation Loss: 0.0235, F1 Score: 0.8898\n","Epoch [44/100] Training Loss: 0.0195, F1 Score: 0.7826 | Validation Loss: 0.0212, F1 Score: 0.9020\n","Epoch [45/100] Training Loss: 0.0199, F1 Score: 0.7856 | Validation Loss: 0.0216, F1 Score: 0.8938\n","Epoch [46/100] Training Loss: 0.0197, F1 Score: 0.7809 | Validation Loss: 0.0218, F1 Score: 0.8586\n","Epoch [47/100] Training Loss: 0.0193, F1 Score: 0.7883 | Validation Loss: 0.0222, F1 Score: 0.8880\n","Epoch [48/100] Training Loss: 0.0194, F1 Score: 0.7835 | Validation Loss: 0.0203, F1 Score: 0.8947\n","Epoch [49/100] Training Loss: 0.0195, F1 Score: 0.7825 | Validation Loss: 0.0212, F1 Score: 0.8731\n","Epoch [50/100] Training Loss: 0.0190, F1 Score: 0.7801 | Validation Loss: 0.0226, F1 Score: 0.9083\n","Epoch [51/100] Training Loss: 0.0192, F1 Score: 0.7887 | Validation Loss: 0.0203, F1 Score: 0.8873\n","Epoch [52/100] Training Loss: 0.0192, F1 Score: 0.7835 | Validation Loss: 0.0212, F1 Score: 0.8686\n","Epoch [53/100] Training Loss: 0.0185, F1 Score: 0.7907 | Validation Loss: 0.0214, F1 Score: 0.8745\n","Epoch [54/100] Training Loss: 0.0190, F1 Score: 0.7950 | Validation Loss: 0.0202, F1 Score: 0.8727\n","Epoch [55/100] Training Loss: 0.0188, F1 Score: 0.7912 | Validation Loss: 0.0198, F1 Score: 0.8848\n","Epoch [56/100] Training Loss: 0.0189, F1 Score: 0.7958 | Validation Loss: 0.0208, F1 Score: 0.8852\n","Epoch [57/100] Training Loss: 0.0188, F1 Score: 0.7899 | Validation Loss: 0.0215, F1 Score: 0.8721\n","Epoch [58/100] Training Loss: 0.0183, F1 Score: 0.7806 | Validation Loss: 0.0209, F1 Score: 0.8791\n","Epoch [59/100] Training Loss: 0.0181, F1 Score: 0.7907 | Validation Loss: 0.0194, F1 Score: 0.8836\n","Epoch [60/100] Training Loss: 0.0184, F1 Score: 0.7907 | Validation Loss: 0.0215, F1 Score: 0.8793\n","Epoch [61/100] Training Loss: 0.0182, F1 Score: 0.7909 | Validation Loss: 0.0229, F1 Score: 0.9122\n","Epoch [62/100] Training Loss: 0.0181, F1 Score: 0.7899 | Validation Loss: 0.0220, F1 Score: 0.8959\n","Epoch [63/100] Training Loss: 0.0185, F1 Score: 0.7878 | Validation Loss: 0.0201, F1 Score: 0.8802\n","Epoch [64/100] Training Loss: 0.0175, F1 Score: 0.7904 | Validation Loss: 0.0199, F1 Score: 0.9062\n","Epoch [65/100] Training Loss: 0.0179, F1 Score: 0.7950 | Validation Loss: 0.0238, F1 Score: 0.8471\n","Epoch [66/100] Training Loss: 0.0182, F1 Score: 0.7907 | Validation Loss: 0.0195, F1 Score: 0.8864\n","Epoch [67/100] Training Loss: 0.0178, F1 Score: 0.7922 | Validation Loss: 0.0199, F1 Score: 0.9011\n","Epoch [68/100] Training Loss: 0.0180, F1 Score: 0.7943 | Validation Loss: 0.0212, F1 Score: 0.8459\n","Epoch [69/100] Training Loss: 0.0176, F1 Score: 0.7915 | Validation Loss: 0.0197, F1 Score: 0.8956\n","Epoch 00070: reducing learning rate of group 0 to 1.0000e-04.\n","Epoch [70/100] Training Loss: 0.0175, F1 Score: 0.7935 | Validation Loss: 0.0204, F1 Score: 0.8984\n","Epoch [71/100] Training Loss: 0.0148, F1 Score: 0.8167 | Validation Loss: 0.0196, F1 Score: 0.8919\n","Epoch [72/100] Training Loss: 0.0147, F1 Score: 0.8214 | Validation Loss: 0.0197, F1 Score: 0.8956\n","Epoch [73/100] Training Loss: 0.0140, F1 Score: 0.8177 | Validation Loss: 0.0199, F1 Score: 0.8917\n","Epoch [74/100] Training Loss: 0.0141, F1 Score: 0.8191 | Validation Loss: 0.0197, F1 Score: 0.8938\n","Epoch [75/100] Training Loss: 0.0140, F1 Score: 0.8211 | Validation Loss: 0.0199, F1 Score: 0.8966\n","Epoch [76/100] Training Loss: 0.0140, F1 Score: 0.8230 | Validation Loss: 0.0197, F1 Score: 0.8919\n","Epoch [77/100] Training Loss: 0.0140, F1 Score: 0.8195 | Validation Loss: 0.0201, F1 Score: 0.8982\n","Epoch [78/100] Training Loss: 0.0140, F1 Score: 0.8212 | Validation Loss: 0.0199, F1 Score: 0.8966\n","Epoch [79/100] Training Loss: 0.0140, F1 Score: 0.8202 | Validation Loss: 0.0199, F1 Score: 0.8956\n","Epoch [80/100] Training Loss: 0.0140, F1 Score: 0.8195 | Validation Loss: 0.0198, F1 Score: 0.8956\n","Epoch 00081: reducing learning rate of group 0 to 1.0000e-05.\n","Epoch [81/100] Training Loss: 0.0140, F1 Score: 0.8240 | Validation Loss: 0.0196, F1 Score: 0.8928\n","Epoch [82/100] Training Loss: 0.0135, F1 Score: 0.8141 | Validation Loss: 0.0198, F1 Score: 0.8947\n","Epoch [83/100] Training Loss: 0.0135, F1 Score: 0.8214 | Validation Loss: 0.0198, F1 Score: 0.8956\n","Epoch [84/100] Training Loss: 0.0135, F1 Score: 0.8233 | Validation Loss: 0.0198, F1 Score: 0.8966\n","Epoch [85/100] Training Loss: 0.0135, F1 Score: 0.8223 | Validation Loss: 0.0199, F1 Score: 0.8966\n","Epoch [86/100] Training Loss: 0.0135, F1 Score: 0.8219 | Validation Loss: 0.0199, F1 Score: 0.8966\n","Epoch [87/100] Training Loss: 0.0135, F1 Score: 0.8226 | Validation Loss: 0.0199, F1 Score: 0.8966\n","Epoch [88/100] Training Loss: 0.0135, F1 Score: 0.8223 | Validation Loss: 0.0199, F1 Score: 0.8966\n","Epoch [89/100] Training Loss: 0.0135, F1 Score: 0.8251 | Validation Loss: 0.0199, F1 Score: 0.8956\n","Epoch [90/100] Training Loss: 0.0135, F1 Score: 0.8247 | Validation Loss: 0.0199, F1 Score: 0.8956\n","Epoch [91/100] Training Loss: 0.0135, F1 Score: 0.8233 | Validation Loss: 0.0199, F1 Score: 0.8945\n","Epoch 00092: reducing learning rate of group 0 to 1.0000e-06.\n","Epoch [92/100] Training Loss: 0.0135, F1 Score: 0.8219 | Validation Loss: 0.0199, F1 Score: 0.8954\n","Epoch [93/100] Training Loss: 0.0134, F1 Score: 0.8230 | Validation Loss: 0.0199, F1 Score: 0.8954\n","Epoch [94/100] Training Loss: 0.0134, F1 Score: 0.8223 | Validation Loss: 0.0199, F1 Score: 0.8954\n","Epoch [95/100] Training Loss: 0.0134, F1 Score: 0.8223 | Validation Loss: 0.0199, F1 Score: 0.8954\n","Epoch [96/100] Training Loss: 0.0134, F1 Score: 0.8226 | Validation Loss: 0.0199, F1 Score: 0.8954\n","Epoch [97/100] Training Loss: 0.0134, F1 Score: 0.8226 | Validation Loss: 0.0199, F1 Score: 0.8954\n","Epoch [98/100] Training Loss: 0.0134, F1 Score: 0.8223 | Validation Loss: 0.0199, F1 Score: 0.8954\n","Epoch [99/100] Training Loss: 0.0134, F1 Score: 0.8223 | Validation Loss: 0.0199, F1 Score: 0.8954\n","Epoch [100/100] Training Loss: 0.0134, F1 Score: 0.8226 | Validation Loss: 0.0199, F1 Score: 0.8954\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x500 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training complete! Total time: 1513.97 seconds\n"]}],"source":["# Train the GatedCombination model using training and validation data\n","trained_model = train_gated_combination_model(\n","    X1_train,          # Updated source embeddings (after applying the GNN model)\n","    X2_train,          # Original source embeddings (before applying the GNN model)\n","    X3_train,          # Updated target embeddings (after applying the GNN model)\n","    X4_train,          # Original target embeddings (before applying the GNN model)\n","    tensor_score_train, # Ground truth labels for the training set (1 for matched pairs, 0 for unmatched pairs)\n","\n","    X1_val,            # Updated source embeddings for the validation set\n","    X2_val,            # Original source embeddings for the validation set\n","    X3_val,            # Updated target embeddings for the validation set\n","    X4_val,            # Original target embeddings for the validation set\n","    tensor_score_val,  # Ground truth labels for the validation set (1 for matched pairs, 0 for unmatched pairs)\n","\n","    epochs=100,        # Number of epochs (iterations over the entire training dataset)\n","    batch_size=32,     # Number of training samples processed in one forward/backward pass\n","    learning_rate=0.001, # Learning rate for the optimizer (controls step size during optimization)\n","    weight_decay=1e-5  # Weight decay (L2 regularization) to prevent overfitting\n",")"]},{"cell_type":"markdown","metadata":{"id":"uAmLuMtGW9c2"},"source":["# **Mappings Selector**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lnFtpUAfJQHl"},"outputs":[],"source":["# Build an indexed dictionary for the source ontology classes\n","# src_class is the file path to the JSON file containing the source ontology classes\n","indexed_dict_src = build_indexed_dict(src_class)\n","\n","# Build an indexed dictionary for the target ontology classes\n","# tgt_class is the file path to the JSON file containing the target ontology classes\n","indexed_dict_tgt = build_indexed_dict(tgt_class)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"beipwavuJQHl"},"outputs":[],"source":["# Read the candidate pairs from a Candidates CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(candidates_Prediction, index_col=0)\n","\n","# Extract the 'SrcEntity' column (source entity indices) and convert it to a NumPy array of integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)\n","\n","# Extract the 'TgtEntity' column (target entity indices) and convert it to a NumPy array of integers\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)\n","\n","# Convert the source entity indices to a PyTorch LongTensor\n","src_entity_tensor_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)\n","\n","# Convert the target entity indices to a PyTorch LongTensor\n","tgt_entity_tenso_or = torch.from_numpy(tensor_term2).type(torch.LongTensor)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ECLhmxyKJQHl"},"outputs":[],"source":["# Select rows from the updated source embeddings based on the indices in src_entity_tensor_o\n","X1_tt = select_rows_by_index(embeddings_src, src_entity_tensor_o)\n","\n","# Select rows from the original source embeddings based on the indices in src_entity_tensor_o\n","X2_tt = select_rows_by_index(x_src, src_entity_tensor_o)\n","\n","# Select rows from the updated target embeddings based on the indices in tgt_entity_tenso_or\n","X3_tt = select_rows_by_index(embeddings_tgt, tgt_entity_tenso_or)\n","\n","# Select rows from the original target embeddings based on the indices in tgt_entity_tenso_or\n","X4_tt = select_rows_by_index(x_tgt, tgt_entity_tenso_or)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"000969b6-98b8-45c2-a11e-2b5b119d2e50","id":"UFP6OQR-7D4N","executionInfo":{"status":"ok","timestamp":1732213448384,"user_tz":-60,"elapsed":37044,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting time: 12.40 seconds\n","Predictions saved to /content/gdrive/My Drive/BioGITOM-VLDB/Experiments/ncit2doid/BERT_Model_Choice/Results/ncit2doid_all_predictions_Mini.tsv\n"]}],"source":["# Generate predictions for candidate mappings using the trained GatedCombination model\n","Prediction_with_candidates(\n","    model=trained_model,             # The trained GatedCombination model used to evaluate similarity\n","    X1_tt=X1_tt,                     # Updated source embeddings (after applying the GIT model)\n","    X2_tt=X2_tt,                     # Original source embeddings (before applying the GIT model)\n","    X3_tt=X3_tt,                     # Updated target embeddings (after applying the GIT model)\n","    X4_tt=X4_tt,                     # Original target embeddings (before applying the GIT model)\n","    src_entity_tensor_o=src_entity_tensor_o,  # Tensor of source entity indices used for evaluation\n","    tgt_entity_tensor_o=tgt_entity_tenso_or,  # Tensor of target entity indices used for evaluation\n","    indexed_dict_src=indexed_dict_src,        # Dictionary mapping source entity indices to their URIs\n","    indexed_dict_tgt=indexed_dict_tgt,        # Dictionary mapping target entity indices to their URIs\n","    all_predictions_path=all_predictions_path # Path to save all predictions with similarity scores in TSV format\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mEc12J-B7D4N","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d1c54fa4-d3b8-4bce-aff4-152904ec7788","executionInfo":{"status":"ok","timestamp":1732213463627,"user_tz":-60,"elapsed":15246,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Positive predictions: 3226\n"]}],"source":["# Filter the highest scoring predictions from the predictions file and save the results to a new file\n","matching_results_df = filter_highest_predictions(\n","    all_predictions_path,  # Path to the file containing all predictions with scores for all candidate pairs\n","    prediction_path        # Path where the filtered predictions with highest scores will be saved\n",")"]},{"cell_type":"markdown","metadata":{"id":"BIx74lNV7D4O"},"source":["# **Evaluation**"]},{"cell_type":"markdown","source":["# Global metrics calculation"],"metadata":{"id":"Pp3IpBBfWn9m"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bkOewzXr7D4O","outputId":"d4d4dfbd-655a-4b87-fa41-d54a619a4b0e","executionInfo":{"status":"ok","timestamp":1732213464506,"user_tz":-60,"elapsed":883,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Correct Predictions: 2838\n","{'P': 0.88, 'R': 0.865, 'F1': 0.872}\n"]}],"source":["# Retrieve the indices of the ignored classes (from source and target ontologies)\n","ignored_class_index = get_ignored_class_index(src_onto)  # Get ignored class indices from source ontology\n","ignored_class_index.update(get_ignored_class_index(tgt_onto))  # Update with ignored class indices from target ontology\n","\n","# Read the predicted mappings from the prediction results file\n","preds = EntityMapping.read_table_mappings(prediction_path)\n","\n","# Read the reference mappings from the ground truth test file\n","refs = ReferenceMapping.read_table_mappings(f\"{dataset_dir}/refs_equiv/test.tsv\")\n","\n","# Filter the predicted mappings to remove any mappings that involve ignored classes\n","preds = remove_ignored_mappings(preds, ignored_class_index)\n","\n","# Compute the precision, recall, and F1-score by comparing predictions with the reference mappings\n","results = AlignmentEvaluator.f1(preds, refs)\n","\n","preds2 = [p.to_tuple() for p in preds]\n","refs2 = [r.to_tuple() for r in refs]\n","\n","correct= len(set(preds2).intersection(set(refs2)))\n","\n","print(f\"Number of Correct Predictions: {correct}\")\n","\n","# Print the computed precision, recall, and F1-score metrics\n","print(results)"]},{"cell_type":"markdown","source":["# Ranked-based metrics calculation"],"metadata":{"id":"aECB6igZW04C"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-AK-jADkSbTa"},"outputs":[],"source":["# Read the candidate pairs from a Candidates CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(candidates_Rank, index_col=0)\n","\n","# Extract the 'SrcEntity' column (source entity indices) and convert it to a NumPy array of integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)\n","\n","# Extract the 'TgtEntity' column (target entity indices) and convert it to a NumPy array of integers\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)\n","\n","# Convert the source entity indices to a PyTorch LongTensor\n","src_entity_tensor_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)\n","\n","# Convert the target entity indices to a PyTorch LongTensor\n","tgt_entity_tenso_or = torch.from_numpy(tensor_term2).type(torch.LongTensor)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oyOzcLv-SbTb"},"outputs":[],"source":["# Select rows from the updated source embeddings based on the indices in src_entity_tensor_o\n","X1_tt = select_rows_by_index(embeddings_src, src_entity_tensor_o)\n","\n","# Select rows from the original source embeddings based on the indices in src_entity_tensor_o\n","X2_tt = select_rows_by_index(x_src, src_entity_tensor_o)\n","\n","# Select rows from the updated target embeddings based on the indices in tgt_entity_tenso_or\n","X3_tt = select_rows_by_index(embeddings_tgt, tgt_entity_tenso_or)\n","\n","# Select rows from the original target embeddings based on the indices in tgt_entity_tenso_or\n","X4_tt = select_rows_by_index(x_tgt, tgt_entity_tenso_or)"]},{"cell_type":"code","source":["# Perform ranking-based predictions using the trained GatedCombination model\n","# Generate predictions for candidate mappings using the trained GatedCombination model\n","Prediction_with_candidates(\n","    model=trained_model,             # The trained GatedCombination model used to evaluate similarity\n","    X1_tt=X1_tt,                     # Updated source embeddings (after applying the GIT model)\n","    X2_tt=X2_tt,                     # Original source embeddings (before applying the GIT model)\n","    X3_tt=X3_tt,                     # Updated target embeddings (after applying the GIT model)\n","    X4_tt=X4_tt,                     # Original target embeddings (before applying the GIT model)\n","    src_entity_tensor_o=src_entity_tensor_o,  # Tensor of source entity indices used for evaluation\n","    tgt_entity_tensor_o=tgt_entity_tenso_or,  # Tensor of target entity indices used for evaluation\n","    indexed_dict_src=indexed_dict_src,        # Dictionary mapping source entity indices to their URIs\n","    indexed_dict_tgt=indexed_dict_tgt,        # Dictionary mapping target entity indices to their URIs\n","    all_predictions_path=all_predictions_path_ranked, # Path where the ranked predictions will be saved in TSV format\n",")"],"metadata":{"id":"-O2f7X6cSb-m"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_402seVv7D4O"},"outputs":[],"source":["# Compute MRR and Hits@k metrics\n","# This function evaluates the predicted rankings against the reference mappings\n","results = compute_mrr_and_hits(\n","    reference_file=test_cands,             # Reference file with true ranks\n","    predicted_file=all_predictions_path_ranked,             # File containing predicted rankings\n","    output_file=formatted_predictions_path,    # File path to save formatted predictions\n","    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",")\n","\n","# Display the computed metrics\n","print(\"MRR and Hits@k Results:\")\n","print(results)  # Output the Mean Reciprocal Rank (MRR) and Hits@k metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wStfa4eZ7D4O"},"outputs":[],"source":["# Call the ranking evaluation function, passing the path to the formatted predictions file.\n","# Ks specifies the evaluation levels, checking if the correct target is within the top K candidates.\n","results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n","print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n","print(results)"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}