{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkAX88H3RNRW"
      },
      "source": [
        "# **Package Installation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bSuJvX5_qNhr",
        "outputId": "fe094903-baa8-4878-b4f2-a5d3b6b8ce0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.6.0\n",
            "  Using cached torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchvision==0.21.0\n",
            "  Using cached torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting filelock (from torch==2.6.0)\n",
            "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch==2.6.0)\n",
            "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting networkx (from torch==2.6.0)\n",
            "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch==2.6.0)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch==2.6.0)\n",
            "  Using cached fsspec-2025.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0)\n",
            "  Using cached nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.6.0)\n",
            "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch==2.6.0)\n",
            "  Using cached triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting sympy==1.13.1 (from torch==2.6.0)\n",
            "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting numpy (from torchvision==0.21.0)\n",
            "  Using cached numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.21.0)\n",
            "  Using cached pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch==2.6.0)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.6.0)\n",
            "  Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Using cached torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "Using cached torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
            "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Using cached nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "Using cached triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "Using cached pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl (4.6 MB)\n",
            "Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Using cached fsspec-2025.5.0-py3-none-any.whl (196 kB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "Using cached numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Installing collected packages: triton, nvidia-cusparselt-cu12, mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.13.2\n",
            "    Uninstalling typing_extensions-4.13.2:\n",
            "      Successfully uninstalled typing_extensions-4.13.2\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.2.1\n",
            "    Uninstalling pillow-11.2.1:\n",
            "      Successfully uninstalled pillow-11.2.1\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
            "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
            "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.6\n",
            "    Uninstalling numpy-2.2.6:\n",
            "      Successfully uninstalled numpy-2.2.6\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.18.0\n",
            "    Uninstalling filelock-3.18.0:\n",
            "      Successfully uninstalled filelock-3.18.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
            "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0\n",
            "    Uninstalling torch-2.6.0:\n",
            "      Successfully uninstalled torch-2.6.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0\n",
            "    Uninstalling torchvision-0.21.0:\n",
            "      Successfully uninstalled torchvision-0.21.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.5.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 pillow-11.2.1 sympy-1.13.1 torch-2.6.0 torchvision-0.21.0 triton-3.2.0 typing-extensions-4.13.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "functorch",
                  "markupsafe",
                  "mpmath",
                  "networkx",
                  "sympy",
                  "torch",
                  "torchgen",
                  "triton"
                ]
              },
              "id": "e82f038b926449838d7258b32c0dc4ad"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Reinstall a specific version of PyTorch (v2.6.0) and torchvision (v0.21.0)\n",
        "# The \"--force-reinstall\" flag ensures that the packages are reinstalled even if the correct version is already present.\n",
        "# This is useful to resolve environment issues or when dependencies need to be reset.\n",
        "!pip install torch==2.6.0 torchvision==0.21.0 --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ItSvFeEAfLBF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acab6129-509c-4464-bbf1-e307e3e9674e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.2.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.2.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.2.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\n",
            "Collecting torch-geometric==2.4.0\n",
            "  Using cached torch_geometric-2.4.0-py3-none-any.whl.metadata (63 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (2.2.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (1.15.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (3.1.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (3.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (1.6.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric==2.4.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.4.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.4.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.4.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.4.0) (2025.4.26)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->torch-geometric==2.4.0) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->torch-geometric==2.4.0) (3.6.0)\n",
            "Using cached torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "Installing collected packages: torch-geometric\n",
            "  Attempting uninstall: torch-geometric\n",
            "    Found existing installation: torch-geometric 2.7.0\n",
            "    Uninstalling torch-geometric-2.7.0:\n",
            "      Successfully uninstalled torch-geometric-2.7.0\n",
            "Successfully installed torch-geometric-2.4.0\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.11/dist-packages (2.1.2+pt20cpu)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.11/dist-packages (0.6.18+pt20cpu)\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.11/dist-packages (1.6.3+pt20cpu)\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.11/dist-packages (1.2.2+pt20cpu)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (2.2.6)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: deeponto in /usr/local/lib/python3.11/dist-packages (0.9.3)\n",
            "Requirement already satisfied: JPype1 in /usr/local/lib/python3.11/dist-packages (from deeponto) (1.5.2)\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.11/dist-packages (from deeponto) (0.1.8)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from deeponto) (2.6.0)\n",
            "Requirement already satisfied: anytree in /usr/local/lib/python3.11/dist-packages (from deeponto) (2.13.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from deeponto) (8.2.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from deeponto) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from deeponto) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deeponto) (2.2.6)\n",
            "Requirement already satisfied: scikit_learn in /usr/local/lib/python3.11/dist-packages (from deeponto) (1.6.1)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.11/dist-packages (from deeponto) (4.51.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from deeponto) (3.6.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (from deeponto) (3.8.5)\n",
            "Requirement already satisfied: pprintpp in /usr/local/lib/python3.11/dist-packages (from deeponto) (0.4.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from deeponto) (3.4.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from deeponto) (5.4.0)\n",
            "Requirement already satisfied: textdistance in /usr/local/lib/python3.11/dist-packages (from deeponto) (4.6.3)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from deeponto) (7.7.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from deeponto) (6.17.1)\n",
            "Requirement already satisfied: enlighten in /usr/local/lib/python3.11/dist-packages (from deeponto) (1.14.1)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.11/dist-packages (from deeponto) (7.1.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from deeponto) (3.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (20.0.0)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (0.31.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (6.0.2)\n",
            "Requirement already satisfied: blessed>=1.17.7 in /usr/local/lib/python3.11/dist-packages (from enlighten->deeponto) (1.21.0)\n",
            "Requirement already satisfied: prefixed>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from enlighten->deeponto) (0.9.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (6.4.2)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (5.7.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->deeponto) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->deeponto) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->deeponto) (3.0.15)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->deeponto) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->deeponto) (2024.11.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->deeponto) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->deeponto) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->deeponto) (2025.2)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from rdflib->deeponto) (3.2.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn->deeponto) (1.15.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn->deeponto) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (0.15.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (2.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (4.13.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->deeponto) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->deeponto) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->deeponto) (0.5.3)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->deeponto) (1.6.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.11/dist-packages (from blessed>=1.17.7->enlighten->deeponto) (0.2.13)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (3.11.15)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (5.2.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (4.9.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel->deeponto) (5.7.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->deeponto) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->deeponto) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->deeponto) (2025.4.26)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->deeponto) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->deeponto) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (14.0.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (7.1.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.5.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy->deeponto) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (1.20.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->deeponto) (0.8.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel->deeponto) (4.3.8)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.3.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->deeponto) (0.7.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (3.0.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->deeponto) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (0.1.2)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.23.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.24.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "# === Base Libraries ===\n",
        "!pip install numpy --upgrade\n",
        "!pip install pandas\n",
        "!pip install optuna\n",
        "\n",
        "# === FAISS (for Approximate Nearest Neighbor Search) ===\n",
        "!pip install faiss-cpu        # CPU version (recommended unless using GPU)\n",
        "# !pip install faiss-gpu      # Uncomment if running on CUDA-enabled GPU\n",
        "\n",
        "# === PyTorch Geometric and dependencies ===\n",
        "!pip install torch-geometric==2.4.0\n",
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
        "# Optional: latest dev version from GitHub\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "# === DeepOnto (Ontology Matching Toolkit) ===\n",
        "!pip install deeponto\n",
        "# Optionally install custom version from a GitHub repository\n",
        "# !pip install git+https://github.com/<username>/deeponto.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nFonRjT5fMCv"
      },
      "outputs": [],
      "source": [
        "# Import pandas for working with tabular data (e.g., CSV, TSV files)\n",
        "import pandas as pd\n",
        "\n",
        "# Import numpy for numerical operations and efficient array handling\n",
        "import numpy as np\n",
        "\n",
        "# Import json for reading and writing JSON-formatted files (useful for config or ontology structures)\n",
        "import json\n",
        "\n",
        "# Import pickle for serializing and deserializing Python objects (e.g., saving models or processed data)\n",
        "import pickle\n",
        "\n",
        "# Import warnings to control or suppress warning messages during runtime\n",
        "import warnings\n",
        "\n",
        "# Import gc (garbage collector) for managing memory manually when dealing with large datasets\n",
        "import gc\n",
        "\n",
        "# Ignore all warning messages to keep the output clean\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uchfZJP2fZwe"
      },
      "outputs": [],
      "source": [
        "# Import PyTorch core library for tensor operations and model definition\n",
        "import torch\n",
        "\n",
        "# Import commonly used PyTorch components\n",
        "from torch import Tensor, optim  # Tensor type and optimization algorithms (e.g., SGD, Adam)\n",
        "\n",
        "# Import PyTorch's neural network module (base class for defining models)\n",
        "import torch.nn as nn\n",
        "\n",
        "# Import PyTorch's functional API for operations like activations and loss functions\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Import DataLoader utilities for batching and loading datasets during training\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# === PyTorch Geometric (PyG) modules for graph-based learning ===\n",
        "\n",
        "# Basic graph data structure from PyG\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# PyG-specific DataLoader for batching graphs\n",
        "from torch_geometric.loader import DataLoader as GeoDataLoader\n",
        "\n",
        "# Import graph convolution layers and pooling functions from PyG\n",
        "from torch_geometric.nn import (\n",
        "    GCNConv,             # Graph Convolutional Network layer\n",
        "    GINConv,             # Graph Isomorphism Network convolution\n",
        "    global_mean_pool,    # Global mean pooling over node embeddings\n",
        "    global_add_pool,     # Global sum pooling over node embeddings\n",
        "    MessagePassing       # Base class for defining custom GNN layers\n",
        ")\n",
        "\n",
        "# Explicitly re-import MessagePassing (optional if already above)\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "\n",
        "# Graph utility functions from PyG\n",
        "from torch_geometric.utils import (\n",
        "    to_undirected,       # Converts a directed graph to undirected\n",
        "    softmax              # Softmax over edges (e.g., for attention)\n",
        ")\n",
        "\n",
        "# Initialization utilities for GNN layers\n",
        "from torch_geometric.nn.inits import (\n",
        "    reset,               # Reset parameters\n",
        "    glorot,              # Glorot (Xavier) weight initialization\n",
        "    zeros                # Zero initialization\n",
        ")\n",
        "\n",
        "# Typing utilities from PyG for adjacency and tensor specifications\n",
        "from torch_geometric.typing import (\n",
        "    Adj, OptTensor, PairTensor, SparseTensor\n",
        ")\n",
        "\n",
        "# Dense linear transformation layer from PyG (alternative to torch.nn.Linear)\n",
        "from torch_geometric.nn.dense.linear import Linear\n",
        "\n",
        "# Additional PyTorch neural network components\n",
        "from torch.nn import (\n",
        "    Linear,             # Fully connected (dense) layer\n",
        "    PReLU,              # Parametric ReLU activation\n",
        "    Sequential,         # Layer container for building sequential models\n",
        "    BatchNorm1d,        # Batch normalization for 1D inputs\n",
        "    Dropout             # Dropout regularization\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ziMBSWE8ff1N"
      },
      "outputs": [],
      "source": [
        "# Import matplotlib for creating visualizations (e.g., loss curves, evaluation metrics, embedding projections)\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JeAvp6PNfiLh"
      },
      "outputs": [],
      "source": [
        "# Import function to split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import encoder to convert categorical labels into integer values (useful for classification tasks)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Import evaluation metrics for classification and regression tasks\n",
        "from sklearn.metrics import (\n",
        "    f1_score,            # Harmonic mean of precision and recall; useful for imbalanced classification\n",
        "    precision_score,     # Measures the proportion of true positives among all predicted positives\n",
        "    accuracy_score,      # Measures overall correctness of predictions (classification)\n",
        "    mean_squared_error,  # Measures average squared difference between predicted and actual values (regression)\n",
        "    mean_absolute_error  # Measures average absolute difference between predicted and actual values (regression)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jm1rMZvmfl2M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8c1e298-c5c6-487d-a644-a5435b5d7816"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter the maximum memory located to JVM [8g]: 8g\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import the Ontology class for loading and manipulating OWL ontologies\n",
        "from deeponto.onto import Ontology\n",
        "\n",
        "# Import all components related to OAEI (Ontology Alignment Evaluation Initiative) benchmarking\n",
        "from deeponto.align.oaei import *\n",
        "\n",
        "# Import data structures for representing mappings between ontology entities\n",
        "from deeponto.align.mapping import EntityMapping, ReferenceMapping\n",
        "# - EntityMapping: represents a predicted alignment (one or more mappings)\n",
        "# - ReferenceMapping: represents the gold standard/reference alignments\n",
        "\n",
        "# Import the evaluator to compute Precision, Recall, and F1-score for alignments\n",
        "from deeponto.align.evaluation import AlignmentEvaluator\n",
        "\n",
        "# Utility function to read TSV/CSV tables as mapping or data frames\n",
        "from deeponto.utils import read_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JYhwr3Q_ft2N"
      },
      "outputs": [],
      "source": [
        "# Import Optuna, a hyperparameter optimization framework for automating model tuning using strategies like Bayesian optimization\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UmSCo5Olfzuz"
      },
      "outputs": [],
      "source": [
        "# Import the math module for mathematical functions (e.g., sqrt, log, exp)\n",
        "import math\n",
        "\n",
        "# Import the time module for measuring execution time of code blocks or functions\n",
        "import time\n",
        "\n",
        "# Import typing annotations for function signatures and code clarity\n",
        "from typing import Optional, Tuple, Union, Callable\n",
        "# - Optional[T]: denotes a value that could be of type T or None\n",
        "# - Tuple: fixed-size ordered collection of elements\n",
        "# - Union: allows multiple possible types (e.g., Union[int, str])\n",
        "# - Callable: represents a function or method type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9WNn0OMQW2CS"
      },
      "outputs": [],
      "source": [
        "# Import Python's built-in random module for generating pseudo-random numbers\n",
        "import random\n",
        "\n",
        "# Set the seed for PyTorch's random number generator to ensure reproducibility\n",
        "import torch\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Set the seed for NumPy's random number generator to ensure reproducibility\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "\n",
        "# Set the seed for Python's built-in random module to ensure reproducibility\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-abbBHOoRdWl"
      },
      "source": [
        "# **Paths Definition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AVgl_Bb42naS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63b16793-ab46-4a5e-ab3d-587b5bc6202f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Importing the 'drive' module from Google Colab to interact with Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount the user's Google Drive to the Colab environment\n",
        "# After running this, a link will appear to authorize access, and Google Drive will be mounted at '/content/gdrive'\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "36ttssQ3W7cx"
      },
      "outputs": [],
      "source": [
        "# Define the source ontology name\n",
        "src_ent = \"snomed.neoplas\"\n",
        "\n",
        "# Define the target ontology name\n",
        "tgt_ent = \"ncit.neoplas\"\n",
        "\n",
        "# Define the task name for this ontology matching process\n",
        "task = \"neoplas\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SJpvkdwVSQye"
      },
      "outputs": [],
      "source": [
        "dir = \"/content/gdrive/My Drive/BioGITOM-VLDB/\"\n",
        "\n",
        "# Define the directory for the dataset containing source and target ontologies\n",
        "dataset_dir = f\"{dir}/Datasets/{task}\"\n",
        "\n",
        "# Define the data directory for storing embeddings, adjacency matrices, and related files\n",
        "data_dir = f\"{dir}/{task}/Data\"\n",
        "\n",
        "# Define the directory for storing the results\n",
        "results_dir = f\"{dir}/{task}/Results\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "eFDNSFef23er"
      },
      "outputs": [],
      "source": [
        "# Load the Source ontology using the Ontology class from DeepOnto\n",
        "# This initializes the source ontology by loading its .owl file.\n",
        "src_onto = Ontology(f\"{dataset_dir}/{src_ent}.owl\")\n",
        "\n",
        "# Load the Target ontology using the Ontology class from DeepOnto\n",
        "# This initializes the target ontology by loading its .owl file.\n",
        "tgt_onto = Ontology(f\"{dataset_dir}/{tgt_ent}.owl\")\n",
        "\n",
        "# Define the file path for the Source embeddings CSV file\n",
        "# Embeddings for the source ontology entities are stored in this file.\n",
        "src_Emb = f\"{data_dir}/{src_ent}_Sentence_SapBERT_emb.csv\"\n",
        "\n",
        "# Define the file path for the Target embeddings CSV file\n",
        "# Embeddings for the target ontology entities are stored in this file.\n",
        "tgt_Emb = f\"{data_dir}/{tgt_ent}_Sentence_SapBERT_emb.csv\"\n",
        "\n",
        "# Define the file path for the Source adjacency matrix\n",
        "# This file represents the relationships (edges) between entities in the source ontology.\n",
        "src_Adjacence = f\"{data_dir}/{src_ent}_adjacence.csv\"\n",
        "\n",
        "# Define the file path for the Target adjacency matrix\n",
        "# This file represents the relationships (edges) between entities in the target ontology.\n",
        "tgt_Adjacence = f\"{data_dir}/{tgt_ent}_adjacence.csv\"\n",
        "\n",
        "# Define the file path for the JSON file containing the Source ontology class labels\n",
        "# This file maps the source ontology entities to their labels or names.\n",
        "src_class = f\"{data_dir}/{src_ent}_classes.json\"\n",
        "\n",
        "# Define the file path for the JSON file containing the Target ontology class labels\n",
        "# This file maps the target ontology entities to their labels or names.\n",
        "tgt_class = f\"{data_dir}/{tgt_ent}_classes.json\"\n",
        "\n",
        "# Define the file path for the train data\n",
        "train_file = f\"{data_dir}/{task}_train.csv\"\n",
        "\n",
        "# Define the file path for the test data\n",
        "# The test file contains reference mappings (ground truth) between the source and target ontologies.\n",
        "test_file = f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "\n",
        "# Define the file path for the candidate mappings used during testing\n",
        "# This file includes the candidate pairs (source and target entities) for ranking based metrics.\n",
        "test_cands = f\"{dataset_dir}/refs_equiv/test.cands.tsv\"\n",
        "cands_path = f\"{data_dir}/{task}_cands.csv\"\n",
        "\n",
        "# Define the path where the prediction results will be saved in TSV format\n",
        "# This file will store the final predictions (mappings) between source and target entities.\n",
        "prediction_path = f\"{results_dir}/{task}_matching_results.tsv\"\n",
        "\n",
        "# Define the path where all prediction results will be saved in TSV format\n",
        "# This file will store detailed prediction results, including all candidate scores.\n",
        "all_predictions_path = f\"{results_dir}/{task}_all_predictions.tsv\"\n",
        "\n",
        "# Define the path where formatted ranking predictions will be saved in TSV format\n",
        "# This file will contain predictions formatted for evaluation using ranking-based metrics.\n",
        "formatted_predictions_path = f\"{results_dir}/{task}_formatted_predictions.tsv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqEXsgPGMVhw"
      },
      "source": [
        "# **GIT Architecture**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "A_d6XCsUMVhx"
      },
      "outputs": [],
      "source": [
        "# RGIT class definition which inherits from PyTorch Geometric's MessagePassing class\n",
        "class RGIT(MessagePassing):\n",
        "\n",
        "    _alpha: OptTensor  # Define _alpha as an optional tensor for storing attention weights\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        nn: Callable,  # Neural network to be used in the final layer of the GNN\n",
        "        in_channels: Union[int, Tuple[int, int]],  # Input dimension, can be a single or pair of integers\n",
        "        out_channels: int,  # Output dimension of the GNN\n",
        "        eps: float = 0.,  # GIN parameter: epsilon for GIN aggregation\n",
        "        train_eps: bool = False,  # GIN parameter: whether epsilon should be learnable\n",
        "        heads: int = 1,  # Transformer parameter: number of attention heads\n",
        "        dropout: float = 0.,  # Dropout rate for attention weights\n",
        "        edge_dim: Optional[int] = None,  # Dimension for edge attributes (optional)\n",
        "        bias: bool = True,  # Whether to use bias in linear layers\n",
        "        root_weight: bool = True,  # GIN parameter: whether to apply root weight in aggregation\n",
        "        **kwargs,  # Additional arguments passed to the parent class\n",
        "    ):\n",
        "        # Set the aggregation type to 'add' and initialize the parent class with node_dim=0\n",
        "        kwargs.setdefault('aggr', 'add')\n",
        "        super().__init__(node_dim=0, **kwargs)\n",
        "\n",
        "        # Initialize input/output dimensions, neural network, and GIN/transformer parameters\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.nn = nn  # Neural network used by the GNN\n",
        "        self.initial_eps = eps  # Initial value of epsilon for GIN\n",
        "\n",
        "        # Set epsilon to be learnable or fixed\n",
        "        if train_eps:\n",
        "            self.eps = torch.nn.Parameter(torch.empty(1))  # Learnable epsilon\n",
        "        else:\n",
        "            self.register_buffer('eps', torch.empty(1))  # Non-learnable epsilon (fixed)\n",
        "\n",
        "        # Initialize transformer-related parameters\n",
        "        self.heads = heads\n",
        "        self.dropout = dropout\n",
        "        self.edge_dim = edge_dim\n",
        "        self._alpha = None  # Placeholder for attention weights\n",
        "\n",
        "        # Handle case where in_channels is a single integer or a tuple\n",
        "        if isinstance(in_channels, int):\n",
        "            in_channels = (in_channels, in_channels)\n",
        "\n",
        "        # Define the linear layers for key, query, and value for the transformer mechanism\n",
        "        self.lin_key = Linear(in_channels[0], heads * out_channels)\n",
        "        self.lin_query = Linear(in_channels[1], heads * out_channels)\n",
        "        self.lin_value = Linear(in_channels[0], heads * out_channels)\n",
        "\n",
        "        # Define linear transformation for edge embeddings if provided\n",
        "        if edge_dim is not None:\n",
        "            self.lin_edge = Linear(edge_dim, heads * out_channels, bias=False)\n",
        "        else:\n",
        "            self.lin_edge = self.register_parameter('lin_edge', None)\n",
        "\n",
        "        # Reset all parameters to their initial values\n",
        "        self.reset_parameters()\n",
        "\n",
        "    # Function to reset model parameters\n",
        "    def reset_parameters(self):\n",
        "        super().reset_parameters()  # Call parent class reset method\n",
        "        self.lin_key.reset_parameters()  # Reset key linear layer\n",
        "        self.lin_query.reset_parameters()  # Reset query linear layer\n",
        "        self.lin_value.reset_parameters()  # Reset value linear layer\n",
        "        if self.edge_dim:\n",
        "            self.lin_edge.reset_parameters()  # Reset edge linear layer if used\n",
        "        reset(self.nn)  # Reset the neural network provided\n",
        "        self.eps.data.fill_(self.initial_eps)  # Initialize epsilon with the starting value\n",
        "\n",
        "    # Forward function defining how the input data flows through the model\n",
        "    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj,\n",
        "                edge_attr: OptTensor = None, return_attention_weights=None):\n",
        "        # Unpack number of heads and output channels\n",
        "        H, C = self.heads, self.out_channels\n",
        "\n",
        "        # If x is a tensor, treat it as a pair of tensors (source and target embeddings)\n",
        "        if isinstance(x, Tensor):\n",
        "            x: PairTensor = (x, x)\n",
        "\n",
        "        # Extract source node embeddings\n",
        "        x_t = x[0]\n",
        "\n",
        "        # Apply linear transformations and reshape query, key, and value for multi-head attention\n",
        "        query = self.lin_query(x[1]).view(-1, H, C)\n",
        "        key = self.lin_key(x[0]).view(-1, H, C)\n",
        "        value = self.lin_value(x[0]).view(-1, H, C)\n",
        "\n",
        "        # Propagate messages through the graph using the propagate function\n",
        "        out = self.propagate(edge_index, query=query, key=key, value=value,\n",
        "                             edge_attr=edge_attr, size=None)\n",
        "\n",
        "        # Retrieve attention weights and reset them\n",
        "        alpha = self._alpha\n",
        "        self._alpha = None  # Reset _alpha after use\n",
        "        out = out.mean(dim=1)  # Take the mean over all attention heads\n",
        "\n",
        "        # Apply GIN aggregation by adding epsilon-scaled original node embeddings\n",
        "        out = out + (1 + self.eps) * x_t\n",
        "        return self.nn(out)  # Pass through the neural network\n",
        "\n",
        "    # Message passing function which calculates attention and combines messages\n",
        "    def message(self, query_i: Tensor, key_j: Tensor, value_j: Tensor,\n",
        "                edge_attr: OptTensor, index: Tensor, ptr: OptTensor,\n",
        "                size_i: Optional[int]) -> Tensor:\n",
        "        # If edge attributes are used, apply linear transformation and add them to the key\n",
        "        if self.lin_edge is not None:\n",
        "            assert edge_attr is not None\n",
        "            edge_attr = self.lin_edge(edge_attr).view(-1, self.heads, self.out_channels)\n",
        "            key_j = key_j + edge_attr\n",
        "\n",
        "        # Calculate attention (alpha) using the dot product between query and key\n",
        "        alpha = (query_i * key_j).sum(dim=-1) / math.sqrt(self.out_channels)\n",
        "        alpha = softmax(alpha, index, ptr, size_i)  # Apply softmax to normalize attention\n",
        "        self._alpha = alpha  # Store attention weights\n",
        "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)  # Apply dropout\n",
        "\n",
        "        # Calculate the output message by applying attention to the value\n",
        "        out = value_j\n",
        "        if edge_attr is not None:\n",
        "            out = out + edge_attr  # Add edge embeddings to the output if present\n",
        "        out = out * alpha.view(-1, self.heads, 1)  # Scale by attention weights\n",
        "        return out\n",
        "\n",
        "    # String representation function for debugging or printing\n",
        "    def __repr__(self) -> str:\n",
        "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
        "                f'{self.out_channels}, heads={self.heads})')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qwFv6RgHmGCf"
      },
      "outputs": [],
      "source": [
        "# Define the RGIT_mod class, a multi-layer GNN that uses both RGIT and linear layers\n",
        "class RGIT_mod(torch.nn.Module):\n",
        "    \"\"\"Multi-layer RGIT with optional linear layers\"\"\"\n",
        "\n",
        "    # Initialize the model with hidden dimension, number of RGIT layers, and number of linear layers\n",
        "    def __init__(self, dim_h, num_layers, num_linear_layers=1):\n",
        "        super(RGIT_mod, self).__init__()\n",
        "        self.num_layers = num_layers  # Number of RGIT layers\n",
        "        self.num_linear_layers = num_linear_layers  # Number of linear layers\n",
        "        self.linears = torch.nn.ModuleList()  # List to store linear layers\n",
        "        self.rgit_layers = torch.nn.ModuleList()  # List to store RGIT layers\n",
        "\n",
        "        # Create a list of Linear and PReLU layers (for encoding entity names)\n",
        "        for _ in range(num_linear_layers):\n",
        "            self.linears.append(Linear(dim_h, dim_h))  # Linear transformation layer\n",
        "            self.linears.append(PReLU(num_parameters=dim_h))  # Parametric ReLU activation function\n",
        "\n",
        "        # Create a list of RGIT layers\n",
        "        for _ in range(num_layers):\n",
        "            self.rgit_layers.append(RGIT(  # Each RGIT layer contains a small MLP with Linear and PReLU\n",
        "                Sequential(Linear(dim_h, dim_h), PReLU(num_parameters=dim_h),\n",
        "                           Linear(dim_h, dim_h), PReLU(num_parameters=dim_h)), dim_h, dim_h))\n",
        "\n",
        "    # Forward pass through the model\n",
        "    def forward(self, x, edge_index):\n",
        "        # Apply the linear layers first to the input\n",
        "        for layer in self.linears:\n",
        "            x = layer(x)\n",
        "\n",
        "        # Then apply the RGIT layers for message passing\n",
        "        for layer in self.rgit_layers:\n",
        "            x = layer(x, edge_index)\n",
        "\n",
        "        return x  # Return the final node embeddings after all layers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxCn5ztKVztw"
      },
      "source": [
        "# **Gated Network Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7MKQUv7o7zay"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GatedCombination(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(GatedCombination, self).__init__()\n",
        "        self.gate_A_fc = nn.Linear(input_dim, input_dim)\n",
        "        self.gate_B_fc = nn.Linear(input_dim, input_dim)\n",
        "        self.fc = nn.Linear(1, 1)\n",
        "\n",
        "    def euclidean_distance(self, a, b):\n",
        "        \"\"\"\n",
        "        Compute the Euclidean distance between two tensors.\n",
        "        Args:\n",
        "            a: Tensor of shape [batch, dim]\n",
        "            b: Tensor of shape [batch, dim]\n",
        "        Returns:\n",
        "            Tensor of shape [batch] representing the L2 distance.\n",
        "        \"\"\"\n",
        "        return torch.norm(a - b, p=2, dim=1)\n",
        "\n",
        "    def forward(self, x1, x2, x3, x4, return_embeddings=False):\n",
        "        gate_values1 = torch.sigmoid(self.gate_A_fc(x1))\n",
        "        a = x1 * gate_values1 + x2 * (1 - gate_values1)\n",
        "\n",
        "        gate_values2 = torch.sigmoid(self.gate_B_fc(x3))\n",
        "        b = x3 * gate_values2 + x4 * (1 - gate_values2)\n",
        "\n",
        "        if return_embeddings:\n",
        "            return a, b\n",
        "\n",
        "        # Utilisation de la distance Euclidienne\n",
        "        distance = self.euclidean_distance(a, b)\n",
        "\n",
        "        # Passage dans couche de classification\n",
        "        out = torch.sigmoid(self.fc(distance.unsqueeze(1)))\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-niEvlkie_vx"
      },
      "source": [
        "\n",
        "\n",
        "# **Encoder Definition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8GHQKz8Re_vx"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# === Simple Linear Encoder ===\n",
        "class LinearEncoder(nn.Module):\n",
        "    def __init__(self, embedding_dim):\n",
        "        super(LinearEncoder, self).__init__()\n",
        "        # A single linear transformation layer: y = Wx + b\n",
        "        self.linear = nn.Linear(embedding_dim, embedding_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass: apply the linear transformation\n",
        "        return self.linear(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLJ5j9FNMVhy"
      },
      "source": [
        "# **Utility functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "k0L86DgUQjMU"
      },
      "outputs": [],
      "source": [
        "def adjacency_matrix_to_undirected_edge_index(adjacency_matrix):\n",
        "    \"\"\"\n",
        "    Converts an adjacency matrix into an undirected edge index for use in graph-based neural networks.\n",
        "\n",
        "    Args:\n",
        "        adjacency_matrix: A 2D list or array representing the adjacency matrix of a graph.\n",
        "\n",
        "    Returns:\n",
        "        edge_index_undirected: A PyTorch tensor representing the undirected edges.\n",
        "    \"\"\"\n",
        "    # Convert each element in the adjacency matrix to an integer (from boolean or float)\n",
        "    adjacency_matrix = [[int(element) for element in sublist] for sublist in adjacency_matrix]\n",
        "\n",
        "    # Convert the adjacency matrix into a PyTorch LongTensor (used for indexing)\n",
        "    edge_index = torch.tensor(adjacency_matrix, dtype=torch.long)\n",
        "\n",
        "    # Transpose the edge_index tensor so that rows represent edges in the form [source, target]\n",
        "    edge_index = edge_index.t().contiguous()\n",
        "\n",
        "    # Convert the directed edge_index into an undirected edge_index, meaning both directions are added (i.e., (i, j) and (j, i))\n",
        "    edge_index_undirected = to_undirected(edge_index)\n",
        "\n",
        "    return edge_index_undirected  # Return the undirected edge index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YvmOxkLcpf9w"
      },
      "outputs": [],
      "source": [
        "def build_indexed_dict(file_path):\n",
        "    \"\"\"\n",
        "    Builds a dictionary with numeric indexes for each key from a JSON file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): The path to the JSON file.\n",
        "\n",
        "    Returns:\n",
        "        indexed_dict (dict): A new dictionary where each key from the JSON file is assigned a numeric index.\n",
        "    \"\"\"\n",
        "    # Load the JSON file into a Python dictionary\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    # Create a new dictionary with numeric indexes as keys and the original JSON keys as values\n",
        "    indexed_dict = {index: key for index, key in enumerate(data.keys())}\n",
        "\n",
        "    return indexed_dict  # Return the newly created dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QgFINoPGl9Wg"
      },
      "outputs": [],
      "source": [
        "def select_rows_by_index(embedding_vector, index_vector):\n",
        "    \"\"\"\n",
        "    Select rows from an embedding vector using an index vector.\n",
        "\n",
        "    Args:\n",
        "        embedding_vector (torch.Tensor): 2D tensor representing the embedding vector with shape [num_rows, embedding_size].\n",
        "        index_vector (torch.Tensor): 1D tensor representing the index vector.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: New tensor with selected rows from the embedding vector.\n",
        "    \"\"\"\n",
        "    # Use torch.index_select to select the desired rows\n",
        "    new_tensor = torch.index_select(embedding_vector, 0, index_vector)\n",
        "\n",
        "    return new_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "a12L7vEmmCJq"
      },
      "outputs": [],
      "source": [
        "def contrastive_loss(source_embeddings, target_embeddings, labels, margin=1.0):\n",
        "    \"\"\"\n",
        "    Computes the contrastive loss, a type of loss function used to train models in tasks like matching or similarity learning.\n",
        "\n",
        "    Args:\n",
        "        source_embeddings (torch.Tensor): Embeddings of the source graphs, shape [batch_size, embedding_size].\n",
        "        target_embeddings (torch.Tensor): Embeddings of the target graphs, shape [batch_size, embedding_size].\n",
        "        labels (torch.Tensor): Binary labels indicating if the pairs are matched (1) or not (0), shape [batch_size].\n",
        "        margin (float): Margin value for the contrastive loss. Defaults to 1.0.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The contrastive loss value.\n",
        "    \"\"\"\n",
        "    # Calculate the pairwise Euclidean distance between source and target embeddings\n",
        "    distances = F.pairwise_distance(source_embeddings, target_embeddings)\n",
        "\n",
        "    # Compute the contrastive loss:\n",
        "    # - For matched pairs (label == 1), the loss is the squared distance between embeddings.\n",
        "    # - For non-matched pairs (label == 0), the loss is based on how far apart the embeddings are,\n",
        "    #   but penalizes them only if the distance is less than the margin.\n",
        "    loss = torch.mean(\n",
        "        labels * 0.4 * distances.pow(2) +  # For positive pairs, minimize the distance (squared)\n",
        "        (1 - labels) * 0.4 * torch.max(torch.zeros_like(distances), margin - distances).pow(2)  # For negative pairs, maximize the distance (up to the margin)\n",
        "    )\n",
        "\n",
        "    return loss  # Return the computed contrastive loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_ggVYlTiO_WA"
      },
      "outputs": [],
      "source": [
        "def compute_mrr_and_hits(reference_file, predicted_file, output_file, k_values=[1, 5, 10]):\n",
        "    \"\"\"\n",
        "    Compute Mean Reciprocal Rank (MRR) and Hits@k metrics for ontology matching results.\n",
        "\n",
        "    Args:\n",
        "        reference_file (str): Path to the reference test candidate file (usually 'test.cands.tsv').\n",
        "        predicted_file (str): Path to the prediction results (with columns: SrcEntity, TgtEntity, Score).\n",
        "        output_file (str): Path to save ranked candidate predictions with scores.\n",
        "        k_values (list): List of integers specifying which Hits@k metrics to compute.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary with MRR and Hits@k scores.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load reference candidate mappings: each row = (SrcEntity, CorrectTgtEntity, [CandidateTgtEntities])\n",
        "    test_candidate_mappings = read_table(reference_file).values.tolist()\n",
        "\n",
        "    # Load predictions and ensure Score is float\n",
        "    predicted_data = pd.read_csv(predicted_file, sep=\"\\t\")\n",
        "    predicted_data[\"Score\"] = predicted_data[\"Score\"].apply(\n",
        "        lambda x: float(x.strip(\"[]\")) if isinstance(x, str) else float(x)\n",
        "    )\n",
        "\n",
        "    # Create a dictionary mapping (SrcEntity, TgtEntity) -> predicted score\n",
        "    score_lookup = {\n",
        "        (row[\"SrcEntity\"], row[\"TgtEntity\"]): row[\"Score\"]\n",
        "        for _, row in predicted_data.iterrows()\n",
        "    }\n",
        "\n",
        "    ranking_results = []\n",
        "\n",
        "    # Rank the candidates for each source entity\n",
        "    for src_ref_class, tgt_ref_class, tgt_cands in test_candidate_mappings:\n",
        "        # Safely parse the candidate list (tgt_cands is a stringified list)\n",
        "        try:\n",
        "            tgt_cands = eval(tgt_cands)\n",
        "        except Exception:\n",
        "            tgt_cands = []\n",
        "\n",
        "        # Score each candidate (use a large negative default if not found)\n",
        "        scored_cands = [\n",
        "            (tgt_cand, score_lookup.get((src_ref_class, tgt_cand), -1e9))\n",
        "            for tgt_cand in tgt_cands\n",
        "        ]\n",
        "\n",
        "        # Sort candidates by score descending\n",
        "        scored_cands = sorted(scored_cands, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Store the ranking result\n",
        "        ranking_results.append((src_ref_class, tgt_ref_class, scored_cands))\n",
        "\n",
        "    # Save ranked predictions for inspection/debugging\n",
        "    pd.DataFrame(ranking_results, columns=[\"SrcEntity\", \"TgtEntity\", \"TgtCandidates\"]).to_csv(\n",
        "        output_file, sep=\"\\t\", index=False\n",
        "    )\n",
        "\n",
        "    # === Evaluation: compute MRR and Hits@k ===\n",
        "    total_entities = len(ranking_results)\n",
        "    reciprocal_ranks = []\n",
        "    hits_at_k = {k: 0 for k in k_values}\n",
        "\n",
        "    for src_entity, tgt_ref_class, tgt_cands in ranking_results:\n",
        "        ranked_candidates = [cand[0] for cand in tgt_cands]  # candidate URIs only\n",
        "        if tgt_ref_class in ranked_candidates:\n",
        "            rank = ranked_candidates.index(tgt_ref_class) + 1\n",
        "            reciprocal_ranks.append(1 / rank)\n",
        "            for k in k_values:\n",
        "                if rank <= k:\n",
        "                    hits_at_k[k] += 1\n",
        "        else:\n",
        "            reciprocal_ranks.append(0)  # No correct match in candidate list\n",
        "\n",
        "    # Compute final metrics\n",
        "    mrr = sum(reciprocal_ranks) / total_entities\n",
        "    hits_at_k = {k: hits / total_entities for k, hits in hits_at_k.items()}\n",
        "\n",
        "    return {\"MRR\": mrr, \"Hits@k\": hits_at_k}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_git_only_embeddings(embeddings_src, embeddings_tgt,\n",
        "                              indexed_dict_src, indexed_dict_tgt,\n",
        "                              output_file_src, output_file_tgt):\n",
        "    \"\"\"\n",
        "    Ablation: use only GIT (graph-based) embeddings without gated combination.\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "    import time\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    final_src = embeddings_src.cpu().numpy()\n",
        "    final_tgt = embeddings_tgt.cpu().numpy()\n",
        "\n",
        "    df_src = pd.DataFrame(final_src)\n",
        "    df_src.insert(0, \"Concept\", [indexed_dict_src[i] for i in range(len(df_src))])\n",
        "\n",
        "    df_tgt = pd.DataFrame(final_tgt)\n",
        "    df_tgt.insert(0, \"Concept\", [indexed_dict_tgt[i] for i in range(len(df_tgt))])\n",
        "\n",
        "    df_src.to_csv(output_file_src, sep='\\t', index=False)\n",
        "    df_tgt.to_csv(output_file_tgt, sep='\\t', index=False)\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"✅ GIT-only embeddings saved:\\n- Source: {output_file_src}\\n- Target: {output_file_tgt}\")\n",
        "    print(f\"⏱️ Execution time: {elapsed_time:.2f} seconds\")"
      ],
      "metadata": {
        "id": "AjYY8UKNRRJG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "kh1zdPJQe_vy"
      },
      "outputs": [],
      "source": [
        "def save_semantic_only_embeddings(x_src, x_tgt,\n",
        "                                   indexed_dict_src, indexed_dict_tgt,\n",
        "                                   output_file_src, output_file_tgt):\n",
        "    \"\"\"\n",
        "    Ablation: ignore GIT embeddings, use only semantic embeddings (x_src, x_tgt).\n",
        "    Saves embeddings with Concept URI and semantic vector only.\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "    import torch\n",
        "    import time\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Use GPU if available\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    x_src = x_src.to(device)\n",
        "    x_tgt = x_tgt.to(device)\n",
        "\n",
        "    # Simply detach and convert semantic embeddings to CPU\n",
        "    final_src = x_src.cpu().numpy()\n",
        "    final_tgt = x_tgt.cpu().numpy()\n",
        "\n",
        "    # Create DataFrames with Concept URI and embedding values\n",
        "    df_src = pd.DataFrame(final_src)\n",
        "    df_src.insert(0, \"Concept\", [indexed_dict_src[i] for i in range(len(df_src))])\n",
        "\n",
        "    df_tgt = pd.DataFrame(final_tgt)\n",
        "    df_tgt.insert(0, \"Concept\", [indexed_dict_tgt[i] for i in range(len(df_tgt))])\n",
        "\n",
        "    # Save embeddings to file\n",
        "    df_src.to_csv(output_file_src, sep='\\t', index=False)\n",
        "    df_tgt.to_csv(output_file_tgt, sep='\\t', index=False)\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"✅ Semantic-only embeddings saved:\\n- Source: {output_file_src}\\n- Target: {output_file_tgt}\")\n",
        "    print(f\"⏱️ Execution time: {elapsed_time:.2f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "LXvbHTVfe_vz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def filter_ignored_class(src_emb_path, tgt_emb_path, src_onto, tgt_onto):\n",
        "    \"\"\"\n",
        "    Filters the source and target embedding files by removing concepts considered \"ignored classes\"\n",
        "    (e.g., owl:Thing, deprecated entities, etc.) based on both source and target ontologies.\n",
        "\n",
        "    Args:\n",
        "        src_emb_path (str): Path to the TSV file containing source embeddings with 'Concept' column.\n",
        "        tgt_emb_path (str): Path to the TSV file containing target embeddings with 'Concept' column.\n",
        "        src_onto (Ontology): Source ontology object loaded with DeepOnto.\n",
        "        tgt_onto (Ontology): Target ontology object loaded with DeepOnto.\n",
        "\n",
        "    Returns:\n",
        "        (str, str): Paths to the cleaned source and target embedding files.\n",
        "    \"\"\"\n",
        "\n",
        "    # === Load the embedding files ===\n",
        "    df_src = pd.read_csv(src_emb_path, sep='\\t', dtype=str)\n",
        "    print(f\"🔍 Initial source file: {len(df_src)} rows\")\n",
        "\n",
        "    df_tgt = pd.read_csv(tgt_emb_path, sep='\\t', dtype=str)\n",
        "    print(f\"🔍 Initial target file: {len(df_tgt)} rows\")\n",
        "\n",
        "    # === Step 1: Retrieve ignored classes from both ontologies ===\n",
        "    ignored_class_index = get_ignored_class_index(src_onto)  # e.g., owl:Thing, non-usable classes\n",
        "    ignored_class_index.update(get_ignored_class_index(tgt_onto))  # Merge with target ontology's ignored classes\n",
        "    ignored_uris = set(str(uri).strip() for uri in ignored_class_index)\n",
        "\n",
        "    # === Step 2: Remove rows where the 'Concept' column matches ignored URIs ===\n",
        "    df_src_cleaned = df_src[~df_src['Concept'].isin(ignored_uris)].reset_index(drop=True)\n",
        "    df_tgt_cleaned = df_tgt[~df_tgt['Concept'].isin(ignored_uris)].reset_index(drop=True)\n",
        "\n",
        "    print(f\"✅ Source after removing ignored classes: {len(df_src_cleaned)} rows\")\n",
        "    print(f\"✅ Target after removing ignored classes: {len(df_tgt_cleaned)} rows\")\n",
        "\n",
        "    # === Step 3: Save the cleaned embedding files ===\n",
        "    output_file_src = src_emb_path.replace(\".tsv\", \"_cleaned.tsv\")\n",
        "    output_file_tgt = tgt_emb_path.replace(\".tsv\", \"_cleaned.tsv\")\n",
        "\n",
        "    df_src_cleaned.to_csv(output_file_src, sep='\\t', index=False)\n",
        "    df_tgt_cleaned.to_csv(output_file_tgt, sep='\\t', index=False)\n",
        "\n",
        "    print(f\"📁 Cleaned source file saved to: {output_file_src}\")\n",
        "    print(f\"📁 Cleaned target file saved to: {output_file_tgt}\")\n",
        "\n",
        "    return output_file_src, output_file_tgt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_9YDcnTbKaHk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "def encode_embeddings_with_concept_column(encoder_model, input_file, output_file):\n",
        "    \"\"\"\n",
        "    Applies an encoder model to a set of embeddings (while preserving the 'Concept' column),\n",
        "    and saves the encoded results in the same tabular format.\n",
        "\n",
        "    Args:\n",
        "        encoder_model: A PyTorch model (e.g., LinearEncoder, MLPEncoder, etc.)\n",
        "        input_file (str): Path to the input TSV file containing 'Concept' and embedding vectors.\n",
        "        output_file (str): Path to save the encoded embeddings.\n",
        "    \"\"\"\n",
        "\n",
        "    # Select device (GPU if available, else CPU)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Move the encoder model to the selected device and set it to evaluation mode\n",
        "    encoder_model = encoder_model.to(device)\n",
        "    encoder_model.eval()\n",
        "\n",
        "    # Load the input TSV file containing concept URIs and embeddings\n",
        "    df = pd.read_csv(input_file, sep='\\t')\n",
        "\n",
        "    # Extract the 'Concept' column to preserve URIs\n",
        "    concepts = df['Concept'].tolist()\n",
        "\n",
        "    # Extract the numerical embedding values (excluding the 'Concept' column)\n",
        "    embedding_values = df.drop(columns=['Concept']).values\n",
        "\n",
        "    # Convert the embedding matrix into a PyTorch tensor and move to the device\n",
        "    embeddings = torch.FloatTensor(embedding_values).to(device)\n",
        "\n",
        "    # Pass the embeddings through the encoder model without computing gradients\n",
        "    with torch.no_grad():\n",
        "        encoded = encoder_model(embeddings).cpu().numpy()\n",
        "\n",
        "    # Reconstruct a new DataFrame with the encoded vectors and corresponding URIs\n",
        "    df_encoded = pd.DataFrame(encoded, columns=[f'dim_{i}' for i in range(encoded.shape[1])])\n",
        "    df_encoded.insert(0, \"Concept\", concepts)  # Re-insert the 'Concept' column at the first position\n",
        "\n",
        "    # Save the encoded embeddings to a TSV file\n",
        "    df_encoded.to_csv(output_file, sep='\\t', index=False)\n",
        "    print(f\"✅ Encoded embeddings saved to: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBAlDrOpe_vz"
      },
      "source": [
        "# **FAISS Similarity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "CyG7ztCne_vz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import faiss\n",
        "import time\n",
        "\n",
        "def load_embeddings(src_emb_path, tgt_emb_path):\n",
        "    \"\"\"\n",
        "    Load the embeddings for the source and target ontologies from TSV files.\n",
        "\n",
        "    Args:\n",
        "        src_emb_path (str): Path to the source embeddings file.\n",
        "        tgt_emb_path (str): Path to the target embeddings file.\n",
        "\n",
        "    Returns:\n",
        "        uris_src (np.ndarray): URIs of source entities.\n",
        "        uris_tgt (np.ndarray): URIs of target entities.\n",
        "        src_vecs (np.ndarray): Embedding vectors for source entities.\n",
        "        tgt_vecs (np.ndarray): Embedding vectors for target entities.\n",
        "    \"\"\"\n",
        "    df_src = pd.read_csv(src_emb_path, sep='\\t')  # Read source embeddings\n",
        "    df_tgt = pd.read_csv(tgt_emb_path, sep='\\t')  # Read target embeddings\n",
        "    uris_src = df_src[\"Concept\"].values           # Extract source URIs\n",
        "    uris_tgt = df_tgt[\"Concept\"].values           # Extract target URIs\n",
        "    src_vecs = df_src.drop(columns=[\"Concept\"]).values.astype('float32')  # Extract and convert source vectors\n",
        "    tgt_vecs = df_tgt.drop(columns=[\"Concept\"]).values.astype('float32')  # Extract and convert target vectors\n",
        "    return uris_src, uris_tgt, src_vecs, tgt_vecs\n",
        "\n",
        "def save_results(uris_src, uris_tgt, indices, scores, output_file, top_k):\n",
        "    \"\"\"\n",
        "    Save the top-k mapping results to a TSV file.\n",
        "\n",
        "    Args:\n",
        "        uris_src (np.ndarray): URIs of source entities.\n",
        "        uris_tgt (np.ndarray): URIs of target entities.\n",
        "        indices (np.ndarray): Indices of top-k matched target entities.\n",
        "        scores (np.ndarray): Corresponding similarity scores.\n",
        "        output_file (str): Output TSV file path.\n",
        "        top_k (int): Number of top matches per source entity.\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for i, (ind_row, score_row) in enumerate(zip(indices, scores)):\n",
        "        src_uri = uris_src[i]\n",
        "        for j, tgt_idx in enumerate(ind_row):\n",
        "            tgt_uri = uris_tgt[tgt_idx]\n",
        "            score = score_row[j]\n",
        "            rows.append((src_uri, tgt_uri, score))  # Store each top-k match\n",
        "    df_result = pd.DataFrame(rows, columns=[\"SrcEntity\", \"TgtEntity\", \"Score\"])\n",
        "    df_result.to_csv(output_file, sep='\\t', index=False)  # Save to file\n",
        "    print(f\"Top-{top_k} FAISS similarity results saved to: {output_file}\")\n",
        "\n",
        "def topk_faiss_l2(src_emb_path, tgt_emb_path, top_k=15, output_file=\"topk_l2.tsv\"):\n",
        "    \"\"\"\n",
        "    Compute the top-k most similar target entities for each source entity using FAISS with L2 distance.\n",
        "\n",
        "    Args:\n",
        "        src_emb_path (str): Path to the source embeddings file.\n",
        "        tgt_emb_path (str): Path to the target embeddings file.\n",
        "        top_k (int): Number of top matches to retrieve.\n",
        "        output_file (str): Path to save the top-k results.\n",
        "    \"\"\"\n",
        "    print(\"🔹 Using L2 (Euclidean) distance with FAISS\")\n",
        "    start = time.time()  # Start timing\n",
        "\n",
        "    # Load embeddings\n",
        "    uris_src, uris_tgt, src_vecs, tgt_vecs = load_embeddings(src_emb_path, tgt_emb_path)\n",
        "\n",
        "    # Build FAISS index using L2 distance\n",
        "    dim = src_vecs.shape[1]\n",
        "    index = faiss.IndexFlatL2(dim)  # Create FAISS index for L2 distance\n",
        "    index.add(tgt_vecs)             # Add target vectors to index\n",
        "\n",
        "    # Perform nearest neighbor search\n",
        "    distances, indices = index.search(src_vecs, top_k)\n",
        "\n",
        "    # Convert distances to similarity scores (optional: inverse of distance)\n",
        "    similarity_scores = 1 / (1 + distances)\n",
        "\n",
        "    # Save the results\n",
        "    save_results(uris_src, uris_tgt, indices, similarity_scores, output_file, top_k)\n",
        "\n",
        "    # Display execution time\n",
        "    print(f\"⏱️ Execution time: {time.time() - start:.2f} seconds\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zq0p_64e_vz"
      },
      "source": [
        "# **Mappings Evaluation Functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "repA9zGMe_vz"
      },
      "source": [
        "# **Precision, Recall, F1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GW0Am-TmVMR"
      },
      "source": [
        "### Evaluation Strategy and Filtering Justification\n",
        "\n",
        "### Filtering Justification\n",
        "\n",
        "In the `evaluate_predictions` function, two important filtering steps are applied to ensure that the evaluation metrics (such as Precision, Recall, and F1-score) accurately reflect the model's performance:\n",
        "\n",
        "\n",
        "#### 1. Filtering Out Training-Only Entities\n",
        "\n",
        "We remove all predicted mappings involving source or target entities that are present **only in the training set** and not in the test set.\n",
        "\n",
        "This step is critical because:\n",
        "\n",
        "- In some datasets like **Bio-ML**, the same entity can appear in both training and test sets, although with **different correspondences**.\n",
        "- If we don't remove training-only entities, it can lead to **label leakage** and **metric distortion**.\n",
        "\n",
        "#### 2. Filtering on `SrcEntity` present in the test set\n",
        "\n",
        "The second step keeps only the predictions where the `SrcEntity` is included in the test reference set.\n",
        "\n",
        "- This eliminates **non-evaluable false positives**, i.e., predicted mappings for source entities that do not appear in the test set and therefore have no ground-truth correspondences. Including such predictions **unfairly penalizes precision and F1-score**, even though they are technically not verifiable errors.\n",
        "\n",
        "- It focuses the evaluation on entities with defined ground-truth mappings, which is critical for computing metrics such as :\n",
        "\n",
        "$P_{\\text{test}} = \\frac{|\\mathcal{M}_{\\text{out}} \\cap \\mathcal{M}_{\\text{test}}|}{|\\mathcal{M}_{\\text{out}} \\setminus (\\mathcal{M}_{\\text{ref}} \\setminus \\mathcal{M}_{\\text{test}})|}$.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "eOQkhXEVOQDT"
      },
      "outputs": [],
      "source": [
        "def select_best_candidates_per_src_with_margin(df, score_margin=0.01):\n",
        "    \"\"\"\n",
        "    For each SrcEntity, retain all candidate mappings whose similarity score is\n",
        "    within 99% of the best score (default margin = 0.01).\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing columns ['SrcEntity', 'TgtEntity', 'Score'].\n",
        "        score_margin (float): Score margin. 0.01 means keep scores ≥ 99% of best score.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Filtered DataFrame with multiple high-quality candidates per SrcEntity.\n",
        "    \"\"\"\n",
        "    selected_rows = []\n",
        "\n",
        "    for src, group in df.groupby(\"SrcEntity\"):\n",
        "        group_sorted = group.sort_values(by=\"Score\", ascending=False)\n",
        "        best_score = group_sorted.iloc[0][\"Score\"]\n",
        "        threshold = best_score * (1 - score_margin)\n",
        "\n",
        "        # Keep all target entities with score >= threshold\n",
        "        close_matches = group_sorted[group_sorted[\"Score\"] >= threshold]\n",
        "        selected_rows.append(close_matches)\n",
        "\n",
        "    result_df = pd.concat(selected_rows).reset_index(drop=True)\n",
        "    print(f\"🏆 Selected candidates within {(1 - score_margin) * 100:.1f}% of best score per SrcEntity: {len(result_df)} rows\")\n",
        "    return result_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "-4deIPBfOQDU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "def evaluate_predictions(\n",
        "    pred_file, train_file, test_file,\n",
        "    threshold=0.0, margin_ratio=0.997\n",
        "):\n",
        "    \"\"\"\n",
        "    Evaluate predicted mappings by applying filtering, thresholding, top-1 selection with margin,\n",
        "    and computing precision, recall, and F1-score against the test set.\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 1: Load prediction, train, and test data\n",
        "    df = pd.read_csv(pred_file, sep='\\t')\n",
        "    train_df = pd.read_csv(train_file, sep='\\t')\n",
        "    test_df = pd.read_csv(test_file, sep='\\t')\n",
        "    print(f\"🔍 Initial file: {len(df)} rows\")\n",
        "\n",
        "    # Step 2: Remove entities that appear only in the training set\n",
        "    train_uris = set(train_df['SrcEntity']) | set(train_df['TgtEntity'])\n",
        "    test_uris = set(test_df['SrcEntity']) | set(test_df['TgtEntity'])\n",
        "    uris_to_exclude = train_uris - test_uris\n",
        "    df = df[~df['SrcEntity'].isin(uris_to_exclude) & ~df['TgtEntity'].isin(uris_to_exclude)]\n",
        "    print(f\"✅ After removing train-only URIs: {len(df)} rows\")\n",
        "\n",
        "    # Step 3: Keep only predictions where SrcEntity is part of the test set\n",
        "    test_src_entities = set(test_df['SrcEntity'])\n",
        "    df = df[df['SrcEntity'].isin(test_src_entities)]\n",
        "    print(f\"✅ After keeping only test SrcEntities: {len(df)} rows\")\n",
        "\n",
        "    # Step 4: Apply a minimum score threshold\n",
        "    df = df[df[\"Score\"] >= threshold]\n",
        "    print(f\"✅ After applying threshold ≥ {threshold}: {len(df)} rows\")\n",
        "\n",
        "    # Step 5: Save filtered predictions to file\n",
        "    output_file_all = pred_file.replace(\".tsv\", f\"_filtered.tsv\")\n",
        "    df.to_csv(output_file_all, sep='\\t', index=False)\n",
        "    print(f\"📁 Filtered predictions saved: {output_file_all}\")\n",
        "\n",
        "    # Step 6: Select best predictions per SrcEntity using a relaxed top-1 margin\n",
        "    df_top1 = select_best_candidates_per_src_with_margin(df, score_margin=0.0075)\n",
        "\n",
        "    # Step 7: Save the top-1 filtered predictions\n",
        "    output_file_top1 = pred_file.replace(\".tsv\", f\"_filtered_top1_th{threshold}.tsv\")\n",
        "    df_top1.to_csv(output_file_top1, sep='\\t', index=False)\n",
        "    print(f\"📁 Filtered Top-1 file saved: {output_file_top1}\")\n",
        "\n",
        "    # Step 8: Evaluate using gold standard test mappings\n",
        "    preds = EntityMapping.read_table_mappings(output_file_top1)   # Read predicted mappings\n",
        "    refs = ReferenceMapping.read_table_mappings(test_file)        # Read reference (gold standard) mappings\n",
        "\n",
        "    results = AlignmentEvaluator.f1(preds, refs)  # Compute precision, recall, and F1\n",
        "\n",
        "    # Optional: Count correct predictions (intersection)\n",
        "    preds2 = [p.to_tuple() for p in preds]\n",
        "    refs2 = [r.to_tuple() for r in refs]\n",
        "    correct = len(set(preds2).intersection(set(refs2)))\n",
        "\n",
        "    print(f\"🎯 Correct mappings (Top-1): {correct}\")\n",
        "    print(f\"📊 Evaluation (P / R / F1): {results}\")\n",
        "\n",
        "    return output_file_top1, results, correct\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVyzng3Pe_v0"
      },
      "source": [
        "# **Precision@k, Recall@k, F1@k**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "FstoSsHPe_v0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "def evaluate_topk(topk_file, train_file, test_file, k=1, threshold=0.0):\n",
        "    \"\"\"\n",
        "    Evaluate Top-K predictions using Precision, Recall, and F1-score,\n",
        "    after filtering out training-only URIs, keeping only test sources, and applying 1-1 constraint.\n",
        "\n",
        "    Args:\n",
        "        topk_file (str): Path to the top-k prediction file (TSV with SrcEntity, TgtEntity, Score)\n",
        "        train_file (str): Path to the training mappings file (TSV)\n",
        "        test_file (str): Path to the test mappings file (TSV)\n",
        "        k (int): Value of K for top-k evaluation\n",
        "        threshold (float): Minimum score to consider a prediction valid\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing Precision@K, Recall@K, and F1@K\n",
        "    \"\"\"\n",
        "\n",
        "    # === Step 1: Load input files ===\n",
        "    df = pd.read_csv(topk_file, sep='\\t', dtype=str)\n",
        "    train_df = pd.read_csv(train_file, sep='\\t', dtype=str)\n",
        "    test_df = pd.read_csv(test_file, sep='\\t', dtype=str)\n",
        "\n",
        "    # === Step 2: Remove URIs only present in the training set ===\n",
        "    train_uris = set(train_df['SrcEntity']) | set(train_df['TgtEntity'])\n",
        "    test_uris = set(test_df['SrcEntity']) | set(test_df['TgtEntity'])\n",
        "    uris_to_exclude = train_uris - test_uris\n",
        "    df = df[~(df['SrcEntity'].isin(uris_to_exclude) | df['TgtEntity'].isin(uris_to_exclude))].reset_index(drop=True)\n",
        "\n",
        "    # === Step 3: Keep only source entities from the test set ===\n",
        "    src_entities_test = set(test_df['SrcEntity'])\n",
        "    df = df[df['SrcEntity'].isin(src_entities_test)].reset_index(drop=True)\n",
        "\n",
        "    # === Step 4: Convert score column to float and sort ===\n",
        "    df['Score'] = df['Score'].apply(lambda x: float(x.strip(\"[]\")) if isinstance(x, str) else float(x))\n",
        "    df_sorted = df.sort_values(by='Score', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    # === Step 5: Apply 1-to-1 constraint (greedy strategy with optional threshold)\n",
        "    matched_sources = set()\n",
        "    matched_targets = set()\n",
        "    result = []\n",
        "\n",
        "    for _, row in df_sorted.iterrows():\n",
        "        src, tgt, score = row['SrcEntity'], row['TgtEntity'], row['Score']\n",
        "        if src not in matched_sources and tgt not in matched_targets and score >= threshold:\n",
        "            result.append((src, tgt, score))\n",
        "            matched_sources.add(src)\n",
        "            matched_targets.add(tgt)\n",
        "\n",
        "    # === Step 6: Create and save Top-K prediction dataframe\n",
        "    matching_results_df = pd.DataFrame(result, columns=['SrcEntity', 'TgtEntity', 'Score'])\n",
        "    output_file = topk_file.replace(\".tsv\", \"_predictions.tsv\")\n",
        "    matching_results_df.to_csv(output_file, sep='\\t', index=False)\n",
        "\n",
        "    # === Step 7: Build reference dictionary from test set\n",
        "    ref_dict = defaultdict(set)\n",
        "    for _, row in test_df.iterrows():\n",
        "        ref_dict[row['SrcEntity']].add(row['TgtEntity'])\n",
        "\n",
        "    # === Step 8: Select Top-K predictions for each source entity\n",
        "    matching_results_df['Score'] = matching_results_df['Score'].astype(float)\n",
        "    topk_df = matching_results_df.sort_values(by='Score', ascending=False).groupby('SrcEntity').head(k)\n",
        "\n",
        "    # === Step 9: Compute Precision@K, Recall@K, F1@K\n",
        "    total_tp = total_pred = total_ref = 0\n",
        "\n",
        "    for src, group in topk_df.groupby('SrcEntity'):\n",
        "        predicted = set(group['TgtEntity'])\n",
        "        true = ref_dict.get(src, set())\n",
        "        tp = len(predicted & true)\n",
        "        total_tp += tp\n",
        "        total_pred += len(predicted)\n",
        "        total_ref += len(true)\n",
        "\n",
        "    precision = total_tp / total_pred if total_pred else 0.0\n",
        "    recall = total_tp / total_ref if total_ref else 0.0\n",
        "    f1 = 2 * precision * recall / (precision + recall + 1e-8) if precision + recall > 0 else 0.0\n",
        "\n",
        "    # === Step 10: Print metrics\n",
        "\n",
        "    print(f\"📊 Precision@{k}:            {precision:.3f}\")\n",
        "    print(f\"📊 Recall@{k}:               {recall:.3f}\")\n",
        "    print(f\"📊 F1@{k}:                   {f1:.3f}\\n\")\n",
        "\n",
        "    return {\n",
        "        f'Precision@{k}': round(precision, 3),\n",
        "        f'Recall@{k}': round(recall, 3),\n",
        "        f'F1@{k}': round(f1, 3)\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HyWMsw1MVhz"
      },
      "source": [
        "# **Main Code**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC37FlwGDqGM"
      },
      "source": [
        "\n",
        "\n",
        "# Reading semantic node embeddings provided by the ENE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "FuEfSnw5mod0"
      },
      "outputs": [],
      "source": [
        "# Read the source embeddings from a CSV file into a pandas DataFrame\n",
        "df_embbedings_src = pd.read_csv(src_Emb, index_col=0)\n",
        "\n",
        "# Convert the DataFrame to a NumPy array, which will remove the index and store the data as a raw matrix\n",
        "numpy_array = df_embbedings_src.to_numpy()\n",
        "\n",
        "# Convert the NumPy array into a PyTorch FloatTensor, which is the format required for PyTorch operations\n",
        "x_src = torch.FloatTensor(numpy_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "STUwqMUXmlG2"
      },
      "outputs": [],
      "source": [
        "# Read the target embeddings from a CSV file into a pandas DataFrame\n",
        "df_embbedings_tgt = pd.read_csv(tgt_Emb, index_col=0)\n",
        "\n",
        "# Convert the DataFrame to a NumPy array, which removes the index and converts the data to a raw matrix\n",
        "numpy_array = df_embbedings_tgt.to_numpy()\n",
        "\n",
        "# Convert the NumPy array into a PyTorch FloatTensor, which is required for PyTorch operations\n",
        "x_tgt = torch.FloatTensor(numpy_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZIu9P08DqGN"
      },
      "source": [
        "# Reading adjacency Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "pH69Up40mycz"
      },
      "outputs": [],
      "source": [
        "# Read the source adjacency matrix from a CSV file into a pandas DataFrame\n",
        "df_ma1 = pd.read_csv(src_Adjacence, index_col=0)\n",
        "\n",
        "# Convert the DataFrame to a list of lists (Python native list format)\n",
        "ma1 = df_ma1.values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "hYCmAO5Ymzpl"
      },
      "outputs": [],
      "source": [
        "# Read the target adjacency matrix from a CSV file into a pandas DataFrame\n",
        "df_ma2 = pd.read_csv(tgt_Adjacence, index_col=0)\n",
        "\n",
        "# Convert the DataFrame to a list of lists (Python native list format)\n",
        "ma2 = df_ma2.values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSyksqh3TrU-"
      },
      "source": [
        "# Convert Adjacency matrix (in list format) to an undirected edge index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "uVt-Pce5m5ll"
      },
      "outputs": [],
      "source": [
        "# Convert the source adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n",
        "edge_src = adjacency_matrix_to_undirected_edge_index(ma1)\n",
        "\n",
        "# Convert the target adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n",
        "edge_tgt = adjacency_matrix_to_undirected_edge_index(ma2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9wMTRdqT4aY"
      },
      "source": [
        "# GIT Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "eqiEKCLSMVh3"
      },
      "outputs": [],
      "source": [
        "def train_model_gnn(model, x_src, edge_src, x_tgt, edge_tgt,\n",
        "                    tensor_term1, tensor_term2, tensor_score,\n",
        "                    learning_rate, weight_decay_value, num_epochs, print_interval=10):\n",
        "    \"\"\"\n",
        "    Trains a graph neural network (GNN) model using source and target embeddings and contrastive loss.\n",
        "\n",
        "    Args:\n",
        "        model: The GNN model to be trained.\n",
        "        x_src (torch.Tensor): Source node embeddings.\n",
        "        edge_src (torch.Tensor): Source graph edges.\n",
        "        x_tgt (torch.Tensor): Target node embeddings.\n",
        "        edge_tgt (torch.Tensor): Target graph edges.\n",
        "        tensor_term1 (torch.Tensor): Indices of the source nodes to be compared.\n",
        "        tensor_term2 (torch.Tensor): Indices of the target nodes to be compared.\n",
        "        tensor_score (torch.Tensor): Labels indicating if the pairs are matched (1) or not (0).\n",
        "        learning_rate (float): Learning rate for the optimizer.\n",
        "        weight_decay_value (float): Weight decay (L2 regularization) value for the optimizer.\n",
        "        num_epochs (int): Number of epochs for training.\n",
        "        print_interval (int): Interval at which training progress is printed (every `print_interval` epochs).\n",
        "\n",
        "    Returns:\n",
        "        model: The trained GNN model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 1: Set device (GPU or CPU) for computation\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Step 2: Move the model and all inputs to the selected device\n",
        "    model.to(device)\n",
        "    x_tgt = x_tgt.to(device)               # Target node embeddings\n",
        "    edge_tgt = edge_tgt.to(device)         # Target graph edges\n",
        "    x_src = x_src.to(device)               # Source node embeddings\n",
        "    edge_src = edge_src.to(device)         # Source graph edges\n",
        "    tensor_term1 = tensor_term1.to(device) # Indices for source nodes\n",
        "    tensor_term2 = tensor_term2.to(device) # Indices for target nodes\n",
        "    tensor_score = tensor_score.to(device) # Ground truth labels\n",
        "\n",
        "    # Step 3: Define optimizer with learning rate and regularization\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay_value)\n",
        "\n",
        "    # Step 4: Initialize list to store training losses\n",
        "    train_losses = []\n",
        "\n",
        "    # Record the start time of training\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Step 5: Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        # Zero out gradients from the previous iteration\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass: Compute embeddings for source and target graphs\n",
        "        out1 = model(x_src, edge_src)  # Updated source embeddings\n",
        "        out2 = model(x_tgt, edge_tgt)  # Updated target embeddings\n",
        "\n",
        "        # Extract specific rows of embeddings for terms being compared\n",
        "        src_embeddings = select_rows_by_index(out1, tensor_term1)\n",
        "        tgt_embeddings = select_rows_by_index(out2, tensor_term2)\n",
        "\n",
        "        # Compute contrastive loss based on the embeddings and ground truth labels\n",
        "        loss = contrastive_loss(src_embeddings, tgt_embeddings, tensor_score)\n",
        "\n",
        "        # Backward pass: Compute gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the model's parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Append the loss for this iteration to the list\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        # Print loss every `print_interval` epochs\n",
        "        if (epoch + 1) % print_interval == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item()}\")\n",
        "\n",
        "    # Step 6: Record end time of training\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Step 7: Plot the training loss over time\n",
        "    plt.semilogy(range(1, num_epochs + 1), train_losses, label=\"Training Loss\", marker='o')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Print the total training time\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training complete! Total training time: {training_time:.2f} seconds\")\n",
        "\n",
        "    # Step 8: Return the trained model\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "6_tzUG_emtBg"
      },
      "outputs": [],
      "source": [
        "# Initialize the GIT_mod model with the dimensionality of the target embeddings\n",
        "# The first argument is the dimensionality of the target node embeddings (x_tgt.shape[1])\n",
        "# The second argument (1) represents the number of RGIT layers in the model\n",
        "GIT_model = RGIT_mod(x_tgt.shape[1], 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "wVo-s7UQssSp"
      },
      "outputs": [],
      "source": [
        "# Reading the training pairs from a CSV file into a pandas DataFrame\n",
        "df_embbedings = pd.read_csv(train_file, index_col=0)\n",
        "\n",
        "# Extract the 'SrcEntity' and 'TgtEntity' columns as NumPy arrays and convert them to integers\n",
        "tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)  # Source entity indices\n",
        "tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)  # Target entity indices\n",
        "\n",
        "# Extract the 'Score' column as a NumPy array and convert it to floats\n",
        "tensor_score = df_embbedings['Score'].values.astype(float)  # Scores (labels) indicating if pairs match (1) or not (0)\n",
        "\n",
        "# Convert the NumPy arrays to PyTorch LongTensors (for indices) and FloatTensors (for scores)\n",
        "tensor_term1_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)  # Source entity tensor\n",
        "tensor_term2_o = torch.from_numpy(tensor_term2).type(torch.LongTensor)  # Target entity tensor\n",
        "tensor_score_o = torch.from_numpy(tensor_score).type(torch.FloatTensor)  # Score tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "agHlFNesMVh3",
        "outputId": "1f465ca3-ae0a-4a9b-8201-d163bdd98a8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/1000], Training Loss: 0.0021081245504319668\n",
            "Epoch [20/1000], Training Loss: 0.001681274501606822\n",
            "Epoch [30/1000], Training Loss: 0.0014367621624842286\n",
            "Epoch [40/1000], Training Loss: 0.0012676046462729573\n",
            "Epoch [50/1000], Training Loss: 0.0011441366514191031\n",
            "Epoch [60/1000], Training Loss: 0.001047448138706386\n",
            "Epoch [70/1000], Training Loss: 0.0009674379834905267\n",
            "Epoch [80/1000], Training Loss: 0.0008995779207907617\n",
            "Epoch [90/1000], Training Loss: 0.0008411019225604832\n",
            "Epoch [100/1000], Training Loss: 0.0007900946657173336\n",
            "Epoch [110/1000], Training Loss: 0.0007449586410075426\n",
            "Epoch [120/1000], Training Loss: 0.0007048730622045696\n",
            "Epoch [130/1000], Training Loss: 0.0006687865825369954\n",
            "Epoch [140/1000], Training Loss: 0.0006360700936056674\n",
            "Epoch [150/1000], Training Loss: 0.0006065039779059589\n",
            "Epoch [160/1000], Training Loss: 0.0005794122698716819\n",
            "Epoch [170/1000], Training Loss: 0.0005542213912121952\n",
            "Epoch [180/1000], Training Loss: 0.0005314037553034723\n",
            "Epoch [190/1000], Training Loss: 0.000510155048687011\n",
            "Epoch [200/1000], Training Loss: 0.0004904076340608299\n",
            "Epoch [210/1000], Training Loss: 0.00047241910942830145\n",
            "Epoch [220/1000], Training Loss: 0.00045567049528472126\n",
            "Epoch [230/1000], Training Loss: 0.00044024395174346864\n",
            "Epoch [240/1000], Training Loss: 0.000426059850724414\n",
            "Epoch [250/1000], Training Loss: 0.00041290666558779776\n",
            "Epoch [260/1000], Training Loss: 0.0004008858813904226\n",
            "Epoch [270/1000], Training Loss: 0.00038981178659014404\n",
            "Epoch [280/1000], Training Loss: 0.00037953609717078507\n",
            "Epoch [290/1000], Training Loss: 0.0003701631794683635\n",
            "Epoch [300/1000], Training Loss: 0.00036156180431135\n",
            "Epoch [310/1000], Training Loss: 0.000353629031451419\n",
            "Epoch [320/1000], Training Loss: 0.00034612519084475935\n",
            "Epoch [330/1000], Training Loss: 0.00033891963539645076\n",
            "Epoch [340/1000], Training Loss: 0.00033208844251930714\n",
            "Epoch [350/1000], Training Loss: 0.00032557552913203835\n",
            "Epoch [360/1000], Training Loss: 0.0003194928867742419\n",
            "Epoch [370/1000], Training Loss: 0.0003138134197797626\n",
            "Epoch [380/1000], Training Loss: 0.00030843293643556535\n",
            "Epoch [390/1000], Training Loss: 0.0003034363326150924\n",
            "Epoch [400/1000], Training Loss: 0.00029870515572838485\n",
            "Epoch [410/1000], Training Loss: 0.0002942778810393065\n",
            "Epoch [420/1000], Training Loss: 0.000290059600956738\n",
            "Epoch [430/1000], Training Loss: 0.0002860281092580408\n",
            "Epoch [440/1000], Training Loss: 0.0002821967354975641\n",
            "Epoch [450/1000], Training Loss: 0.00027844859869219363\n",
            "Epoch [460/1000], Training Loss: 0.0002748005499597639\n",
            "Epoch [470/1000], Training Loss: 0.0002711457200348377\n",
            "Epoch [480/1000], Training Loss: 0.00026762651395983994\n",
            "Epoch [490/1000], Training Loss: 0.00026417250046506524\n",
            "Epoch [500/1000], Training Loss: 0.00026085571153089404\n",
            "Epoch [510/1000], Training Loss: 0.0002576123224571347\n",
            "Epoch [520/1000], Training Loss: 0.0002545212919358164\n",
            "Epoch [530/1000], Training Loss: 0.00025154586182907224\n",
            "Epoch [540/1000], Training Loss: 0.00024862916325218976\n",
            "Epoch [550/1000], Training Loss: 0.0002458039962220937\n",
            "Epoch [560/1000], Training Loss: 0.00024297276104334742\n",
            "Epoch [570/1000], Training Loss: 0.00024015111557673663\n",
            "Epoch [580/1000], Training Loss: 0.0002373634051764384\n",
            "Epoch [590/1000], Training Loss: 0.00023462180979549885\n",
            "Epoch [600/1000], Training Loss: 0.00023196473193820566\n",
            "Epoch [610/1000], Training Loss: 0.0002293900615768507\n",
            "Epoch [620/1000], Training Loss: 0.00022685954172629863\n",
            "Epoch [630/1000], Training Loss: 0.0002244682691525668\n",
            "Epoch [640/1000], Training Loss: 0.0002220859023509547\n",
            "Epoch [650/1000], Training Loss: 0.00021969292720314115\n",
            "Epoch [660/1000], Training Loss: 0.00021736635244451463\n",
            "Epoch [670/1000], Training Loss: 0.00021500184084288776\n",
            "Epoch [680/1000], Training Loss: 0.0002127758489223197\n",
            "Epoch [690/1000], Training Loss: 0.0002108926564687863\n",
            "Epoch [700/1000], Training Loss: 0.00020884309196844697\n",
            "Epoch [710/1000], Training Loss: 0.000206699623959139\n",
            "Epoch [720/1000], Training Loss: 0.0002050087641691789\n",
            "Epoch [730/1000], Training Loss: 0.00020360715279821306\n",
            "Epoch [740/1000], Training Loss: 0.0002017276274273172\n",
            "Epoch [750/1000], Training Loss: 0.00020004049292765558\n",
            "Epoch [760/1000], Training Loss: 0.00019868393428623676\n",
            "Epoch [770/1000], Training Loss: 0.00019729907216969877\n",
            "Epoch [780/1000], Training Loss: 0.00019541324581950903\n",
            "Epoch [790/1000], Training Loss: 0.00019371521193534136\n",
            "Epoch [800/1000], Training Loss: 0.0001925591641338542\n",
            "Epoch [810/1000], Training Loss: 0.00019082608923781663\n",
            "Epoch [820/1000], Training Loss: 0.00018867697508540004\n",
            "Epoch [830/1000], Training Loss: 0.00018686572730075568\n",
            "Epoch [840/1000], Training Loss: 0.00018548704974818975\n",
            "Epoch [850/1000], Training Loss: 0.00018330510647501796\n",
            "Epoch [860/1000], Training Loss: 0.0001811403053579852\n",
            "Epoch [870/1000], Training Loss: 0.00017956351803150028\n",
            "Epoch [880/1000], Training Loss: 0.00017854012548923492\n",
            "Epoch [890/1000], Training Loss: 0.00017679586017038673\n",
            "Epoch [900/1000], Training Loss: 0.00017518868844490498\n",
            "Epoch [910/1000], Training Loss: 0.00017413226305507123\n",
            "Epoch [920/1000], Training Loss: 0.0001735908299451694\n",
            "Epoch [930/1000], Training Loss: 0.000172316053067334\n",
            "Epoch [940/1000], Training Loss: 0.00017093346104957163\n",
            "Epoch [950/1000], Training Loss: 0.0001698429259704426\n",
            "Epoch [960/1000], Training Loss: 0.00016950449207797647\n",
            "Epoch [970/1000], Training Loss: 0.00016859355673659593\n",
            "Epoch [980/1000], Training Loss: 0.00016723270528018475\n",
            "Epoch [990/1000], Training Loss: 0.0001665895397309214\n",
            "Epoch [1000/1000], Training Loss: 0.0001663649018155411\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete! Total training time: 1250.66 seconds\n"
          ]
        }
      ],
      "source": [
        "# Train the GNN model using the provided source and target graph embeddings, edges, and training data\n",
        "trained_model = train_model_gnn(\n",
        "    model=GIT_model,                # The GNN model to be trained (initialized earlier)\n",
        "    x_src=x_src,                    # Source node embeddings (tensor for source graph)\n",
        "    edge_src=edge_src,              # Source graph edges (undirected edge index for source graph)\n",
        "    x_tgt=x_tgt,                    # Target node embeddings (tensor for target graph)\n",
        "    edge_tgt=edge_tgt,              # Target graph edges (undirected edge index for target graph)\n",
        "    tensor_term1=tensor_term1_o,    # Indices of source entities for training\n",
        "    tensor_term2=tensor_term2_o,    # Indices of target entities for training\n",
        "    tensor_score=tensor_score_o,    # Scores (labels) indicating if pairs match (1) or not (0)\n",
        "    learning_rate=0.0001,            # Learning rate for the Adam optimizer\n",
        "    weight_decay_value=1e-4,        # Weight decay for L2 regularization to prevent overfitting\n",
        "    num_epochs=1000,                # Number of training epochs\n",
        "    print_interval=10               # Interval at which to print training progress (every 10 epochs)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYyhvjcTUaae"
      },
      "source": [
        "# GIT Application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "BZ_VqP6tq6iD"
      },
      "outputs": [],
      "source": [
        "# Determine if a GPU is available and move the computations to it; otherwise, use the CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Assuming the model has been trained and hyperparameters (x_src, edge_src, x_tgt, edge_tgt) are set\n",
        "\n",
        "# Move the trained GIT_model to the device (GPU or CPU)\n",
        "GIT_model.to(device)\n",
        "\n",
        "# Move the data tensors to the same device (GPU or CPU)\n",
        "x_tgt = x_tgt.to(device)         # Target node embeddings\n",
        "edge_tgt = edge_tgt.to(device)   # Target graph edges\n",
        "x_src = x_src.to(device)         # Source node embeddings\n",
        "edge_src = edge_src.to(device)   # Source graph edges\n",
        "\n",
        "# Set the model to evaluation mode; this disables dropout and batch normalization\n",
        "GIT_model.eval()\n",
        "\n",
        "# Pass the source and target embeddings through the trained GNN model to update the embeddings\n",
        "with torch.no_grad():  # Disable gradient computation (inference mode)\n",
        "    embeddings_tgt = GIT_model(x_tgt, edge_tgt)  # Get updated embeddings for the target graph\n",
        "    embeddings_src = GIT_model(x_src, edge_src)  # Get updated embeddings for the source graph\n",
        "\n",
        "# Detach the embeddings from the computation graph and move them back to the CPU\n",
        "# This step is useful if you need to use the embeddings for tasks outside PyTorch (e.g., saving to disk)\n",
        "embeddings_tgt = embeddings_tgt.detach().cpu()  # Target graph embeddings\n",
        "embeddings_src = embeddings_src.detach().cpu()  # Source graph embeddings\n",
        "\n",
        "# At this point, embeddings_tgt and embeddings_src contain the updated embeddings, ready for downstream tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og5fdoGJrTCG"
      },
      "source": [
        "# Selecting embedding pairs to train the Gated Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "J0nTwc-dnjLn"
      },
      "outputs": [],
      "source": [
        "# Read the training pairs from a CSV file into a pandas DataFrame\n",
        "df_embeddings = pd.read_csv(train_file, index_col=0)\n",
        "\n",
        "# Extract columns and convert to NumPy arrays\n",
        "tensor_term1 = df_embeddings['SrcEntity'].values.astype(int)  # Source entity indices\n",
        "tensor_term2 = df_embeddings['TgtEntity'].values.astype(int)  # Target entity indices\n",
        "tensor_score = df_embeddings['Score'].values.astype(float)  # Matching scores\n",
        "\n",
        "# Split data into training and validation sets\n",
        "tensor_term1_train, tensor_term1_val, tensor_term2_train, tensor_term2_val, tensor_score_train, tensor_score_val = train_test_split(\n",
        "    tensor_term1, tensor_term2, tensor_score, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Convert split data to PyTorch tensors\n",
        "tensor_term1_train = torch.from_numpy(tensor_term1_train).type(torch.LongTensor)\n",
        "tensor_term2_train = torch.from_numpy(tensor_term2_train).type(torch.LongTensor)\n",
        "tensor_score_train = torch.from_numpy(tensor_score_train).type(torch.FloatTensor)\n",
        "\n",
        "tensor_term1_val = torch.from_numpy(tensor_term1_val).type(torch.LongTensor)\n",
        "tensor_term2_val = torch.from_numpy(tensor_term2_val).type(torch.LongTensor)\n",
        "tensor_score_val = torch.from_numpy(tensor_score_val).type(torch.FloatTensor)\n",
        "\n",
        "# Move the embeddings back to the CPU if not already there\n",
        "x_tgt = x_tgt.cpu()  # Target node embeddings\n",
        "x_src = x_src.cpu()  # Source node embeddings\n",
        "\n",
        "# Select embeddings for the training set\n",
        "X1_train = select_rows_by_index(embeddings_src, tensor_term1_train)\n",
        "X2_train = select_rows_by_index(x_src, tensor_term1_train)\n",
        "X3_train = select_rows_by_index(embeddings_tgt, tensor_term2_train)\n",
        "X4_train = select_rows_by_index(x_tgt, tensor_term2_train)\n",
        "\n",
        "# Select embeddings for the validation set\n",
        "X1_val = select_rows_by_index(embeddings_src, tensor_term1_val)\n",
        "X2_val = select_rows_by_index(x_src, tensor_term1_val)\n",
        "X3_val = select_rows_by_index(embeddings_tgt, tensor_term2_val)\n",
        "X4_val = select_rows_by_index(x_tgt, tensor_term2_val)\n",
        "\n",
        "# Now you have:\n",
        "# - Training tensors: X1_train, X2_train, X3_train, X4_train, tensor_score_train\n",
        "# - Validation tensors: X1_val, X2_val, X3_val, X4_val, tensor_score_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNdCgaTMExPK"
      },
      "source": [
        "# Gated Network Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "Gof1eIPIWSVU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def train_gated_combination_model(X1_t, X2_t, X3_t, X4_t, tensor_score_o,\n",
        "                                  X1_val, X2_val, X3_val, X4_val, tensor_score_val,\n",
        "                                  epochs=120, batch_size=32, learning_rate=0.001, weight_decay=1e-5):\n",
        "    \"\"\"\n",
        "    Trains the GatedCombination model with training and validation data, using ReduceLROnPlateau scheduler.\n",
        "    Also calculates and displays F1-score during training and validation.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create datasets and DataLoaders\n",
        "    train_dataset = TensorDataset(X1_t, X2_t, X3_t, X4_t, tensor_score_o)\n",
        "    val_dataset = TensorDataset(X1_val, X2_val, X3_val, X4_val, tensor_score_val)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = GatedCombination(X1_t.shape[1]).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # Use ReduceLROnPlateau scheduler\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_train_loss = 0.0\n",
        "        y_true_train, y_pred_train = [], []\n",
        "\n",
        "        for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in train_loader:\n",
        "            batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (\n",
        "                batch_X1.to(device),\n",
        "                batch_X2.to(device),\n",
        "                batch_X3.to(device),\n",
        "                batch_X4.to(device),\n",
        "                batch_y.to(device),\n",
        "            )\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = F.binary_cross_entropy(outputs, batch_y.unsqueeze(1).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # Store true labels and predictions for F1-score\n",
        "            y_true_train.extend(batch_y.cpu().numpy())\n",
        "            y_pred_train.extend((outputs > 0.5).float().cpu().numpy())\n",
        "\n",
        "        train_loss = total_train_loss / len(train_loader)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # Calculate F1-score for training\n",
        "        train_f1 = f1_score(y_true_train, y_pred_train)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        total_val_loss = 0.0\n",
        "        y_true_val, y_pred_val = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in val_loader:\n",
        "                batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (\n",
        "                    batch_X1.to(device),\n",
        "                    batch_X2.to(device),\n",
        "                    batch_X3.to(device),\n",
        "                    batch_X4.to(device),\n",
        "                    batch_y.to(device),\n",
        "                )\n",
        "                outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n",
        "\n",
        "                # Compute loss\n",
        "                val_loss = F.binary_cross_entropy(outputs, batch_y.unsqueeze(1).float())\n",
        "                total_val_loss += val_loss.item()\n",
        "\n",
        "                # Store true labels and predictions for F1-score\n",
        "                y_true_val.extend(batch_y.cpu().numpy())\n",
        "                y_pred_val.extend((outputs > 0.5).float().cpu().numpy())\n",
        "\n",
        "        avg_val_loss = total_val_loss / len(val_loader)\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        # Calculate F1-score for validation\n",
        "        val_f1 = f1_score(y_true_val, y_pred_val)\n",
        "\n",
        "        # Step the scheduler with validation loss\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        # Print training and validation metrics\n",
        "        print(f\"Epoch [{epoch + 1}/{epochs}] Training Loss: {train_loss:.4f}, F1 Score: {train_f1:.4f} | \"\n",
        "              f\"Validation Loss: {avg_val_loss:.4f}, F1 Score: {val_f1:.4f}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Plotting training and validation loss\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label=\"Training Loss\", marker='o')\n",
        "    plt.plot(val_losses, label=\"Validation Loss\", marker='x')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Training complete! Total time: {end_time - start_time:.2f} seconds\")\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QrpFp6aDbtSW",
        "outputId": "86bfc011-ddeb-47e1-8a1f-a6ccb5af7142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100] Training Loss: 0.0502, F1 Score: 0.0000 | Validation Loss: 0.0499, F1 Score: 0.0000\n",
            "Epoch [2/100] Training Loss: 0.0456, F1 Score: 0.0000 | Validation Loss: 0.0451, F1 Score: 0.0000\n",
            "Epoch [3/100] Training Loss: 0.0410, F1 Score: 0.0519 | Validation Loss: 0.0406, F1 Score: 0.0867\n",
            "Epoch [4/100] Training Loss: 0.0370, F1 Score: 0.1459 | Validation Loss: 0.0365, F1 Score: 0.2438\n",
            "Epoch [5/100] Training Loss: 0.0336, F1 Score: 0.2959 | Validation Loss: 0.0333, F1 Score: 0.3770\n",
            "Epoch [6/100] Training Loss: 0.0305, F1 Score: 0.4204 | Validation Loss: 0.0309, F1 Score: 0.4381\n",
            "Epoch [7/100] Training Loss: 0.0280, F1 Score: 0.4986 | Validation Loss: 0.0281, F1 Score: 0.5105\n",
            "Epoch [8/100] Training Loss: 0.0258, F1 Score: 0.5784 | Validation Loss: 0.0261, F1 Score: 0.5680\n",
            "Epoch [9/100] Training Loss: 0.0238, F1 Score: 0.6242 | Validation Loss: 0.0237, F1 Score: 0.6291\n",
            "Epoch [10/100] Training Loss: 0.0220, F1 Score: 0.6745 | Validation Loss: 0.0223, F1 Score: 0.6603\n",
            "Epoch [11/100] Training Loss: 0.0206, F1 Score: 0.7190 | Validation Loss: 0.0206, F1 Score: 0.6828\n",
            "Epoch [12/100] Training Loss: 0.0193, F1 Score: 0.7480 | Validation Loss: 0.0195, F1 Score: 0.7022\n",
            "Epoch [13/100] Training Loss: 0.0183, F1 Score: 0.7679 | Validation Loss: 0.0185, F1 Score: 0.7469\n",
            "Epoch [14/100] Training Loss: 0.0172, F1 Score: 0.7887 | Validation Loss: 0.0179, F1 Score: 0.7460\n",
            "Epoch [15/100] Training Loss: 0.0165, F1 Score: 0.8042 | Validation Loss: 0.0165, F1 Score: 0.7700\n",
            "Epoch [16/100] Training Loss: 0.0157, F1 Score: 0.8197 | Validation Loss: 0.0157, F1 Score: 0.7897\n",
            "Epoch [17/100] Training Loss: 0.0151, F1 Score: 0.8255 | Validation Loss: 0.0148, F1 Score: 0.8436\n",
            "Epoch [18/100] Training Loss: 0.0145, F1 Score: 0.8370 | Validation Loss: 0.0145, F1 Score: 0.8548\n",
            "Epoch [19/100] Training Loss: 0.0140, F1 Score: 0.8421 | Validation Loss: 0.0141, F1 Score: 0.8474\n",
            "Epoch [20/100] Training Loss: 0.0134, F1 Score: 0.8505 | Validation Loss: 0.0136, F1 Score: 0.8278\n",
            "Epoch [21/100] Training Loss: 0.0131, F1 Score: 0.8555 | Validation Loss: 0.0134, F1 Score: 0.8455\n",
            "Epoch [22/100] Training Loss: 0.0127, F1 Score: 0.8588 | Validation Loss: 0.0124, F1 Score: 0.8680\n",
            "Epoch [23/100] Training Loss: 0.0123, F1 Score: 0.8686 | Validation Loss: 0.0127, F1 Score: 0.8412\n",
            "Epoch [24/100] Training Loss: 0.0120, F1 Score: 0.8718 | Validation Loss: 0.0123, F1 Score: 0.8680\n",
            "Epoch [25/100] Training Loss: 0.0118, F1 Score: 0.8806 | Validation Loss: 0.0119, F1 Score: 0.8585\n",
            "Epoch [26/100] Training Loss: 0.0116, F1 Score: 0.8801 | Validation Loss: 0.0114, F1 Score: 0.8823\n",
            "Epoch [27/100] Training Loss: 0.0113, F1 Score: 0.8908 | Validation Loss: 0.0116, F1 Score: 0.8530\n",
            "Epoch [28/100] Training Loss: 0.0111, F1 Score: 0.8861 | Validation Loss: 0.0118, F1 Score: 0.8455\n",
            "Epoch [29/100] Training Loss: 0.0109, F1 Score: 0.8911 | Validation Loss: 0.0117, F1 Score: 0.8474\n",
            "Epoch [30/100] Training Loss: 0.0108, F1 Score: 0.8954 | Validation Loss: 0.0112, F1 Score: 0.8567\n",
            "Epoch [31/100] Training Loss: 0.0106, F1 Score: 0.9039 | Validation Loss: 0.0107, F1 Score: 0.8766\n",
            "Epoch [32/100] Training Loss: 0.0104, F1 Score: 0.9068 | Validation Loss: 0.0102, F1 Score: 0.9389\n",
            "Epoch [33/100] Training Loss: 0.0103, F1 Score: 0.9071 | Validation Loss: 0.0101, F1 Score: 0.9080\n",
            "Epoch [34/100] Training Loss: 0.0102, F1 Score: 0.9085 | Validation Loss: 0.0098, F1 Score: 0.9012\n",
            "Epoch [35/100] Training Loss: 0.0100, F1 Score: 0.9123 | Validation Loss: 0.0106, F1 Score: 0.8730\n",
            "Epoch [36/100] Training Loss: 0.0099, F1 Score: 0.9098 | Validation Loss: 0.0095, F1 Score: 0.9080\n",
            "Epoch [37/100] Training Loss: 0.0099, F1 Score: 0.9107 | Validation Loss: 0.0095, F1 Score: 0.9163\n",
            "Epoch [38/100] Training Loss: 0.0098, F1 Score: 0.9137 | Validation Loss: 0.0096, F1 Score: 0.9421\n",
            "Epoch [39/100] Training Loss: 0.0096, F1 Score: 0.9144 | Validation Loss: 0.0098, F1 Score: 0.9196\n",
            "Epoch [40/100] Training Loss: 0.0096, F1 Score: 0.9212 | Validation Loss: 0.0094, F1 Score: 0.9261\n",
            "Epoch [41/100] Training Loss: 0.0095, F1 Score: 0.9232 | Validation Loss: 0.0096, F1 Score: 0.8910\n",
            "Epoch [42/100] Training Loss: 0.0094, F1 Score: 0.9211 | Validation Loss: 0.0095, F1 Score: 0.9341\n",
            "Epoch [43/100] Training Loss: 0.0095, F1 Score: 0.9219 | Validation Loss: 0.0089, F1 Score: 0.9245\n",
            "Epoch [44/100] Training Loss: 0.0093, F1 Score: 0.9204 | Validation Loss: 0.0092, F1 Score: 0.8910\n",
            "Epoch [45/100] Training Loss: 0.0093, F1 Score: 0.9227 | Validation Loss: 0.0090, F1 Score: 0.8961\n",
            "Epoch [46/100] Training Loss: 0.0092, F1 Score: 0.9226 | Validation Loss: 0.0092, F1 Score: 0.9277\n",
            "Epoch [47/100] Training Loss: 0.0091, F1 Score: 0.9183 | Validation Loss: 0.0087, F1 Score: 0.9261\n",
            "Epoch [48/100] Training Loss: 0.0091, F1 Score: 0.9198 | Validation Loss: 0.0093, F1 Score: 0.8871\n",
            "Epoch [49/100] Training Loss: 0.0091, F1 Score: 0.9234 | Validation Loss: 0.0096, F1 Score: 0.8854\n",
            "Epoch [50/100] Training Loss: 0.0092, F1 Score: 0.9234 | Validation Loss: 0.0097, F1 Score: 0.9545\n",
            "Epoch [51/100] Training Loss: 0.0090, F1 Score: 0.9234 | Validation Loss: 0.0092, F1 Score: 0.9421\n",
            "Epoch [52/100] Training Loss: 0.0090, F1 Score: 0.9228 | Validation Loss: 0.0083, F1 Score: 0.9325\n",
            "Epoch [53/100] Training Loss: 0.0089, F1 Score: 0.9226 | Validation Loss: 0.0086, F1 Score: 0.9560\n",
            "Epoch [54/100] Training Loss: 0.0088, F1 Score: 0.9272 | Validation Loss: 0.0090, F1 Score: 0.9499\n",
            "Epoch [55/100] Training Loss: 0.0088, F1 Score: 0.9257 | Validation Loss: 0.0085, F1 Score: 0.9436\n",
            "Epoch [56/100] Training Loss: 0.0088, F1 Score: 0.9236 | Validation Loss: 0.0082, F1 Score: 0.9309\n",
            "Epoch [57/100] Training Loss: 0.0088, F1 Score: 0.9270 | Validation Loss: 0.0083, F1 Score: 0.9245\n",
            "Epoch [58/100] Training Loss: 0.0087, F1 Score: 0.9270 | Validation Loss: 0.0085, F1 Score: 0.9293\n",
            "Epoch [59/100] Training Loss: 0.0088, F1 Score: 0.9272 | Validation Loss: 0.0083, F1 Score: 0.9529\n",
            "Epoch [60/100] Training Loss: 0.0088, F1 Score: 0.9278 | Validation Loss: 0.0086, F1 Score: 0.9405\n",
            "Epoch [61/100] Training Loss: 0.0086, F1 Score: 0.9291 | Validation Loss: 0.0083, F1 Score: 0.9357\n",
            "Epoch [62/100] Training Loss: 0.0087, F1 Score: 0.9298 | Validation Loss: 0.0084, F1 Score: 0.9405\n",
            "Epoch [63/100] Training Loss: 0.0087, F1 Score: 0.9249 | Validation Loss: 0.0085, F1 Score: 0.9560\n",
            "Epoch [64/100] Training Loss: 0.0087, F1 Score: 0.9257 | Validation Loss: 0.0083, F1 Score: 0.9228\n",
            "Epoch [65/100] Training Loss: 0.0087, F1 Score: 0.9207 | Validation Loss: 0.0084, F1 Score: 0.9357\n",
            "Epoch [66/100] Training Loss: 0.0087, F1 Score: 0.9329 | Validation Loss: 0.0084, F1 Score: 0.9179\n",
            "Epoch [67/100] Training Loss: 0.0086, F1 Score: 0.9257 | Validation Loss: 0.0088, F1 Score: 0.9029\n",
            "Epoch [68/100] Training Loss: 0.0079, F1 Score: 0.9337 | Validation Loss: 0.0078, F1 Score: 0.9467\n",
            "Epoch [69/100] Training Loss: 0.0078, F1 Score: 0.9379 | Validation Loss: 0.0077, F1 Score: 0.9436\n",
            "Epoch [70/100] Training Loss: 0.0079, F1 Score: 0.9386 | Validation Loss: 0.0077, F1 Score: 0.9467\n",
            "Epoch [71/100] Training Loss: 0.0078, F1 Score: 0.9393 | Validation Loss: 0.0078, F1 Score: 0.9357\n",
            "Epoch [72/100] Training Loss: 0.0079, F1 Score: 0.9386 | Validation Loss: 0.0078, F1 Score: 0.9341\n",
            "Epoch [73/100] Training Loss: 0.0079, F1 Score: 0.9357 | Validation Loss: 0.0078, F1 Score: 0.9436\n",
            "Epoch [74/100] Training Loss: 0.0079, F1 Score: 0.9336 | Validation Loss: 0.0078, F1 Score: 0.9452\n",
            "Epoch [75/100] Training Loss: 0.0079, F1 Score: 0.9379 | Validation Loss: 0.0078, F1 Score: 0.9421\n",
            "Epoch [76/100] Training Loss: 0.0079, F1 Score: 0.9350 | Validation Loss: 0.0077, F1 Score: 0.9467\n",
            "Epoch [77/100] Training Loss: 0.0079, F1 Score: 0.9379 | Validation Loss: 0.0078, F1 Score: 0.9421\n",
            "Epoch [78/100] Training Loss: 0.0079, F1 Score: 0.9329 | Validation Loss: 0.0077, F1 Score: 0.9436\n",
            "Epoch [79/100] Training Loss: 0.0079, F1 Score: 0.9343 | Validation Loss: 0.0077, F1 Score: 0.9405\n",
            "Epoch [80/100] Training Loss: 0.0079, F1 Score: 0.9357 | Validation Loss: 0.0078, F1 Score: 0.9436\n",
            "Epoch [81/100] Training Loss: 0.0079, F1 Score: 0.9329 | Validation Loss: 0.0077, F1 Score: 0.9436\n",
            "Epoch [82/100] Training Loss: 0.0077, F1 Score: 0.9393 | Validation Loss: 0.0077, F1 Score: 0.9436\n",
            "Epoch [83/100] Training Loss: 0.0077, F1 Score: 0.9393 | Validation Loss: 0.0077, F1 Score: 0.9436\n",
            "Epoch [84/100] Training Loss: 0.0077, F1 Score: 0.9372 | Validation Loss: 0.0077, F1 Score: 0.9436\n",
            "Epoch [85/100] Training Loss: 0.0077, F1 Score: 0.9386 | Validation Loss: 0.0077, F1 Score: 0.9436\n",
            "Epoch [86/100] Training Loss: 0.0077, F1 Score: 0.9379 | Validation Loss: 0.0077, F1 Score: 0.9436\n",
            "Epoch [87/100] Training Loss: 0.0077, F1 Score: 0.9386 | Validation Loss: 0.0077, F1 Score: 0.9436\n",
            "Epoch [88/100] Training Loss: 0.0077, F1 Score: 0.9386 | Validation Loss: 0.0077, F1 Score: 0.9436\n",
            "Epoch [89/100] Training Loss: 0.0077, F1 Score: 0.9379 | Validation Loss: 0.0077, F1 Score: 0.9436\n",
            "Epoch [90/100] Training Loss: 0.0077, F1 Score: 0.9386 | Validation Loss: 0.0077, F1 Score: 0.9436\n",
            "Epoch [91/100] Training Loss: 0.0077, F1 Score: 0.9372 | Validation Loss: 0.0077, F1 Score: 0.9436\n",
            "Epoch [92/100] Training Loss: 0.0077, F1 Score: 0.9393 | Validation Loss: 0.0077, F1 Score: 0.9436\n",
            "Epoch [93/100] Training Loss: 0.0077, F1 Score: 0.9386 | Validation Loss: 0.0077, F1 Score: 0.9436\n",
            "Epoch [94/100] Training Loss: 0.0077, F1 Score: 0.9386 | Validation Loss: 0.0077, F1 Score: 0.9436\n",
            "Epoch [95/100] Training Loss: 0.0077, F1 Score: 0.9386 | Validation Loss: 0.0077, F1 Score: 0.9436\n",
            "Epoch [96/100] Training Loss: 0.0077, F1 Score: 0.9386 | Validation Loss: 0.0077, F1 Score: 0.9436\n",
            "Epoch [97/100] Training Loss: 0.0077, F1 Score: 0.9386 | Validation Loss: 0.0077, F1 Score: 0.9436\n",
            "Epoch [98/100] Training Loss: 0.0077, F1 Score: 0.9386 | Validation Loss: 0.0077, F1 Score: 0.9436\n",
            "Epoch [99/100] Training Loss: 0.0077, F1 Score: 0.9386 | Validation Loss: 0.0077, F1 Score: 0.9436\n",
            "Epoch [100/100] Training Loss: 0.0077, F1 Score: 0.9386 | Validation Loss: 0.0077, F1 Score: 0.9436\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1cAAAHACAYAAABOPpIiAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAfyVJREFUeJzs3Xd4VGX6xvHvOWcmCS0BAiQBaUIUQi+CgAooSiwozYIoWPnpAqJgw4aoiOKCLKC4uCusFSWiYgMBAQsoIEUwiIiRmtBJaElmzpzfHyEDQwotYVLuz3Xlkpw2z8RZNzfv+z6v4TiOg4iIiIiIiJwVM9gFiIiIiIiIlAQKVyIiIiIiIgVA4UpERERERKQAKFyJiIiIiIgUAIUrERERERGRAqBwJSIiIiIiUgAUrkRERERERAqAwpWIiIiIiEgBcAW7gKLI5/Oxfft2KlSogGEYwS5HRERERESCxHEcDhw4QPXq1THN/MemFK5ysX37dmrWrBnsMkREREREpIjYsmUL5513Xr7XKFzlokKFCkDWDzA8PDzI1YiIiIiISLCkpaVRs2ZNf0bIj8JVLrKnAoaHhytciYiIiIjIKS0XUkMLERERERGRAqBwJSIiIiIiUgAUrkRERERERAqA1lyJiIiISLFg2zYejyfYZUgJY1kWLperQLZgUrgSERERkSLv4MGDbN26Fcdxgl2KlEBly5YlJiaGkJCQs3qOwpWIiIiIFGm2bbN161bKli1L1apVC2SEQQSyNgjOzMxk165dJCUlERsbe9KNgvOjcCUiIiIiRZrH48FxHKpWrUqZMmWCXY6UMGXKlMHtdrNp0yYyMzMJCws742epoYWIiIiIFAsasZLCcjajVQHPKZCniIiIiIiIlHIKV0WY7XNYsnEPn63axpKNe7B9WsApIiIiUprVqVOH8ePHn/L1CxcuxDAM9u/fX2g1yTFac1VEzV6bzMjPE0lOTfcfi4kIY0S3OOIbxwSxMhEREZHiyfY5LE3ay84D6VSrEEabupWxzMKZaniyKYwjRozg2WefPe3nLlu2jHLlyp3y9e3btyc5OZmIiIjTfq3TsXDhQjp37sy+ffuoWLFiob5WUVYkRq5ee+016tSpQ1hYGG3btmXp0qX5Xj9jxgwaNGhAWFgYTZo04auvvgo4f8cdd2AYRsBXfHx8Yb6FAjV7bTL3v7siIFgBpKSmc/+7K5i9NjlIlYmIiIgUT7PXJnPJy9/S582fGDJ9FX3e/IlLXv620H6vSk5O9n+NHz+e8PDwgGMPP/yw/1rHcfB6vaf03KpVq1K2bNlTriMkJITo6GitVztHgh6uPvzwQ4YOHcqIESNYsWIFzZo1o2vXruzcuTPX6xcvXkyfPn24++67WblyJd27d6d79+6sXbs24Lr4+PiAD/AHH3xwLt7OWbN9DiM/TyS3CYDZx0Z+nqgpgiIiIiKnKBh/cR0dHe3/ioiIwDAM//e///47FSpU4Ouvv6ZVq1aEhobyww8/sHHjRm644QaioqIoX748F110EfPmzQt47onTAg3D4D//+Q89evSgbNmyxMbGMmvWLP/5E6cFTps2jYoVKzJnzhwaNmxI+fLl/b83Z/N6vTzwwANUrFiRyMhIHnvsMfr370/37t3P+Oexb98++vXrR6VKlShbtixXX301GzZs8J/ftGkT3bp1o1KlSpQrV45GjRr5B1D27dtH3759/d0iY2NjmTp16hnXUpiCHq7GjRvHvffey5133klcXBxvvPEGZcuW5a233sr1+n/961/Ex8fzyCOP0LBhQ55//nlatmzJpEmTAq4LDQ0N+FBXqlTpXLyds7Y0aS83H3qXwdbMXM8PsmZy86F3WZq09xxXJiIiIlI0OI7D4UzvKX0dSPcwYtZv+f7F9bOzEjmQ7jml5xXkJsaPP/44L730EuvWraNp06YcPHiQa665hvnz57Ny5Uri4+Pp1q0bmzdvzvc5I0eO5KabbuLXX3/lmmuuoW/fvuzdm/fviocPH+af//wn77zzDt999x2bN28OGEl7+eWXee+995g6dSo//vgjaWlpfPrpp2f1Xu+44w6WL1/OrFmzWLJkCY7jcM011+DxeAAYOHAgGRkZfPfdd6xZs4aXX36Z8uXLA/D000+TmJjI119/zbp165g8eTJVqlQ5q3oKS1DXXGVmZvLLL78wfPhw/zHTNOnSpQtLlizJ9Z4lS5YwdOjQgGNdu3bN8S984cKFVKtWjUqVKnH55ZfzwgsvEBkZWeDvoaDtPJCO7ZgMcycAMNHu6T832JrJMHcCYz292XkgPa9HiIiIiJRoRzw2cc/MKZBnOUBKWjpNnv3mlK5PfK4rZUMK5lfo5557jiuvvNL/feXKlWnWrJn/++eff55PPvmEWbNmMWjQoDyfc8cdd9CnTx8AXnzxRSZMmMDSpUvzXBbj8Xh44403qFevHgCDBg3iueee85+fOHEiw4cPp0ePHgBMmjQpxzKc07FhwwZmzZrFjz/+SPv27QF47733qFmzJp9++ik33ngjmzdvplevXjRp0gSA888/33//5s2badGiBa1btwayRu+KqqCGq927d2PbNlFRUQHHo6Ki+P3333O9JyUlJdfrU1JS/N/Hx8fTs2dP6taty8aNG3niiSe4+uqrWbJkCZZl5XhmRkYGGRkZ/u/T0tLO5m2dlWoVwhhyNFANcycQZezjV+d8arODge5ZjPX0ZqLdkw8qnPnmZiIiIiISfNlhIdvBgwd59tln+fLLL0lOTsbr9XLkyJGTjlw1bdrU/+dy5coRHh6e5xIbgLJly/qDFUBMTIz/+tTUVHbs2EGbNm385y3LolWrVvh8vtN6f9nWrVuHy+Wibdu2/mORkZFceOGFrFu3DoAHHniA+++/n2+++YYuXbrQq1cv//u6//776dWrFytWrOCqq66ie/fu/pBW1JTIboG33HKL/89NmjShadOm1KtXj4ULF3LFFVfkuH706NGMHDnyXJaYpzZ1KxMTEcak1GMBC+YDMNbTm0l2T2IisrrbiIiIiJRGZdwWic91PaVrlybt5Y6py0563bQ7Lzql36/KuHP+Rf2ZOrHr38MPP8zcuXP55z//Sf369SlTpgy9e/cmMzMz3+e43e6A7w3DyDcI5XZ9QU53PBP33HMPXbt25csvv+Sbb75h9OjRjB07lsGDB3P11VezadMmvvrqK+bOncsVV1zBwIED+ec//xnUmnMT1DVXVapUwbIsduzYEXB8x44dREdH53pPdHT0aV0PWcOKVapU4c8//8z1/PDhw0lNTfV/bdmy5TTfScGxTIMR3eIAmGT3xHayOrt4HZNJR0e0RnSLK7S2oSIiIiJFnWEYlA1xndLXpbFViYkII6/fnAyytru5NLbqKT2vMLvu/fjjj9xxxx306NGDJk2aEB0dzd9//11or5ebiIgIoqKiWLbsWCC1bZsVK1ac8TMbNmyI1+vl559/9h/bs2cP69evJy4uzn+sZs2a3HfffcycOZNhw4bx5ptv+s9VrVqV/v378+677zJ+/HimTJlyxvUUpqCGq5CQEFq1asX8+fP9x3w+H/Pnz6ddu3a53tOuXbuA6wHmzp2b5/UAW7duZc+ePcTE5L4/VGhoKOHh4QFfwRTfOIbJt7VkeLlZWEbW3yK4DB+PlZ3F5Ntaap8rERERkVN0/F9cnxiLsr8vKn9xHRsby8yZM1m1ahWrV6/m1ltvPeOpeGdj8ODBjB49ms8++4z169czZMgQ9u3bd0rBcs2aNaxatcr/tXr1amJjY7nhhhu49957+eGHH1i9ejW33XYbNWrU4IYbbgDgwQcfZM6cOSQlJbFixQoWLFhAw4YNAXjmmWf47LPP+PPPP/ntt9/44osv/OeKmqBPCxw6dCj9+/endevWtGnThvHjx3Po0CHuvPNOAPr160eNGjUYPXo0AEOGDKFjx46MHTuWa6+9lunTp7N8+XJ/ej148CAjR46kV69eREdHs3HjRh599FHq169P166nNnxcFMTveQfs6eyqcwNV//6MXb5w7mM67KkHPBrs8kRERESKjey/uB75eWJAO/boiDBGdIsrMn9xPW7cOO666y7at29PlSpVeOyxx4LSC+Cxxx4jJSWFfv36YVkWAwYMoGvXrrn2LjjRZZddFvC9ZVl4vV6mTp3KkCFDuO6668jMzOSyyy7jq6++8k9RtG2bgQMHsnXrVsLDw4mPj+fVV18FsgZkhg8fzt9//02ZMmW49NJLmT59esG/8QJgOMGeYElWB5JXXnmFlJQUmjdvzoQJE/wL3jp16kSdOnWYNm2a//oZM2bw1FNP8ffffxMbG8uYMWO45pprADhy5Ajdu3dn5cqV7N+/n+rVq3PVVVfx/PPP52iEkZe0tDQiIiJITU0NzijWojGwYBR0fhKa9YHxjfE4Fitq30XbzW9mHe+ogCUiIiKlQ3p6OklJSdStW5ewsDNv6mX7HJYm7WXngXSqVchaw14URqyKOp/PR8OGDbnpppt4/vnng11OocjvM3Y62aBIhKuiJujhasFoMK2sAOU4ZIyqSaj3AC+cN4WnYjeBz4bOw0/+HBEREZESoKDClZyaTZs28c0339CxY0cyMjKYNGkSU6dOZfXq1UV2Ot7ZKqhwFfRpgZKL44OTYZBeuSGhO5di7PwN7nku7/tERERERM6SaZpMmzaNhx9+GMdxaNy4MfPmzSuxwaogKVwVA2HnNYWdS6l2eANp6R7Cw9wnv0lERERE5AzUrFmTH3/8MdhlFEtB7RYopyb0vKyduhsam/g9+UCQqxERERERkdwoXBUHUY0BaGhuJnHb/uDWIiIiIiIiuVK4Kg6qNcSHSaRxgC1bkoJdjYiIiIiI5ELhqjhwl+FwhToAeLavCW4tIiIiIiKSK4WrYsKMbgJAhf2/47HP/U7dIiIiIiKSP4WrYqJMzaYAxLKJjbsOBrkaERERERE5kcJVMWEcHblqaGwmcXtakKsRERERkXOhU6dOPPjgg/7v69Spw/jx4/O9xzAMPv3007N+7YJ6TmmicFVcHO0YWM/Yzvqtu4JcjIiIiIjkp1u3bsTHx+d67vvvv8cwDH799dfTfu6yZcsYMGDA2ZYX4Nlnn6V58+Y5jicnJ3P11VcX6GudaNq0aVSsWLFQX+NcUrgqLsKrk+EOx2X4SNvyW7CrERERESk+FoyGRWNyP7doTNb5Anb33Xczd+5ctm7dmuPc1KlTad26NU2bNj3t51atWpWyZcsWRIknFR0dTWho6Dl5rZJC4aq4MAw8VRoB4N79G47jBLkgERERkWLCtGDBqJwBa9GYrOOmVeAved1111G1alWmTZsWcPzgwYPMmDGDu+++mz179tCnTx9q1KhB2bJladKkCR988EG+zz1xWuCGDRu47LLLCAsLIy4ujrlz5+a457HHHuOCCy6gbNmynH/++Tz99NN4PB4ga+Ro5MiRrF69GsMwMAzDX/OJ0wLXrFnD5ZdfTpkyZYiMjGTAgAEcPHisF8Add9xB9+7d+ec//0lMTAyRkZEMHDjQ/1pnYvPmzdxwww2UL1+e8PBwbrrpJnbs2OE/v3r1ajp37kyFChUIDw+nVatWLF++HIBNmzbRrVs3KlWqRLly5WjUqBFfffXVGddyKlyF+nQpUGE1m0LyEmp7kkhOTad6xTLBLklERETk3HMc8Bw+9evbDQQ7MytI2ZlwyUPww6vw3Stw2SNZ5zMPndqz3GXBME56mcvlol+/fkybNo0nn3wS4+g9M2bMwLZt+vTpw8GDB2nVqhWPPfYY4eHhfPnll9x+++3Uq1ePNm3anPQ1fD4fPXv2JCoqip9//pnU1NSA9VnZKlSowLRp06hevTpr1qzh3nvvpUKFCjz66KPcfPPNrF27ltmzZzNv3jwAIiIicjzj0KFDdO3alXbt2rFs2TJ27tzJPffcw6BBgwIC5IIFC4iJiWHBggX8+eef3HzzzTRv3px77733pO8nt/eXHawWLVqE1+tl4MCB3HzzzSxcuBCAvn370qJFCyZPnoxlWaxatQq32w3AwIEDyczM5LvvvqNcuXIkJiZSvnz5067jdChcFSOumKyh44bGJhK3pylciYiISOnkOQwvVj+ze797Jesrr+9P5ontEFLulC696667eOWVV1i0aBGdOnUCsqYE9urVi4iICCIiInj44Yf91w8ePJg5c+bw0UcfnVK4mjdvHr///jtz5syhevWsn8eLL76YY53UU0895f9znTp1ePjhh5k+fTqPPvooZcqUoXz58rhcLqKjo/N8rffff5/09HTefvttypXLev+TJk2iW7duvPzyy0RFRQFQqVIlJk2ahGVZNGjQgGuvvZb58+efUbiaP38+a9asISkpiZo1awLw9ttv06hRI5YtW8ZFF13E5s2beeSRR2jQoAEAsbGx/vs3b95Mr169aNIkqzHc+eeff9o1nC5NCyxOorKmBTYwN5O4PTXIxYiIiIhIfho0aED79u156623APjzzz/5/vvvufvuuwGwbZvnn3+eJk2aULlyZcqXL8+cOXPYvHnzKT1/3bp11KxZ0x+sANq1a5fjug8//JAOHToQHR1N+fLleeqpp075NY5/rWbNmvmDFUCHDh3w+XysX7/ef6xRo0ZY1rFpljExMezcufO0Xuv416xZs6Y/WAHExcVRsWJF1q1bB8DQoUO555576NKlCy+99BIbN270X/vAAw/wwgsv0KFDB0aMGHFGDUROl0auipOqDfEZFpU5yPYtfwEXBLsiERERkXPPXTZrBOl0ZU8FtEKypgde9kjWFMHTfe3TcPfddzN48GBee+01pk6dSr169ejYsSMAr7zyCv/6178YP348TZo0oVy5cjz44INkZmaeXk35WLJkCX379mXkyJF07dqViIgIpk+fztixYwvsNY6XPSUvm2EY+Hy+QnktyOp0eOutt/Lll1/y9ddfM2LECKZPn06PHj2455576Nq1K19++SXffPMNo0ePZuzYsQwePLjQ6tHIVXHiDiM9PGs405eyJsjFiIiIiASJYWRNzTudryWvZQWrzk/C07uy/vndK1nHT+c5p7De6ng33XQTpmny/vvv8/bbb3PXXXf511/9+OOP3HDDDdx22200a9aM888/nz/++OOUn92wYUO2bNlCcnKy/9hPP/0UcM3ixYupXbs2Tz75JK1btyY2NpZNmzYFXBMSEoJt2yd9rdWrV3Po0LG1aT/++COmaXLhhReecs2nI/v9bdmyxX8sMTGR/fv3ExcX5z92wQUX8NBDD/HNN9/Qs2dPpk6d6j9Xs2ZN7rvvPmbOnMmwYcN48803C6XWbApXxYwrJmu/q8iDf5KWfuadV0RERERKjeyugJ2fhI6PZh3r+GjW97l1ESxA5cuX5+abb2b48OEkJydzxx13+M/FxsYyd+5cFi9ezLp16/i///u/gE54J9OlSxcuuOAC+vfvz+rVq/n+++958sknA66JjY1l8+bNTJ8+nY0bNzJhwgQ++eSTgGvq1KlDUlISq1atYvfu3WRkZOR4rb59+xIWFkb//v1Zu3YtCxYsYPDgwdx+++3+9VZnyrZtVq1aFfC1bt06unTpQpMmTejbty8rVqxg6dKl9OvXj44dO9K6dWuOHDnCoEGDWLhwIZs2beLHH39k2bJlNGzYEIAHH3yQOXPmkJSUxIoVK1iwYIH/XGFRuCpmQmocbWphbuL35ANBrkZERESkGPDZgcEqW3bA8uU/anO27r77bvbt20fXrl0D1kc99dRTtGzZkq5du9KpUyeio6Pp3r37KT/XNE0++eQTjhw5Qps2bbjnnnsYNWpUwDXXX389Dz30EIMGDaJ58+YsXryYp59+OuCaXr16ER8fT+fOnalatWqu7eDLli3LnDlz2Lt3LxdddBG9e/fmiiuuYNKkSaf3w8jFwYMHadGiRcBXt27dMAyDzz77jEqVKnHZZZfRpUsXzj//fD788EMALMtiz5499OvXjwsuuICbbrqJq6++mpEjRwJZoW3gwIE0bNiQ+Ph4LrjgAl5//fWzrjc/hqMNk3JIS0sjIiKC1NRUwsPDg11OoA1z4b3ebPDV4MeuX3JHh7rBrkhERESkUKWnp5OUlETdunUJCwsLdjlSAuX3GTudbKCRq+ImKmta4PnGdv7YtivIxYiIiIiISDaFq+KmQjSZIRWxDIdD234LdjUiIiIiInKUwlVxYxj4qmWNXpXdsw6PXXitLUVERERE5NQpXBVDoUebWlzA32zcdTDI1YiIiIiICChcFUtGdNbIVQNjC4nb04JcjYiIiIiIgMJV8XQ0XDU0N/H5qm0s2bgH26emjyIiIlKyqcm1FJaC+mwpXBVDc3ZWxINFReMQv/+xnj5v/sQlL3/L7LXJJ79ZREREpJixLAuAzMzMIFciJdXhw4cBcLvdZ/UcV0EUI+fO7LXJ3P/BWr4OqU4DcwsNzM0k+yJJSU3n/ndXMPm2lsQ3jgl2mSIiIiIFxuVyUbZsWXbt2oXb7cY0NT4gBcNxHA4fPszOnTupWLGiP8ifKYWrYsT2OYz8PBEH+N2pSQO20NDYxAJa4AAGMPLzRK6Mi8YyjSBXKyIiIlIwDMMgJiaGpKQkNm3aFOxypASqWLEi0dHRZ/0chatiZGnSXpJT0wFY56tNd2sxceZmsLPOO0ByajpLk/bSrl5k8AoVERERKWAhISHExsZqaqAUOLfbfdYjVtkUroqRnQfSedCVgO2YrHbqAdDA2Ow/P9iaiWX42HmgeZAqFBERESk8pmkSFhYW7DJE8qQJq8VItQph2I7JMHcC7Y3fAKhrJBNKJoOtmQxzZwWvahX0Hx0RERERkXNNI1fFSJu6lRla/laMgzDUncAhJ5RyRgbPuN6mr+tbxnl6k1D+Vh6sWznYpYqIiIiIlDoauSpGLNNgRLc4Jto9GefpTTkjA8AfrCbaPRnRLU7NLEREREREgkDhqpiJbxzD5NtaMqP8rdhO1r8+2zF4L+wWtWEXEREREQkihatiKL5xDD+2W45l+ACwDIcptecrWImIiIiIBJHCVXG0aAzmwhehzf8BkOlYtPprMiwaE+TCRERERERKL4Wr4mbRGFgwCjo/CfGj8VplCDFsPgvtlnVcAUtEREREJCgUroobn50VrDo+CqaFXbURAAsP1cbb8Yms8yIiIiIics6pFXtx03l4wLch5zWHlOVcyN/8ceFk4qqHB6cuEREREZFSTiNXxZwR0xSAxkYSiclpQa5GRERERKT0Urgq7o6Gq0bmJhK3pQa5GBERERGR0kvhqrirFofPcFHJOMiOrX8GuxoRERERkVJL4aq4c4WSWSkWAGvnGhzHCXJBIiIiIiKlk8JVCeA+rzkA53s3snXfkeAWIyIiIiJSSilclQBW9eYANDI2qamFiIiIiEiQKFyVBEebWsSZf5O4XeFKRERERCQYFK5KgqjGANQw9rB565YgFyMiIiIiUjopXJUEYeGkV6gNgLN9dZCLEREREREpnRSuSgirRnMAog7/wf7DmcEtRkRERESkFFK4KiHcNZoB0Mj8W00tRERERESCQOGqpIg5Gq4MNbUQEREREQkGhauSIjorXNU1UvhzW0qQixERERERKX0UrkqK8lVJL1MN03DI2Lom2NWIiIiIiJQ6ClclSXTWflcR+9eR7rGDXIyIiIiISOmicFWChJ7XHICGJPHnzoPBLUZEREREpJRRuCpBjJjjOgaqqYWIiIiIyDmlcFWSHA1XFxhbWL9tT5CLEREREREpXRSuSpKKtch0hxNi2KRtWRvsakREREREShWFq5LEMPBWbQxA6O61+HxOkAsSERERESk9FK5KmLBaLQCoZ//Fln2Hg1yNiIiIiEjpoXBVwphqaiEiIiIiEhQKVyVNTNZeV3HGJhK37w9uLSIiIiIipYjCVUkTGYvXDKO8kc7viatZsnEPttZeiYiIiIgUOoWrEmb2ul2s89UEIHTXWvq8+ROXvPwts9cmB7kyEREREZGSTeGqBJm9Npn7313Bam8tIGvdFUBKajr3v7tCAUtEREREpBApXJUQts9h5OeJOMBvTh0AGhl/A5A9KXDk54maIigiIiIiUkhcwS5ACsbSpL3cfOhdbMtkkS+rY2CcuYmsaGUwyJqJdcjH0qTmtKsXGdRaRURERERKIo1clRA7D6RjOybD3AlcYa7A65hUMdKIYh+DrZkMcydgOyY7D6QHu1QRERERkRJJI1clRLUKYQyxewIwzJ3ALl84VY00Hne9Tw/XYsZ6ejPR7skHFcKCXKmIiIiISMmkcFVCtKlbmZiIMCalHgtYgD9YTbJ7EhMRRpu6lYNZpoiIiIhIiaVpgSWEZRqM6BYHwCS7J14n61+tzzGYeHREa0S3OCzTCFqNIiIiIiIlWZEIV6+99hp16tQhLCyMtm3bsnTp0nyvnzFjBg0aNCAsLIwmTZrw1Vdf5Xntfffdh2EYjB8/voCrLnriG8cw+baWDC83C5fhA8A0HIaFfsLk21oS3zgmyBWKiIiIiJRcQQ9XH374IUOHDmXEiBGsWLGCZs2a0bVrV3bu3Jnr9YsXL6ZPnz7cfffdrFy5ku7du9O9e3fWrl2b49pPPvmEn376ierVqxf22ygy4ve8wwB7OluaDMZrZM36HGzMIH7PO0GuTERERESkZAt6uBo3bhz33nsvd955J3FxcbzxxhuULVuWt956K9fr//WvfxEfH88jjzxCw4YNef7552nZsiWTJk0KuG7btm0MHjyY9957D7fbfS7eSvAtGgMLRkHnJ6nZ6wW8VRoB8JWvXdbxRWOCXKCIiIiISMkV1HCVmZnJL7/8QpcuXfzHTNOkS5cuLFmyJNd7lixZEnA9QNeuXQOu9/l83H777TzyyCM0atTopHVkZGSQlpYW8FUs+Wzo/CR0fBSAkNoXAbDFV5ldrYdlnRcRERERkUIR1HC1e/dubNsmKioq4HhUVBQpKSm53pOSknLS619++WVcLhcPPPDAKdUxevRoIiIi/F81a9Y8zXdSRHQe7g9WAOZ5rQBobm5kXrU7ss6LiIiIiEihCPq0wIL2yy+/8K9//Ytp06ZhGKfWGW/48OGkpqb6v7Zs2VLIVZ4jNbLCVRMjidWbdgW5GBERERGRki2o4apKlSpYlsWOHTsCju/YsYPo6Ohc74mOjs73+u+//56dO3dSq1YtXC4XLpeLTZs2MWzYMOrUqZPrM0NDQwkPDw/4KhEiY/G6ylHWyGDvppwNP0REREREpOAENVyFhITQqlUr5s+f7z/m8/mYP38+7dq1y/Wedu3aBVwPMHfuXP/1t99+O7/++iurVq3yf1WvXp1HHnmEOXPmFN6bKYpME1/1lgBU2reGA+meIBckIiIiIlJyuYJdwNChQ+nfvz+tW7emTZs2jB8/nkOHDnHnnXcC0K9fP2rUqMHo0aMBGDJkCB07dmTs2LFce+21TJ8+neXLlzNlyhQAIiMjiYyMDHgNt9tNdHQ0F1544bl9c0VASK3WsPl7mhkb+XVrKh3qVwl2SSIiIiIiJVLQw9XNN9/Mrl27eOaZZ0hJSaF58+bMnj3b37Ri8+bNmOaxAbb27dvz/vvv89RTT/HEE08QGxvLp59+SuPGjYP1Foq2o+uumpkbWbhlv8KViIiIiEghMRzHcYJdRFGTlpZGREQEqampxX/9Vdp2GNcQr2PyQJ1ZvH7npcGuSERERESk2DidbFDiugXKCcKrk1k2CpfhI2PrKpSlRUREREQKh8JVKWCd1xqAOum/s3XfkSBXIyIiIiJSMilclQJWzWPrrlZu2R/cYkRERERESiiFq9Igu6mFsZFVm/cHtxYRERERkRJK4ao0qN4CgNrmTv7c9HdwaxERERERKaEUrkqDsAg8leoDELJjFRleO8gFiYiIiIiUPApXpYSrVlZTi0a+P1mXfCDI1YiIiIiIlDwKV6WEUSMrXDU3/2TV5n1BrkZEREREpORRuCotarQEjnYMVLgSERERESlwClelRVRjfKabysZBdmxeH+xqRERERERKHIWr0sIVii+qCQBVU9ey91BmkAsSERERESlZFK5KEVfNrHVXzcyNrNqiqYEiIiIiIgVJ4ao0yd5M2NRmwiIiIiIiBU3hqjQ5Gq4aG3/z3e/b+WzVNpZs3IPtc4JcmIiIiIhI8ecKdgFyDlWuR4arPGW8B8lMTmTI9MMAxESEMaJbHPGNY4JcoIiIiIhI8aWRq1JkduIOlmXUAbKmBmZLSU3n/ndXMHttcpAqExEREREp/hSuSgnb5zDy80RWOfUAaGYcC1fZkwJHfp6oKYIiIiIiImdI4aqUWJq0l+TUdFb7joar40auICtgJaemszRpbxCqExEREREp/rTmqpTYeSCdB10JhDlZ+1tdYGylLOkcJgyAwdZMLMPHzgPNg1iliIiIiEjxpZGrUqJahTBsx+Q+9xekOWWwDIfGRhKQFayGuROwHZNqFcKCXKmIiIiISPGkkatSok3dygwtfyvGQRjqTgCypga2ZR3D3AmM8/QmofytPFi3cpArFREREREpnhSuSgnLNBjRLY773+1Ja/N3LrPWMtz1AabhMM7Tm4l2TyZ3i8MyjWCXKiIiIiJSLGlaYCkS3ziGybe15H9htwFgGg4ZjosZ5W9l8m0ttc+ViIiIiMhZ0MhVKRPfOIardu2HRVnfhxpevmq+hEqNrwhqXSIiIiIixZ1GrkqbRWMwF70EkRcA8L3dmEo/vwKLxgS5MBERERGR4k3hqjRZNAYWjILOT0KbewEwcPiqyl1ZxxWwRERERETOmKYFliY+OytYdXwUdv0BwEXmH1yV+hRXd4rG8NlBLlBEREREpPhSuCpNOg8/9ucqsTjlYwg9mEyNQ2tIajSQ86uWD15tIiIiIiLFnKYFllaGgVGvEwCXmGtZ8tee4NYjIiIiIlLMKVyVZud3AqC9uZbFGxWuRERERETOhsJVaVa3IwBNjSR++3MTjuMEuSARERERkeJL4ao0C4/BqXIhpuFwYfoq/thxMNgViYiIiIgUWwpXpZxxdGpgB/M3lmzcHdxiRERERESKMYWr0u78rKmBHbTuSkRERETkrChclXZ1LsExTOqZyST9tR7bp3VXIiIiIiJnQuGqtAuLgOqtAGjmWc265LQgFyQiIiIiUjwpXAlGwNRArbsSERERETkTClfi3++qg/kbS/5UuBIRERERORMKVwI12+Czwqhm7GfP37/isX3BrkhEREREpNhRuBJwhWLUbg9AK3s1a7alBrkgEREREZHiR+FKADDqdQKgvfkbS9SSXURERETktLmCXYAUEXWzmlpcbK5j0q9bOK9SGapVCKNN3cpYphHk4kREREREij6FK8kS3ZR0dwQVPKlYKasYMv0wADERYYzoFkd845ggFygiIiIiUrRpWqAAMDtxB/PTGwBZLdmzpaSmc/+7K5i9NjlYpYmIiIiIFAsKV4Ltc9j6yTOE4AHgEutYuHKAwdZMtn7yDLbPCVKFIiIiIiJFn8KVsDRpL6npPq60VgDQwthAGdKBrGA11J1AarqPpUl7g1mmiIiIiEiRpjVXws4D6Uy0ewIwzJ1AiGHTxlxPU2Mjw9wJjPX0ZqLdk/oH0oNcqYiIiIhI0aVwJVSrEAbARLsnV5nLaWL9zVvuV7AMnz9YHX+diIiIiIjkpGmBQpu6lYmJCMMA/m13A8AyfGQ4LibaPTHI6hrYpm7loNYpIiIiIlKUKVwJlmkwolscABcaW/zHQw0vD1gzARjRLU77XYmIiIiI5EPhSgCIbxzDNy1/YrD7U37z1QJgtX0+Q90JfNPyJ+1zJSIiIiJyEgpXkmXRGGITJ+Dr9ARcNQqAOmYKy+sMIDZxAiwaE+QCRURERESKNjW0kCw+Gzo/idnxURr5bA5+H0VExg4WH6hG685PZp0XEREREZE8KVxJls7Dj/3ZtMhsdCOsmESjXV9zpN1cyoRYwatNRERERKQY0LRAyVWldv0AuMxYxYp1fwS5GhERERGRok/hSnJlVL2QLWUa4jZsDiz7INjliIiIiIgUeQpXkqcDF/YGoN72z4NciYiIiIhI0adwJXmq2fF2Mh2LWN9fpPzxS7DLEREREREp0hSuJE8VKkWxMqwtAHsX/y/I1YiIiIiIFG0KV5KvPfV7AVBjy+dge4NcjYiIiIhI0aVwJfmq3fYG9jrlibD34vnz22CXIyIiIiJSZClcSb4anleFb8xLAUhdoqmBIiIiIiJ5UbiSfJmmwfba3QGI2DQX0lODW5CIiIiISBGlcCUndX7TS/jDVwO3kwG/fRrsckREREREiiSFKzmpq3ZNJcWpBEDmivcDTy4aAwtGB6EqEREREZGiReFKTqpsWCiXWWvxORCy7SfYm5R1YtEYWDAKTCu4BYqIiIiIFAGuYBcgxUDHR/nxz9102PJvAH6fM4WyYaHUWv0qdH4SOj4a5AJFRERERIJP4UpOycq697I/aSXXupZy4e+vYxgwxbqFWpG3Ex/s4kREREREigBNC5STmr02mbHf/MEj3vtwHDAMyHQsRh+6nvvfXcHstcnBLlFEREREJOgUriRfts9h5OeJOMDd1lcYRtbxEMNmkDUTgJGfJ2L7nOAVKSIiIiJSBChcSb6WJu0lOTWdwdZMhrkTmGe3AGCrL5Jh7gQGWTNJTk1nadLeIFcqIiIiIhJcRSJcvfbaa9SpU4ewsDDatm3L0qVL871+xowZNGjQgLCwMJo0acJXX30VcP7ZZ5+lQYMGlCtXjkqVKtGlSxd+/vnnwnwLJdbOA8eC1VhPb57x3AlAjLGX1z3dGOZOYLA1k50H0oNcqYiIiIhIcAU9XH344YcMHTqUESNGsGLFCpo1a0bXrl3ZuXNnrtcvXryYPn36cPfdd7Ny5Uq6d+9O9+7dWbt2rf+aCy64gEmTJrFmzRp++OEH6tSpw1VXXcWuXbvO1dsqMapVCMMyfIz19Gai3ZPtVCHRVxvLcPjTqcFYT28sw0e1CmHBLlVEREREJKgMx3FOe7HMli1bMAyD8847D4ClS5fy/vvvExcXx4ABA07rWW3btuWiiy5i0qRJAPh8PmrWrMngwYN5/PHHc1x/8803c+jQIb744gv/sYsvvpjmzZvzxhtv5PoaaWlpREREMG/ePK644oqT1pR9fWpqKuHh4af1fkoa2+dwycvfkpKaTvYHZajrIx5wfcqXdhsGeR4kOiKMHx67HMs0glqriIiIiEhBO51scEYjV7feeisLFiwAICUlhSuvvJKlS5fy5JNP8txzz53yczIzM/nll1/o0qXLsYJMky5durBkyZJc71myZEnA9QBdu3bN8/rMzEymTJlCREQEzZo1y/WajIwM0tLSAr4ki2UajOgWB0B2dJpntwLgMnMNIXgY0S1OwUpERERESr0zCldr166lTZs2AHz00Uc0btyYxYsX89577zFt2rRTfs7u3buxbZuoqKiA41FRUaSkpOR6T0pKyild/8UXX1C+fHnCwsJ49dVXmTt3LlWqVMn1maNHjyYiIsL/VbNmzVN+D6VBfOMYJt/WkuiIrKl/a5y67HQqUsE4wrtdPMQ3jglyhSIiIiIiwXdG4crj8RAaGgrAvHnzuP766wFo0KAByclFY8+jzp07s2rVKhYvXkx8fDw33XRTnuu4hg8fTmpqqv9ry5Yt57jaoi++cQw/PHY5H9x7Mb1b1WL+0a6BF2Xm33xERERERKS0OKNw1ahRI9544w2+//575s6dS3x8PADbt28nMjLylJ9TpUoVLMtix44dAcd37NhBdHR0rvdER0ef0vXlypWjfv36XHzxxfz3v//F5XLx3//+N9dnhoaGEh4eHvAlOVmmQbt6kTwa34BvnZYAeNd9Bae/bE9EREREpMQ5o3D18ssv8+9//5tOnTrRp08f/1qmWbNm+acLnoqQkBBatWrF/Pnz/cd8Ph/z58+nXbt2ud7Trl27gOsB5s6dm+f1xz83IyPjlGuTvFWtEIqn1mWkO25cB7bCzsRglyQiIiIiEnSuM7mpU6dO7N69m7S0NCpVquQ/PmDAAMqWLXtazxo6dCj9+/endevWtGnThvHjx3Po0CHuvDNrP6V+/fpRo0YNRo8eDcCQIUPo2LEjY8eO5dprr2X69OksX76cKVOmAHDo0CFGjRrF9ddfT0xMDLt37+a1115j27Zt3HjjjWfydiUXVzavyw9bG9PFWgnrv4aoRsEuSUREREQkqM5o5OrIkSNkZGT4g9WmTZsYP34869evp1q1aqf1rJtvvpl//vOfPPPMMzRv3pxVq1Yxe/Zsf9OKzZs3B6zjat++Pe+//z5TpkyhWbNmJCQk8Omnn9K4cWMALMvi999/p1evXlxwwQV069aNPXv28P3339OokQJAQYlvFM0CJ6trYEbiVye5WkRERESk5Dujfa6uuuoqevbsyX333cf+/ftp0KABbreb3bt3M27cOO6///7CqPWc0T5Xp2bwlK+YuL0PDgbGw39A+dML1iIiIiIiRV2h73O1YsUKLr30UgASEhKIiopi06ZNvP3220yYMOFMHinFUIfmjfnVVxcDB/6YE+xyRERERESC6ozC1eHDh6lQoQIA33zzDT179sQ0TS6++GI2bdpUoAVK0dW1UTQLfFldAw+t+SLI1YiIiIiIBNcZhav69evz6aefsmXLFubMmcNVV10FwM6dOzWNrhSpVC6EPeddAUDIpoXgSQ9uQSIiIiIiQXRG4eqZZ57h4Ycfpk6dOrRp08bfBv2bb76hRYsWBVqgFG1NWl1KslMZty8d/v4+2OWIiIiIiATNGYWr3r17s3nzZpYvX86cOcfW2lxxxRW8+uqrBVacFH1XNYrxTw1MXTUryNWIiIiIiATPGe1zBRAdHU10dDRbt24F4LzzzjutDYSlZIj4+Z/UCXfgEDjrv+azlVupFl6GNnUrY33/Cvhs6Dw82GWKiIiIiBS6Mxq58vl8PPfcc0RERFC7dm1q165NxYoVef755/H5fAVdoxRlpkX7Q/PJdCwqencx5aPP6PPmT/x31H2wYBSYVrArFBERERE5J85o5OrJJ5/kv//9Ly+99BIdOnQA4IcffuDZZ58lPT2dUaNGFWiRUnTNjrydRM96hroTALjCXMHlrGCAncA4T2/iIm8nPsg1ioiIiIicC2e0iXD16tV54403uP766wOOf/bZZ/zjH/9g27ZtBVZgMGgT4VNj+xwueflbklPT+bd7HF2t5fgcMA0Y6+nNJLsn0RFh/PDY5VimEexyRUREREROW6FvIrx3714aNGiQ43iDBg3Yu3fvmTxSiqGlSXtJTs1qv/6k526co8Eq07GYaPfEAZJT01mapM+EiIiIiJR8ZxSumjVrxqRJk3IcnzRpEk2bNj3roqR42Hng2L5Wfaz5GEcHp0IMm8HWzFyvExEREREpqc5ozdWYMWO49tprmTdvnn+PqyVLlrBlyxa++uqrAi1Qiq5qFcIAGGzNZJg7geneTtziWojHsRh2dA3WRLun/zoRERERkZLsjEauOnbsyB9//EGPHj3Yv38/+/fvp2fPnvz222+88847BV2jFFFt6lbmiXKzGOZOYKynN4977+U3X23chs13dhOGuRN4otws2tStHOxSRUREREQK3Rk1tMjL6tWradmyJbZtF9Qjg0INLU7dnx8+waxfd/jXWPW2FvFP97/Z5kTykbcT3ZpGU//mF4NdpoiIiIjIGSn0hhYi2erf/CJxfV4gOiJr6t/ndjt2O+HUMPbQ6dJLFaxEREREpNQ4ozVXIseLbxzDlXHRLE3ay8ZdB5n+5eUMsj7lwr/fA+4MdnkiIiIiIueERq6kQFimQbt6kdx2cW221b8Vj2NRNmUZbF8V7NJERERERM6J0xq56tmzZ77n9+/ffza1SAlxdbuWfPlnW7pbi7F/egOr5xvBLklEREREpNCd1shVREREvl+1a9emX79+hVWrFBOX1K/CF2VuyPpmbQIc3BncgkREREREzoHTGrmaOnVqYdUhJYhpGjRpcwUrv6tPC/6E5VOh02PBLktEREREpFBpzZUUihtbn8dUOx4A79L/gDczyBWJiIiIiBQuhSspFNUrluFQvWtJcSrhOrwTEj8NdkkiIiIiIoVK4UoKzfByX/CnrzoAzk+T4fj9qheNgQWjg1SZiIiIiEjBU7iSQlOnWgSXWL/hdUyM7Sv4bsFXLNm4B9/Cl2HBKDCtYJcoIiIiIlJgtImwFBpX58f49NftdN83DYDUBRP4wzeTdu4ENsQ9QGzHR4NboIiIiIhIAdLIlRSa2WuTeTD5Kt7xdgHgOvMnhrkTGOfpzVUrLmb22uQgVygiIiIiUnAUrqRQ2D6HkZ8nAvC09y58joFhgNcxmWBnbUY98vNEbJ+T32NERERERIoNhSspFEuT9pKcmg7AYGsmppEVolyGj8HWTBwgOTWdpUl7g1iliIiIiEjBUbiSQrHzwLFgNcydwCTP9WQ4bgCGuRMYbM0MuE5EREREpLhTQwspFNUqhPmD1VhPbybaPalj7uA662d+sWMZ5k44et3FQa5URERERKRgaORKCkWbupWJCDMZdzRYAcy0LwWglrmD8Z6eRISZtKlbOZhlioiIiIgUGIUrKRSWaXBej+eYaPfEOHrsO19TdjnhVDXSWOOcz3k9nsMyjXyfIyIiIiJSXChcSaGJbxzD5NtaEh0RBoAXF7PsDgCMqPUr8Y1jglmeiIiIiEiB0porKVTxjWO4Mi6apUl72XkgnW/m7eLug19TfccCOLIPylQKdokiIiIiIgVCI1dS6CzToF29SG5oXoMeV8ezzlcTl+MhffXHwS5NRERERKTAKFzJOXV5wygWhnUBIHXJ/4JcjYiIiIhIwVG4knPKNA2qtb8N2zGISv0Ve9efwS5JRERERKRAKFzJOXdN+xYsMZoD8Nf8/wS3GBERERGRAqJwJedcmRCL1At6ARDxx8fg8wW5IhERERGRs6dwJUFxUfxtHHDKUM23k9lffcxnq7axZOMebJ8T7NJERERERM6IWrFLUFSrXIlvy3Xk8sOzSfvpHR71lgUgJiKMEd3itAeWiIiIiBQ7GrmSoPjzwyfYmZYOwDXWz5Qh688pqekkfvAUf374RDDLExERERE5bQpXcs7ZPodv/9jDLa6F7PeVo7yRzlXmcgAGWTMZ6k7g2z80RVBEREREihdNC5RzbmnSXl48dD0HLC/D3AkA9LK+p5axk2HuBMZ6ejMx/XqaJO2lXb3IIFcrIiIiInJqFK7knNt5IGsK4ES7JxHGIe5xfc2l5hous9ZkBSu7Z8B1IiIiIiLFgaYFyjlXrUKY/88veG/H5xgYBtiO4Q9WJ14nIiIiIlLUKVzJOdembmViIsIwgMHWTEzDwXHAMhz+6ZqMQVbXwDZ1Kwe7VBERERGRU6ZpgXLOWabBiG5xJH7wFEOPrrGqZBzkLtdseru+Z5tTlQu7vYhlGsEuVURERETklClcSVDE73mHeHcCU6xbmJh+PRU4TDdrCVWNVIa4Z8KehsCjwS5TREREROSUKVxJcPhs6Pwkd1/6CE2S9rLzQDo/rHqAHn8/jwcL89AerGDXKCIiIiJyGhSuJDg6DwfAAn+79fS4B1n5YgItWMeWLX9RM4jliYiIiIicLjW0kCIjLMTFnxeNwOuY1Ez+BnvDt8EuSURERETklClcSZFydZcr+cjoCsCRz4aCNzPIFYmIiIiInBqFKylSyoe6iK1RjUNOKOUPJuFb8lrgBYvGwILRwSlORERERCQfCldS5DSpG0M5IwMAe8FLzFm8nCUb9+Bb+DIsGAWmWl2IiIiISNGjhhZS5IR1Gc5nv6Vww75puH3peL5+gsW+mrRzJ7Ah7gFiO6pFu4iIiIgUPRq5kiJn9tpkhiRfxdveLgBcZ/3MMHcC4zy9uWrFxcxemxzkCkVEREREclK4kiLF9jmM/DwRgGe8d2E7BgA+BybYPQAY+Xkits8JWo0iIiIiIrlRuJIiZWnSXpJT0wEYbM3EMhwcB0wDxrlexwGSU9NZmrQ3uIWKiIiIiJxA4UqKlJ0HjgWrYe4Exnp682+7GwA9XT/ygPVxwHUiIiIiIkWFGlpIkVKtQlhAsJpo96QiB+hrzaOCcYSh7o9xMKhW4eJglyoiIiIiEkAjV1KktKlbmYgwk3FHgxXAfirwX/tqAPb4KlAx1KBN3crBLFNEREREJAeFKylSLNPgvB7PMdHuiXHc8f94r2GfU55I8wAXtWyJZRp5PkNEREREJBgUrqTIiW8cw+TbWhIdEeY/dpCyvOHNWnsVu+418GYGqzwRERERkVxpzZUUSfGNY7gyLpqlSXvZeSCdahXC+HZtNLtWfEXVQ1vxLH8b98X3BLtMERERERE/jVxJkWWZBu3qRXJD8xq0qxfJA12b8j9XbwAyvn0JPEeCXKGIiIiIyDEKV1JsVAhzE3fdA2x1qlA+cxdrPh3LZ6u2sWTjHm0qLCIiIiJBp2mBUqxcvf99loTU4zzPbqqvfYNbfmnAIcoQExHG2/UWElu1LHQeHuwyRURERKQU0siVFCt/7jpCe8/P7PWVJ9I4wJ3WbABuPPg+sYkT2LDrcJArFBEREZHSSiNXUmzYPod+GzvR27OdYe4EAAa4viSMDAa5ZzHO05sZGzvxg89Rq3YREREROec0ciXFxtKkvSSnpjPR7sk4Ty8Awo3DDHLPYqynNxPsniSnprM0aW+QKxURERGR0qhIhKvXXnuNOnXqEBYWRtu2bVm6dGm+18+YMYMGDRoQFhZGkyZN+Oqrr/znPB4Pjz32GE2aNKFcuXJUr16dfv36sX379sJ+G1LIdh5I9/95gt0Lj2MdO0elXK8TERERETlXgh6uPvzwQ4YOHcqIESNYsWIFzZo1o2vXruzcuTPX6xcvXkyfPn24++67WblyJd27d6d79+6sXbsWgMOHD7NixQqefvppVqxYwcyZM1m/fj3XX3/9uXxbUgiqVTi2qfBgayZuw8brZH2ER7n+SyPj7xzXiYiIiIicK4bjOEHtYd22bVsuuugiJk2aBIDP56NmzZoMHjyYxx9/PMf1N998M4cOHeKLL77wH7v44otp3rw5b7zxRq6vsWzZMtq0acOmTZuoVavWSWtKS0sjIiKC1NRUwsPDz/CdSUGzfQ6XvPwtNx58n6HuBMZ6ejPJ7s68kEeoZyaz31eOG8PeYPbj3bTmSkREREQKxOlkg6COXGVmZvLLL7/QpUsX/zHTNOnSpQtLlizJ9Z4lS5YEXA/QtWvXPK8HSE1NxTAMKlasWCB1S3BYpsHb9RYy1J3AOE9vJto9cTDpkTmSVF9ZKpqHmG4+haVcJSIiIiJBENRwtXv3bmzbJioqKuB4VFQUKSkpud6TkpJyWtenp6fz2GOP0adPnzyTZkZGBmlpaQFfUjTFVi3LhrgHmFH+Vv+xNMpzj/E0XsckMn0Thxe+GsQKRURERKS0KtGt2D0eDzfddBOO4zB58uQ8rxs9ejQjR448h5XJGes8nFjgB5/D0qS97DyQTrUKYTQ9ryuTXt3Cg+mvE7boOby1L2KZE+c/36ZuZazvXwGfrU2GRURERKRQBDVcValSBcuy2LFjR8DxHTt2EB0dnes90dHRp3R9drDatGkT3377bb7zI4cPH87QoUP936elpVGzZs3TfTtyDlmmQbt6kQHHruj7GOve/IKG5maOvN2bB9LHsYuKADxRbhYD7OnQ+ckgVCsiIiIipUFQpwWGhITQqlUr5s+f7z/m8/mYP38+7dq1y/Wedu3aBVwPMHfu3IDrs4PVhg0bmDdvHpGRkSc+JkBoaCjh4eEBX1L8NKlZkTcveIPdvnDKkc7HISOwsBlszWSAPZ1xnt7Mjrw92GWKiIiISAkV9GmBQ4cOpX///rRu3Zo2bdowfvx4Dh06xJ133glAv379qFGjBqNHjwZgyJAhdOzYkbFjx3Lttdcyffp0li9fzpQpU4CsYNW7d29WrFjBF198gW3b/vVYlStXJiQkJDhvVAqd7XNYvDmdmzzP8HXI49Qyd/FHaD8swznaWbAn0Z8ncmVctLoJioiIiEiBC3q4uvnmm9m1axfPPPMMKSkpNG/enNmzZ/ubVmzevBnTPDbA1r59e95//32eeuopnnjiCWJjY/n0009p3LgxANu2bWPWrFkANG/ePOC1FixYQKdOnc7J+5Jzb2nSXlLS0oHqPOT5B6+HTMAyHLyOyUS7JwDJqeksTdqbY0qhiIiIiMjZCvo+V0WR9rkqnj5btY0h01cBWZsMD3Mn+M/NsVvzf56sdXX/uqU5NzSvEYwSRURERKSYKTb7XIkUpGoVwoBjwWqspzdveLsB0NVazquuSQHXiYiIiIgUpKBPCxQpKG3qVj7aFTArWGVNBXSoYqTS2/qOHq7FmCFlaVP3mmCXKiIiIiIlkEaupMSwTIPLL4hk3NHmFVkMHvfcw3y7BQDdnAVYu3/PefOiMbBg9LkrVkRERERKHIUrKVHq3/wicX1eIDri2NQ/Ly4Geh5gu68ypmPj/OdKfvn1Vz5btY0lG/fgW/gyLBgFphXEykVERESkuFNDi1yooUXxZ/sclibtZeeBdKpVCGPrvsOMSviR+SEPE2keYI+vAl0yX+E2ax7D3AlsiHuA2JueD3bZIiIiIlLEnE420JorKZEs0zih3Xok3yTW57rEF5kT+iiR5gFWhN6HYcA4T28mrriYyXHJxDeOCVrNIiIiIlK8aVqglAq2z2HN1lSSiaRn5kgcBwwDHAf2UgFwGPl5IrZPA7kiIiIicmYUrqRUOLbBMFxtLsUwwOcYGAa84J7KnJBH6HvwfyxN2pvzZjW7EBEREZFToHAlpcLOA1nB6vg9sM7PeJeFdlMALjC3M8j9GdHfPx5446IxanYhIiIiIqdE4UpKhWoVwgKCVdYeWAZ3eB7nPe/l/uvq/v0RvNs7a75gdrDq/CR0fDR4xYuIiIhIsaCGFlIqtKlbmd/CTMalZwerY5703sM+pwLXupdTl23w51x4rjI4PgUrERERETllGrmSUsEyDc7r8RwT7Z4YuZz/p30zP139NVz9StYBxwemS8FKRERERE6ZwpWUGvGNY5h8W8uADYYBXGZW3Ppw+VYyDx3X0MLnxffti+eyRBEREREpxjQtUEqV+MYxXBkXHbDBcFR4KD1eX8yl298iZFcCkzw3cLNrAVWNNMzvXmbD7iPaYFhERERETkrhSkqdnBsMw+vnzaPDlmPNLjY61Xk1ZDKZjkVs4gQ2fIQCloiIiIjkS9MCpdSzfQ7rtu87rosgfOK7hJ99DQgxbDb4qrNofYo2GBYRERGRfClcSam3NGkvLxzqfkIXQYOnPXficSxize38eKR27hsMi4iIiIgcpXAlpV72BsMn+sOpyX/tqwEY6ZrGzr37WLJxD5+t2saSjXs0kiUiIiIiAbTmSkq9ahXC8jw3wduT663F1DJ3Mfur0Qw5cmx0KyYijBHd4ohvHHMuyhQRERGRIk4jV1LqtalbmZiIsFz3vzpMGCt8sQD0931KHSPZfy4lNZ3ED57izw+fOEeVioiIiEhRpnAlpZ5lGozoFgeQa8Ba76sJQKjh5TnXNCBrOuAgayZD3Ql8+4emCIqIiIiIwpUIkPcGw5XLuZlo9+S/3ngALrPWcI35M4OtmQxzZ7Vuf/HQ9Wp2ISIiIiJacyWSLbcNhlPS0nnow1U87+1HQ2MT7a11vOaegGEQ0Lo9r6YYIiIiIlJ6KFyJHOfEDYaXbNzj//OdnsdYZ96JaTg4DmxwzvOfy68phoiIiIiUDpoWKJKP45tdDLC+wDQcfI6BYcDr7vHcYc0mJiKMVrUrqU27iIiISClnOI6j3wJPkJaWRkREBKmpqYSHhwe7HAmy2WuTSfzgKYYeXWP1un0DH7tH0Nz6C4BEV0PuNp8nOS3Tf09MRBhv11tIbNWy0Hl4kCoXERERkbN1OtlAI1ciJxG/5x2GuhOYYt3CRLsnNhbdPc+zmCYAxHnXMTX9QULw+O+58eD7xCZOYMOuw8EqW0RERETOMa25EjkZnw2dn+TuSx+hyXHNLlrV/o65L8RzhfMzDcytzA8ZxrWZL9Lf+oah7gTGeXozY2MnfvA5WGZuTd5FREREpCRRuBI5maPT+izI0ezi3vQhtDfXMtU9hprmblaFDsA8vpNgajpLk/YG3CciIiIiJZOmBYqcoez264t9jeme+TyOA6YBPgfet6/wX5eSekTNLkRERERKAY1ciZyh49uvdzF/wTDwB6w5IY/SNXMMe4jg+S/XsfdQYLOLEd3iiG8cE4yyRURERKSQaORK5Axlt2l/wJrJsKOdBDtnjuWAE0YV8wBzQh4jktSAYAWQkprO/e+uYPba5CBVLiIiIiKFQeFK5AxZpsHb9Rb6m1dMtHvytxNDt8xRRwNWGt+FPEgkqQH3OcBgayZbP3lGUwRFREREShCFK5GzEFu1LBviHmBG+Vv9x/52YrjdepkMx0U5M4PZIY9RmTT/+cHWTIa6E0hN97E0aW8wyhYRERGRQqA1VyJno/NwYoEffA5Lj2vTnpKWTvxHL/N5yJNUNdP8a7D6WvP8Uwgn2j05/2izi+z72tStrLbtIiIiIsWU4TiO5iWd4HR2YRbJzZKNe+jz5k/UNZL5PORJyhvpOA4YBkzwdMdnmNiOyXtht+RodvF2vYXEVi3rbwEvIiIiIsFzOtlA0wJFCkF2s4vsNVjZwQrgLtdsLjdWMsydQN/06QH33XjwfWITJ7Bh1+EgVC0iIiIiZ0PhSqQQWKbBiG5xAHQzl2AY4HWy/udW3kinqZUEwDB3Am+5xxDBQf9arHGe3vTb2EnNLkRERESKGa25Eikk8Y1j+KblT8QmHltjNfho2/bffLWoZyQTZni43FrFKnMAhgH/9lyLafjoffB9ftrYDNM0Atdjff8K+GxNGRQREREpghSuRArLojHEJk7A1+kJ2te8h/oH0qlW4WISl8XQ6PeJTPLcQAqVec41leweFne45vC7rxbNXH/x2nsWr6Tf4H/cE+VmMcCeDp2fDNIbEhEREZH8KFyJFBafDZ2fxOz4KO2OO7yEhxi7JhnL8FHJOYBpgMexcBs2oYaXZtZf2I7BQONDwlypPO/tx2BrJgPsrCmDcZG3Ex+0NyUiIiIieVG3wFyoW6AUJtvncMnL33LjwfcZ6s45ZfBvXzXqmDuPXe8YWIbDWE9vJtk9iY4I44fHLlfLdhEREZFzQN0CRYowyzR4u95Cf/OKiXZPACbaPRnr6U0dcyfvezsz326Rdb3h4DjgYBBCJsmp6dp8WERERKQI0rRAkSCIrVqWDXEPMGNjJ0hN9x9/J+RmyATL8JHsi+QKayU+x8A0HB52z+Bu11cssFuQktos5+bDanYhIiIiElSaFpgLTQuUc8X2OSxN2usPST7Hoe9/fvZPEcyaMtiD11z/4lrXUv99f1GDfhmPstWpChzX7KLOpVD3Muj4aM4XWzRG4UtERETkNJ1ONtDIlUgQWaZBu3qR/u9tn3M0KB1biwUw0PsgfzkfMtj9GT4Hzje2sSDkISZ5exBhHOIuezbjPL3pVrY6sQtGZT3s+IC1aAwsGKVOgyIiIiKFSOFKpAixTIPLL4hk3K9ZzSuON9a+mUzcVDX208lcTS1zFw+5PwYg3XHTxvydxet91GvUC3PBKDbvOcTK8wfQIulNaq1+NStY5TaiJSIiIiIFQtMCc6FpgRJss9cmM/LzRJKPW49VuZybvYc8R79z2BB6O27Dh+OAkUfjQI9j4jZ8TLFuoVaPZ4lvHFP4xYuIiIiUIJoWKFLMxTeO4cq46ID1WClp6Tz04SoABluf4DZ8ZDguQg0v73i7kOjUpqnxF83Mv7jA2ILL8OE2fHgci9GHrod3VzD5tpYKWCIiIiKFRK3YRYqo7PVYNzSvQbt6kUSHhwEENLu4MONtxnp6c7trHlVIZbj3Xq7JHM1r3hv8z3EbNk+53gZg5OeJZHp9LNm4h89WbWPJxj3YPg1ei4iIiBQEjVyJFBNt6lbOtdlF9j+HuRP81w5xf8K/PD3oaP1Kc3Mjd7tmk+6E8ErqLVw8ej57D2X6r42JCOOd8+dTP7qiugyKiIiInAWNXIkUE/5mF56czS4mHd2AuJ35m39U61X7Ru7NHMZWpwoAA92zeNBKCAhWACmp6cz6dUdWN8FFYwJfNLvLoGkV6nsTERERKQkUrkSKkfo3v0hcnxeIjggLOB4dEYar82MsdRoGjGrtoiL3ZD7MQSfr+i7WL0DgNECHrNGvKdYtsGAUmz95ls9WbWPzJ88ea9+uLoMiIiIiJ6VugblQt0Ap6k7cfLhN3coAXPLyt6SkpnPi/6g7mSt5y/0KpgGjPX34t90t4PxgayZRxj4aurbTinX4HAPTcJhm9eKSC6I1ZVBERERKLXULFCnhTtx8ONuIbnHc/+4KDALHpxb6WrDQ15zLrVU85vqAv51o5vguoo6RzCjXf+lgJQY8xzSy7u7j/YxNv0XBum1ge+HyJ45dpI2JRURERAJo5CoXGrmS4izvPbIy+cT9DC2sjXgci9+dmjQx//Zfk+G42exUI9bchtcxcRm+HM8+WLkRKxsNp3bqcmr9Ol5TBkVERKTEO51soHCVC4UrKe5OnDbYqnYlOr6ygF2ph5gb8jB1zR3+a5N80Uzydqeukcwg92f+NVvZLd+X2hdynrmL6sbegNeYY15KvQubUD+6Evalj+SYpmh9/4qmDIqIiEixp3B1lhSupCSavTaZ+99dQXkOsyp0AJbhI9NxcUHG2wF7Z008rhNh9vFxnl787Ivj/ZAXsIxj/8nY46tApHmA/1g38cKh7v7jWS3jp5/ZyNaC0VndCbXGS0RERIqA08kG6hYoUkrEN45h8m0tGVxuHpbhI8NxEWJ4ebTMZ1iGL0ewgqwugmM9vTENhzbmOizDIdPJWqqZ7riJNA8AcI/9Ef9zj6Y8hxlszWSAPZ1xnt7Mjrwd2+ec3qbFppV/W/hNP+Y8F3DN6DP6+YiIiIicLTW0EClF4ve8A/Z0Njd7iJV176VF0pv8Y/WrTAm9hdGHrs/1nuOnCJ44ZXCh3ZQLza3EGHvpaK1hjXkPhgFjj+7FFTFzDc/OSiQl7dj6r5NuWgxQ59KsIAVZ15zYPOP4c9nUYENERESCTOFKpLQ4LnzU6vgotQCaPwuVyzJgwSgOWl4m2j1ztHHPbcpg9j+HuRMY7+nJNqowxjUFw8i652JzHZHGNPZkhDPxcOBoWEpqOjvWLqD+ukR8jsPPNe/xr9Vqu+U/mAtfhMsegfAaWfUuHA2OD+pdAdXioHJdsDPzDl9qsCEiIiJBojVXudCaKymRTrKW6c+U/dz+1xU5ugz2y/gA2zFzTBmErOBlGT5sx2SYOyGgy2D2n8d7ejLe7h1wzzB3Aj/TmLasZaynN1Ps63je9RY3ub7jcJnqlM3YBT5P/u8npBxkHgLTBT6vgpWIiIgUCjW0OEsKV1Ja5dVlMLeNibOdOLL1lOsd7nF9HXDNdG8nHvcO8F873duJRKc2vc3vaGol4Tj4R72yOaHhGBlp+AwL07HxVW2I6QqFfUmQnnpCFQbcMw82zFUzDBERESlQCldnSeFK5JjsLoPAKU0ZPP74ISeUckYGAD7H8G9OnBvHgc987Vnia0Rj93Zu58sca7w2xD1A7E3Pw+G9MP85+GVq4EOqNYKdv+UcxdK0QRERETlDp5MNtOZKRPKV3WXwxI2JYyLCaBMZwbhNWc0rjpcdtMoa6VTkEH1cCwKC1VanCut8tajAYS62fifTsQgxbDb6qlONfQHBKvt5BjA0cQIbPoLYqArwy1Q2N3uIddE30GHpPyi/LzErWJmurCBlZ8LlTylYiYiIyDmjkatcaORKJKcTpwy2qVsZyzSYvTY5R/CKDg8l3esj9bCHQUdHnbLXYE3y3MA/7Zvz7EC42G7IEl+jXNd4PWDN5LKQdbR2fmOKdQsvHtfhcFzZafT0fRNwvX9KYacnMDs9Vng/HBERESmxNC3wLClciZye3ILX3MQUEj94iqG5BKgf7Tg6WIl5TifMbc+tbA+6EnJtsGEcvf/qansJ3/cbNdgBZE03fNb9ILfHZlI/uhL2pY/kDInfv6L1WCIiIpIrhauzpHAlUgCOTsc7cYRpeLlZ/J89nR/tOPp6nspxW3YHwvHe3jnOnaqHrBkMcX8S0Chjly+cqmZajnqeKDeLAfb0gp82eJLujApzIiIixYPWXIlI8Pls6Pwkd1/6CE0CRoquYUNCNZb9uhWDnE0y8hqxOlWDrZkMcX/CWE9v/mtfw7/dY7nU+o2qZhoAA+zpRLq2Msx7P4OtTxhgJzDO05u4yNu5Mo+pj2fEtLTZsYiISCmjkatcaORKpPCdbK3WmfyHKa9phQ9bHzLI/RkZjotQwwsc61441pPVkCOirJswl0VKWmDTjhHd4ohvHJPnmrN8ndhMQ801REREih1NCzxLClci50Zea7Vya/2e2yjXifJajwVZwau8cQQDuNf6EsPIWo/1tPdO3rOvwMHMcU92dBpwWV1mrU7O0S3xlIJXdqAyTHB8ClYiIiLFjMLVWVK4Egmu3Ea1YiLCePrahjz/5bp8NzU+mezRreP33driq8Ic30W84L09x/Xvu58H4FbP0wHHsxtoXFQ7gkf3XJt78GoUjW/us5iLxwPgYOB7cieWO+QMqxcREZFz7XSyQc6/qj3HXnvtNerUqUNYWBht27Zl6dKl+V4/Y8YMGjRoQFhYGE2aNOGrr74KOD9z5kyuuuoqIiMjMQyDVatWFWL1IlIY4hvH8MNjl/PBvRfzr1ua88G9F/PDY5dzTdPqjOgWBxwbVTodx08brJfxDt/azQGoae7mHtfXTHW/jIEv4Pr21jraW+sYbM0MeNYgayZD3Qks3ZQaEKwAUlLTGfjucla+3v9YsHLAwGH9i+2YvWY7kDVyt2TjHj5btY0lG/dg+45FxvzOiYiISNEU1JGrDz/8kH79+vHGG2/Qtm1bxo8fz4wZM1i/fj3VqlXLcf3ixYu57LLLGD16NNdddx3vv/8+L7/8MitWrKBx48YAvPPOOyQlJVG9enXuvfdeVq5cSfPmzU+rLo1ciRRteY1sXd8shinfJQE5pxDmtR7rKdc73OP62v/9Vl8kT3vv4krzF251fcvrnm5kEMJD7o9ztJTPq2V8CB7GuV/nOutnAL6xW/GR3Ykp7rGYBnxrN+fndpPznGoI5Pr+sqchQt77jomIiEjBKjbTAtu2bctFF13EpEmTAPD5fNSsWZPBgwfz+OOP57j+5ptv5tChQ3zxxRf+YxdffDHNmzfnjTfeCLj277//pm7dugpXIiXU6WxqHBMRxpjIL1m2KZWJds8cwesB62OamRu5xFzrb3hxouxmGNnTCf/l6YFjGDnWeJUlnTfcr3KZtQaAWd6LecD7AAD/Z33OcPcHAHzsvYRh3n8EvEZ+68qyY9Pk21oCuYevd86fT/3oivm2f7c7Pq5QJiIichqKRSv2zMxMfvnlF4YPP7bPi2madOnShSVLluR6z5IlSxg6dGjAsa5du/Lpp5+eVS0ZGRlkZGT4v09LSzur54lI4bNMg3b1InMcj28cw5Vx0bkEiCs4tDaZ6Fw6FL7tvYXUwx6qs4vvQh/EMhwcBw5QhnDjCIA/dGWv07rDNYckXzTNXX8BWS3kIzjI1JAxtDT/BOA3u7Y/WAH8276O+sY2bnR9x3XWT7xu38BGp4b/fH5/0+WQFbD+Tniawx6H5BNGzFJS09mxdgH11yXicxx+rnmP//233fIfzIUvsiHuAfq9/G2eoexMN1guFqNo+e07Nu26rH/e8UXOc9qTTERETkPQwtXu3buxbZuoqKiA41FRUfz++++53pOSkpLr9SkpKWdVy+jRoxk5cuRZPUNEio7TDV7ZHQp7Wd9jGY5/lOpNz7W8bt9AOIcY5PqUu12zsR0Ty/ARYRymuZUVrIa5E2htrifa2MeF5lYA3vd25gnvvSdUYPCk927aWb9xnrGHt9yv0D3zOfZx7G/B8mqgAVnrvJrav9HevQ6HwD3BBlkz6WAl8jONabvwRRZ7/vBPYWznTuC7GvfSf8XFOORcHzbr1x0MXfca//1uY+4bLNe9LPcA9f0r/Jmyn9v/uiLfKYxFQn77jv39/bE/a08yERE5C9pEGBg+fHjAiFhaWho1a9YMYkUiUlhyC17xjWP4puVPxCYm5FhXdVGdSiz/ex93u2b7zz1gfcxQ98es89XkfCOFUMNDx6PTAAH+572SEd47c339TNzM8rbnH+7PqW3u5I2Q8dyW+QQeXP4GGgCDfTMDwtPx67yW+BoxzJ0AZAWsR6zpDHTPYqHdlL2Es8sIZ5g7gYdcH2MaDuM8vTA37WGQNTPHGjHn6NdiuyEDmM4By+t//wPsBH604+iQ9B3/HXVfrsFrlqc3yXbOwHb/uyuYfFvLPEYRs0a1TjbiddojYvmNTgHUuTQwYH07Cr4bA63uhMxDWec2LYZWd8Cu32HhaLXOFxGR0xK0cFWlShUsy2LHjh0Bx3fs2EF0dHSu90RHR5/W9acqNDSU0NDQs3qGiBRji8YQmzgBX6cnaF/zHuofSKdahYvxbbmAyxa+yGVumGLdwsT0rHAxwe5F+TA3A5jOJM8NJBPJ8663MA3IdKw8g1W2MXYfyhoZ3OH6hrbm77zkfpN0x01f17e86bkGD9Zx4akHj1gfMtA9i4+9l5BCZaLYxyr7fIa5ExjqSsA4mjc6Wb8GvE72FMbrrJ/4y4kh3rX86DNzhrb3vZ2xbN/RUJaAacB3dhPesq9mra8u/5dL8MqroUf2FMbHZ67h2VmJuW7MDPk37chr7Vy+I2JHR6fymhZJ67uy9hpbMOpYyAL4ZeqxP/+1IOsL8MX1wLS9OUe0smnKoIiInCDoDS3atGnDxIkTgayGFrVq1WLQoEF5NrQ4fPgwn3/+uf9Y+/btadq0qRpaiMiZO4X1OHa/z/OcFvftH3sYYE/3TyecYt3CnlZD8uxcmG2s63V6uX7ItzTHwR+e8vO3L4pEpzaJvtrUM7bTw/WjfwpjtgNOGSoYR5jouYHX7Rt4yfUmN7iWcMgJpZyRkc/T4YjjpozhweuYuAxfnsEqW14bOhtkTWG0DB/jvb1znAN4+/z5LNuUyoRc7h1szeT6plHUvXFUrqNaGz56mtjECYz19OZ1+wZGu97kJtd3eFzlcXsP5qjTsUIwylUj1Yrgt9RQ2torsYxj/8YyQiMJzdiDr+MT/Fwrl8DW+cnc16oVtTVnIiJyxopFQwuAoUOH0r9/f1q3bk2bNm0YP348hw4d4s47s/7Wt1+/ftSoUYPRo0cDMGTIEDp27MjYsWO59tprmT59OsuXL2fKlCn+Z+7du5fNmzezfXvWPjLr168Hska9znaES0RKqPxGHo42ObAg5zqujo9Sf9EY6q97jc3NHmJl3XtpkfQmA1a/CuXq0eK22/NtGf+w9x/cYC3GZfhwHNhPecqSQajh8V+fHaz2OeVJcSqx16zMVm8lahk7aGetw+NYuA2bj+1L/aNKPVw/+sPPw9aHDHJ/xkEnjApHm3MMdn/GINdn/meXMzJIc8qw3YmkgbnV/8zffTUx8XG+kUyZozVl17rKqZ/vj9R2zICpi9kGHR0p+9GOy3GPQ1Z4cm35jaF5rCsb6k7gtd9v5p2Xvs0xInZ9sximrLiYR62kHKN6bu9BMs0wtjpVON/ZSqZjEWLYvElP9jTICsKDrJm0d68g03ERYnhJd1yEZewBwFz0IineRTzk/QeDrU9o505gQ9wDbIy8nZG5NAnJHmE7m2YfxaJRiIiIBAjqyBXApEmTeOWVV0hJSaF58+ZMmDCBtm3bAtCpUyfq1KnDtGnT/NfPmDGDp556ir///pvY2FjGjBnDNddc4z8/bdo0fzg73ogRI3j22WdPqSaNXInIKTm+4UEejRDyGtWYvTaZzZ88m2PEq1aPZ8GxSf50BHfaCf4Q4D8HJH7wFEPdOdeH/WjH0cFKzDGqlH1+jt2aesZ26ptZf/nkODDN7spcXyvaGL/zoHtmrnt5TbGv4ynXu9zumhcwkrbOV5OFdnNetvvk+NEMtmbSzvyN9tY6Jnlu4FNfB641f+Yh98cnrXOspzcubIa4P2G+3ZxnPHfS0/o+373FsrUx1jExZCJRxn7/e/zI7sQ3vlY0Nf5iiPuTXN8jEPD87HM/2Q1obP5NeSMrPGW34h/n6Z1jZC1bdvwZcFndXPcyO5XujLOr3pHvtMj8gte5PiciUtIVm32uiiqFKxE5JflNJzzZepyjAez4Ea9aq1891pnuJOemWLcENJgYXm4W/2dP50c7jr6ep3K83OCjU/F8jsFQ98f+0JZbsDj+nhND21v21bztHk0r60//dbPt1tzneYjsWJF93yK7CXWNFGqZu/zXbvZV5XNfO6qzmx6uxf7XHGJ9zEPuj/nBboTL8NHC2OBvf58d6P7l6cGr9o25/jgNfNxvfc4w10f+aX3ZI3Cn8h6BPM+97umGaWTtU2YYWQHrgoz/4T2DyR/ZUxuHuhNy/DvMbhKyIe4BrlpxcY7ppCcLbSdby1YY5wor6J3NvbmeW/QSmNYZbzcgIqWbwtVZUrgSkUJ1shEvyPtcnUuzWqPn8kviXwnP8OWvW/mXt3fAL+bZv67+r94CLtv2Zo7RmU0VWvLx3vNz3WD5PfcLuY4yjXL9h76ub/3fb/JV5SXvrQywvqCFtfG0fhzZo0En2upUoTq7yf59e5OvGqucevzpqxFQSyXSGOeeTGdrtf/YBE93xtk3+d/jYrshS3yNch31yq/9fXYozZ7mmB301th16OYZxbGf7unJruttbxd+d2pTl2TudX/FWE9v3gm9mf2HPSd/yHFOtgH1mZ4bks/aucHWTC6qHcGje64t8MCWX0OTM3nu2/UWEps4Ic9Aq66QIpIfhauzpHAlIoWqEDe0zeuX0uxfLn2dnsh7g+GNnXLcNybyS5ZtSs0RvAxgiJXADZFbOC9tBW7sgDoycLPEjsOHweXWKv/Ux2/sVuxzKtDS3ECsuS3gnn1OeRb74ljia8wPvsZ0MxczzJ2AxzFxH9eYA+C/3nie9/ajlbGeiSETqW7s9Z/Lb7phflMK83L8/WucurzlfgXTgB/sRtzmyX0PrLwaemQ/r5axk9bmH9Q1j+3TuNKux/95hnKra36+9+bWDORkTlZPXs/M62eX38/0bMIcZI3MTfkuKdeRu7MJkNk1f+Vtw7u+LrQy/mCYO4Fxnt7E9XmhaO3LJiJFSrFpaCEiUiqdQgONXJ3C36zntVGytWgpdH4Ss+OjtDv+hnqPgWEQ67P5offluUy1uoJDa5OJPiGwRUeE0aDbi9RtHIO9JwlnYgsMHBzDxHfTe3yXcSFrZryY69qwsZ7ePJY5wL8/V3YHwqnerky0ezHgsrpc/+PYgHuHWh/xgPtTvI6By3C42zWbDuZa6hvbcR0NXqt95zPPbpnjl/3s760TAtqpyC1EPO29i1Hut7jE+o3XnPEM9D6Y477cGnoY+HjV9TrdXYv91x2/hq2FtZHvzAdZ66tDa9eGgHtPrOV05dVg5GTPzL72+HtPFlYd8g5zDnmPFGYHIGuxD4ec9ZzNcx+xptPC3MAhJ5RrXEu52lmKYWQF8Ul2T6I/T+TKuGitIxORs6ZwJSJSwuS2UXK+ge5oaMu1IyL5BLajv4haa2cADlghGHYm1s61XMlarjy6rih7f7CJdk8qhLkYxnTuqL6VyF0/5Qhe3ZrVILbcb3DCvePsmwgNC+P/7On87atGHXMnDcyt/honeroz1r4JyH0U41RGrHK7z8ql7fx7dhdqGju5z/UFV1tLaWuv42enYY7nLbYbMsydgIWPLU41nnC9R6R5AIAMx806X02aW3/5R/W2+iI5z9xDa2sDmU7WXmdhZPKKfcspjb7lNzp1fD3ZP4/jp0zmJXtUa7KnG8PcCTzomun/mViGj8G5bEwNcJHxOx1cif7XOv55J9soe7HdsMCeW9PYwb9ck2h53FTV7EDrOPCFrx0OkJyaztKkvbl+/kVETofClYiInFSugQ1yrh87fm1Y5ye5+9JHaBIQyq6Bd7YTmfRdrps2xy58EQ7nfe+GhGp8+etWEr21ecM9HtNwyHBcjLNvwiDvZg/Z7e+BXNej5XXfkWaPMOW7pBzBa4z3FjqbK7nQ3Mb/Ql7i2swX2ejUAI6FhI+8HfnVTudB90z/femOm//Y12A5Pu53f54jXCZ4L6W+uZ3mZlYYGOiexX2uz7EM56wCTfb6riN22NGQ9DGW4TDB0x0PrnxHtRJ9tahvZE3hzB7962D9xk5fBNe7f8r1vg5WIj/acbmGudc93QgzMhnmTqCukcw8XysuMddwq2tBQPOR033uOE8vQvEwzJ1ALWMHZYxMrjF/9q/ZW+urwyZfFNe6fvav8/vYPYKOmeM5QFl2Hjj2715E5ExpzVUutOZKROQUnEIr+lynMp5Nl0XIt419ft3r8muScCb3jbzmfC6dHU+ZIymk+spyReZYhrgSuN01n3SzLGG+wwF1ex2T5hlTuNOane86pte4iZWZNXnIlUAjc5P/fJIvimQnkvb5tLHP7uz4L08PfvQ1ZrBrJpdav5HuuAkzcjbJyHDc/ORriI3J5dYqf+v98a7XuNq1LMf1JzYfSXPKEG4cYbKnGy/bffx1vO/tzCqnPjebC2llbTjlzbDTnLL87UQRgpcG5hbm2K351teCeHMpna3V/GxfyDqnNq2N9TS2NvnrOeSEEorHP0X0eEm+KJ703u1fYzXW05vp9uXMDx1GuHGEv3zRdMn8J+/c3Q7TNIpFu/kzbY1fGPcVVkdIkaJEDS3OksKViMgpOMuQdMbya2N/knVpBf7L5aE9OJNaYRzZh0Ng70CPO5w/vVVo6PwVEAIbRpXLs0nIYGsm1zeN4s9Gg9n8yQgG2B9iO4a/vfzx5tst+NrXhu7mD1xi/cafvhjSCaWukUw5IyPH9QedMHY74dQxd+b5TAhcB5bhuPnTqU4jc5M/0A233uP/3F9yyAkNeJ28uj7mJs0pS6pTjhrGLkyDUw5fp/bsMlTgCIYBmY7FBRnv5DqtsrHxF5+EPIPb8LHcdyGDwkbn2Ji6KLabL+i/JDib+6BwOkKquYgUNQpXZ0nhSkSkiDrT0bLCtGcjTGx57PtGPaDJjZC8Gha9nGsInB15e/6/WJ4QIFv++Ro1174Gleri7NuEwak157Adg3+57qJtp2uptv1bYtdNyjEVcVfUJZg+LxG7luE62vXRcWCy6za61i9DvfVv5tnC/GvvRVQ399DM/CvgdXc4FVnvq0lZ0mltbfDvOfa653rG2jdiY/HA0f2+soPnvzw9+NLXjgGNHf5IXE1tYwd9rG8xDQfbMZhhd+IQYRwilObGn1xmrfU3Q3nH24VJ3u7sowL3WZ8HPHecpzfm0Xb6k04ItNebi5kQMgmAIZn/4DPfJf5zZ9Nu/p3z5+MYVq4dON+ut5DYQ7+woVyrXM9/UeElAK478HiOc9NDXmDb/iM5mnacrNbsabG5dWAc4kqgZe1IHtt9dY77Xq7yNSs27cnRSbIgWvj3++uKPPdym3xby3zXeRalTbTP6X5txexcYT73XFO3QBERKZl8du4BKvt7n53znsK29uOsf5ou8HmhWhzs+A0WvQydn6RWx0epBdD8WahcFhaMIr4zXPlYLhvamkZAUDx274tQtSIsGIXR/gF8ZatizHsmq0MjJs6lwzAjakB4dXx/zMFc/l9s043l8/DgpVGYvl9g3aRc17lVXfgidH4Sn6cD/DAWn+HCxMt9l9bCdHxQPY+1c9/XIzZlP9/+sYdm9l/+oPM/qydRPV6kXuLrxCZOyBHmrmxWB4DYxJydJK+Jq0nsTc/7p36atuMPSWmhUdTq8ezR536a496Lm8bl+dwNcQ+wMe4fObpeLi3fmWXp87jI/J1/ut/gr8zqrHHOB2DQ0fD345Y4kj1XBPwrT0lNJ/zDHgAknxB0UlLT2bF2AR2sRHp7tjORYwHjxoPvE5uYwN8VWhG7aUKu5yMzlgLQ2/N+wLneB9+ntnsFta2czUDyqzU5NZ2OS+6iozv3TooXGb/TYVsivT37crzeZRkJWEZcjo/8yboz5rX+L7vOJVsbMshKzbXr4wfu57ESTDqEPJ9jJDG/4FmUzp1NgC4J5wrr/b9dbyGxVcsW+Q2/Fa5ERKT4OIWuh+fUSRp65BcC82wScgoB0rTTOb5Do+EKgdZ3wqIxmMv/C52fxDpaj3lcPXm14ifpO8y/v/df47/vaB25dpLs+Cj1F42h/rrXAkbn+q9+FX7ZDfk1LYG8zy2qQDyAPT3guQNWvwq/bD/j58ZGVcgRaH2Ow03/eYp5IY9Qz0zm/ZBRXJ7xT26xFgSsYcstzOTV9XBQLo033rSv5X5rFkPcnzDe05OJu3vyD/PTHI05srcfgLzb3+d1Lq9aT9ahMb8mIYXxzJM1LWl39Lk3Hnr/lINnUTt3pgG6pJwrrPcfm5j1FyWxFG0KVyIiImcit6mI2f9cMArqXpb7fScLgScLkHkFur+/h6TvTr8eyLo3r/vyqjnXEbZn/aNz1L0Ms9NjOcPc398D5H7uaNDLrqdAn5tLoP1s1TYcTG7IfJ5FIQ8RaR5gaehADAN+89VmnVMbxzYY5k7gAmMr032dudpcym2u+bzmuZ4M3AEhYZj1EYPdnzLHbsU2pyrn+XYxzJ3gvwbgQfdMHuRYB8lh7gSGuhIwjKx1cTdai8gghJ2+CIa5E3jI9TGm4ZDki6ap+RdeLH73nRfQ9fFXuy4bnRqUsbO6MF5m/soSJ45mxkY6Wmv40tuGzKNdIasZ+/jEvpT+1hxucC1hid2ALU41Nvr2HX29BEwD1tq1WeXUJ90OYZg7gerGHv5jX0N/6xv6ueYy3dsJC5th7gTqG9v41teC663FXGGtYrkdyzanKht81QOeudEXQz1zOwedMiy1L2SYO4EW5p/M87Wio7martZyvvC2xSZrX7Y6Rgqf+C7lBvNHbnR9x0fejjhHf2bVjT18ZHeit7WIvq5vecfbxX8u0kjjHftKbrPmcqfrG6Z6r/L/rCsbabx73Lm3vF2BrH/HFY2DvG1fxe3WXO5xfc1/vFf774swDvGOfSX9rG+42zWbt7xdMXD8z3zP7kJfa57/9d7bcyV9zch8XjPruZWMg7xtX8nt1lzuds3mP96r/e8jnMNMs7tyhzWHe91f8ab3Gv994cZh/md3pb81h3tdRe/c27u70s+KOuvn/sd7DTdZCxl6dMPvGRs78YPPKdKNT7TmKhdacyUiIicVjIYeJ1tzVvcy6P/56dVzpu+jsN7/Ofy5Ltm4hz5vZrWTr22ksDBk6Gk31kh3XIQZ3gJtyiEiWbL/d3V8M5oP7r34nO9Jp4YWZ0nhSkREiqRgdWgsoWyfwyUvf0tKajqDjk5by26+8Z3dmESnLhU5QCXjIFeav2AaDo4DhwnNtSMjHGvm8YdzHjWNXXS1lpPpuAgxvEz03MCb9nUYOJj4GGB9yf3uz8l0LEIMm3e8XfjYvoxQPNxkLaCX6wd/PV97L2Kh0xw3Xi43V3K5tcq/zu1HO47lTgNMfLiwGWB9iWX4sB2Deb5WlOcI5YwjlCedesb2rIE8B77xXcQuJ4KdTkWamElcZf3if73v7cZsdKoTZewjythHC+NP/+bL26hCpuMiAzeZuGliJPkbj3xodyKN8qQ65Whl/kEXa4X/mXPsViz1NaSCcSSrJo5wk7UQy3DwOQY/+BrjwsZteHFj09TYiHm01g3OeZg4GEe/zjeS/fVsJxLz6M/UxKEKqf5z+ygf8O+nEgf959IoC2Q30nD8XSYdBw5SJuC+8sedO0BZHPBXU/G4Z+6lAsYJrTqOf81Uyh19zaxrwjnsP3eIsKNPzDofRqb/XDohR6vMqrYMGf5zRwgNeL2idK4gnpvhuLgw423/8X/d0pwbmtfI8TqF6XSygXmOahIREZGz1Xl43tMKOz6qYHWaLNNgRLe4gPVAsRnvMNbTm8ustRxyQnncO4C1vjr+DasNA97wdiM2/W1apU/mLW88AB7HAuBdbxf6eYaT6pSjq7WcsZ7eXJDxNmM9vRns/oz+1hwOGOW53Zrn30j6gqOvebtrHpeav9LGXEcv1w8B9VztWkY19lGJA/49yepnvMtYT286WIl4HZOx3ps47IRiGT4yHBeW4bDWV4e+nifpnvkCs+z2/l9WzaNTH5/23gXAVdYvAa93qbWWPU4493seYqHd3H+fYcBH3k5cnjmOqzNfZr7d0v+zsQyHFCeSl7x9cOGli7Ui4JldrV8oRzpH2j/MKO9tJDuRWEfvNQ2HZb4LudXzFDdmPst8uwXmcbV+YV/MlZmv0CXzn3xqdwioZ7q3M+0yJtE243Xe9l4ZcG6qN56WGVNomTGFqd74gHP/8V5Ds4z/0DTjP7zpvTbg3BTvtTTJ+C9NMv7LlBPOvXn0vuYZb/LWCc+c5u3qf73cXvO/3qtpnvEmzTL+w3+81wSc+7f3OhplTCUuYyqve68POPe693oaZkwjLmMqk73dAs5N9nYj7uh9RelcQT031PAy2Do2lbZahbBz/x+L06A1VyIiIlJqxe95h3h3AlOsW5iYntVufqLdkwphLoYxnYvNRDoct3FzdhDLdpdrds7OhUfvGXfcVKaJdk8MstaS9KqQRJ0Dv+R5Hsj33OnWagCt61Tism05Oyn2qpx/LdnnT7yvW7PqQO7dGftX30rkrp9yrXMo06HchfRueSDXe8NCLDIybX9zj9x+5sOKwbnXfD0ZZM4s9u+jKL1/A5hR/lba1K1MUaZpgbnQtEAREZFS4uhUS/vSXFrjv3M9JH2X5z5fQJ7n9lS9mOvSHi3wNtWR5UOx+31+RrX6Oj3BzzXv8d/Xdst/MBe+mGetX4SPIXLXT3nel98zqXsZ9u2zctb5/Sv+piX5PXecpzcTjuskmL0vWnE593eFVv7QWhTqKSnvf0PcA8Te9DznmtZcnSWFKxEREck3eL3dDSD3oPP9K+CzsTs+XigbrJ5prdzxRc77jq7Vy7XWRS/lvcZv2nUnfWae01TzWzs47Tr2HMwoEvs1FbV9norLuZK4z5XC1VlSuBIREREJnjMNnkXpXFGrp6S8/2BQuDpLClciIiIiIgLqFigiIiIiInLOKVyJiIiIiIgUAIUrERERERGRAqBwJSIiIiIiUgAUrkRERERERAqAwpWIiIiIiEgBULgSEREREREpAApXIiIiIiIiBUDhSkREREREpAAoXImIiIiIiBQAV7ALKIocxwEgLS0tyJWIiIiIiEgwZWeC7IyQH4WrXBw4cACAmjVrBrkSEREREREpCg4cOEBERES+1xjOqUSwUsbn87F9+3YqVKiAYRhBrSUtLY2aNWuyZcsWwsPDg1qLFC/67MiZ0OdGzoQ+N3Km9NmRM3GuPzeO43DgwAGqV6+Oaea/qkojV7kwTZPzzjsv2GUECA8P13905IzosyNnQp8bORP63MiZ0mdHzsS5/NycbMQqmxpaiIiIiIiIFACFKxERERERkQKgcFXEhYaGMmLECEJDQ4NdihQz+uzImdDnRs6EPjdypvTZkTNRlD83amghIiIiIiJSADRyJSIiIiIiUgAUrkRERERERAqAwpWIiIiIiEgBULgSEREREREpAApXRdxrr71GnTp1CAsLo23btixdujTYJUkRMnr0aC666CIqVKhAtWrV6N69O+vXrw+4Jj09nYEDBxIZGUn58uXp1asXO3bsCFLFUhS99NJLGIbBgw8+6D+mz43kZtu2bdx2221ERkZSpkwZmjRpwvLly/3nHcfhmWeeISYmhjJlytClSxc2bNgQxIqlKLBtm6effpq6detSpkwZ6tWrx/PPP8/xPdX02ZHvvvuObt26Ub16dQzD4NNPPw04fyqfkb1799K3b1/Cw8OpWLEid999NwcPHjyH70Lhqkj78MMPGTp0KCNGjGDFihU0a9aMrl27snPnzmCXJkXEokWLGDhwID/99BNz587F4/Fw1VVXcejQIf81Dz30EJ9//jkzZsxg0aJFbN++nZ49ewaxailKli1bxr///W+aNm0acFyfGznRvn376NChA263m6+//prExETGjh1LpUqV/NeMGTOGCRMm8MYbb/Dzzz9Trlw5unbtSnp6ehArl2B7+eWXmTx5MpMmTWLdunW8/PLLjBkzhokTJ/qv0WdHDh06RLNmzXjttddyPX8qn5G+ffvy22+/MXfuXL744gu+++47BgwYcK7eQhZHiqw2bdo4AwcO9H9v27ZTvXp1Z/To0UGsSoqynTt3OoCzaNEix3EcZ//+/Y7b7XZmzJjhv2bdunUO4CxZsiRYZUoRceDAASc2NtaZO3eu07FjR2fIkCGO4+hzI7l77LHHnEsuuSTP8z6fz4mOjnZeeeUV/7H9+/c7oaGhzgcffHAuSpQi6tprr3XuuuuugGM9e/Z0+vbt6ziOPjuSE+B88skn/u9P5TOSmJjoAM6yZcv813z99deOYRjOtm3bzlntGrkqojIzM/nll1/o0qWL/5hpmnTp0oUlS5YEsTIpylJTUwGoXLkyAL/88gsejyfgc9SgQQNq1aqlz5EwcOBArr322oDPB+hzI7mbNWsWrVu35sYbb6RatWq0aNGCN998038+KSmJlJSUgM9NREQEbdu21eemlGvfvj3z58/njz/+AGD16tX88MMPXH311YA+O3Jyp/IZWbJkCRUrVqR169b+a7p06YJpmvz888/nrFbXOXslOS27d+/Gtm2ioqICjkdFRfH7778HqSopynw+Hw8++CAdOnSgcePGAKSkpBASEkLFihUDro2KiiIlJSUIVUpRMX36dFasWMGyZctynNPnRnLz119/MXnyZIYOHcoTTzzBsmXLeOCBBwgJCaF///7+z0Zu/7+lz03p9vjjj5OWlkaDBg2wLAvbthk1ahR9+/YF0GdHTupUPiMpKSlUq1Yt4LzL5aJy5crn9HOkcCVSQgwcOJC1a9fyww8/BLsUKeK2bNnCkCFDmDt3LmFhYcEuR4oJn89H69atefHFFwFo0aIFa9eu5Y033qB///5Brk6Kso8++oj33nuP999/n0aNGrFq1SoefPBBqlevrs+OlDiaFlhEValSBcuycnTn2rFjB9HR0UGqSoqqQYMG8cUXX7BgwQLOO+88//Ho6GgyMzPZv39/wPX6HJVuv/zyCzt37qRly5a4XC5cLheLFi1iwoQJuFwuoqKi9LmRHGJiYoiLiws41rBhQzZv3gzg/2zo/7fkRI888giPP/44t9xyC02aNOH222/noYceYvTo0YA+O3Jyp/IZiY6OztH0zev1snfv3nP6OVK4KqJCQkJo1aoV8+fP9x/z+XzMnz+fdu3aBbEyKUocx2HQoEF88sknfPvtt9StWzfgfKtWrXC73QGfo/Xr17N582Z9jkqxK664gjVr1rBq1Sr/V+vWrenbt6//z/rcyIk6dOiQY6uHP/74g9q1awNQt25doqOjAz43aWlp/Pzzz/rclHKHDx/GNAN/5bQsC5/PB+izIyd3Kp+Rdu3asX//fn755Rf/Nd9++y0+n4+2bdueu2LPWesMOW3Tp093QkNDnWnTpjmJiYnOgAEDnIoVKzopKSnBLk2KiPvvv9+JiIhwFi5c6CQnJ/u/Dh8+7L/mvvvuc2rVquV8++23zvLly5127do57dq1C2LVUhQd3y3QcfS5kZyWLl3quFwuZ9SoUc6GDRuc9957zylbtqzz7rvv+q956aWXnIoVKzqfffaZ8+uvvzo33HCDU7duXefIkSNBrFyCrX///k6NGjWcL774wklKSnJmzpzpVKlSxXn00Uf91+izIwcOHHBWrlzprFy50gGccePGOStXrnQ2bdrkOM6pfUbi4+OdFi1aOD///LPzww8/OLGxsU6fPn3O6ftQuCriJk6c6NSqVcsJCQlx2rRp4/z000/BLkmKECDXr6lTp/qvOXLkiPOPf/zDqVSpklO2bFmnR48eTnJycvCKliLpxHClz43k5vPPP3caN27shIaGOg0aNHCmTJkScN7n8zlPP/20ExUV5YSGhjpXXHGFs379+iBVK0VFWlqaM2TIEKdWrVpOWFiYc/755ztPPvmkk5GR4b9Gnx1ZsGBBrr/T9O/f33GcU/uM7Nmzx+nTp49Tvnx5Jzw83LnzzjudAwcOnNP3YTjOcdtji4iIiIiIyBnRmisREREREZECoHAlIiIiIiJSABSuRERERERECoDClYiIiIiISAFQuBIRERERESkAClciIiIiIiIFQOFKRERERESkAChciYiIFDDDMPj000+DXYaIiJxjClciIlKi3HHHHRiGkeMrPj4+2KWJiEgJ5wp2ASIiIgUtPj6eqVOnBhwLDQ0NUjUiIlJaaORKRERKnNDQUKKjowO+KlWqBGRN2Zs8eTJXX301ZcqU4fzzzychISHg/jVr1nD55ZdTpkwZIiMjGTBgAAcPHgy45q233qJRo0aEhoYSExPDoEGDAs7v3r2bHj16ULZsWWJjY5k1a1bhvmkREQk6hSsRESl1nn76aXr16sXq1avp27cvt9xyC+vWrQPg0KFDdO3alUqVKrFs2TJmzJjBvHnzAsLT5MmTGThwIAMGDGDNmjXMmjWL+vXrB7zGyJEjuemmm/j111+55ppr6Nu3L3v37j2n71NERM4tw3EcJ9hFiIiIFJQ77riDd999l7CwsIDjTzzxBE888QSGYXDfffcxefJk/7mLL76Yli1b8vrrr/Pmm2/y2GOPsWXLFsqVKwfAV199Rbdu3di+fTtRUVHUqFGDO++8kxdeeCHXGgzD4KmnnuL5558HsgJb+fLl+frrr7X2S0SkBNOaKxERKXE6d+4cEJ4AKleu7P9zu3btAs61a9eOVatWAbBu3TqaNWvmD1YAHTp0wOfzsX79egzDYPv27VxxxRX51tC0aVP/n8uVK0d4eDg7d+4807ckIiLFgMKViIiUOOXKlcsxTa+glClT5pSuc7vdAd8bhoHP5yuMkkREpIjQmisRESl1fvrppxzfN2zYEICGDRuyevVqDh065D//448/YpomF154IRUqVKBOnTrMnz//nNYsIiJF3/+3c/eoqQUBGIY/wcpaFFcgWGuXDaQTtBM5rQiHNPa6ArMCS0nAwlYXYOMKXEIgpY12KS5cSH9ubkiep5ximClf5sfJFQA/zv1+z9vb26exer2eZrOZJNntdun3+3l4eMh2u835fM5ms0mSTCaTLJfLFEWR1WqV9/f3lGWZ6XSadrudJFmtVpnNZmm1Wnl8fMz1es3pdEpZll+7UQC+FXEFwI9zOBzS6XQ+jXW73VwulyR/fvJ7fX3NfD5Pp9PJy8tLer1ekqTRaOR4PObp6SmDwSCNRiOj0Sjr9frvXEVR5Ha75fn5OYvFIs1mM+Px+Os2CMC35LdAAH6VWq2W/X6f4XD4v5cCwA/jzRUAAEAFxBUAAEAFvLkC4FdxGx6Af8XJFQAAQAXEFQAAQAXEFQAAQAXEFQAAQAXEFQAAQAXEFQAAQAXEFQAAQAXEFQAAQAXEFQAAQAU+AODDxyrch53BAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete! Total time: 649.13 seconds\n"
          ]
        }
      ],
      "source": [
        "# Train the GatedCombination model using training and validation data\n",
        "trained_model = train_gated_combination_model(\n",
        "    X1_train,          # Updated source embeddings (after applying the GNN model)\n",
        "    X2_train,          # Original source embeddings (before applying the GNN model)\n",
        "    X3_train,          # Updated target embeddings (after applying the GNN model)\n",
        "    X4_train,          # Original target embeddings (before applying the GNN model)\n",
        "    tensor_score_train, # Ground truth labels for the training set (1 for matched pairs, 0 for unmatched pairs)\n",
        "\n",
        "    X1_val,            # Updated source embeddings for the validation set\n",
        "    X2_val,            # Original source embeddings for the validation set\n",
        "    X3_val,            # Updated target embeddings for the validation set\n",
        "    X4_val,            # Original target embeddings for the validation set\n",
        "    tensor_score_val,  # Ground truth labels for the validation set (1 for matched pairs, 0 for unmatched pairs)\n",
        "\n",
        "    epochs=100,        # Number of epochs (iterations over the entire training dataset)\n",
        "    batch_size=32,     # Number of training samples processed in one forward/backward pass\n",
        "    learning_rate=0.001, # Learning rate for the optimizer (controls step size during optimization)\n",
        "    weight_decay=1e-4 # Weight decay (L2 regularization) to prevent overfitting\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAmLuMtGW9c2"
      },
      "source": [
        "# **Second Round Modifications**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVDqN5AxFu9m"
      },
      "source": [
        "# **Generate Embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "ITZZcElm8qRN"
      },
      "outputs": [],
      "source": [
        "# Build an indexed dictionary for the source ontology classes\n",
        "# src_class is the file path to the JSON file containing the source ontology classes\n",
        "indexed_dict_src = build_indexed_dict(src_class)\n",
        "\n",
        "# Build an indexed dictionary for the target ontology classes\n",
        "# tgt_class is the file path to the JSON file containing the target ontology classes\n",
        "indexed_dict_tgt = build_indexed_dict(tgt_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbSbmPlRDOs3",
        "outputId": "5163a12c-8d8f-4abe-86ee-62d1d59af074"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ GIT-only embeddings saved:\n",
            "- Source: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_O_GN.tsv\n",
            "- Target: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_O_GN.tsv\n",
            "⏱️ Execution time: 41.74 seconds\n"
          ]
        }
      ],
      "source": [
        "# Define output file paths for final embeddings of source and target ontologies\n",
        "output_file_src = f\"{data_dir}/{src_ent}_final_embeddings_O_GN.tsv\"\n",
        "output_file_tgt = f\"{data_dir}/{tgt_ent}_final_embeddings_O_GN.tsv\"\n",
        "\n",
        "# Save the final gated embeddings for all concepts in source and target ontologies\n",
        "save_git_only_embeddings(\n",
        "    embeddings_src=embeddings_src,      # GNN-transformed embeddings for source entities\n",
        "                     # Initial semantic embeddings for source entities\n",
        "    embeddings_tgt=embeddings_tgt,      # GNN-transformed embeddings for target entities\n",
        "                          # Initial semantic embeddings for target entities\n",
        "    indexed_dict_src=indexed_dict_src,  # Index-to-URI mapping for source ontology\n",
        "    indexed_dict_tgt=indexed_dict_tgt,  # Index-to-URI mapping for target ontology\n",
        "    output_file_src=output_file_src,    # Destination file path for source embeddings\n",
        "    output_file_tgt=output_file_tgt     # Destination file path for target embeddings\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIDvbZj2GIGo"
      },
      "source": [
        "# **Filter No Used Concepts**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Gl_wUG9KADo",
        "outputId": "25a013c1-8c29-49c6-9056-1667e8fd108a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Initial source file: 23107 rows\n",
            "🔍 Initial target file: 20498 rows\n",
            "✅ Source after removing ignored classes: 11407 rows\n",
            "✅ Target after removing ignored classes: 14207 rows\n",
            "📁 Cleaned source file saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_O_GN_cleaned.tsv\n",
            "📁 Cleaned target file saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_O_GN_cleaned.tsv\n"
          ]
        }
      ],
      "source": [
        "# Call the function to filter out ignored concepts (e.g., owl:Thing, deprecated, etc.)\n",
        "# from the source and target ontology embeddings.\n",
        "\n",
        "# Input:\n",
        "# - src_emb_path: Path to the TSV file containing embeddings for the source ontology\n",
        "# - tgt_emb_path: Path to the TSV file containing embeddings for the target ontology\n",
        "# - src_onto / tgt_onto: DeepOnto ontology objects used to identify ignored concepts\n",
        "\n",
        "# Output:\n",
        "# - src_file: Path to the cleaned source embeddings (with ignored concepts removed)\n",
        "# - tgt_file: Path to the cleaned target embeddings (with ignored concepts removed)\n",
        "\n",
        "src_file, tgt_file = filter_ignored_class(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_O_GN.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_O_GN.tsv\",\n",
        "    src_onto=src_onto,\n",
        "    tgt_onto=tgt_onto\n",
        "\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpUklR4xnVMH"
      },
      "source": [
        "# **Mappings Generation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP5o60scKn2e"
      },
      "source": [
        "# **Using faiss l2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOSRYREwerBi",
        "outputId": "f1ee35d0-e571-408c-c818-9a768e133170"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-10 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_O_GN.tsv\n",
            "⏱️ Execution time: 5.93 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using l2 distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the l2 distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_l2(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_O_GN_cleaned.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_O_GN_cleaned.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2_O_GN.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD-mvVjaerBh"
      },
      "source": [
        "# **Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Global Metrics: Precision, Recall and F1 score**"
      ],
      "metadata": {
        "id": "r8GRfT_pR1kD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WZKJM46erBi",
        "outputId": "c92e79f1-7d32-42ba-db6c-03cc0644a599"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 95915 rows\n",
            "✅ After keeping only test SrcEntities: 22587 rows\n",
            "✅ After applying threshold ≥ 0.0: 22587 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_O_GN_filtered.tsv\n",
            "🏆 Selected candidates within 99.2% of best score per SrcEntity: 2915 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_O_GN_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1437\n",
            "📊 Evaluation (P / R / F1): {'P': 0.493, 'R': 0.54, 'F1': 0.515}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = evaluate_predictions(\n",
        "    pred_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2_O_GN.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "KBAlDrOpe_vz"
      ],
      "gpuType": "V28",
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}