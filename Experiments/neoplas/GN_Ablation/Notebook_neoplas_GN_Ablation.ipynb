{"cells":[{"cell_type":"markdown","metadata":{"id":"MkAX88H3RNRW"},"source":["# **Package Installation**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SlL2v0xgmFJ-","outputId":"d7966c8d-3dda-4038-f963-db936ead2370","executionInfo":{"status":"ok","timestamp":1732451930430,"user_tz":-60,"elapsed":204641,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==2.0.0\n","  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.16.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n","  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n","  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n","  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n","  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n","  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n","  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.0.0 (from torch==2.0.0)\n","  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (75.1.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.45.0)\n","Collecting cmake (from triton==2.0.0->torch==2.0.0)\n","  Downloading cmake-3.31.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n","Collecting lit (from triton==2.0.0->torch==2.0.0)\n","  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n","Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m600.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cmake-3.31.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.8/27.8 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, cmake, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.1+cpu\n","    Uninstalling torch-2.5.1+cpu:\n","      Successfully uninstalled torch-2.5.1+cpu\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.5.1+cpu requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\n","torchvision 0.20.1+cpu requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed cmake-3.31.1 lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 triton-2.0.0\n","Collecting torch-geometric==2.4.0\n","  Downloading torch_geometric-2.4.0-py3-none-any.whl.metadata (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (4.66.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (3.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (2.32.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (3.2.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.5.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric==2.4.0) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (2024.8.30)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.4.0) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.4.0) (3.5.0)\n","Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-geometric\n","Successfully installed torch-geometric-2.4.0\n","Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_scatter-2.1.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (494 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_sparse-0.6.18%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-cluster\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_cluster-1.6.3%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (751 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.3/751.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-spline-conv\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (208 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n","Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n","Installing collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster\n","Successfully installed torch-cluster-1.6.3+pt20cpu torch-scatter-2.1.2+pt20cpu torch-sparse-0.6.18+pt20cpu torch-spline-conv-1.2.2+pt20cpu\n","Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.5.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m727.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.9/208.9 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.4/319.4 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting deeponto\n","  Downloading deeponto-0.9.2-py3-none-any.whl.metadata (15 kB)\n","Collecting JPype1 (from deeponto)\n","  Downloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting yacs (from deeponto)\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deeponto) (2.0.0)\n","Collecting anytree (from deeponto)\n","  Downloading anytree-2.12.1-py3-none-any.whl.metadata (8.1 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from deeponto) (8.1.7)\n","Collecting dill (from deeponto)\n","  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from deeponto) (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deeponto) (1.26.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deeponto) (1.5.2)\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (from deeponto) (4.46.2)\n","Collecting datasets (from deeponto)\n","  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.7.5)\n","Collecting pprintpp (from deeponto)\n","  Downloading pprintpp-0.4.0-py2.py3-none-any.whl.metadata (7.9 kB)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.4.2)\n","Collecting lxml (from deeponto)\n","  Downloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n","Collecting textdistance (from deeponto)\n","  Downloading textdistance-4.6.3-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from deeponto) (7.7.1)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from deeponto) (5.5.6)\n","Collecting enlighten (from deeponto)\n","  Downloading enlighten-1.12.4-py2.py3-none-any.whl.metadata (18 kB)\n","Collecting rdflib (from deeponto)\n","  Downloading rdflib-7.1.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.9.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anytree->deeponto) (1.16.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (18.0.0)\n","Collecting dill (from deeponto)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (4.66.6)\n","Collecting xxhash (from datasets->deeponto)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets->deeponto)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->deeponto)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (3.11.7)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (0.26.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (6.0.2)\n","Collecting blessed>=1.17.7 (from enlighten->deeponto)\n","  Downloading blessed-1.20.0-py2.py3-none-any.whl.metadata (13 kB)\n","Collecting prefixed>=0.3.2 (from enlighten->deeponto)\n","  Downloading prefixed-0.9.0-py2.py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (0.2.0)\n","Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (7.34.0)\n","Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (5.7.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (6.1.12)\n","Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (6.3.3)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->deeponto) (3.6.10)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->deeponto) (3.0.13)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->deeponto) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->deeponto) (2024.11.6)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2024.2)\n","Collecting isodate<1.0.0,>=0.7.2 (from rdflib->deeponto)\n","  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib->deeponto) (3.2.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deeponto) (1.13.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deeponto) (3.5.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (0.13.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.9.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.1.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (75.1.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.4.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (1.13.1)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (2.0.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->deeponto) (0.45.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deeponto) (3.31.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deeponto) (18.1.8)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (0.20.3)\n","Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (1.1.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->transformers[torch]->deeponto) (5.9.5)\n","Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.7->enlighten->deeponto) (0.2.13)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.3.1)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (5.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (0.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.18.0)\n","Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->deeponto)\n","  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (5.1.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (3.0.48)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (2.18.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (4.9.0)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.2.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (2024.8.30)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->deeponto) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->deeponto) (0.1.5)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (0.20.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (7.0.5)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.5.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy->deeponto) (3.0.2)\n","Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->deeponto) (5.7.2)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->deeponto) (24.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deeponto) (1.3.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->deeponto) (0.8.4)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel->deeponto) (4.3.6)\n","Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.2.1)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (23.1.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (5.10.4)\n","Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (7.16.4)\n","Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.6.0)\n","Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.3)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.18.1)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.21.0)\n","Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.1.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel->deeponto) (0.7.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (3.0.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->deeponto) (1.14.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (0.1.2)\n","Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.2.4)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.12.3)\n","Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.2.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.7.1)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.3.0)\n","Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.0.2)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.10.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.5.1)\n","Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.4.0)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.20.0)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.23.0)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (21.2.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.5.1)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.21.0)\n","Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.24.0)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.17.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.6)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.22)\n","Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.7.1)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.2.2)\n","Downloading deeponto-0.9.2-py3-none-any.whl (89.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading anytree-2.12.1-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading enlighten-1.12.4-py2.py3-none-any.whl (41 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.8/493.8 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n","Downloading rdflib-7.1.1-py3-none-any.whl (562 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m562.4/562.4 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading textdistance-4.6.3-py3-none-any.whl (31 kB)\n","Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n","Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading prefixed-0.9.0-py2.py3-none-any.whl (13 kB)\n","Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: prefixed, pprintpp, yacs, xxhash, textdistance, lxml, JPype1, jedi, isodate, fsspec, dill, blessed, anytree, rdflib, multiprocess, enlighten, datasets, deeponto\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","Successfully installed JPype1-1.5.1 anytree-2.12.1 blessed-1.20.0 datasets-3.1.0 deeponto-0.9.2 dill-0.3.8 enlighten-1.12.4 fsspec-2024.9.0 isodate-0.7.2 jedi-0.19.2 lxml-5.3.0 multiprocess-0.70.16 pprintpp-0.4.0 prefixed-0.9.0 rdflib-7.1.1 textdistance-4.6.3 xxhash-3.5.0 yacs-0.1.8\n","/bin/bash: line 1: username: No such file or directory\n"]}],"source":["# We assume that PyTorch is already installed in the environment.\n","# If not, this command installs it.\n","!pip install torch==2.0.0\n","\n","# Install PyTorch Geometric, a library for creating graph neural networks using PyTorch.\n","!pip install torch-geometric==2.4.0\n","\n","# Import PyTorch to access its functionalities.\n","import torch\n","\n","# Install additional PyTorch Geometric dependencies for graph processing (scatter, sparse, cluster, spline-conv).\n","# These packages enable operations like sparse tensors and convolutions on graphs.\n","!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","\n","# Reinstall PyTorch Geometric to ensure all dependencies are correctly loaded.\n","!pip install torch-geometric\n","\n","# Retrieve the installed version of PyTorch to ensure compatibility with other packages.\n","torchversion = torch.__version__\n","\n","# Install the latest version of PyTorch Geometric directly from the GitHub repository.\n","# This allows access to the most recent updates and features for graph-based neural networks.\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","\n","# Install DeepOnto, a package specifically designed for ontology matching, particularly useful in biomedical applications.\n","!pip install deeponto\n","\n","# Install a custom version of DeepOnto from a GitHub repository.\n","# The '<username>' part should be replaced with the actual GitHub username of the repository maintainer.\n","!pip install git+https://github.com/<username>/deeponto.git\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"HPAlAgjLMVhw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732452027773,"user_tz":-60,"elapsed":97357,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"5b29480a-c206-4316-ad28-5d889a27cf58"},"outputs":[{"output_type":"stream","name":"stdout","text":["Please enter the maximum memory located to JVM [8g]: 8g\n","\n"]}],"source":["# Import pandas for data manipulation and analysis, such as loading, processing, and saving tabular data.\n","import pandas as pd\n","\n","# Import pickle for saving and loading serialized objects (e.g., trained models or preprocessed data).\n","import pickle\n","\n","# Import function to convert a directed graph to an undirected one, useful for certain graph algorithms.\n","from torch_geometric.utils import to_undirected\n","\n","# Import optimizer module from PyTorch for training models using gradient-based optimization techniques.\n","import torch.optim as optim\n","\n","# Import PyTorch's modules for defining neural network architectures and operations:\n","from torch.nn import (\n","    Linear,       # For linear transformations (dense layers).\n","    Sequential,   # For stacking layers sequentially.\n","    BatchNorm1d,  # For normalizing input within mini-batches.\n","    PReLU,        # Parametric ReLU activation function.\n","    Dropout       # For regularization by randomly dropping connections during training.\n",")\n","\n","# Import functional API from PyTorch for operations like activations and loss functions.\n","import torch.nn.functional as F\n","\n","# Import Matplotlib for visualizations, such as plotting training loss curves.\n","import matplotlib.pyplot as plt\n","\n","# Import PyTorch Geometric's graph convolutional layers:\n","from torch_geometric.nn import GCNConv, GINConv\n","\n","# Import pooling operations for aggregating node embeddings to graph-level representations:\n","from torch_geometric.nn import global_mean_pool, global_add_pool\n","\n","# Import NumPy for numerical operations, such as working with arrays and matrices.\n","import numpy as np\n","\n","# Import time module for measuring execution time of code blocks.\n","import time\n","\n","# Import typing module for specifying types in function arguments and return values.\n","from typing import Optional, Tuple, Union, Callable\n","\n","# Import PyTorch's DataLoader and TensorDataset for handling data batching and loading during training.\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","# Import PyTorch's Parameter class for defining learnable parameters in custom models.\n","from torch.nn import Parameter\n","\n","# Import math module for performing mathematical computations.\n","import math\n","\n","# Import Tensor type from PyTorch for defining and manipulating tensors.\n","from torch import Tensor\n","\n","# Import PyTorch's nn module for defining and building neural network architectures.\n","import torch.nn as nn\n","\n","# Import initialization utilities from PyTorch Geometric for resetting weights and biases in layers.\n","from torch_geometric.nn.inits import reset\n","\n","# Import the base class for defining message-passing layers in graph neural networks (GNNs).\n","from torch_geometric.nn.conv import MessagePassing\n","\n","# Import linear transformation utilities for creating dense representations in graph models.\n","from torch_geometric.nn.dense.linear import Linear\n","\n","# Import typing utilities for defining adjacency matrices and tensor types specific to PyTorch Geometric.\n","from torch_geometric.typing import Adj, OptTensor, PairTensor, SparseTensor\n","\n","# Import softmax function for normalizing attention scores in GNNs.\n","from torch_geometric.utils import softmax\n","\n","# Import initialization utilities for weight initialization (e.g., Glorot initialization).\n","from torch_geometric.nn.inits import glorot, zeros\n","\n","# Import F1 score metric from scikit-learn for evaluating model performance in binary/multi-class tasks.\n","from sklearn.metrics import f1_score\n","\n","# Import JSON module for reading and writing JSON files, useful for storing configuration or ontology data.\n","import json\n","\n","# Import Ontology class from DeepOnto for representing and manipulating ontologies in the pipeline.\n","from deeponto.onto import Ontology\n","\n","# Import tools from DeepOnto for handling Ontology Alignment Evaluation Initiative (OAEI) tasks.\n","from deeponto.align.oaei import *\n","\n","# Import evaluation tools from DeepOnto for assessing alignment results using metrics like precision, recall, and F1.\n","from deeponto.align.evaluation import AlignmentEvaluator\n","\n","# Import mapping utilities from DeepOnto for working with reference mappings and entity pairs.\n","from deeponto.align.mapping import ReferenceMapping, EntityMapping\n","\n","# Import utility function for reading tables (e.g., TSV, CSV) from DeepOnto.\n","from deeponto.utils import read_table\n","\n","# Importing the train_test_split function from sklearn's model_selection module.\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"-abbBHOoRdWl"},"source":["# **Paths Definition**"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AVgl_Bb42naS","outputId":"d7d8c75b-9c1f-42a3-a86d-d47bc34dbb6f","executionInfo":{"status":"ok","timestamp":1732452058348,"user_tz":-60,"elapsed":30578,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# Importing the 'drive' module from Google Colab to interact with Google Drive\n","from google.colab import drive\n","\n","# Mount the user's Google Drive to the Colab environment\n","# After running this, a link will appear to authorize access, and Google Drive will be mounted at '/content/gdrive'\n","drive.mount('/content/gdrive')\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"36ttssQ3W7cx","executionInfo":{"status":"ok","timestamp":1732452058348,"user_tz":-60,"elapsed":5,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Define the source ontology name\n","src_ent = \"snomed.neoplas\"\n","\n","# Define the target ontology name\n","tgt_ent = \"ncit.neoplas\"\n","\n","# Define the task name for this ontology matching process\n","task = \"neoplas\"\n","\n","# Define the weight for the training data\n","# This weight is likely used to balance the training process, giving more emphasis to certain examples.\n","# For instance, a weight of 10.0 could be applied to penalize errors in certain types of predictions more heavily.\n","weight_train= 50.0\n","\n","# Define the similarity threshold for validating matches\n","thres = 0.50"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"SJpvkdwVSQye","executionInfo":{"status":"ok","timestamp":1732452058348,"user_tz":-60,"elapsed":4,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["dir = f\"/content/gdrive/My Drive/BioGITOM-VLDB/Experiments/{task}\"\n","\n","dataset=\"/content/gdrive/My Drive/BioGITOM-VLDB/\"\n","\n","# Define the directory for the dataset containing source and target ontologies\n","dataset_dir = f\"{dataset}/Datasets/{task}\"\n","\n","# Define the data directory for storing embeddings, adjacency matrices, and related files\n","data_dir = f\"{dir}/Data\"\n","\n","# Define the directory for storing the results\n","results_dir = f\"{dir}/GN_Ablation/Results\""]},{"cell_type":"code","execution_count":28,"metadata":{"id":"eFDNSFef23er","executionInfo":{"status":"ok","timestamp":1732452157092,"user_tz":-60,"elapsed":20366,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Load the Source ontology using the Ontology class from DeepOnto\n","# This initializes the source ontology by loading its .owl file.\n","src_onto = Ontology(f\"{dataset_dir}/{src_ent}.owl\")\n","\n","# Load the Target ontology using the Ontology class from DeepOnto\n","# This initializes the target ontology by loading its .owl file.\n","tgt_onto = Ontology(f\"{dataset_dir}/{tgt_ent}.owl\")\n","\n","# Define the file path for the Source embeddings CSV file\n","# Embeddings for the source ontology entities are stored in this file.\n","src_Emb = f\"{data_dir}/{src_ent}_emb.csv\"\n","\n","# Define the file path for the Target embeddings CSV file\n","# Embeddings for the target ontology entities are stored in this file.\n","tgt_Emb = f\"{data_dir}/{tgt_ent}_emb.csv\"\n","\n","# Define the file path for the Source adjacency matrix\n","# This file represents the relationships (edges) between entities in the source ontology.\n","src_Adjacence = f\"{data_dir}/{src_ent}_adjacence.csv\"\n","\n","# Define the file path for the Target adjacency matrix\n","# This file represents the relationships (edges) between entities in the target ontology.\n","tgt_Adjacence = f\"{data_dir}/{tgt_ent}_adjacence.csv\"\n","\n","# Define the file path for the JSON file containing the Source ontology class labels\n","# This file maps the source ontology entities to their labels or names.\n","src_class = f\"{data_dir}/{src_ent}_classes.json\"\n","\n","# Define the file path for the JSON file containing the Target ontology class labels\n","# This file maps the target ontology entities to their labels or names.\n","tgt_class = f\"{data_dir}/{tgt_ent}_classes.json\"\n","\n","# Define the file path for the train data\n","train_file = f\"{data_dir}/{task}_train_100.csv\"\n","\n","# Define the file path for the test data\n","# The test file contains reference mappings (ground truth) between the source and target ontologies.\n","test_file = f\"{dataset_dir}/refs_equiv/test.tsv\"\n","\n","# Define the file path for the candidate mappings used during testing\n","# This file includes the candidate pairs (source and target entities) for ranking and evaluation.\n","test_cands = f\"{dataset_dir}/refs_equiv/test.cands.tsv\"\n","\n","# Define the file path for the candidate mappings between Source to Target entities\n","# This file contains cleaned, combined, and encoded candidates used for predictions.\n","candidates_Prediction = f\"{data_dir}/{task}_candidates_prediction.csv\"\n","\n","# Define the file path for the candidate mappings between Source to Target entities for ranking-based metrics\n","# This file is used to compute ranking-based metrics like MRR and Hits@k.\n","candidates_Rank = f\"{data_dir}/{task}_candidates.csv\"\n","\n","# Define the path where the prediction results will be saved in TSV format\n","# This file will store the final predictions (mappings) between source and target entities.\n","prediction_path = f\"{results_dir}/{task}_matching_results.tsv\"\n","\n","# Define the path where all prediction results will be saved in TSV format\n","# This file will store detailed prediction results, including all candidate scores.\n","all_predictions_path = f\"{results_dir}/{task}_all_predictions.tsv\"\n","\n","# Define the path where all ranking prediction results will be saved in TSV format\n","# This file will store predictions sorted by rank based on their scores.\n","all_predictions_path_ranked = f\"{results_dir}/{task}_all_predictions_ranked.tsv\"\n","\n","# Define the path where formatted ranking predictions will be saved in TSV format\n","# This file will contain predictions formatted for evaluation using ranking-based metrics.\n","formatted_predictions_path = f\"{results_dir}/{task}_formatted_predictions.tsv\""]},{"cell_type":"markdown","metadata":{"id":"zqEXsgPGMVhw"},"source":["# **GIT Architecture**\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"A_d6XCsUMVhx","executionInfo":{"status":"ok","timestamp":1732452083949,"user_tz":-60,"elapsed":332,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# RGIT class definition which inherits from PyTorch Geometric's MessagePassing class\n","class RGIT(MessagePassing):\n","\n","    _alpha: OptTensor  # Define _alpha as an optional tensor for storing attention weights\n","\n","    def __init__(\n","        self,\n","        nn: Callable,  # Neural network to be used in the final layer of the GNN\n","        in_channels: Union[int, Tuple[int, int]],  # Input dimension, can be a single or pair of integers\n","        out_channels: int,  # Output dimension of the GNN\n","        eps: float = 0.,  # GIN parameter: epsilon for GIN aggregation\n","        train_eps: bool = False,  # GIN parameter: whether epsilon should be learnable\n","        heads: int = 1,  # Transformer parameter: number of attention heads\n","        dropout: float = 0.,  # Dropout rate for attention weights\n","        edge_dim: Optional[int] = None,  # Dimension for edge attributes (optional)\n","        bias: bool = True,  # Whether to use bias in linear layers\n","        root_weight: bool = True,  # GIN parameter: whether to apply root weight in aggregation\n","        **kwargs,  # Additional arguments passed to the parent class\n","    ):\n","        # Set the aggregation type to 'add' and initialize the parent class with node_dim=0\n","        kwargs.setdefault('aggr', 'add')\n","        super().__init__(node_dim=0, **kwargs)\n","\n","        # Initialize input/output dimensions, neural network, and GIN/transformer parameters\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.nn = nn  # Neural network used by the GNN\n","        self.initial_eps = eps  # Initial value of epsilon for GIN\n","\n","        # Set epsilon to be learnable or fixed\n","        if train_eps:\n","            self.eps = torch.nn.Parameter(torch.empty(1))  # Learnable epsilon\n","        else:\n","            self.register_buffer('eps', torch.empty(1))  # Non-learnable epsilon (fixed)\n","\n","        # Initialize transformer-related parameters\n","        self.heads = heads\n","        self.dropout = dropout\n","        self.edge_dim = edge_dim\n","        self._alpha = None  # Placeholder for attention weights\n","\n","        # Handle case where in_channels is a single integer or a tuple\n","        if isinstance(in_channels, int):\n","            in_channels = (in_channels, in_channels)\n","\n","        # Define the linear layers for key, query, and value for the transformer mechanism\n","        self.lin_key = Linear(in_channels[0], heads * out_channels)\n","        self.lin_query = Linear(in_channels[1], heads * out_channels)\n","        self.lin_value = Linear(in_channels[0], heads * out_channels)\n","\n","        # Define linear transformation for edge embeddings if provided\n","        if edge_dim is not None:\n","            self.lin_edge = Linear(edge_dim, heads * out_channels, bias=False)\n","        else:\n","            self.lin_edge = self.register_parameter('lin_edge', None)\n","\n","        # Reset all parameters to their initial values\n","        self.reset_parameters()\n","\n","    # Function to reset model parameters\n","    def reset_parameters(self):\n","        super().reset_parameters()  # Call parent class reset method\n","        self.lin_key.reset_parameters()  # Reset key linear layer\n","        self.lin_query.reset_parameters()  # Reset query linear layer\n","        self.lin_value.reset_parameters()  # Reset value linear layer\n","        if self.edge_dim:\n","            self.lin_edge.reset_parameters()  # Reset edge linear layer if used\n","        reset(self.nn)  # Reset the neural network provided\n","        self.eps.data.fill_(self.initial_eps)  # Initialize epsilon with the starting value\n","\n","    # Forward function defining how the input data flows through the model\n","    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj,\n","                edge_attr: OptTensor = None, return_attention_weights=None):\n","        # Unpack number of heads and output channels\n","        H, C = self.heads, self.out_channels\n","\n","        # If x is a tensor, treat it as a pair of tensors (source and target embeddings)\n","        if isinstance(x, Tensor):\n","            x: PairTensor = (x, x)\n","\n","        # Extract source node embeddings\n","        x_t = x[0]\n","\n","        # Apply linear transformations and reshape query, key, and value for multi-head attention\n","        query = self.lin_query(x[1]).view(-1, H, C)\n","        key = self.lin_key(x[0]).view(-1, H, C)\n","        value = self.lin_value(x[0]).view(-1, H, C)\n","\n","        # Propagate messages through the graph using the propagate function\n","        out = self.propagate(edge_index, query=query, key=key, value=value,\n","                             edge_attr=edge_attr, size=None)\n","\n","        # Retrieve attention weights and reset them\n","        alpha = self._alpha\n","        self._alpha = None  # Reset _alpha after use\n","        out = out.mean(dim=1)  # Take the mean over all attention heads\n","\n","        # Apply GIN aggregation by adding epsilon-scaled original node embeddings\n","        out = out + (1 + self.eps) * x_t\n","        return self.nn(out)  # Pass through the neural network\n","\n","    # Message passing function which calculates attention and combines messages\n","    def message(self, query_i: Tensor, key_j: Tensor, value_j: Tensor,\n","                edge_attr: OptTensor, index: Tensor, ptr: OptTensor,\n","                size_i: Optional[int]) -> Tensor:\n","        # If edge attributes are used, apply linear transformation and add them to the key\n","        if self.lin_edge is not None:\n","            assert edge_attr is not None\n","            edge_attr = self.lin_edge(edge_attr).view(-1, self.heads, self.out_channels)\n","            key_j = key_j + edge_attr\n","\n","        # Calculate attention (alpha) using the dot product between query and key\n","        alpha = (query_i * key_j).sum(dim=-1) / math.sqrt(self.out_channels)\n","        alpha = softmax(alpha, index, ptr, size_i)  # Apply softmax to normalize attention\n","        self._alpha = alpha  # Store attention weights\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)  # Apply dropout\n","\n","        # Calculate the output message by applying attention to the value\n","        out = value_j\n","        if edge_attr is not None:\n","            out = out + edge_attr  # Add edge embeddings to the output if present\n","        out = out * alpha.view(-1, self.heads, 1)  # Scale by attention weights\n","        return out\n","\n","    # String representation function for debugging or printing\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}({self.in_channels}, '\n","                f'{self.out_channels}, heads={self.heads})')"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"qwFv6RgHmGCf","executionInfo":{"status":"ok","timestamp":1732452083949,"user_tz":-60,"elapsed":5,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Define the RGIT_mod class, a multi-layer GNN that uses both RGIT and linear layers\n","class RGIT_mod(torch.nn.Module):\n","    \"\"\"Multi-layer RGIT with optional linear layers\"\"\"\n","\n","    # Initialize the model with hidden dimension, number of RGIT layers, and number of linear layers\n","    def __init__(self, dim_h, num_layers, num_linear_layers=1):\n","        super(RGIT_mod, self).__init__()\n","        self.num_layers = num_layers  # Number of RGIT layers\n","        self.num_linear_layers = num_linear_layers  # Number of linear layers\n","        self.linears = torch.nn.ModuleList()  # List to store linear layers\n","        self.rgit_layers = torch.nn.ModuleList()  # List to store RGIT layers\n","\n","        # Create a list of Linear and PReLU layers (for encoding entity names)\n","        for _ in range(num_linear_layers):\n","            self.linears.append(Linear(dim_h, dim_h))  # Linear transformation layer\n","            self.linears.append(PReLU(num_parameters=dim_h))  # Parametric ReLU activation function\n","\n","        # Create a list of RGIT layers\n","        for _ in range(num_layers):\n","            self.rgit_layers.append(RGIT(  # Each RGIT layer contains a small MLP with Linear and PReLU\n","                Sequential(Linear(dim_h, dim_h), PReLU(num_parameters=dim_h),\n","                           Linear(dim_h, dim_h), PReLU(num_parameters=dim_h)), dim_h, dim_h))\n","\n","    # Forward pass through the model\n","    def forward(self, x, edge_index):\n","        # Apply the linear layers first to the input\n","        for layer in self.linears:\n","            x = layer(x)\n","\n","        # Then apply the RGIT layers for message passing\n","        for layer in self.rgit_layers:\n","            x = layer(x, edge_index)\n","\n","        return x  # Return the final node embeddings after all layers\n"]},{"cell_type":"markdown","metadata":{"id":"zxCn5ztKVztw"},"source":["# **Gated Network Architecture**"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"7MKQUv7o7zay","executionInfo":{"status":"ok","timestamp":1732452083949,"user_tz":-60,"elapsed":5,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Define the GatedCombination class for combining two pairs of embeddings using a gating mechanism\n","class GatedCombination(nn.Module):\n","    def __init__(self, input_dim):\n","        \"\"\"\n","        Initialize the GatedCombination model.\n","\n","        Args:\n","            input_dim (int): The dimensionality of the input embeddings (x1, x2, x3, x4).\n","        \"\"\"\n","        super(GatedCombination, self).__init__()\n","\n","        # Define a linear layer (gate) for combining embeddings x1 and x2 (first pair)\n","        self.gate_A_fc = nn.Linear(input_dim, input_dim)\n","\n","        # Define a linear layer (gate) for combining embeddings x3 and x4 (second pair)\n","        self.gate_B_fc = nn.Linear(input_dim, input_dim)\n","\n","        # A final fully connected layer that outputs a single neuron (binary classification)\n","        self.fc = nn.Linear(1, 1)\n","\n","    def forward(self, x1, x2, x3, x4):\n","        \"\"\"\n","        Forward pass through the gating mechanism and cosine similarity.\n","\n","        Args:\n","            x1 (torch.Tensor): First set of embeddings (source embeddings after update).\n","            x2 (torch.Tensor): Second set of embeddings (original source embeddings).\n","            x3 (torch.Tensor): Third set of embeddings (target embeddings after update).\n","            x4 (torch.Tensor): Fourth set of embeddings (original target embeddings).\n","\n","        Returns:\n","            torch.Tensor: Output of the model (probability score for binary classification).\n","        \"\"\"\n","        # Compute gate values for the first pair (x1 and x2) using a sigmoid activation\n","        gate_values1 = torch.sigmoid(self.gate_A_fc(x1))\n","\n","        # Combine x1 and x2 using the gate values\n","        # The result is a weighted combination of x1 and x2\n","        a = x1 * gate_values1 + x2 * (1 - gate_values1)\n","\n","        # Compute gate values for the second pair (x3 and x4) using a sigmoid activation\n","        gate_values2 = torch.sigmoid(self.gate_B_fc(x3))\n","\n","        # Combine x3 and x4 using the gate values\n","        # The result is a weighted combination of x3 and x4\n","        b = x3 * gate_values2 + x4 * (1 - gate_values2)\n","\n","        # Compute cosine similarity between the combined vectors a and b\n","        x = torch.cosine_similarity(a, b, dim=1)\n","\n","        # Pass the cosine similarity result through a fully connected layer (fc) for classification\n","        # Use a sigmoid activation to output a probability for binary classification\n","        out = torch.sigmoid(self.fc(x.unsqueeze(1)))  # unsqueeze(1) to match the input shape for the fc layer\n","        return out\n","\n"]},{"cell_type":"code","source":["class WeightedBCELoss(nn.Module):\n","    def __init__(self, pos_weight):\n","        \"\"\"\n","        Weighted Binary Cross-Entropy Loss.\n","\n","        Args:\n","            pos_weight (float): Weight for the positive class.\n","        \"\"\"\n","        super(WeightedBCELoss, self).__init__()\n","        self.pos_weight = pos_weight\n","\n","    def forward(self, outputs, targets):\n","        \"\"\"\n","        Args:\n","            outputs (torch.Tensor): Predicted probabilities from the model (after sigmoid).\n","            targets (torch.Tensor): Ground truth labels (0 or 1).\n","\n","        Returns:\n","            torch.Tensor: Computed weighted binary cross-entropy loss.\n","        \"\"\"\n","        # Compute weighted BCE loss\n","        loss = - (self.pos_weight * targets * torch.log(outputs + 1e-8) +\n","                  (1 - targets) * torch.log(1 - outputs + 1e-8))\n","        return loss.mean()"],"metadata":{"id":"PCzq6hHCD8vg","executionInfo":{"status":"ok","timestamp":1732452083950,"user_tz":-60,"elapsed":5,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":11,"metadata":{"id":"4kO42TTCqQZ8","executionInfo":{"status":"ok","timestamp":1732452083950,"user_tz":-60,"elapsed":5,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["class FocalLoss(nn.Module):\n","    def __init__(self, alpha=0.25, gamma=2):\n","        \"\"\"\n","        Focal Loss for binary classification.\n","\n","        Args:\n","            alpha (float): Balancing factor for positive/negative classes.\n","            gamma (float): Focusing parameter for hard examples.\n","        \"\"\"\n","        super(FocalLoss, self).__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","\n","    def forward(self, outputs, targets):\n","        \"\"\"\n","        Args:\n","            outputs (torch.Tensor): Predicted probabilities from the model (after sigmoid).\n","            targets (torch.Tensor): Ground truth labels (0 or 1).\n","\n","        Returns:\n","            torch.Tensor: Computed focal loss.\n","        \"\"\"\n","        # Compute binary cross-entropy loss\n","        bce_loss = F.binary_cross_entropy(outputs, targets, reduction='none')\n","\n","        # Compute modulating factor (1 - p_t)^gamma\n","        pt = torch.where(targets == 1, outputs, 1 - outputs)  # pt = p if y==1 else 1-p\n","        modulating_factor = (1 - pt) ** self.gamma\n","\n","        # Apply alpha and modulating factor\n","        focal_loss = self.alpha * modulating_factor * bce_loss\n","        return focal_loss.mean()"]},{"cell_type":"markdown","metadata":{"id":"aLJ5j9FNMVhy"},"source":["# **Utility functions**"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"k0L86DgUQjMU","executionInfo":{"status":"ok","timestamp":1732452083950,"user_tz":-60,"elapsed":5,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def adjacency_matrix_to_undirected_edge_index(adjacency_matrix):\n","    \"\"\"\n","    Converts an adjacency matrix into an undirected edge index for use in graph-based neural networks.\n","\n","    Args:\n","        adjacency_matrix: A 2D list or array representing the adjacency matrix of a graph.\n","\n","    Returns:\n","        edge_index_undirected: A PyTorch tensor representing the undirected edges.\n","    \"\"\"\n","    # Convert each element in the adjacency matrix to an integer (from boolean or float)\n","    adjacency_matrix = [[int(element) for element in sublist] for sublist in adjacency_matrix]\n","\n","    # Convert the adjacency matrix into a PyTorch LongTensor (used for indexing)\n","    edge_index = torch.tensor(adjacency_matrix, dtype=torch.long)\n","\n","    # Transpose the edge_index tensor so that rows represent edges in the form [source, target]\n","    edge_index = edge_index.t().contiguous()\n","\n","    # Convert the directed edge_index into an undirected edge_index, meaning both directions are added (i.e., (i, j) and (j, i))\n","    edge_index_undirected = to_undirected(edge_index)\n","\n","    return edge_index_undirected  # Return the undirected edge index"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"YvmOxkLcpf9w","executionInfo":{"status":"ok","timestamp":1732452083950,"user_tz":-60,"elapsed":5,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def build_indexed_dict(file_path):\n","    \"\"\"\n","    Builds a dictionary with numeric indexes for each key from a JSON file.\n","\n","    Args:\n","        file_path (str): The path to the JSON file.\n","\n","    Returns:\n","        indexed_dict (dict): A new dictionary where each key from the JSON file is assigned a numeric index.\n","    \"\"\"\n","    # Load the JSON file into a Python dictionary\n","    with open(file_path, 'r') as file:\n","        data = json.load(file)\n","\n","    # Create a new dictionary with numeric indexes as keys and the original JSON keys as values\n","    indexed_dict = {index: key for index, key in enumerate(data.keys())}\n","\n","    return indexed_dict  # Return the newly created dictionary"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"QgFINoPGl9Wg","executionInfo":{"status":"ok","timestamp":1732452083950,"user_tz":-60,"elapsed":5,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def select_rows_by_index(embedding_vector, index_vector):\n","    \"\"\"\n","    Select rows from an embedding vector using an index vector.\n","\n","    Args:\n","        embedding_vector (torch.Tensor): 2D tensor representing the embedding vector with shape [num_rows, embedding_size].\n","        index_vector (torch.Tensor): 1D tensor representing the index vector.\n","\n","    Returns:\n","        torch.Tensor: New tensor with selected rows from the embedding vector.\n","    \"\"\"\n","    # Use torch.index_select to select the desired rows\n","    new_tensor = torch.index_select(embedding_vector, 0, index_vector)\n","\n","    return new_tensor"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"a12L7vEmmCJq","executionInfo":{"status":"ok","timestamp":1732452083950,"user_tz":-60,"elapsed":4,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def contrastive_loss(source_embeddings, target_embeddings, labels, margin=1.0):\n","    \"\"\"\n","    Computes the contrastive loss, a type of loss function used to train models in tasks like matching or similarity learning.\n","\n","    Args:\n","        source_embeddings (torch.Tensor): Embeddings of the source graphs, shape [batch_size, embedding_size].\n","        target_embeddings (torch.Tensor): Embeddings of the target graphs, shape [batch_size, embedding_size].\n","        labels (torch.Tensor): Binary labels indicating if the pairs are matched (1) or not (0), shape [batch_size].\n","        margin (float): Margin value for the contrastive loss. Defaults to 1.0.\n","\n","    Returns:\n","        torch.Tensor: The contrastive loss value.\n","    \"\"\"\n","    # Calculate the pairwise Euclidean distance between source and target embeddings\n","    distances = F.pairwise_distance(source_embeddings, target_embeddings)\n","\n","    # Compute the contrastive loss:\n","    # - For matched pairs (label == 1), the loss is the squared distance between embeddings.\n","    # - For non-matched pairs (label == 0), the loss is based on how far apart the embeddings are,\n","    #   but penalizes them only if the distance is less than the margin.\n","    loss = torch.mean(\n","        labels * 0.4 * distances.pow(2) +  # For positive pairs, minimize the distance (squared)\n","        (1 - labels) * 0.4 * torch.max(torch.zeros_like(distances), margin - distances).pow(2)  # For negative pairs, maximize the distance (up to the margin)\n","    )\n","\n","    return loss  # Return the computed contrastive loss\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"ZhCizXEb7D4N","executionInfo":{"status":"ok","timestamp":1732452083950,"user_tz":-60,"elapsed":4,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def Prediction_with_candidates(model, X1_tt, X2_tt, X3_tt, X4_tt, src_entity_tensor_o, tgt_entity_tensor_o,\n","                                   indexed_dict_src, indexed_dict_tgt, all_predictions_path):\n","    \"\"\"\n","    Evaluates the GatedCombination model using the given embeddings and candidate entity pairs.\n","    Saves the predictions and evaluation results to a file.\n","\n","    Args:\n","        model: Trained GatedCombination model.\n","        X1_tt, X2_tt, X3_tt, X4_tt (torch.Tensor): Tensors of source and target entity embeddings (updated and original).\n","        src_entity_tensor_o, tgt_entity_tensor_o (torch.Tensor): Tensors of source and target entity indices.\n","        indexed_dict_src, indexed_dict_tgt (dict): Dictionaries mapping entity indices to URIs for source and target.\n","        output_file (str): Path to save the predictions and results.\n","        hits_at_k_values (list): List of k-values for which hits@k is evaluated.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    # Move the model to CPU and set it to evaluation mode\n","    model = model.to(\"cpu\")\n","    model.eval()\n","\n","    # Set batch size for evaluation\n","    batch_size_test = 32\n","\n","    # Create a DataLoader for the evaluation data\n","    test_dataset = TensorDataset(X1_tt, X2_tt, X3_tt, X4_tt)\n","    test_dataloader = DataLoader(test_dataset, batch_size=batch_size_test)\n","\n","    # Prepare for collecting predictions and results\n","    predictions = []\n","    results = []\n","    count_predictions = 0  # Counter for predictions above threshold (0.5)\n","\n","    # Measure prediction time\n","    start_time = time.time()\n","\n","    # Disable gradient computation for evaluation\n","    with torch.no_grad():\n","        # Iterate over batches and compute model predictions\n","        for batch_X1, batch_X2, batch_X3, batch_X4 in test_dataloader:\n","            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","            predictions.extend(outputs.cpu().numpy())  # Collect predictions in CPU memory\n","\n","    end_time = time.time()\n","    predicting_time = end_time - start_time\n","    print(f\"Predicting time: {predicting_time:.2f} seconds\")\n","\n","    # Convert tensors to lists for easier iteration\n","    src_indices = src_entity_tensor_o.tolist()\n","    tgt_indices = tgt_entity_tensor_o.tolist()\n","\n","    # Prepare results\n","    for i in range(len(predictions)):\n","        if predictions[i] >= 0.00:  # Consider only predictions greater than 0.5\n","            count_predictions += 1  # Increment the counter\n","\n","            # Map the source and target entity indices to their URIs\n","            src_code = src_indices[i]\n","            tgt_code = tgt_indices[i]\n","\n","            src_uri = indexed_dict_src.get(int(src_code), \"Unknown URI\")\n","            tgt_uri = indexed_dict_tgt.get(int(tgt_code), \"Unknown URI\")\n","\n","            # Get the model's predicted score for the current pair\n","            score = predictions[i]\n","\n","            # Append the results (with URIs instead of entity indices)\n","            results.append({\n","                'SrcEntity': src_uri,\n","                'TgtEntity': tgt_uri,\n","                'Score': score\n","            })\n","\n","    # Convert the results into a pandas DataFrame\n","    df_results = pd.DataFrame(results)\n","\n","    # Save the results to a TSV file\n","    df_results.to_csv(all_predictions_path, sep='\\t', index=False)\n","\n","    print(f\"Predictions saved to {all_predictions_path}\")"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"TslUdYHBcGVj","executionInfo":{"status":"ok","timestamp":1732455133994,"user_tz":-60,"elapsed":337,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def filter_highest_predictions(input_file_path, output_file_path, threshold=0.5):\n","    # Load the all predictions file\n","    df = pd.read_csv(input_file_path, sep='\\t')\n","\n","    # Ensure 'Score' is treated as a numeric column\n","    if not pd.api.types.is_numeric_dtype(df['Score']):\n","        df['Score'] = df['Score'].apply(float)\n","\n","    # Sorting the dataframe by similarity score in descending order\n","    df_sorted = df.sort_values(by='Score', ascending=False).reset_index(drop=True)\n","\n","    # Initialize variables with threshold value\n","    source_concepts = set(df_sorted['SrcEntity'])\n","    target_concepts = set(df_sorted['TgtEntity'])\n","    matched_sources = set()\n","    matched_targets = set()\n","    result = []\n","\n","    # Iterate through the sorted dataframe and find highest correspondences\n","    for _, row in df_sorted.iterrows():\n","        source, target, similarity = row['SrcEntity'], row['TgtEntity'], row['Score']\n","\n","        # Check if the source or target has already been matched and if the similarity is above the threshold\n","        if source not in matched_sources and target not in matched_targets and similarity >= threshold:\n","            # Add the match to the result list\n","            result.append((source, target, similarity))\n","            # Mark the source and target as matched\n","            matched_sources.add(source)\n","            matched_targets.add(target)\n","\n","    # Create a dataframe for the matching results with threshold applied\n","    matching_results_df_threshold = pd.DataFrame(result, columns=['SrcEntity', 'TgtEntity', 'Score'])\n","\n","    # Save the matching results with the updated column names to a new TSV file\n","    matching_results_df_threshold.to_csv(output_file_path, sep='\\t', index=False)\n","\n","    # Print the number of predictions saved\n","    print(f\"Number of Positive Predictions : {len(matching_results_df_threshold)}\")\n","\n","    return matching_results_df_threshold, len(matching_results_df_threshold)\n"]},{"cell_type":"code","source":["def compute_mrr_and_hits(reference_file, predicted_file, output_file, k_values=[1, 5, 10]):\n","    \"\"\"\n","    Compute MRR and Hits@k for ontology matching predictions based on a reference file.\n","\n","    Args:\n","        reference_file (str): Path to the reference file (test.cands.tsv format).\n","        predicted_file (str): Path to the predictions file with scores.\n","        output_file (str): Path to save the scored results.\n","        k_values (list): List of k values for Hits@k.\n","\n","    Returns:\n","        dict: A dictionary containing MRR and Hits@k metrics.\n","    \"\"\"\n","    # Read the reference mappings\n","    test_candidate_mappings = read_table(reference_file).values.tolist()\n","    ranking_results = []\n","\n","    # Read the predicted scores\n","    predicted_data = pd.read_csv(predicted_file, sep=\"\\t\")\n","    predicted_data[\"Score\"] = predicted_data[\"Score\"].apply(lambda x: float(x.strip(\"[]\")))\n","\n","    # Create a lookup dictionary for predicted scores\n","    score_lookup = {}\n","    for _, row in predicted_data.iterrows():\n","        score_lookup[(row[\"SrcEntity\"], row[\"TgtEntity\"])] = row[\"Score\"]\n","\n","    for src_ref_class, tgt_ref_class, tgt_cands in test_candidate_mappings:\n","        tgt_cands = eval(tgt_cands)  # Convert string to list of candidates\n","        scored_cands = []\n","        for tgt_cand in tgt_cands:\n","            # Retrieve score for each candidate, defaulting to a very low score if not found\n","            matching_score = score_lookup.get((src_ref_class, tgt_cand), -1e9)\n","            scored_cands.append((tgt_cand, matching_score))\n","\n","        # Sort candidates by score in descending order\n","        scored_cands = sorted(scored_cands, key=lambda x: x[1], reverse=True)\n","        ranking_results.append((src_ref_class, tgt_ref_class, scored_cands))\n","\n","    # Save the ranked results to a file\n","    pd.DataFrame(ranking_results, columns=[\"SrcEntity\", \"TgtEntity\", \"TgtCandidates\"]).to_csv(output_file, sep=\"\\t\", index=False)\n","\n","    # Compute MRR and Hits@k\n","    total_entities = len(ranking_results)\n","    reciprocal_ranks = []\n","    hits_at_k = {k: 0 for k in k_values}\n","\n","    for src_entity, tgt_ref_class, tgt_cands in ranking_results:\n","        ranked_candidates = [candidate[0] for candidate in tgt_cands]\n","        if tgt_ref_class in ranked_candidates:\n","            rank = ranked_candidates.index(tgt_ref_class) + 1\n","            reciprocal_ranks.append(1 / rank)\n","            for k in k_values:\n","                if rank <= k:\n","                    hits_at_k[k] += 1\n","        else:\n","            reciprocal_ranks.append(0)\n","\n","    mrr = sum(reciprocal_ranks) / total_entities\n","    hits_at_k = {k: hits / total_entities for k, hits in hits_at_k.items()}\n","\n","    return {\"MRR\": mrr, \"Hits@k\": hits_at_k}"],"metadata":{"id":"_ggVYlTiO_WA","executionInfo":{"status":"ok","timestamp":1732452083950,"user_tz":-60,"elapsed":4,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def Prediction_with_git(embeddings_src, embeddings_tgt, src_entity_tensor_o, tgt_entity_tensor_o,\n","                        indexed_dict_src, indexed_dict_tgt, all_predictions_path):\n","    \"\"\"\n","    Directly predicts similarity scores using GIT model embeddings and cosine similarity.\n","    \"\"\"\n","    # Ensure embeddings are on CPU\n","    embeddings_src = embeddings_src.cpu()\n","    embeddings_tgt = embeddings_tgt.cpu()\n","\n","    # Select rows for source and target entities\n","    src_embeddings = select_rows_by_index(embeddings_src, src_entity_tensor_o)\n","    tgt_embeddings = select_rows_by_index(embeddings_tgt, tgt_entity_tensor_o)\n","\n","    # Compute cosine similarity\n","    with torch.no_grad():\n","        similarity_scores = F.cosine_similarity(src_embeddings, tgt_embeddings, dim=1).cpu().numpy()\n","\n","    # Prepare results\n","    results = []\n","    for i in range(len(similarity_scores)):\n","        src_uri = indexed_dict_src.get(int(src_entity_tensor_o[i].item()), \"Unknown URI\")\n","        tgt_uri = indexed_dict_tgt.get(int(tgt_entity_tensor_o[i].item()), \"Unknown URI\")\n","        score = similarity_scores[i]\n","        results.append({'SrcEntity': src_uri, 'TgtEntity': tgt_uri, 'Score': score})\n","\n","    # Save results to a TSV file\n","    df_results = pd.DataFrame(results)\n","    df_results.to_csv(all_predictions_path, sep='\\t', index=False)\n","    print(f\"Predictions saved to {all_predictions_path}\")\n"],"metadata":{"id":"pOlIyC7MIOXQ","executionInfo":{"status":"ok","timestamp":1732452083950,"user_tz":-60,"elapsed":4,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1HyWMsw1MVhz"},"source":["# **Main Code**\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"IC37FlwGDqGM"},"source":["\n","\n","# Reading semantic node embeddings provided by the ENE"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"FuEfSnw5mod0","executionInfo":{"status":"ok","timestamp":1732452093803,"user_tz":-60,"elapsed":9857,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the source embeddings from a CSV file into a pandas DataFrame\n","df_embbedings_src = pd.read_csv(src_Emb, index_col=0)\n","\n","# Convert the DataFrame to a NumPy array, which will remove the index and store the data as a raw matrix\n","numpy_array = df_embbedings_src.to_numpy()\n","\n","# Convert the NumPy array into a PyTorch FloatTensor, which is the format required for PyTorch operations\n","x_src = torch.FloatTensor(numpy_array)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"STUwqMUXmlG2","executionInfo":{"status":"ok","timestamp":1732452098860,"user_tz":-60,"elapsed":5059,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the target embeddings from a CSV file into a pandas DataFrame\n","df_embbedings_tgt = pd.read_csv(tgt_Emb, index_col=0)\n","\n","# Convert the DataFrame to a NumPy array, which removes the index and converts the data to a raw matrix\n","numpy_array = df_embbedings_tgt.to_numpy()\n","\n","# Convert the NumPy array into a PyTorch FloatTensor, which is required for PyTorch operations\n","x_tgt = torch.FloatTensor(numpy_array)"]},{"cell_type":"markdown","metadata":{"id":"jZIu9P08DqGN"},"source":["# Reading adjacency Matrix"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"pH69Up40mycz","executionInfo":{"status":"ok","timestamp":1732452098860,"user_tz":-60,"elapsed":3,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the source adjacency matrix from a CSV file into a pandas DataFrame\n","df_ma1 = pd.read_csv(src_Adjacence, index_col=0)\n","\n","# Convert the DataFrame to a list of lists (Python native list format)\n","ma1 = df_ma1.values.tolist()"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"hYCmAO5Ymzpl","executionInfo":{"status":"ok","timestamp":1732452099281,"user_tz":-60,"elapsed":423,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the target adjacency matrix from a CSV file into a pandas DataFrame\n","df_ma2 = pd.read_csv(tgt_Adjacence, index_col=0)\n","\n","# Convert the DataFrame to a list of lists (Python native list format)\n","ma2 = df_ma2.values.tolist()"]},{"cell_type":"markdown","metadata":{"id":"PSyksqh3TrU-"},"source":["# Convert Adjacency matrix (in list format) to an undirected edge index"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"uVt-Pce5m5ll","executionInfo":{"status":"ok","timestamp":1732452099281,"user_tz":-60,"elapsed":3,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Convert the source adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n","edge_src = adjacency_matrix_to_undirected_edge_index(ma1)\n","\n","# Convert the target adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n","edge_tgt = adjacency_matrix_to_undirected_edge_index(ma2)"]},{"cell_type":"markdown","metadata":{"id":"H9wMTRdqT4aY"},"source":["# GIT Training"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"eqiEKCLSMVh3","executionInfo":{"status":"ok","timestamp":1732452099281,"user_tz":-60,"elapsed":3,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def train_model_gnn(model, x_src, edge_src, x_tgt, edge_tgt,\n","                    tensor_term1, tensor_term2, tensor_score,\n","                    learning_rate, weight_decay_value, num_epochs, print_interval=10):\n","    \"\"\"\n","    Trains a graph neural network (GNN) model using source and target embeddings and contrastive loss.\n","\n","    Args:\n","        model: The GNN model to be trained.\n","        x_src (torch.Tensor): Source node embeddings.\n","        edge_src (torch.Tensor): Source graph edges.\n","        x_tgt (torch.Tensor): Target node embeddings.\n","        edge_tgt (torch.Tensor): Target graph edges.\n","        tensor_term1 (torch.Tensor): Indices of the source nodes to be compared.\n","        tensor_term2 (torch.Tensor): Indices of the target nodes to be compared.\n","        tensor_score (torch.Tensor): Labels indicating if the pairs are matched (1) or not (0).\n","        learning_rate (float): Learning rate for the optimizer.\n","        weight_decay_value (float): Weight decay (L2 regularization) value for the optimizer.\n","        num_epochs (int): Number of epochs for training.\n","        print_interval (int): Interval at which training progress is printed (every `print_interval` epochs).\n","\n","    Returns:\n","        model: The trained GNN model.\n","    \"\"\"\n","\n","    # Step 1: Set device (GPU or CPU) for computation\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    # Step 2: Move the model and all inputs to the selected device\n","    model.to(device)\n","    x_tgt = x_tgt.to(device)               # Target node embeddings\n","    edge_tgt = edge_tgt.to(device)         # Target graph edges\n","    x_src = x_src.to(device)               # Source node embeddings\n","    edge_src = edge_src.to(device)         # Source graph edges\n","    tensor_term1 = tensor_term1.to(device) # Indices for source nodes\n","    tensor_term2 = tensor_term2.to(device) # Indices for target nodes\n","    tensor_score = tensor_score.to(device) # Ground truth labels\n","\n","    # Step 3: Define optimizer with learning rate and regularization\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay_value)\n","\n","    # Step 4: Initialize list to store training losses\n","    train_losses = []\n","\n","    # Record the start time of training\n","    start_time = time.time()\n","\n","    # Step 5: Training loop\n","    for epoch in range(num_epochs):\n","        # Zero out gradients from the previous iteration\n","        optimizer.zero_grad()\n","\n","        # Forward pass: Compute embeddings for source and target graphs\n","        out1 = model(x_src, edge_src)  # Updated source embeddings\n","        out2 = model(x_tgt, edge_tgt)  # Updated target embeddings\n","\n","        # Extract specific rows of embeddings for terms being compared\n","        src_embeddings = select_rows_by_index(out1, tensor_term1)\n","        tgt_embeddings = select_rows_by_index(out2, tensor_term2)\n","\n","        # Compute contrastive loss based on the embeddings and ground truth labels\n","        loss = contrastive_loss(src_embeddings, tgt_embeddings, tensor_score)\n","\n","        # Backward pass: Compute gradients\n","        loss.backward()\n","\n","        # Update the model's parameters\n","        optimizer.step()\n","\n","        # Append the loss for this iteration to the list\n","        train_losses.append(loss.item())\n","\n","        # Print loss every `print_interval` epochs\n","        if (epoch + 1) % print_interval == 0:\n","            print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item()}\")\n","\n","    # Step 6: Record end time of training\n","    end_time = time.time()\n","\n","    # Step 7: Plot the training loss over time\n","    plt.semilogy(range(1, num_epochs + 1), train_losses, label=\"Training Loss\", marker='o')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    # Print the total training time\n","    training_time = end_time - start_time\n","    print(f\"Training complete! Total training time: {training_time:.2f} seconds\")\n","\n","    # Step 8: Return the trained model\n","    return model"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"6_tzUG_emtBg","executionInfo":{"status":"ok","timestamp":1732452099281,"user_tz":-60,"elapsed":3,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Initialize the GIT_mod model with the dimensionality of the target embeddings\n","# The first argument is the dimensionality of the target node embeddings (x_tgt.shape[1])\n","# The second argument (1) represents the number of RGIT layers in the model\n","GIT_model = RGIT_mod(x_tgt.shape[1], 1)"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"wVo-s7UQssSp","executionInfo":{"status":"ok","timestamp":1732452157490,"user_tz":-60,"elapsed":400,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Reading the training pairs from a CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(train_file, index_col=0)\n","\n","# Extract the 'SrcEntity' and 'TgtEntity' columns as NumPy arrays and convert them to integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)  # Source entity indices\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)  # Target entity indices\n","\n","# Extract the 'Score' column as a NumPy array and convert it to floats\n","tensor_score = df_embbedings['Score'].values.astype(float)  # Scores (labels) indicating if pairs match (1) or not (0)\n","\n","# Convert the NumPy arrays to PyTorch LongTensors (for indices) and FloatTensors (for scores)\n","tensor_term1_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)  # Source entity tensor\n","tensor_term2_o = torch.from_numpy(tensor_term2).type(torch.LongTensor)  # Target entity tensor\n","tensor_score_o = torch.from_numpy(tensor_score).type(torch.FloatTensor)  # Score tensor"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"agHlFNesMVh3","outputId":"1ea6fa40-fff8-4c68-bd04-fe292ce112e7","executionInfo":{"status":"ok","timestamp":1732453915350,"user_tz":-60,"elapsed":1757862,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [10/1000], Training Loss: 0.0016712708165869117\n","Epoch [20/1000], Training Loss: 0.0014094123616814613\n","Epoch [30/1000], Training Loss: 0.0012607572134584188\n","Epoch [40/1000], Training Loss: 0.001158032682724297\n","Epoch [50/1000], Training Loss: 0.001077420311048627\n","Epoch [60/1000], Training Loss: 0.0010102245723828673\n","Epoch [70/1000], Training Loss: 0.0009530358365736902\n","Epoch [80/1000], Training Loss: 0.0009031285881064832\n","Epoch [90/1000], Training Loss: 0.0008599116117693484\n","Epoch [100/1000], Training Loss: 0.0008215750567615032\n","Epoch [110/1000], Training Loss: 0.0007878413307480514\n","Epoch [120/1000], Training Loss: 0.0007579987868666649\n","Epoch [130/1000], Training Loss: 0.0007318439311347902\n","Epoch [140/1000], Training Loss: 0.0007084478274919093\n","Epoch [150/1000], Training Loss: 0.0006879005813971162\n","Epoch [160/1000], Training Loss: 0.0006692704046145082\n","Epoch [170/1000], Training Loss: 0.0006528531666845083\n","Epoch [180/1000], Training Loss: 0.000638019060716033\n","Epoch [190/1000], Training Loss: 0.0006249377620406449\n","Epoch [200/1000], Training Loss: 0.0006131154950708151\n","Epoch [210/1000], Training Loss: 0.0006024641334079206\n","Epoch [220/1000], Training Loss: 0.0005929061444476247\n","Epoch [230/1000], Training Loss: 0.0005840306403115392\n","Epoch [240/1000], Training Loss: 0.0005759295891039073\n","Epoch [250/1000], Training Loss: 0.0005684875650331378\n","Epoch [260/1000], Training Loss: 0.0005615610862150788\n","Epoch [270/1000], Training Loss: 0.0005552042275667191\n","Epoch [280/1000], Training Loss: 0.0005492367199622095\n","Epoch [290/1000], Training Loss: 0.0005435856292024255\n","Epoch [300/1000], Training Loss: 0.0005382148665376008\n","Epoch [310/1000], Training Loss: 0.0005331399734131992\n","Epoch [320/1000], Training Loss: 0.0005283502978272736\n","Epoch [330/1000], Training Loss: 0.0005238704616203904\n","Epoch [340/1000], Training Loss: 0.0005196126294322312\n","Epoch [350/1000], Training Loss: 0.0005155053222551942\n","Epoch [360/1000], Training Loss: 0.0005115197272971272\n","Epoch [370/1000], Training Loss: 0.0005077189416624606\n","Epoch [380/1000], Training Loss: 0.0005039898678660393\n","Epoch [390/1000], Training Loss: 0.0005002503166906536\n","Epoch [400/1000], Training Loss: 0.0004965748521499336\n","Epoch [410/1000], Training Loss: 0.0004930297145619988\n","Epoch [420/1000], Training Loss: 0.0004895235761068761\n","Epoch [430/1000], Training Loss: 0.00048608818906359375\n","Epoch [440/1000], Training Loss: 0.00048271831474266946\n","Epoch [450/1000], Training Loss: 0.00047951171291060746\n","Epoch [460/1000], Training Loss: 0.00047641806304454803\n","Epoch [470/1000], Training Loss: 0.00047332202666439116\n","Epoch [480/1000], Training Loss: 0.00047034176532179117\n","Epoch [490/1000], Training Loss: 0.0004674073134083301\n","Epoch [500/1000], Training Loss: 0.00046446637134067714\n","Epoch [510/1000], Training Loss: 0.00046145819942466915\n","Epoch [520/1000], Training Loss: 0.0004584711277857423\n","Epoch [530/1000], Training Loss: 0.0004554564075078815\n","Epoch [540/1000], Training Loss: 0.00045241325278766453\n","Epoch [550/1000], Training Loss: 0.0004494234162848443\n","Epoch [560/1000], Training Loss: 0.0004465184756554663\n","Epoch [570/1000], Training Loss: 0.0004436260787770152\n","Epoch [580/1000], Training Loss: 0.00044073231401853263\n","Epoch [590/1000], Training Loss: 0.00043786157038994133\n","Epoch [600/1000], Training Loss: 0.0004349817172624171\n","Epoch [610/1000], Training Loss: 0.0004321289306972176\n","Epoch [620/1000], Training Loss: 0.0004291947989258915\n","Epoch [630/1000], Training Loss: 0.0004262780712451786\n","Epoch [640/1000], Training Loss: 0.0004234297957736999\n","Epoch [650/1000], Training Loss: 0.00042066321475431323\n","Epoch [660/1000], Training Loss: 0.0004179232055321336\n","Epoch [670/1000], Training Loss: 0.0004153630288783461\n","Epoch [680/1000], Training Loss: 0.0004128249711357057\n","Epoch [690/1000], Training Loss: 0.0004103686660528183\n","Epoch [700/1000], Training Loss: 0.00040791623177938163\n","Epoch [710/1000], Training Loss: 0.00040542386705055833\n","Epoch [720/1000], Training Loss: 0.0004030531272292137\n","Epoch [730/1000], Training Loss: 0.00040072898264043033\n","Epoch [740/1000], Training Loss: 0.00039842238766141236\n","Epoch [750/1000], Training Loss: 0.000396231742342934\n","Epoch [760/1000], Training Loss: 0.00039409034070558846\n","Epoch [770/1000], Training Loss: 0.0003919380542356521\n","Epoch [780/1000], Training Loss: 0.0003896332927979529\n","Epoch [790/1000], Training Loss: 0.00038737821159884334\n","Epoch [800/1000], Training Loss: 0.0003854768583551049\n","Epoch [810/1000], Training Loss: 0.00038313213735818863\n","Epoch [820/1000], Training Loss: 0.0003810780181083828\n","Epoch [830/1000], Training Loss: 0.00037872555549256504\n","Epoch [840/1000], Training Loss: 0.0003767276357393712\n","Epoch [850/1000], Training Loss: 0.00037433148827403784\n","Epoch [860/1000], Training Loss: 0.00037197256460785866\n","Epoch [870/1000], Training Loss: 0.00036935191019438207\n","Epoch [880/1000], Training Loss: 0.00036693571018986404\n","Epoch [890/1000], Training Loss: 0.0003644235257524997\n","Epoch [900/1000], Training Loss: 0.00036188834928907454\n","Epoch [910/1000], Training Loss: 0.00035931306774728\n","Epoch [920/1000], Training Loss: 0.0003567437524907291\n","Epoch [930/1000], Training Loss: 0.0003544101200532168\n","Epoch [940/1000], Training Loss: 0.0003520420868881047\n","Epoch [950/1000], Training Loss: 0.00035002428921870887\n","Epoch [960/1000], Training Loss: 0.0003478334110695869\n","Epoch [970/1000], Training Loss: 0.0003456070553511381\n","Epoch [980/1000], Training Loss: 0.0003431134100537747\n","Epoch [990/1000], Training Loss: 0.0003408135671634227\n","Epoch [1000/1000], Training Loss: 0.0003386490570846945\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training complete! Total training time: 1757.58 seconds\n"]}],"source":["# Train the GNN model using the provided source and target graph embeddings, edges, and training data\n","trained_model = train_model_gnn(\n","    model=GIT_model,                # The GNN model to be trained (initialized earlier)\n","    x_src=x_src,                    # Source node embeddings (tensor for source graph)\n","    edge_src=edge_src,              # Source graph edges (undirected edge index for source graph)\n","    x_tgt=x_tgt,                    # Target node embeddings (tensor for target graph)\n","    edge_tgt=edge_tgt,              # Target graph edges (undirected edge index for target graph)\n","    tensor_term1=tensor_term1_o,    # Indices of source entities for training\n","    tensor_term2=tensor_term2_o,    # Indices of target entities for training\n","    tensor_score=tensor_score_o,    # Scores (labels) indicating if pairs match (1) or not (0)\n","    learning_rate=0.0001,            # Learning rate for the Adam optimizer\n","    weight_decay_value=1e-4,        # Weight decay for L2 regularization to prevent overfitting\n","    num_epochs=1000,                # Number of training epochs\n","    print_interval=10               # Interval at which to print training progress (every 10 epochs)\n",")"]},{"cell_type":"markdown","metadata":{"id":"MYyhvjcTUaae"},"source":["# GIT Application"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"BZ_VqP6tq6iD","executionInfo":{"status":"ok","timestamp":1732453915928,"user_tz":-60,"elapsed":583,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Determine if a GPU is available and move the computations to it; otherwise, use the CPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Assuming the model has been trained and hyperparameters (x_src, edge_src, x_tgt, edge_tgt) are set\n","\n","# Move the trained GIT_model to the device (GPU or CPU)\n","GIT_model.to(device)\n","\n","# Move the data tensors to the same device (GPU or CPU)\n","x_tgt = x_tgt.to(device)         # Target node embeddings\n","edge_tgt = edge_tgt.to(device)   # Target graph edges\n","x_src = x_src.to(device)         # Source node embeddings\n","edge_src = edge_src.to(device)   # Source graph edges\n","\n","# Set the model to evaluation mode; this disables dropout and batch normalization\n","GIT_model.eval()\n","\n","# Pass the source and target embeddings through the trained GNN model to update the embeddings\n","with torch.no_grad():  # Disable gradient computation (inference mode)\n","    embeddings_tgt = GIT_model(x_tgt, edge_tgt)  # Get updated embeddings for the target graph\n","    embeddings_src = GIT_model(x_src, edge_src)  # Get updated embeddings for the source graph\n","\n","# Detach the embeddings from the computation graph and move them back to the CPU\n","# This step is useful if you need to use the embeddings for tasks outside PyTorch (e.g., saving to disk)\n","embeddings_tgt = embeddings_tgt.detach().cpu()  # Target graph embeddings\n","embeddings_src = embeddings_src.detach().cpu()  # Source graph embeddings\n","\n","# At this point, embeddings_tgt and embeddings_src contain the updated embeddings, ready for downstream tasks"]},{"cell_type":"markdown","metadata":{"id":"uAmLuMtGW9c2"},"source":["# **Mappings Selector**"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"lnFtpUAfJQHl","executionInfo":{"status":"ok","timestamp":1732454872569,"user_tz":-60,"elapsed":1751,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Build an indexed dictionary for the source ontology classes\n","# src_class is the file path to the JSON file containing the source ontology classes\n","indexed_dict_src = build_indexed_dict(src_class)\n","\n","# Build an indexed dictionary for the target ontology classes\n","# tgt_class is the file path to the JSON file containing the target ontology classes\n","indexed_dict_tgt = build_indexed_dict(tgt_class)"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"beipwavuJQHl","executionInfo":{"status":"ok","timestamp":1732454969956,"user_tz":-60,"elapsed":382,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the candidate pairs from a Candidates CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(candidates_Prediction, index_col=0)\n","\n","# Extract the 'SrcEntity' column (source entity indices) and convert it to a NumPy array of integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)\n","\n","# Extract the 'TgtEntity' column (target entity indices) and convert it to a NumPy array of integers\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)\n","\n","# Convert the source entity indices to a PyTorch LongTensor\n","src_entity_tensor_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)\n","\n","# Convert the target entity indices to a PyTorch LongTensor\n","tgt_entity_tenso_or = torch.from_numpy(tensor_term2).type(torch.LongTensor)"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"ECLhmxyKJQHl","executionInfo":{"status":"ok","timestamp":1732454973863,"user_tz":-60,"elapsed":1182,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Select rows from the updated source embeddings based on the indices in src_entity_tensor_o\n","X1_tt = select_rows_by_index(embeddings_src, src_entity_tensor_o)\n","\n","# Select rows from the original source embeddings based on the indices in src_entity_tensor_o\n","X2_tt = select_rows_by_index(x_src, src_entity_tensor_o)\n","\n","# Select rows from the updated target embeddings based on the indices in tgt_entity_tenso_or\n","X3_tt = select_rows_by_index(embeddings_tgt, tgt_entity_tenso_or)\n","\n","# Select rows from the original target embeddings based on the indices in tgt_entity_tenso_or\n","X4_tt = select_rows_by_index(x_tgt, tgt_entity_tenso_or)"]},{"cell_type":"code","source":["# Generate predictions for candidate mappings using the GIT model outputs directly\n","Prediction_with_git(\n","    embeddings_src=embeddings_src,          # Updated source embeddings from GIT\n","    embeddings_tgt=embeddings_tgt,          # Updated target embeddings from GIT\n","    src_entity_tensor_o=src_entity_tensor_o, # Tensor of source entity indices\n","    tgt_entity_tensor_o=tgt_entity_tenso_or, # Tensor of target entity indices\n","    indexed_dict_src=indexed_dict_src,       # Source entity URI mapping\n","    indexed_dict_tgt=indexed_dict_tgt,       # Target entity URI mapping\n","    all_predictions_path=all_predictions_path # Path to save predictions\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UXbpoLNxW1Rm","executionInfo":{"status":"ok","timestamp":1732455013869,"user_tz":-60,"elapsed":5172,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"e608e670-c569-4b74-c364-568212fc28ca"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Predictions saved to /content/gdrive/My Drive/BioGITOM-VLDB/Experiments/neoplas/GN_Ablation/Results/neoplas_all_predictions.tsv\n"]}]},{"cell_type":"code","execution_count":47,"metadata":{"id":"mEc12J-B7D4N","colab":{"base_uri":"https://localhost:8080/"},"outputId":"57fb43dc-350d-42c0-9009-24d84eaee2c7","executionInfo":{"status":"ok","timestamp":1732455155580,"user_tz":-60,"elapsed":14134,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Positive Predictions : 2488\n"]}],"source":["# Filter the highest scoring predictions from the predictions file and save the results to a new file\n","matching_results_df = filter_highest_predictions(\n","    all_predictions_path,  # Path to the file containing all predictions with scores for all candidate pairs\n","    prediction_path        # Path where the filtered predictions with highest scores will be saved\n",")"]},{"cell_type":"markdown","metadata":{"id":"BIx74lNV7D4O"},"source":["# **Evaluation**"]},{"cell_type":"markdown","source":["# Global metrics calculation"],"metadata":{"id":"Pp3IpBBfWn9m"}},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bkOewzXr7D4O","outputId":"0122d470-b479-4bfb-bd3a-f2769c9a1d86","executionInfo":{"status":"ok","timestamp":1732455156754,"user_tz":-60,"elapsed":1175,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Correct Predictions : 1509\n","{'P': 0.607, 'R': 0.567, 'F1': 0.586}\n"]}],"source":["# Retrieve the indices of the ignored classes (from source and target ontologies)\n","ignored_class_index = get_ignored_class_index(src_onto)  # Get ignored class indices from source ontology\n","ignored_class_index.update(get_ignored_class_index(tgt_onto))  # Update with ignored class indices from target ontology\n","\n","# Read the predicted mappings from the prediction results file\n","preds = EntityMapping.read_table_mappings(prediction_path)\n","\n","# Read the reference mappings from the ground truth test file\n","refs = ReferenceMapping.read_table_mappings(f\"{dataset_dir}/refs_equiv/test.tsv\")\n","\n","# Filter the predicted mappings to remove any mappings that involve ignored classes\n","preds = remove_ignored_mappings(preds, ignored_class_index)\n","\n","# Compute the precision, recall, and F1-score by comparing predictions with the reference mappings\n","results = AlignmentEvaluator.f1(preds, refs)\n","\n","preds2 = [p.to_tuple() for p in preds]\n","refs2 = [r.to_tuple() for r in refs]\n","\n","correct= len(set(preds2).intersection(set(refs2)))\n","\n","print(f\"Number of Correct Predictions : {correct}\")\n","\n","# Print the computed precision, recall, and F1-score metrics\n","print(results)"]},{"cell_type":"markdown","source":["# Ranked-based metrics calculation"],"metadata":{"id":"aECB6igZW04C"}},{"cell_type":"code","execution_count":50,"metadata":{"id":"-AK-jADkSbTa","executionInfo":{"status":"ok","timestamp":1732455691477,"user_tz":-60,"elapsed":4888,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the candidate pairs from a Candidates CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(candidates_Rank, index_col=0)\n","\n","# Extract the 'SrcEntity' column (source entity indices) and convert it to a NumPy array of integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)\n","\n","# Extract the 'TgtEntity' column (target entity indices) and convert it to a NumPy array of integers\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)\n","\n","# Convert the source entity indices to a PyTorch LongTensor\n","src_entity_tensor_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)\n","\n","# Convert the target entity indices to a PyTorch LongTensor\n","tgt_entity_tenso_or = torch.from_numpy(tensor_term2).type(torch.LongTensor)"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"oyOzcLv-SbTb","executionInfo":{"status":"ok","timestamp":1732455699419,"user_tz":-60,"elapsed":1119,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Select rows from the updated source embeddings based on the indices in src_entity_tensor_o\n","X1_tt = select_rows_by_index(embeddings_src, src_entity_tensor_o)\n","\n","# Select rows from the original source embeddings based on the indices in src_entity_tensor_o\n","X2_tt = select_rows_by_index(x_src, src_entity_tensor_o)\n","\n","# Select rows from the updated target embeddings based on the indices in tgt_entity_tenso_or\n","X3_tt = select_rows_by_index(embeddings_tgt, tgt_entity_tenso_or)\n","\n","# Select rows from the original target embeddings based on the indices in tgt_entity_tenso_or\n","X4_tt = select_rows_by_index(x_tgt, tgt_entity_tenso_or)"]},{"cell_type":"code","source":["# Perform ranking-based predictions using the trained GatedCombination model\n","# Generate predictions for candidate mappings using the trained GatedCombination model\n","Prediction_with_candidates(\n","    model=trained_model,             # The trained GatedCombination model used to evaluate similarity\n","    X1_tt=X1_tt,                     # Updated source embeddings (after applying the GIT model)\n","    X2_tt=X2_tt,                     # Original source embeddings (before applying the GIT model)\n","    X3_tt=X3_tt,                     # Updated target embeddings (after applying the GIT model)\n","    X4_tt=X4_tt,                     # Original target embeddings (before applying the GIT model)\n","    src_entity_tensor_o=src_entity_tensor_o,  # Tensor of source entity indices used for evaluation\n","    tgt_entity_tensor_o=tgt_entity_tenso_or,  # Tensor of target entity indices used for evaluation\n","    indexed_dict_src=indexed_dict_src,        # Dictionary mapping source entity indices to their URIs\n","    indexed_dict_tgt=indexed_dict_tgt,        # Dictionary mapping target entity indices to their URIs\n","    all_predictions_path=all_predictions_path_ranked, # Path where the ranked predictions will be saved in TSV format\n",")"],"metadata":{"id":"-O2f7X6cSb-m","executionInfo":{"status":"aborted","timestamp":1732453915931,"user_tz":-60,"elapsed":8,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_402seVv7D4O","executionInfo":{"status":"aborted","timestamp":1732453915931,"user_tz":-60,"elapsed":8,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Compute MRR and Hits@k metrics\n","# This function evaluates the predicted rankings against the reference mappings\n","results = compute_mrr_and_hits(\n","    reference_file=test_cands,             # Reference file with true ranks\n","    predicted_file=all_predictions_path_ranked,             # File containing predicted rankings\n","    output_file=formatted_predictions_path,    # File path to save formatted predictions\n","    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",")\n","\n","# Display the computed metrics\n","print(\"MRR and Hits@k Results:\")\n","print(results)  # Output the Mean Reciprocal Rank (MRR) and Hits@k metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wStfa4eZ7D4O","executionInfo":{"status":"aborted","timestamp":1732453915932,"user_tz":-60,"elapsed":1764781,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Call the ranking evaluation function, passing the path to the formatted predictions file.\n","# Ks specifies the evaluation levels, checking if the correct target is within the top K candidates.\n","results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n","print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n","print(results)"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}