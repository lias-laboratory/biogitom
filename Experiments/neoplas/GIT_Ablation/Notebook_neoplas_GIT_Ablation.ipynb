{"cells":[{"cell_type":"markdown","metadata":{"id":"MkAX88H3RNRW"},"source":["# **Package Installation**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SlL2v0xgmFJ-","outputId":"e8d1ba7f-e459-4ba7-df42-6377fffa7882","executionInfo":{"status":"ok","timestamp":1732279607973,"user_tz":-60,"elapsed":202878,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==2.0.0\n","  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.16.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n","  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n","  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n","  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n","  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n","  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n","  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.0.0 (from torch==2.0.0)\n","  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (75.1.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.45.0)\n","Collecting cmake (from triton==2.0.0->torch==2.0.0)\n","  Downloading cmake-3.31.0.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n","Collecting lit (from triton==2.0.0->torch==2.0.0)\n","  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n","Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m974.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cmake-3.31.0.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.8/27.8 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, cmake, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.1+cpu\n","    Uninstalling torch-2.5.1+cpu:\n","      Successfully uninstalled torch-2.5.1+cpu\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.5.1+cpu requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\n","torchvision 0.20.1+cpu requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed cmake-3.31.0.1 lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 triton-2.0.0\n","Collecting torch-geometric==2.4.0\n","  Downloading torch_geometric-2.4.0-py3-none-any.whl.metadata (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (4.66.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (3.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (2.32.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (3.2.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.5.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric==2.4.0) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (2024.8.30)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.4.0) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.4.0) (3.5.0)\n","Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-geometric\n","Successfully installed torch-geometric-2.4.0\n","Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_scatter-2.1.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (494 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_sparse-0.6.18%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-cluster\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_cluster-1.6.3%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (751 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.3/751.3 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-spline-conv\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (208 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n","Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n","Installing collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster\n","Successfully installed torch-cluster-1.6.3+pt20cpu torch-scatter-2.1.2+pt20cpu torch-sparse-0.6.18+pt20cpu torch-spline-conv-1.2.2+pt20cpu\n","Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.5.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.9/208.9 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.4/319.4 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting deeponto\n","  Downloading deeponto-0.9.2-py3-none-any.whl.metadata (15 kB)\n","Collecting JPype1 (from deeponto)\n","  Downloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting yacs (from deeponto)\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deeponto) (2.0.0)\n","Collecting anytree (from deeponto)\n","  Downloading anytree-2.12.1-py3-none-any.whl.metadata (8.1 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from deeponto) (8.1.7)\n","Collecting dill (from deeponto)\n","  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from deeponto) (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deeponto) (1.26.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deeponto) (1.5.2)\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (from deeponto) (4.46.2)\n","Collecting datasets (from deeponto)\n","  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.7.5)\n","Collecting pprintpp (from deeponto)\n","  Downloading pprintpp-0.4.0-py2.py3-none-any.whl.metadata (7.9 kB)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.4.2)\n","Collecting lxml (from deeponto)\n","  Downloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n","Collecting textdistance (from deeponto)\n","  Downloading textdistance-4.6.3-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from deeponto) (7.7.1)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from deeponto) (5.5.6)\n","Collecting enlighten (from deeponto)\n","  Downloading enlighten-1.12.4-py2.py3-none-any.whl.metadata (18 kB)\n","Collecting rdflib (from deeponto)\n","  Downloading rdflib-7.1.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.9.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anytree->deeponto) (1.16.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (18.0.0)\n","Collecting dill (from deeponto)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (4.66.6)\n","Collecting xxhash (from datasets->deeponto)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets->deeponto)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->deeponto)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (3.11.7)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (0.26.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (6.0.2)\n","Collecting blessed>=1.17.7 (from enlighten->deeponto)\n","  Downloading blessed-1.20.0-py2.py3-none-any.whl.metadata (13 kB)\n","Collecting prefixed>=0.3.2 (from enlighten->deeponto)\n","  Downloading prefixed-0.9.0-py2.py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (0.2.0)\n","Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (7.34.0)\n","Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (5.7.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (6.1.12)\n","Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (6.3.3)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->deeponto) (3.6.10)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->deeponto) (3.0.13)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->deeponto) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->deeponto) (2024.11.6)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2024.2)\n","Collecting isodate<1.0.0,>=0.7.2 (from rdflib->deeponto)\n","  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib->deeponto) (3.2.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deeponto) (1.13.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deeponto) (3.5.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (0.13.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.9.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.1.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (75.1.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.4.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (1.13.1)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (2.0.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->deeponto) (0.45.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deeponto) (3.31.0.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deeponto) (18.1.8)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (0.20.3)\n","Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (1.1.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->transformers[torch]->deeponto) (5.9.5)\n","Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.7->enlighten->deeponto) (0.2.13)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.3.1)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (5.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (0.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.18.0)\n","Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->deeponto)\n","  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (5.1.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (3.0.48)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (2.18.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (4.9.0)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.2.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (2024.8.30)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->deeponto) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->deeponto) (0.1.5)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (0.20.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (7.0.5)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.5.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy->deeponto) (3.0.2)\n","Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->deeponto) (5.7.2)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->deeponto) (24.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deeponto) (1.3.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->deeponto) (0.8.4)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel->deeponto) (4.3.6)\n","Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.2.1)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (23.1.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (5.10.4)\n","Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (7.16.4)\n","Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.6.0)\n","Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.3)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.18.1)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.21.0)\n","Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.1.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel->deeponto) (0.7.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (3.0.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->deeponto) (1.14.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (0.1.2)\n","Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.2.4)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.12.3)\n","Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.2.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.7.1)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.3.0)\n","Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.0.2)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.10.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.5.1)\n","Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.4.0)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.20.0)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.23.0)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (21.2.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.5.1)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.21.0)\n","Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.24.0)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.17.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.6)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.22)\n","Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.7.1)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.2.2)\n","Downloading deeponto-0.9.2-py3-none-any.whl (89.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading anytree-2.12.1-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading enlighten-1.12.4-py2.py3-none-any.whl (41 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.8/493.8 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n","Downloading rdflib-7.1.1-py3-none-any.whl (562 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m562.4/562.4 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading textdistance-4.6.3-py3-none-any.whl (31 kB)\n","Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n","Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading prefixed-0.9.0-py2.py3-none-any.whl (13 kB)\n","Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: prefixed, pprintpp, yacs, xxhash, textdistance, lxml, JPype1, jedi, isodate, fsspec, dill, blessed, anytree, rdflib, multiprocess, enlighten, datasets, deeponto\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","Successfully installed JPype1-1.5.1 anytree-2.12.1 blessed-1.20.0 datasets-3.1.0 deeponto-0.9.2 dill-0.3.8 enlighten-1.12.4 fsspec-2024.9.0 isodate-0.7.2 jedi-0.19.2 lxml-5.3.0 multiprocess-0.70.16 pprintpp-0.4.0 prefixed-0.9.0 rdflib-7.1.1 textdistance-4.6.3 xxhash-3.5.0 yacs-0.1.8\n","/bin/bash: line 1: username: No such file or directory\n"]}],"source":["# We assume that PyTorch is already installed in the environment.\n","# If not, this command installs it.\n","!pip install torch==2.0.0\n","\n","# Install PyTorch Geometric, a library for creating graph neural networks using PyTorch.\n","!pip install torch-geometric==2.4.0\n","\n","# Import PyTorch to access its functionalities.\n","import torch\n","\n","# Install additional PyTorch Geometric dependencies for graph processing (scatter, sparse, cluster, spline-conv).\n","# These packages enable operations like sparse tensors and convolutions on graphs.\n","!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","\n","# Reinstall PyTorch Geometric to ensure all dependencies are correctly loaded.\n","!pip install torch-geometric\n","\n","# Retrieve the installed version of PyTorch to ensure compatibility with other packages.\n","torchversion = torch.__version__\n","\n","# Install the latest version of PyTorch Geometric directly from the GitHub repository.\n","# This allows access to the most recent updates and features for graph-based neural networks.\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","\n","# Install DeepOnto, a package specifically designed for ontology matching, particularly useful in biomedical applications.\n","!pip install deeponto\n","\n","# Install a custom version of DeepOnto from a GitHub repository.\n","# The '<username>' part should be replaced with the actual GitHub username of the repository maintainer.\n","!pip install git+https://github.com/<username>/deeponto.git\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"HPAlAgjLMVhw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732280076361,"user_tz":-60,"elapsed":468402,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"c57931b7-df28-4757-93f2-c813682e6dfe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Please enter the maximum memory located to JVM [8g]: 8g\n","\n"]}],"source":["# Import pandas for data manipulation and analysis, such as loading, processing, and saving tabular data.\n","import pandas as pd\n","\n","# Import pickle for saving and loading serialized objects (e.g., trained models or preprocessed data).\n","import pickle\n","\n","# Import function to convert a directed graph to an undirected one, useful for certain graph algorithms.\n","from torch_geometric.utils import to_undirected\n","\n","# Import optimizer module from PyTorch for training models using gradient-based optimization techniques.\n","import torch.optim as optim\n","\n","# Import PyTorch's modules for defining neural network architectures and operations:\n","from torch.nn import (\n","    Linear,       # For linear transformations (dense layers).\n","    Sequential,   # For stacking layers sequentially.\n","    BatchNorm1d,  # For normalizing input within mini-batches.\n","    PReLU,        # Parametric ReLU activation function.\n","    Dropout       # For regularization by randomly dropping connections during training.\n",")\n","\n","# Import functional API from PyTorch for operations like activations and loss functions.\n","import torch.nn.functional as F\n","\n","# Import Matplotlib for visualizations, such as plotting training loss curves.\n","import matplotlib.pyplot as plt\n","\n","# Import PyTorch Geometric's graph convolutional layers:\n","from torch_geometric.nn import GCNConv, GINConv\n","\n","# Import pooling operations for aggregating node embeddings to graph-level representations:\n","from torch_geometric.nn import global_mean_pool, global_add_pool\n","\n","# Import NumPy for numerical operations, such as working with arrays and matrices.\n","import numpy as np\n","\n","# Import time module for measuring execution time of code blocks.\n","import time\n","\n","# Import typing module for specifying types in function arguments and return values.\n","from typing import Optional, Tuple, Union, Callable\n","\n","# Import PyTorch's DataLoader and TensorDataset for handling data batching and loading during training.\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","# Import PyTorch's Parameter class for defining learnable parameters in custom models.\n","from torch.nn import Parameter\n","\n","# Import math module for performing mathematical computations.\n","import math\n","\n","# Import Tensor type from PyTorch for defining and manipulating tensors.\n","from torch import Tensor\n","\n","# Import PyTorch's nn module for defining and building neural network architectures.\n","import torch.nn as nn\n","\n","# Import initialization utilities from PyTorch Geometric for resetting weights and biases in layers.\n","from torch_geometric.nn.inits import reset\n","\n","# Import the base class for defining message-passing layers in graph neural networks (GNNs).\n","from torch_geometric.nn.conv import MessagePassing\n","\n","# Import linear transformation utilities for creating dense representations in graph models.\n","from torch_geometric.nn.dense.linear import Linear\n","\n","# Import typing utilities for defining adjacency matrices and tensor types specific to PyTorch Geometric.\n","from torch_geometric.typing import Adj, OptTensor, PairTensor, SparseTensor\n","\n","# Import softmax function for normalizing attention scores in GNNs.\n","from torch_geometric.utils import softmax\n","\n","# Import initialization utilities for weight initialization (e.g., Glorot initialization).\n","from torch_geometric.nn.inits import glorot, zeros\n","\n","# Import F1 score metric from scikit-learn for evaluating model performance in binary/multi-class tasks.\n","from sklearn.metrics import f1_score\n","\n","# Import JSON module for reading and writing JSON files, useful for storing configuration or ontology data.\n","import json\n","\n","# Import Ontology class from DeepOnto for representing and manipulating ontologies in the pipeline.\n","from deeponto.onto import Ontology\n","\n","# Import tools from DeepOnto for handling Ontology Alignment Evaluation Initiative (OAEI) tasks.\n","from deeponto.align.oaei import *\n","\n","# Import evaluation tools from DeepOnto for assessing alignment results using metrics like precision, recall, and F1.\n","from deeponto.align.evaluation import AlignmentEvaluator\n","\n","# Import mapping utilities from DeepOnto for working with reference mappings and entity pairs.\n","from deeponto.align.mapping import ReferenceMapping, EntityMapping\n","\n","# Import utility function for reading tables (e.g., TSV, CSV) from DeepOnto.\n","from deeponto.utils import read_table\n","\n","# Importing the train_test_split function from sklearn's model_selection module.\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"-abbBHOoRdWl"},"source":["# **Paths Definition**"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AVgl_Bb42naS","outputId":"9a4eb8b7-427e-4b77-bf24-f25076634705","executionInfo":{"status":"ok","timestamp":1732280096896,"user_tz":-60,"elapsed":20542,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# Importing the 'drive' module from Google Colab to interact with Google Drive\n","from google.colab import drive\n","\n","# Mount the user's Google Drive to the Colab environment\n","# After running this, a link will appear to authorize access, and Google Drive will be mounted at '/content/gdrive'\n","drive.mount('/content/gdrive')\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"36ttssQ3W7cx","executionInfo":{"status":"ok","timestamp":1732280096897,"user_tz":-60,"elapsed":7,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Define the source ontology name\n","src_ent = \"snomed.neoplas\"\n","\n","# Define the target ontology name\n","tgt_ent = \"ncit.neoplas\"\n","\n","# Define the task name for this ontology matching process\n","task = \"neoplas\"\n","\n","# Define the weight for the training data\n","# This weight is likely used to balance the training process, giving more emphasis to certain examples.\n","# For instance, a weight of 10.0 could be applied to penalize errors in certain types of predictions more heavily.\n","weight_train= 50.0\n","\n","# Define the similarity threshold for validating matches\n","thres = 0.50"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"SJpvkdwVSQye","executionInfo":{"status":"ok","timestamp":1732280096897,"user_tz":-60,"elapsed":6,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["dir = f\"/content/gdrive/My Drive/BioGITOM-VLDB/Experiments/{task}\"\n","\n","dataset=\"/content/gdrive/My Drive/BioGITOM-VLDB/\"\n","\n","# Define the directory for the dataset containing source and target ontologies\n","dataset_dir = f\"{dataset}/Datasets/{task}\"\n","\n","# Define the data directory for storing embeddings, adjacency matrices, and related files\n","data_dir = f\"{dir}/Data\"\n","\n","# Define the directory for storing the results\n","results_dir = f\"{dir}/GIT_Ablation/Results\""]},{"cell_type":"code","execution_count":6,"metadata":{"id":"eFDNSFef23er","executionInfo":{"status":"ok","timestamp":1732280121203,"user_tz":-60,"elapsed":24312,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Load the Source ontology using the Ontology class from DeepOnto\n","# This initializes the source ontology by loading its .owl file.\n","src_onto = Ontology(f\"{dataset_dir}/{src_ent}.owl\")\n","\n","# Load the Target ontology using the Ontology class from DeepOnto\n","# This initializes the target ontology by loading its .owl file.\n","tgt_onto = Ontology(f\"{dataset_dir}/{tgt_ent}.owl\")\n","\n","# Define the file path for the Source embeddings CSV file\n","# Embeddings for the source ontology entities are stored in this file.\n","src_Emb = f\"{data_dir}/{src_ent}_emb.csv\"\n","\n","# Define the file path for the Target embeddings CSV file\n","# Embeddings for the target ontology entities are stored in this file.\n","tgt_Emb = f\"{data_dir}/{tgt_ent}_emb.csv\"\n","\n","# Define the file path for the Source adjacency matrix\n","# This file represents the relationships (edges) between entities in the source ontology.\n","src_Adjacence = f\"{data_dir}/{src_ent}_adjacence.csv\"\n","\n","# Define the file path for the Target adjacency matrix\n","# This file represents the relationships (edges) between entities in the target ontology.\n","tgt_Adjacence = f\"{data_dir}/{tgt_ent}_adjacence.csv\"\n","\n","# Define the file path for the JSON file containing the Source ontology class labels\n","# This file maps the source ontology entities to their labels or names.\n","src_class = f\"{data_dir}/{src_ent}_classes.json\"\n","\n","# Define the file path for the JSON file containing the Target ontology class labels\n","# This file maps the target ontology entities to their labels or names.\n","tgt_class = f\"{data_dir}/{tgt_ent}_classes.json\"\n","\n","# Define the file path for the train data\n","train_file = f\"{data_dir}/{task}_train_100.csv\"\n","\n","# Define the file path for the test data\n","# The test file contains reference mappings (ground truth) between the source and target ontologies.\n","test_file = f\"{dataset_dir}/refs_equiv/test.tsv\"\n","\n","# Define the file path for the candidate mappings used during testing\n","# This file includes the candidate pairs (source and target entities) for ranking and evaluation.\n","test_cands = f\"{dataset_dir}/refs_equiv/test.cands.tsv\"\n","\n","# Define the file path for the candidate mappings between Source to Target entities\n","# This file contains cleaned, combined, and encoded candidates used for predictions.\n","candidates_Prediction = f\"{data_dir}/{task}_candidates_prediction.csv\"\n","\n","# Define the file path for the candidate mappings between Source to Target entities for ranking-based metrics\n","# This file is used to compute ranking-based metrics like MRR and Hits@k.\n","candidates_Rank = f\"{data_dir}/{task}_candidates.csv\"\n","\n","# Define the path where the prediction results will be saved in TSV format\n","# This file will store the final predictions (mappings) between source and target entities.\n","prediction_path = f\"{results_dir}/{task}_matching_results.tsv\"\n","\n","# Define the path where all prediction results will be saved in TSV format\n","# This file will store detailed prediction results, including all candidate scores.\n","all_predictions_path = f\"{results_dir}/{task}_all_predictions.tsv\"\n","\n","# Define the path where all ranking prediction results will be saved in TSV format\n","# This file will store predictions sorted by rank based on their scores.\n","all_predictions_path_ranked = f\"{results_dir}/{task}_all_predictions_ranked.tsv\"\n","\n","# Define the path where formatted ranking predictions will be saved in TSV format\n","# This file will contain predictions formatted for evaluation using ranking-based metrics.\n","formatted_predictions_path = f\"{results_dir}/{task}_formatted_predictions.tsv\""]},{"cell_type":"markdown","metadata":{"id":"zqEXsgPGMVhw"},"source":["# **GIT Architecture**\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"A_d6XCsUMVhx","executionInfo":{"status":"ok","timestamp":1732280121204,"user_tz":-60,"elapsed":23,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# RGIT class definition which inherits from PyTorch Geometric's MessagePassing class\n","class RGIT(MessagePassing):\n","\n","    _alpha: OptTensor  # Define _alpha as an optional tensor for storing attention weights\n","\n","    def __init__(\n","        self,\n","        nn: Callable,  # Neural network to be used in the final layer of the GNN\n","        in_channels: Union[int, Tuple[int, int]],  # Input dimension, can be a single or pair of integers\n","        out_channels: int,  # Output dimension of the GNN\n","        eps: float = 0.,  # GIN parameter: epsilon for GIN aggregation\n","        train_eps: bool = False,  # GIN parameter: whether epsilon should be learnable\n","        heads: int = 1,  # Transformer parameter: number of attention heads\n","        dropout: float = 0.,  # Dropout rate for attention weights\n","        edge_dim: Optional[int] = None,  # Dimension for edge attributes (optional)\n","        bias: bool = True,  # Whether to use bias in linear layers\n","        root_weight: bool = True,  # GIN parameter: whether to apply root weight in aggregation\n","        **kwargs,  # Additional arguments passed to the parent class\n","    ):\n","        # Set the aggregation type to 'add' and initialize the parent class with node_dim=0\n","        kwargs.setdefault('aggr', 'add')\n","        super().__init__(node_dim=0, **kwargs)\n","\n","        # Initialize input/output dimensions, neural network, and GIN/transformer parameters\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.nn = nn  # Neural network used by the GNN\n","        self.initial_eps = eps  # Initial value of epsilon for GIN\n","\n","        # Set epsilon to be learnable or fixed\n","        if train_eps:\n","            self.eps = torch.nn.Parameter(torch.empty(1))  # Learnable epsilon\n","        else:\n","            self.register_buffer('eps', torch.empty(1))  # Non-learnable epsilon (fixed)\n","\n","        # Initialize transformer-related parameters\n","        self.heads = heads\n","        self.dropout = dropout\n","        self.edge_dim = edge_dim\n","        self._alpha = None  # Placeholder for attention weights\n","\n","        # Handle case where in_channels is a single integer or a tuple\n","        if isinstance(in_channels, int):\n","            in_channels = (in_channels, in_channels)\n","\n","        # Define the linear layers for key, query, and value for the transformer mechanism\n","        self.lin_key = Linear(in_channels[0], heads * out_channels)\n","        self.lin_query = Linear(in_channels[1], heads * out_channels)\n","        self.lin_value = Linear(in_channels[0], heads * out_channels)\n","\n","        # Define linear transformation for edge embeddings if provided\n","        if edge_dim is not None:\n","            self.lin_edge = Linear(edge_dim, heads * out_channels, bias=False)\n","        else:\n","            self.lin_edge = self.register_parameter('lin_edge', None)\n","\n","        # Reset all parameters to their initial values\n","        self.reset_parameters()\n","\n","    # Function to reset model parameters\n","    def reset_parameters(self):\n","        super().reset_parameters()  # Call parent class reset method\n","        self.lin_key.reset_parameters()  # Reset key linear layer\n","        self.lin_query.reset_parameters()  # Reset query linear layer\n","        self.lin_value.reset_parameters()  # Reset value linear layer\n","        if self.edge_dim:\n","            self.lin_edge.reset_parameters()  # Reset edge linear layer if used\n","        reset(self.nn)  # Reset the neural network provided\n","        self.eps.data.fill_(self.initial_eps)  # Initialize epsilon with the starting value\n","\n","    # Forward function defining how the input data flows through the model\n","    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj,\n","                edge_attr: OptTensor = None, return_attention_weights=None):\n","        # Unpack number of heads and output channels\n","        H, C = self.heads, self.out_channels\n","\n","        # If x is a tensor, treat it as a pair of tensors (source and target embeddings)\n","        if isinstance(x, Tensor):\n","            x: PairTensor = (x, x)\n","\n","        # Extract source node embeddings\n","        x_t = x[0]\n","\n","        # Apply linear transformations and reshape query, key, and value for multi-head attention\n","        query = self.lin_query(x[1]).view(-1, H, C)\n","        key = self.lin_key(x[0]).view(-1, H, C)\n","        value = self.lin_value(x[0]).view(-1, H, C)\n","\n","        # Propagate messages through the graph using the propagate function\n","        out = self.propagate(edge_index, query=query, key=key, value=value,\n","                             edge_attr=edge_attr, size=None)\n","\n","        # Retrieve attention weights and reset them\n","        alpha = self._alpha\n","        self._alpha = None  # Reset _alpha after use\n","        out = out.mean(dim=1)  # Take the mean over all attention heads\n","\n","        # Apply GIN aggregation by adding epsilon-scaled original node embeddings\n","        out = out + (1 + self.eps) * x_t\n","        return self.nn(out)  # Pass through the neural network\n","\n","    # Message passing function which calculates attention and combines messages\n","    def message(self, query_i: Tensor, key_j: Tensor, value_j: Tensor,\n","                edge_attr: OptTensor, index: Tensor, ptr: OptTensor,\n","                size_i: Optional[int]) -> Tensor:\n","        # If edge attributes are used, apply linear transformation and add them to the key\n","        if self.lin_edge is not None:\n","            assert edge_attr is not None\n","            edge_attr = self.lin_edge(edge_attr).view(-1, self.heads, self.out_channels)\n","            key_j = key_j + edge_attr\n","\n","        # Calculate attention (alpha) using the dot product between query and key\n","        alpha = (query_i * key_j).sum(dim=-1) / math.sqrt(self.out_channels)\n","        alpha = softmax(alpha, index, ptr, size_i)  # Apply softmax to normalize attention\n","        self._alpha = alpha  # Store attention weights\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)  # Apply dropout\n","\n","        # Calculate the output message by applying attention to the value\n","        out = value_j\n","        if edge_attr is not None:\n","            out = out + edge_attr  # Add edge embeddings to the output if present\n","        out = out * alpha.view(-1, self.heads, 1)  # Scale by attention weights\n","        return out\n","\n","    # String representation function for debugging or printing\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}({self.in_channels}, '\n","                f'{self.out_channels}, heads={self.heads})')"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"qwFv6RgHmGCf","executionInfo":{"status":"ok","timestamp":1732280121204,"user_tz":-60,"elapsed":22,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Define the RGIT_mod class, a multi-layer GNN that uses both RGIT and linear layers\n","class RGIT_mod(torch.nn.Module):\n","    \"\"\"Multi-layer RGIT with optional linear layers\"\"\"\n","\n","    # Initialize the model with hidden dimension, number of RGIT layers, and number of linear layers\n","    def __init__(self, dim_h, num_layers, num_linear_layers=1):\n","        super(RGIT_mod, self).__init__()\n","        self.num_layers = num_layers  # Number of RGIT layers\n","        self.num_linear_layers = num_linear_layers  # Number of linear layers\n","        self.linears = torch.nn.ModuleList()  # List to store linear layers\n","        self.rgit_layers = torch.nn.ModuleList()  # List to store RGIT layers\n","\n","        # Create a list of Linear and PReLU layers (for encoding entity names)\n","        for _ in range(num_linear_layers):\n","            self.linears.append(Linear(dim_h, dim_h))  # Linear transformation layer\n","            self.linears.append(PReLU(num_parameters=dim_h))  # Parametric ReLU activation function\n","\n","        # Create a list of RGIT layers\n","        for _ in range(num_layers):\n","            self.rgit_layers.append(RGIT(  # Each RGIT layer contains a small MLP with Linear and PReLU\n","                Sequential(Linear(dim_h, dim_h), PReLU(num_parameters=dim_h),\n","                           Linear(dim_h, dim_h), PReLU(num_parameters=dim_h)), dim_h, dim_h))\n","\n","    # Forward pass through the model\n","    def forward(self, x, edge_index):\n","        # Apply the linear layers first to the input\n","        for layer in self.linears:\n","            x = layer(x)\n","\n","        # Then apply the RGIT layers for message passing\n","        for layer in self.rgit_layers:\n","            x = layer(x, edge_index)\n","\n","        return x  # Return the final node embeddings after all layers\n"]},{"cell_type":"markdown","metadata":{"id":"zxCn5ztKVztw"},"source":["# **Gated Network Architecture**"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"7MKQUv7o7zay","executionInfo":{"status":"ok","timestamp":1732280121204,"user_tz":-60,"elapsed":22,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Define the GatedCombination class for combining two pairs of embeddings using a gating mechanism\n","class GatedCombination(nn.Module):\n","    def __init__(self, input_dim):\n","        \"\"\"\n","        Initialize the GatedCombination model.\n","\n","        Args:\n","            input_dim (int): The dimensionality of the input embeddings (x1, x2, x3, x4).\n","        \"\"\"\n","        super(GatedCombination, self).__init__()\n","\n","        # Define a linear layer (gate) for combining embeddings x1 and x2 (first pair)\n","        self.gate_A_fc = nn.Linear(input_dim, input_dim)\n","\n","        # Define a linear layer (gate) for combining embeddings x3 and x4 (second pair)\n","        self.gate_B_fc = nn.Linear(input_dim, input_dim)\n","\n","        # A final fully connected layer that outputs a single neuron (binary classification)\n","        self.fc = nn.Linear(1, 1)\n","\n","    def forward(self, x1, x2, x3, x4):\n","        \"\"\"\n","        Forward pass through the gating mechanism and cosine similarity.\n","\n","        Args:\n","            x1 (torch.Tensor): First set of embeddings (source embeddings after update).\n","            x2 (torch.Tensor): Second set of embeddings (original source embeddings).\n","            x3 (torch.Tensor): Third set of embeddings (target embeddings after update).\n","            x4 (torch.Tensor): Fourth set of embeddings (original target embeddings).\n","\n","        Returns:\n","            torch.Tensor: Output of the model (probability score for binary classification).\n","        \"\"\"\n","        # Compute gate values for the first pair (x1 and x2) using a sigmoid activation\n","        gate_values1 = torch.sigmoid(self.gate_A_fc(x1))\n","\n","        # Combine x1 and x2 using the gate values\n","        # The result is a weighted combination of x1 and x2\n","        a = x1 * gate_values1 + x2 * (1 - gate_values1)\n","\n","        # Compute gate values for the second pair (x3 and x4) using a sigmoid activation\n","        gate_values2 = torch.sigmoid(self.gate_B_fc(x3))\n","\n","        # Combine x3 and x4 using the gate values\n","        # The result is a weighted combination of x3 and x4\n","        b = x3 * gate_values2 + x4 * (1 - gate_values2)\n","\n","        # Compute cosine similarity between the combined vectors a and b\n","        x = torch.cosine_similarity(a, b, dim=1)\n","\n","        # Pass the cosine similarity result through a fully connected layer (fc) for classification\n","        # Use a sigmoid activation to output a probability for binary classification\n","        out = torch.sigmoid(self.fc(x.unsqueeze(1)))  # unsqueeze(1) to match the input shape for the fc layer\n","        return out\n","\n"]},{"cell_type":"code","source":["class WeightedBCELoss(nn.Module):\n","    def __init__(self, pos_weight):\n","        \"\"\"\n","        Weighted Binary Cross-Entropy Loss.\n","\n","        Args:\n","            pos_weight (float): Weight for the positive class.\n","        \"\"\"\n","        super(WeightedBCELoss, self).__init__()\n","        self.pos_weight = pos_weight\n","\n","    def forward(self, outputs, targets):\n","        \"\"\"\n","        Args:\n","            outputs (torch.Tensor): Predicted probabilities from the model (after sigmoid).\n","            targets (torch.Tensor): Ground truth labels (0 or 1).\n","\n","        Returns:\n","            torch.Tensor: Computed weighted binary cross-entropy loss.\n","        \"\"\"\n","        # Compute weighted BCE loss\n","        loss = - (self.pos_weight * targets * torch.log(outputs + 1e-8) +\n","                  (1 - targets) * torch.log(1 - outputs + 1e-8))\n","        return loss.mean()"],"metadata":{"id":"PCzq6hHCD8vg","executionInfo":{"status":"ok","timestamp":1732280121204,"user_tz":-60,"elapsed":21,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":11,"metadata":{"id":"4kO42TTCqQZ8","executionInfo":{"status":"ok","timestamp":1732280121204,"user_tz":-60,"elapsed":20,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["class FocalLoss(nn.Module):\n","    def __init__(self, alpha=0.25, gamma=2):\n","        \"\"\"\n","        Focal Loss for binary classification.\n","\n","        Args:\n","            alpha (float): Balancing factor for positive/negative classes.\n","            gamma (float): Focusing parameter for hard examples.\n","        \"\"\"\n","        super(FocalLoss, self).__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","\n","    def forward(self, outputs, targets):\n","        \"\"\"\n","        Args:\n","            outputs (torch.Tensor): Predicted probabilities from the model (after sigmoid).\n","            targets (torch.Tensor): Ground truth labels (0 or 1).\n","\n","        Returns:\n","            torch.Tensor: Computed focal loss.\n","        \"\"\"\n","        # Compute binary cross-entropy loss\n","        bce_loss = F.binary_cross_entropy(outputs, targets, reduction='none')\n","\n","        # Compute modulating factor (1 - p_t)^gamma\n","        pt = torch.where(targets == 1, outputs, 1 - outputs)  # pt = p if y==1 else 1-p\n","        modulating_factor = (1 - pt) ** self.gamma\n","\n","        # Apply alpha and modulating factor\n","        focal_loss = self.alpha * modulating_factor * bce_loss\n","        return focal_loss.mean()"]},{"cell_type":"markdown","metadata":{"id":"aLJ5j9FNMVhy"},"source":["# **Utility functions**"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"k0L86DgUQjMU","executionInfo":{"status":"ok","timestamp":1732280121204,"user_tz":-60,"elapsed":20,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def adjacency_matrix_to_undirected_edge_index(adjacency_matrix):\n","    \"\"\"\n","    Converts an adjacency matrix into an undirected edge index for use in graph-based neural networks.\n","\n","    Args:\n","        adjacency_matrix: A 2D list or array representing the adjacency matrix of a graph.\n","\n","    Returns:\n","        edge_index_undirected: A PyTorch tensor representing the undirected edges.\n","    \"\"\"\n","    # Convert each element in the adjacency matrix to an integer (from boolean or float)\n","    adjacency_matrix = [[int(element) for element in sublist] for sublist in adjacency_matrix]\n","\n","    # Convert the adjacency matrix into a PyTorch LongTensor (used for indexing)\n","    edge_index = torch.tensor(adjacency_matrix, dtype=torch.long)\n","\n","    # Transpose the edge_index tensor so that rows represent edges in the form [source, target]\n","    edge_index = edge_index.t().contiguous()\n","\n","    # Convert the directed edge_index into an undirected edge_index, meaning both directions are added (i.e., (i, j) and (j, i))\n","    edge_index_undirected = to_undirected(edge_index)\n","\n","    return edge_index_undirected  # Return the undirected edge index"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"YvmOxkLcpf9w","executionInfo":{"status":"ok","timestamp":1732280121204,"user_tz":-60,"elapsed":20,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def build_indexed_dict(file_path):\n","    \"\"\"\n","    Builds a dictionary with numeric indexes for each key from a JSON file.\n","\n","    Args:\n","        file_path (str): The path to the JSON file.\n","\n","    Returns:\n","        indexed_dict (dict): A new dictionary where each key from the JSON file is assigned a numeric index.\n","    \"\"\"\n","    # Load the JSON file into a Python dictionary\n","    with open(file_path, 'r') as file:\n","        data = json.load(file)\n","\n","    # Create a new dictionary with numeric indexes as keys and the original JSON keys as values\n","    indexed_dict = {index: key for index, key in enumerate(data.keys())}\n","\n","    return indexed_dict  # Return the newly created dictionary"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"QgFINoPGl9Wg","executionInfo":{"status":"ok","timestamp":1732280121205,"user_tz":-60,"elapsed":20,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def select_rows_by_index(embedding_vector, index_vector):\n","    \"\"\"\n","    Select rows from an embedding vector using an index vector.\n","\n","    Args:\n","        embedding_vector (torch.Tensor): 2D tensor representing the embedding vector with shape [num_rows, embedding_size].\n","        index_vector (torch.Tensor): 1D tensor representing the index vector.\n","\n","    Returns:\n","        torch.Tensor: New tensor with selected rows from the embedding vector.\n","    \"\"\"\n","    # Use torch.index_select to select the desired rows\n","    new_tensor = torch.index_select(embedding_vector, 0, index_vector)\n","\n","    return new_tensor"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"a12L7vEmmCJq","executionInfo":{"status":"ok","timestamp":1732280121205,"user_tz":-60,"elapsed":20,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def contrastive_loss(source_embeddings, target_embeddings, labels, margin=1.0):\n","    \"\"\"\n","    Computes the contrastive loss, a type of loss function used to train models in tasks like matching or similarity learning.\n","\n","    Args:\n","        source_embeddings (torch.Tensor): Embeddings of the source graphs, shape [batch_size, embedding_size].\n","        target_embeddings (torch.Tensor): Embeddings of the target graphs, shape [batch_size, embedding_size].\n","        labels (torch.Tensor): Binary labels indicating if the pairs are matched (1) or not (0), shape [batch_size].\n","        margin (float): Margin value for the contrastive loss. Defaults to 1.0.\n","\n","    Returns:\n","        torch.Tensor: The contrastive loss value.\n","    \"\"\"\n","    # Calculate the pairwise Euclidean distance between source and target embeddings\n","    distances = F.pairwise_distance(source_embeddings, target_embeddings)\n","\n","    # Compute the contrastive loss:\n","    # - For matched pairs (label == 1), the loss is the squared distance between embeddings.\n","    # - For non-matched pairs (label == 0), the loss is based on how far apart the embeddings are,\n","    #   but penalizes them only if the distance is less than the margin.\n","    loss = torch.mean(\n","        labels * 0.4 * distances.pow(2) +  # For positive pairs, minimize the distance (squared)\n","        (1 - labels) * 0.4 * torch.max(torch.zeros_like(distances), margin - distances).pow(2)  # For negative pairs, maximize the distance (up to the margin)\n","    )\n","\n","    return loss  # Return the computed contrastive loss\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"ZhCizXEb7D4N","executionInfo":{"status":"ok","timestamp":1732280121205,"user_tz":-60,"elapsed":19,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def Prediction_with_candidates(model, X1_tt, X2_tt, X3_tt, X4_tt, src_entity_tensor_o, tgt_entity_tensor_o,\n","                                   indexed_dict_src, indexed_dict_tgt, all_predictions_path):\n","    \"\"\"\n","    Evaluates the GatedCombination model using the given embeddings and candidate entity pairs.\n","    Saves the predictions and evaluation results to a file.\n","\n","    Args:\n","        model: Trained GatedCombination model.\n","        X1_tt, X2_tt, X3_tt, X4_tt (torch.Tensor): Tensors of source and target entity embeddings (updated and original).\n","        src_entity_tensor_o, tgt_entity_tensor_o (torch.Tensor): Tensors of source and target entity indices.\n","        indexed_dict_src, indexed_dict_tgt (dict): Dictionaries mapping entity indices to URIs for source and target.\n","        output_file (str): Path to save the predictions and results.\n","        hits_at_k_values (list): List of k-values for which hits@k is evaluated.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    # Move the model to CPU and set it to evaluation mode\n","    model = model.to(\"cpu\")\n","    model.eval()\n","\n","    # Set batch size for evaluation\n","    batch_size_test = 32\n","\n","    # Create a DataLoader for the evaluation data\n","    test_dataset = TensorDataset(X1_tt, X2_tt, X3_tt, X4_tt)\n","    test_dataloader = DataLoader(test_dataset, batch_size=batch_size_test)\n","\n","    # Prepare for collecting predictions and results\n","    predictions = []\n","    results = []\n","    count_predictions = 0  # Counter for predictions above threshold (0.5)\n","\n","    # Measure prediction time\n","    start_time = time.time()\n","\n","    # Disable gradient computation for evaluation\n","    with torch.no_grad():\n","        # Iterate over batches and compute model predictions\n","        for batch_X1, batch_X2, batch_X3, batch_X4 in test_dataloader:\n","            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","            predictions.extend(outputs.cpu().numpy())  # Collect predictions in CPU memory\n","\n","    end_time = time.time()\n","    predicting_time = end_time - start_time\n","    print(f\"Predicting time: {predicting_time:.2f} seconds\")\n","\n","    # Convert tensors to lists for easier iteration\n","    src_indices = src_entity_tensor_o.tolist()\n","    tgt_indices = tgt_entity_tensor_o.tolist()\n","\n","    # Prepare results\n","    for i in range(len(predictions)):\n","        if predictions[i] >= 0.00:  # Consider only predictions greater than 0.5\n","            count_predictions += 1  # Increment the counter\n","\n","            # Map the source and target entity indices to their URIs\n","            src_code = src_indices[i]\n","            tgt_code = tgt_indices[i]\n","\n","            src_uri = indexed_dict_src.get(int(src_code), \"Unknown URI\")\n","            tgt_uri = indexed_dict_tgt.get(int(tgt_code), \"Unknown URI\")\n","\n","            # Get the model's predicted score for the current pair\n","            score = predictions[i]\n","\n","            # Append the results (with URIs instead of entity indices)\n","            results.append({\n","                'SrcEntity': src_uri,\n","                'TgtEntity': tgt_uri,\n","                'Score': score\n","            })\n","\n","    # Convert the results into a pandas DataFrame\n","    df_results = pd.DataFrame(results)\n","\n","    # Save the results to a TSV file\n","    df_results.to_csv(all_predictions_path, sep='\\t', index=False)\n","\n","    print(f\"Predictions saved to {all_predictions_path}\")"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"TslUdYHBcGVj","executionInfo":{"status":"ok","timestamp":1732280121205,"user_tz":-60,"elapsed":19,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def filter_highest_predictions(input_file_path, output_file_path, threshold=thres):\n","    # Load the all predictions file\n","    df = pd.read_csv(input_file_path, sep='\\t')\n","\n","    # Extract the similarity score from the list in the 'Score' column\n","    df['Score'] = df['Score'].apply(lambda x: float(x.strip('[]')))\n","\n","    # Sorting the dataframe by similarity score in descending order\n","    df_sorted = df.sort_values(by='Score', ascending=False).reset_index(drop=True)\n","\n","    # Initialize variables with threshold value\n","    source_concepts = set(df_sorted['SrcEntity'])\n","    target_concepts = set(df_sorted['TgtEntity'])\n","    matched_sources = set()\n","    matched_targets = set()\n","    result = []\n","\n","    # Iterate through the sorted dataframe and find highest correspondences\n","    for _, row in df_sorted.iterrows():\n","        source, target, similarity = row['SrcEntity'], row['TgtEntity'], row['Score']\n","\n","        # Check if the source or target has already been matched and if the similarity is above the threshold\n","        if source not in matched_sources and target not in matched_targets and similarity >= threshold:\n","            # Add the match to the result list\n","            result.append((source, target, similarity))\n","            # Mark the source and target as matched\n","            matched_sources.add(source)\n","            matched_targets.add(target)\n","\n","    # Create a dataframe for the matching results with threshold applied\n","    matching_results_df_threshold = pd.DataFrame(result, columns=['SrcEntity', 'TgtEntity', 'Score'])\n","\n","    # Save the matching results with the updated column names to a new TSV file\n","    matching_results_df_threshold.to_csv(output_file_path, sep='\\t', index=False)\n","\n","    # Print the number of predictions saved\n","    print(f\"Number of Positive Predictions : {len(matching_results_df_threshold)}\")\n","\n","    return matching_results_df_threshold, len(matching_results_df_threshold)"]},{"cell_type":"code","source":["def compute_mrr_and_hits(reference_file, predicted_file, output_file, k_values=[1, 5, 10]):\n","    \"\"\"\n","    Compute MRR and Hits@k for ontology matching predictions based on a reference file.\n","\n","    Args:\n","        reference_file (str): Path to the reference file (test.cands.tsv format).\n","        predicted_file (str): Path to the predictions file with scores.\n","        output_file (str): Path to save the scored results.\n","        k_values (list): List of k values for Hits@k.\n","\n","    Returns:\n","        dict: A dictionary containing MRR and Hits@k metrics.\n","    \"\"\"\n","    # Read the reference mappings\n","    test_candidate_mappings = read_table(reference_file).values.tolist()\n","    ranking_results = []\n","\n","    # Read the predicted scores\n","    predicted_data = pd.read_csv(predicted_file, sep=\"\\t\")\n","    predicted_data[\"Score\"] = predicted_data[\"Score\"].apply(lambda x: float(x.strip(\"[]\")))\n","\n","    # Create a lookup dictionary for predicted scores\n","    score_lookup = {}\n","    for _, row in predicted_data.iterrows():\n","        score_lookup[(row[\"SrcEntity\"], row[\"TgtEntity\"])] = row[\"Score\"]\n","\n","    for src_ref_class, tgt_ref_class, tgt_cands in test_candidate_mappings:\n","        tgt_cands = eval(tgt_cands)  # Convert string to list of candidates\n","        scored_cands = []\n","        for tgt_cand in tgt_cands:\n","            # Retrieve score for each candidate, defaulting to a very low score if not found\n","            matching_score = score_lookup.get((src_ref_class, tgt_cand), -1e9)\n","            scored_cands.append((tgt_cand, matching_score))\n","\n","        # Sort candidates by score in descending order\n","        scored_cands = sorted(scored_cands, key=lambda x: x[1], reverse=True)\n","        ranking_results.append((src_ref_class, tgt_ref_class, scored_cands))\n","\n","    # Save the ranked results to a file\n","    pd.DataFrame(ranking_results, columns=[\"SrcEntity\", \"TgtEntity\", \"TgtCandidates\"]).to_csv(output_file, sep=\"\\t\", index=False)\n","\n","    # Compute MRR and Hits@k\n","    total_entities = len(ranking_results)\n","    reciprocal_ranks = []\n","    hits_at_k = {k: 0 for k in k_values}\n","\n","    for src_entity, tgt_ref_class, tgt_cands in ranking_results:\n","        ranked_candidates = [candidate[0] for candidate in tgt_cands]\n","        if tgt_ref_class in ranked_candidates:\n","            rank = ranked_candidates.index(tgt_ref_class) + 1\n","            reciprocal_ranks.append(1 / rank)\n","            for k in k_values:\n","                if rank <= k:\n","                    hits_at_k[k] += 1\n","        else:\n","            reciprocal_ranks.append(0)\n","\n","    mrr = sum(reciprocal_ranks) / total_entities\n","    hits_at_k = {k: hits / total_entities for k, hits in hits_at_k.items()}\n","\n","    return {\"MRR\": mrr, \"Hits@k\": hits_at_k}"],"metadata":{"id":"_ggVYlTiO_WA","executionInfo":{"status":"ok","timestamp":1732280121205,"user_tz":-60,"elapsed":19,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1HyWMsw1MVhz"},"source":["# **Main Code**\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"IC37FlwGDqGM"},"source":["\n","\n","# Reading semantic node embeddings provided by the ENE"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"FuEfSnw5mod0","executionInfo":{"status":"ok","timestamp":1732280132249,"user_tz":-60,"elapsed":11062,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the source embeddings from a CSV file into a pandas DataFrame\n","df_embbedings_src = pd.read_csv(src_Emb, index_col=0)\n","\n","# Convert the DataFrame to a NumPy array, which will remove the index and store the data as a raw matrix\n","numpy_array = df_embbedings_src.to_numpy()\n","\n","# Convert the NumPy array into a PyTorch FloatTensor, which is the format required for PyTorch operations\n","x_src = torch.FloatTensor(numpy_array)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"STUwqMUXmlG2","executionInfo":{"status":"ok","timestamp":1732280139241,"user_tz":-60,"elapsed":6997,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the target embeddings from a CSV file into a pandas DataFrame\n","df_embbedings_tgt = pd.read_csv(tgt_Emb, index_col=0)\n","\n","# Convert the DataFrame to a NumPy array, which removes the index and converts the data to a raw matrix\n","numpy_array = df_embbedings_tgt.to_numpy()\n","\n","# Convert the NumPy array into a PyTorch FloatTensor, which is required for PyTorch operations\n","x_tgt = torch.FloatTensor(numpy_array)"]},{"cell_type":"markdown","metadata":{"id":"jZIu9P08DqGN"},"source":["# Reading adjacency Matrix"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"pH69Up40mycz","executionInfo":{"status":"ok","timestamp":1732280139621,"user_tz":-60,"elapsed":383,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the source adjacency matrix from a CSV file into a pandas DataFrame\n","df_ma1 = pd.read_csv(src_Adjacence, index_col=0)\n","\n","# Convert the DataFrame to a list of lists (Python native list format)\n","ma1 = df_ma1.values.tolist()"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"hYCmAO5Ymzpl","executionInfo":{"status":"ok","timestamp":1732280140071,"user_tz":-60,"elapsed":454,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the target adjacency matrix from a CSV file into a pandas DataFrame\n","df_ma2 = pd.read_csv(tgt_Adjacence, index_col=0)\n","\n","# Convert the DataFrame to a list of lists (Python native list format)\n","ma2 = df_ma2.values.tolist()"]},{"cell_type":"markdown","metadata":{"id":"PSyksqh3TrU-"},"source":["# Convert Adjacency matrix (in list format) to an undirected edge index"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"uVt-Pce5m5ll","executionInfo":{"status":"ok","timestamp":1732280140071,"user_tz":-60,"elapsed":6,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Convert the source adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n","edge_src = adjacency_matrix_to_undirected_edge_index(ma1)\n","\n","# Convert the target adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n","edge_tgt = adjacency_matrix_to_undirected_edge_index(ma2)"]},{"cell_type":"markdown","metadata":{"id":"H9wMTRdqT4aY"},"source":["# GIT Training"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"eqiEKCLSMVh3","executionInfo":{"status":"ok","timestamp":1732280140071,"user_tz":-60,"elapsed":5,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def train_model_gnn(model, x_src, edge_src, x_tgt, edge_tgt,\n","                    tensor_term1, tensor_term2, tensor_score,\n","                    learning_rate, weight_decay_value, num_epochs, print_interval=10):\n","    \"\"\"\n","    Trains a graph neural network (GNN) model using source and target embeddings and contrastive loss.\n","\n","    Args:\n","        model: The GNN model to be trained.\n","        x_src (torch.Tensor): Source node embeddings.\n","        edge_src (torch.Tensor): Source graph edges.\n","        x_tgt (torch.Tensor): Target node embeddings.\n","        edge_tgt (torch.Tensor): Target graph edges.\n","        tensor_term1 (torch.Tensor): Indices of the source nodes to be compared.\n","        tensor_term2 (torch.Tensor): Indices of the target nodes to be compared.\n","        tensor_score (torch.Tensor): Labels indicating if the pairs are matched (1) or not (0).\n","        learning_rate (float): Learning rate for the optimizer.\n","        weight_decay_value (float): Weight decay (L2 regularization) value for the optimizer.\n","        num_epochs (int): Number of epochs for training.\n","        print_interval (int): Interval at which training progress is printed (every `print_interval` epochs).\n","\n","    Returns:\n","        model: The trained GNN model.\n","    \"\"\"\n","\n","    # Step 1: Set device (GPU or CPU) for computation\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    # Step 2: Move the model and all inputs to the selected device\n","    model.to(device)\n","    x_tgt = x_tgt.to(device)               # Target node embeddings\n","    edge_tgt = edge_tgt.to(device)         # Target graph edges\n","    x_src = x_src.to(device)               # Source node embeddings\n","    edge_src = edge_src.to(device)         # Source graph edges\n","    tensor_term1 = tensor_term1.to(device) # Indices for source nodes\n","    tensor_term2 = tensor_term2.to(device) # Indices for target nodes\n","    tensor_score = tensor_score.to(device) # Ground truth labels\n","\n","    # Step 3: Define optimizer with learning rate and regularization\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay_value)\n","\n","    # Step 4: Initialize list to store training losses\n","    train_losses = []\n","\n","    # Record the start time of training\n","    start_time = time.time()\n","\n","    # Step 5: Training loop\n","    for epoch in range(num_epochs):\n","        # Zero out gradients from the previous iteration\n","        optimizer.zero_grad()\n","\n","        # Forward pass: Compute embeddings for source and target graphs\n","        out1 = model(x_src, edge_src)  # Updated source embeddings\n","        out2 = model(x_tgt, edge_tgt)  # Updated target embeddings\n","\n","        # Extract specific rows of embeddings for terms being compared\n","        src_embeddings = select_rows_by_index(out1, tensor_term1)\n","        tgt_embeddings = select_rows_by_index(out2, tensor_term2)\n","\n","        # Compute contrastive loss based on the embeddings and ground truth labels\n","        loss = contrastive_loss(src_embeddings, tgt_embeddings, tensor_score)\n","\n","        # Backward pass: Compute gradients\n","        loss.backward()\n","\n","        # Update the model's parameters\n","        optimizer.step()\n","\n","        # Append the loss for this iteration to the list\n","        train_losses.append(loss.item())\n","\n","        # Print loss every `print_interval` epochs\n","        if (epoch + 1) % print_interval == 0:\n","            print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item()}\")\n","\n","    # Step 6: Record end time of training\n","    end_time = time.time()\n","\n","    # Step 7: Plot the training loss over time\n","    plt.semilogy(range(1, num_epochs + 1), train_losses, label=\"Training Loss\", marker='o')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    # Print the total training time\n","    training_time = end_time - start_time\n","    print(f\"Training complete! Total training time: {training_time:.2f} seconds\")\n","\n","    # Step 8: Return the trained model\n","    return model"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"6_tzUG_emtBg","executionInfo":{"status":"ok","timestamp":1732280140072,"user_tz":-60,"elapsed":5,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Initialize the GIT_mod model with the dimensionality of the target embeddings\n","# The first argument is the dimensionality of the target node embeddings (x_tgt.shape[1])\n","# The second argument (1) represents the number of RGIT layers in the model\n","GIT_model = RGIT_mod(x_tgt.shape[1], 1)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"wVo-s7UQssSp","executionInfo":{"status":"ok","timestamp":1732280140412,"user_tz":-60,"elapsed":345,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Reading the training pairs from a CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(train_file, index_col=0)\n","\n","# Extract the 'SrcEntity' and 'TgtEntity' columns as NumPy arrays and convert them to integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)  # Source entity indices\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)  # Target entity indices\n","\n","# Extract the 'Score' column as a NumPy array and convert it to floats\n","tensor_score = df_embbedings['Score'].values.astype(float)  # Scores (labels) indicating if pairs match (1) or not (0)\n","\n","# Convert the NumPy arrays to PyTorch LongTensors (for indices) and FloatTensors (for scores)\n","tensor_term1_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)  # Source entity tensor\n","tensor_term2_o = torch.from_numpy(tensor_term2).type(torch.LongTensor)  # Target entity tensor\n","tensor_score_o = torch.from_numpy(tensor_score).type(torch.FloatTensor)  # Score tensor"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"agHlFNesMVh3","outputId":"932f44f4-28c4-44b6-df5c-248a4270c106","executionInfo":{"status":"ok","timestamp":1732281857435,"user_tz":-60,"elapsed":1717026,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [10/1000], Training Loss: 0.0016710218042135239\n","Epoch [20/1000], Training Loss: 0.001408932264894247\n","Epoch [30/1000], Training Loss: 0.0012591452104970813\n","Epoch [40/1000], Training Loss: 0.0011553717777132988\n","Epoch [50/1000], Training Loss: 0.0010737760458141565\n","Epoch [60/1000], Training Loss: 0.0010054978774860501\n","Epoch [70/1000], Training Loss: 0.0009473000536672771\n","Epoch [80/1000], Training Loss: 0.0008970324415713549\n","Epoch [90/1000], Training Loss: 0.0008534895023331046\n","Epoch [100/1000], Training Loss: 0.0008153645903803408\n","Epoch [110/1000], Training Loss: 0.0007817752775736153\n","Epoch [120/1000], Training Loss: 0.0007521072984673083\n","Epoch [130/1000], Training Loss: 0.0007258561090566218\n","Epoch [140/1000], Training Loss: 0.0007024574442766607\n","Epoch [150/1000], Training Loss: 0.0006818191614001989\n","Epoch [160/1000], Training Loss: 0.0006632267613895237\n","Epoch [170/1000], Training Loss: 0.0006465449114330113\n","Epoch [180/1000], Training Loss: 0.0006315554492175579\n","Epoch [190/1000], Training Loss: 0.0006178589537739754\n","Epoch [200/1000], Training Loss: 0.0006056680576875806\n","Epoch [210/1000], Training Loss: 0.0005946217570453882\n","Epoch [220/1000], Training Loss: 0.0005844302359037101\n","Epoch [230/1000], Training Loss: 0.0005752075812779367\n","Epoch [240/1000], Training Loss: 0.0005667968653142452\n","Epoch [250/1000], Training Loss: 0.0005589091451838613\n","Epoch [260/1000], Training Loss: 0.0005515727098099887\n","Epoch [270/1000], Training Loss: 0.0005446876748465002\n","Epoch [280/1000], Training Loss: 0.0005381646915338933\n","Epoch [290/1000], Training Loss: 0.0005320264026522636\n","Epoch [300/1000], Training Loss: 0.000526363612152636\n","Epoch [310/1000], Training Loss: 0.0005210311501286924\n","Epoch [320/1000], Training Loss: 0.0005159677239134908\n","Epoch [330/1000], Training Loss: 0.000511245452798903\n","Epoch [340/1000], Training Loss: 0.000506786978803575\n","Epoch [350/1000], Training Loss: 0.0005025836871936917\n","Epoch [360/1000], Training Loss: 0.0004985253908671439\n","Epoch [370/1000], Training Loss: 0.0004946731496602297\n","Epoch [380/1000], Training Loss: 0.0004908335395157337\n","Epoch [390/1000], Training Loss: 0.00048695129225961864\n","Epoch [400/1000], Training Loss: 0.0004830824036616832\n","Epoch [410/1000], Training Loss: 0.00047922207158990204\n","Epoch [420/1000], Training Loss: 0.0004754441906698048\n","Epoch [430/1000], Training Loss: 0.00047172934864647686\n","Epoch [440/1000], Training Loss: 0.00046806244063191116\n","Epoch [450/1000], Training Loss: 0.0004645479784812778\n","Epoch [460/1000], Training Loss: 0.00046121361083351076\n","Epoch [470/1000], Training Loss: 0.00045795986079610884\n","Epoch [480/1000], Training Loss: 0.0004549160075839609\n","Epoch [490/1000], Training Loss: 0.0004518954665400088\n","Epoch [500/1000], Training Loss: 0.000448967213742435\n","Epoch [510/1000], Training Loss: 0.00044607455492950976\n","Epoch [520/1000], Training Loss: 0.00044332898687571287\n","Epoch [530/1000], Training Loss: 0.0004406119405757636\n","Epoch [540/1000], Training Loss: 0.0004379883175715804\n","Epoch [550/1000], Training Loss: 0.0004354457778390497\n","Epoch [560/1000], Training Loss: 0.00043292995542287827\n","Epoch [570/1000], Training Loss: 0.0004304489411879331\n","Epoch [580/1000], Training Loss: 0.00042788987047970295\n","Epoch [590/1000], Training Loss: 0.00042555612162686884\n","Epoch [600/1000], Training Loss: 0.00042299559572711587\n","Epoch [610/1000], Training Loss: 0.0004206554440315813\n","Epoch [620/1000], Training Loss: 0.0004181192780379206\n","Epoch [630/1000], Training Loss: 0.00041572158806957304\n","Epoch [640/1000], Training Loss: 0.0004132474714424461\n","Epoch [650/1000], Training Loss: 0.0004107634595129639\n","Epoch [660/1000], Training Loss: 0.00040834021638147533\n","Epoch [670/1000], Training Loss: 0.0004058390622958541\n","Epoch [680/1000], Training Loss: 0.00040328275645151734\n","Epoch [690/1000], Training Loss: 0.0004007166135124862\n","Epoch [700/1000], Training Loss: 0.0003982917114626616\n","Epoch [710/1000], Training Loss: 0.0003959706227760762\n","Epoch [720/1000], Training Loss: 0.000393522233935073\n","Epoch [730/1000], Training Loss: 0.0003911982348654419\n","Epoch [740/1000], Training Loss: 0.00038890240830369294\n","Epoch [750/1000], Training Loss: 0.00038671898073516786\n","Epoch [760/1000], Training Loss: 0.0003845782484859228\n","Epoch [770/1000], Training Loss: 0.0003824129526037723\n","Epoch [780/1000], Training Loss: 0.00038027673144824803\n","Epoch [790/1000], Training Loss: 0.00037805267493240535\n","Epoch [800/1000], Training Loss: 0.00037596002221107483\n","Epoch [810/1000], Training Loss: 0.00037370697828009725\n","Epoch [820/1000], Training Loss: 0.00037197969504632056\n","Epoch [830/1000], Training Loss: 0.00036963573074899614\n","Epoch [840/1000], Training Loss: 0.00036784872645512223\n","Epoch [850/1000], Training Loss: 0.00036577286664396524\n","Epoch [860/1000], Training Loss: 0.0003638191847130656\n","Epoch [870/1000], Training Loss: 0.00036191329127177596\n","Epoch [880/1000], Training Loss: 0.0003601547214202583\n","Epoch [890/1000], Training Loss: 0.0003584643709473312\n","Epoch [900/1000], Training Loss: 0.000356921722413972\n","Epoch [910/1000], Training Loss: 0.0003555675211828202\n","Epoch [920/1000], Training Loss: 0.00035411459975875914\n","Epoch [930/1000], Training Loss: 0.0003526787331793457\n","Epoch [940/1000], Training Loss: 0.0003509788366500288\n","Epoch [950/1000], Training Loss: 0.0003495490236673504\n","Epoch [960/1000], Training Loss: 0.0003478949947748333\n","Epoch [970/1000], Training Loss: 0.0003463251341599971\n","Epoch [980/1000], Training Loss: 0.00034491182304918766\n","Epoch [990/1000], Training Loss: 0.00034355735988356173\n","Epoch [1000/1000], Training Loss: 0.0003423502785153687\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training complete! Total training time: 1715.87 seconds\n"]}],"source":["# Train the GNN model using the provided source and target graph embeddings, edges, and training data\n","trained_model = train_model_gnn(\n","    model=GIT_model,                # The GNN model to be trained (initialized earlier)\n","    x_src=x_src,                    # Source node embeddings (tensor for source graph)\n","    edge_src=edge_src,              # Source graph edges (undirected edge index for source graph)\n","    x_tgt=x_tgt,                    # Target node embeddings (tensor for target graph)\n","    edge_tgt=edge_tgt,              # Target graph edges (undirected edge index for target graph)\n","    tensor_term1=tensor_term1_o,    # Indices of source entities for training\n","    tensor_term2=tensor_term2_o,    # Indices of target entities for training\n","    tensor_score=tensor_score_o,    # Scores (labels) indicating if pairs match (1) or not (0)\n","    learning_rate=0.0001,            # Learning rate for the Adam optimizer\n","    weight_decay_value=1e-4,        # Weight decay for L2 regularization to prevent overfitting\n","    num_epochs=1000,                # Number of training epochs\n","    print_interval=10               # Interval at which to print training progress (every 10 epochs)\n",")"]},{"cell_type":"markdown","metadata":{"id":"MYyhvjcTUaae"},"source":["# GIT Application"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"BZ_VqP6tq6iD","executionInfo":{"status":"ok","timestamp":1732281857800,"user_tz":-60,"elapsed":369,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Determine if a GPU is available and move the computations to it; otherwise, use the CPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Assuming the model has been trained and hyperparameters (x_src, edge_src, x_tgt, edge_tgt) are set\n","\n","# Move the trained GIT_model to the device (GPU or CPU)\n","GIT_model.to(device)\n","\n","# Move the data tensors to the same device (GPU or CPU)\n","x_tgt = x_tgt.to(device)         # Target node embeddings\n","edge_tgt = edge_tgt.to(device)   # Target graph edges\n","x_src = x_src.to(device)         # Source node embeddings\n","edge_src = edge_src.to(device)   # Source graph edges\n","\n","# Set the model to evaluation mode; this disables dropout and batch normalization\n","GIT_model.eval()\n","\n","# Pass the source and target embeddings through the trained GNN model to update the embeddings\n","with torch.no_grad():  # Disable gradient computation (inference mode)\n","    embeddings_tgt = GIT_model(x_tgt, edge_tgt)  # Get updated embeddings for the target graph\n","    embeddings_src = GIT_model(x_src, edge_src)  # Get updated embeddings for the source graph\n","\n","# Detach the embeddings from the computation graph and move them back to the CPU\n","# This step is useful if you need to use the embeddings for tasks outside PyTorch (e.g., saving to disk)\n","embeddings_tgt = embeddings_tgt.detach().cpu()  # Target graph embeddings\n","embeddings_src = embeddings_src.detach().cpu()  # Source graph embeddings\n","\n","# At this point, embeddings_tgt and embeddings_src contain the updated embeddings, ready for downstream tasks"]},{"cell_type":"markdown","metadata":{"id":"Og5fdoGJrTCG"},"source":["# Selecting embedding pairs to train the Gated Network"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"J0nTwc-dnjLn","executionInfo":{"status":"ok","timestamp":1732281858135,"user_tz":-60,"elapsed":338,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the training pairs from a CSV file into a pandas DataFrame\n","df_embeddings = pd.read_csv(train_file, index_col=0)\n","\n","# Extract columns and convert to NumPy arrays\n","tensor_term1 = df_embeddings['SrcEntity'].values.astype(int)  # Source entity indices\n","tensor_term2 = df_embeddings['TgtEntity'].values.astype(int)  # Target entity indices\n","tensor_score = df_embeddings['Score'].values.astype(float)  # Matching scores\n","\n","# Split data into training and validation sets\n","tensor_term1_train, tensor_term1_val, tensor_term2_train, tensor_term2_val, tensor_score_train, tensor_score_val = train_test_split(\n","    tensor_term1, tensor_term2, tensor_score, test_size=0.3, random_state=42\n",")\n","\n","# Convert split data to PyTorch tensors\n","tensor_term1_train = torch.from_numpy(tensor_term1_train).type(torch.LongTensor)\n","tensor_term2_train = torch.from_numpy(tensor_term2_train).type(torch.LongTensor)\n","tensor_score_train = torch.from_numpy(tensor_score_train).type(torch.FloatTensor)\n","\n","tensor_term1_val = torch.from_numpy(tensor_term1_val).type(torch.LongTensor)\n","tensor_term2_val = torch.from_numpy(tensor_term2_val).type(torch.LongTensor)\n","tensor_score_val = torch.from_numpy(tensor_score_val).type(torch.FloatTensor)\n","\n","# Move the embeddings back to the CPU if not already there\n","x_tgt = x_tgt.cpu()  # Target node embeddings\n","x_src = x_src.cpu()  # Source node embeddings\n","\n","# x_src: Original source embeddings\n","# x_tgt: Original target embeddings\n","X1_train = select_rows_by_index(x_src, tensor_term1_train)  # Use original source embeddings\n","X2_train = select_rows_by_index(x_src, tensor_term1_train)\n","X3_train = select_rows_by_index(x_tgt, tensor_term2_train)  # Use original target embeddings\n","X4_train = select_rows_by_index(x_tgt, tensor_term2_train)\n","\n","X1_val = select_rows_by_index(x_src, tensor_term1_val)\n","X2_val = select_rows_by_index(x_src, tensor_term1_val)\n","X3_val = select_rows_by_index(x_tgt, tensor_term2_val)\n","X4_val = select_rows_by_index(x_tgt, tensor_term2_val)"]},{"cell_type":"code","source":["positive_weight = len(tensor_score_train) / (weight_train * tensor_score_train.sum())"],"metadata":{"id":"wR3PbrbBETJA","executionInfo":{"status":"ok","timestamp":1732281858135,"user_tz":-60,"elapsed":5,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fNdCgaTMExPK"},"source":["# Gated Network Training"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"Gof1eIPIWSVU","executionInfo":{"status":"ok","timestamp":1732281858135,"user_tz":-60,"elapsed":4,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def train_gated_combination_model(X1_t, X2_t, X3_t, X4_t, tensor_score_o,\n","                                  X1_val, X2_val, X3_val, X4_val, tensor_score_val,\n","                                  epochs=120, batch_size=32, learning_rate=0.001, weight_decay=1e-5):\n","    \"\"\"\n","    Trains the GatedCombination model with training and validation data, using ReduceLROnPlateau scheduler.\n","    \"\"\"\n","\n","    # Create datasets and DataLoaders\n","    train_dataset = TensorDataset(X1_t, X2_t, X3_t, X4_t, tensor_score_o)\n","    val_dataset = TensorDataset(X1_val, X2_val, X3_val, X4_val, tensor_score_val)\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = GatedCombination(X1_t.shape[1]).to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","\n","    # Use ReduceLROnPlateau scheduler\n","    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n","\n","    criterion = WeightedBCELoss(pos_weight=positive_weight).to(device)\n","\n","    train_losses, val_losses = [], []\n","\n","    start_time = time.time()\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        total_train_loss, y_true_train, y_pred_train = 0.0, [], []\n","\n","        for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in train_loader:\n","            batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (batch_X1.to(device), batch_X2.to(device),\n","                                                               batch_X3.to(device), batch_X4.to(device), batch_y.to(device))\n","            optimizer.zero_grad()\n","            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","            loss = criterion(outputs, batch_y.unsqueeze(1).float())\n","            loss.backward()\n","            optimizer.step()\n","            total_train_loss += loss.item()\n","            y_true_train.extend(batch_y.cpu().numpy())\n","            y_pred_train.extend((outputs > 0.2).float().cpu().numpy())\n","\n","        train_f1 = f1_score(y_true_train, y_pred_train)\n","        train_loss = total_train_loss / len(train_loader)\n","        train_losses.append(train_loss)\n","\n","        # Validation phase\n","        model.eval()\n","        total_val_loss, y_true_val, y_pred_val = 0.0, [], []\n","        with torch.no_grad():\n","            for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in val_loader:\n","                batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (batch_X1.to(device), batch_X2.to(device),\n","                                                                   batch_X3.to(device), batch_X4.to(device), batch_y.to(device))\n","                outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","                val_loss = criterion(outputs, batch_y.unsqueeze(1).float())\n","                total_val_loss += val_loss.item()\n","                y_true_val.extend(batch_y.cpu().numpy())\n","                y_pred_val.extend((outputs > 0.4).float().cpu().numpy())\n","\n","        val_f1 = f1_score(y_true_val, y_pred_val)\n","        avg_val_loss = total_val_loss / len(val_loader)\n","        val_losses.append(avg_val_loss)\n","\n","        # Step the scheduler with validation loss\n","        scheduler.step(avg_val_loss)\n","\n","        # Print training and validation metrics\n","        print(f\"Epoch [{epoch + 1}/{epochs}] Training Loss: {train_loss:.4f}, F1 Score: {train_f1:.4f} | \"\n","              f\"Validation Loss: {avg_val_loss:.4f}, F1 Score: {val_f1:.4f}\")\n","\n","    end_time = time.time()\n","\n","    # Plotting\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(train_losses, label=\"Training Loss\", marker='o')\n","    plt.plot(val_losses, label=\"Validation Loss\", marker='x')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    print(f\"Training complete! Total time: {end_time - start_time:.2f} seconds\")\n","    return model"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"l11dgb8ei69T","outputId":"0f92e43b-c411-441a-bb6c-542ae9375d87","executionInfo":{"status":"ok","timestamp":1732285460667,"user_tz":-60,"elapsed":3602535,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/100] Training Loss: 0.2516, F1 Score: 0.0178 | Validation Loss: 0.1403, F1 Score: 0.0000\n","Epoch [2/100] Training Loss: 0.1205, F1 Score: 0.0000 | Validation Loss: 0.1151, F1 Score: 0.0000\n","Epoch [3/100] Training Loss: 0.1085, F1 Score: 0.0000 | Validation Loss: 0.1093, F1 Score: 0.0000\n","Epoch [4/100] Training Loss: 0.1035, F1 Score: 0.0000 | Validation Loss: 0.1046, F1 Score: 0.0000\n","Epoch [5/100] Training Loss: 0.0989, F1 Score: 0.0000 | Validation Loss: 0.0999, F1 Score: 0.0000\n","Epoch [6/100] Training Loss: 0.0945, F1 Score: 0.0000 | Validation Loss: 0.0954, F1 Score: 0.0000\n","Epoch [7/100] Training Loss: 0.0903, F1 Score: 0.0000 | Validation Loss: 0.0912, F1 Score: 0.0000\n","Epoch [8/100] Training Loss: 0.0862, F1 Score: 0.0000 | Validation Loss: 0.0871, F1 Score: 0.0000\n","Epoch [9/100] Training Loss: 0.0823, F1 Score: 0.0000 | Validation Loss: 0.0831, F1 Score: 0.0000\n","Epoch [10/100] Training Loss: 0.0786, F1 Score: 0.0000 | Validation Loss: 0.0794, F1 Score: 0.0000\n","Epoch [11/100] Training Loss: 0.0750, F1 Score: 0.0000 | Validation Loss: 0.0758, F1 Score: 0.0000\n","Epoch [12/100] Training Loss: 0.0717, F1 Score: 0.0000 | Validation Loss: 0.0724, F1 Score: 0.0000\n","Epoch [13/100] Training Loss: 0.0684, F1 Score: 0.0000 | Validation Loss: 0.0691, F1 Score: 0.0000\n","Epoch [14/100] Training Loss: 0.0653, F1 Score: 0.0349 | Validation Loss: 0.0659, F1 Score: 0.0000\n","Epoch [15/100] Training Loss: 0.0623, F1 Score: 0.1989 | Validation Loss: 0.0630, F1 Score: 0.0000\n","Epoch [16/100] Training Loss: 0.0596, F1 Score: 0.4267 | Validation Loss: 0.0602, F1 Score: 0.0000\n","Epoch [17/100] Training Loss: 0.0570, F1 Score: 0.5587 | Validation Loss: 0.0576, F1 Score: 0.0000\n","Epoch [18/100] Training Loss: 0.0545, F1 Score: 0.6433 | Validation Loss: 0.0552, F1 Score: 0.0056\n","Epoch [19/100] Training Loss: 0.0522, F1 Score: 0.6996 | Validation Loss: 0.0529, F1 Score: 0.0334\n","Epoch [20/100] Training Loss: 0.0501, F1 Score: 0.7369 | Validation Loss: 0.0507, F1 Score: 0.1567\n","Epoch [21/100] Training Loss: 0.0481, F1 Score: 0.7696 | Validation Loss: 0.0487, F1 Score: 0.2696\n","Epoch [22/100] Training Loss: 0.0462, F1 Score: 0.7897 | Validation Loss: 0.0468, F1 Score: 0.3619\n","Epoch [23/100] Training Loss: 0.0444, F1 Score: 0.8078 | Validation Loss: 0.0451, F1 Score: 0.4415\n","Epoch [24/100] Training Loss: 0.0428, F1 Score: 0.8152 | Validation Loss: 0.0434, F1 Score: 0.5219\n","Epoch [25/100] Training Loss: 0.0413, F1 Score: 0.8340 | Validation Loss: 0.0419, F1 Score: 0.5726\n","Epoch [26/100] Training Loss: 0.0399, F1 Score: 0.8359 | Validation Loss: 0.0406, F1 Score: 0.6090\n","Epoch [27/100] Training Loss: 0.0386, F1 Score: 0.8381 | Validation Loss: 0.0393, F1 Score: 0.6358\n","Epoch [28/100] Training Loss: 0.0374, F1 Score: 0.8375 | Validation Loss: 0.0381, F1 Score: 0.6565\n","Epoch [29/100] Training Loss: 0.0363, F1 Score: 0.8354 | Validation Loss: 0.0370, F1 Score: 0.6913\n","Epoch [30/100] Training Loss: 0.0352, F1 Score: 0.8365 | Validation Loss: 0.0359, F1 Score: 0.7181\n","Epoch [31/100] Training Loss: 0.0343, F1 Score: 0.8343 | Validation Loss: 0.0350, F1 Score: 0.7394\n","Epoch [32/100] Training Loss: 0.0334, F1 Score: 0.8306 | Validation Loss: 0.0341, F1 Score: 0.7565\n","Epoch [33/100] Training Loss: 0.0326, F1 Score: 0.8300 | Validation Loss: 0.0333, F1 Score: 0.7543\n","Epoch [34/100] Training Loss: 0.0318, F1 Score: 0.8295 | Validation Loss: 0.0325, F1 Score: 0.7770\n","Epoch [35/100] Training Loss: 0.0311, F1 Score: 0.8243 | Validation Loss: 0.0318, F1 Score: 0.7811\n","Epoch [36/100] Training Loss: 0.0304, F1 Score: 0.8256 | Validation Loss: 0.0312, F1 Score: 0.7860\n","Epoch [37/100] Training Loss: 0.0298, F1 Score: 0.8231 | Validation Loss: 0.0305, F1 Score: 0.7900\n","Epoch [38/100] Training Loss: 0.0293, F1 Score: 0.8237 | Validation Loss: 0.0299, F1 Score: 0.7980\n","Epoch [39/100] Training Loss: 0.0287, F1 Score: 0.8234 | Validation Loss: 0.0294, F1 Score: 0.8059\n","Epoch [40/100] Training Loss: 0.0282, F1 Score: 0.8236 | Validation Loss: 0.0289, F1 Score: 0.8130\n","Epoch [41/100] Training Loss: 0.0277, F1 Score: 0.8204 | Validation Loss: 0.0284, F1 Score: 0.8130\n","Epoch [42/100] Training Loss: 0.0273, F1 Score: 0.8204 | Validation Loss: 0.0280, F1 Score: 0.8130\n","Epoch [43/100] Training Loss: 0.0269, F1 Score: 0.8203 | Validation Loss: 0.0275, F1 Score: 0.8169\n","Epoch [44/100] Training Loss: 0.0265, F1 Score: 0.8160 | Validation Loss: 0.0272, F1 Score: 0.8169\n","Epoch [45/100] Training Loss: 0.0261, F1 Score: 0.8187 | Validation Loss: 0.0268, F1 Score: 0.8194\n","Epoch [46/100] Training Loss: 0.0258, F1 Score: 0.8128 | Validation Loss: 0.0264, F1 Score: 0.8213\n","Epoch [47/100] Training Loss: 0.0254, F1 Score: 0.8116 | Validation Loss: 0.0261, F1 Score: 0.8218\n","Epoch [48/100] Training Loss: 0.0251, F1 Score: 0.8096 | Validation Loss: 0.0258, F1 Score: 0.8256\n","Epoch [49/100] Training Loss: 0.0248, F1 Score: 0.8086 | Validation Loss: 0.0255, F1 Score: 0.8275\n","Epoch [50/100] Training Loss: 0.0246, F1 Score: 0.8064 | Validation Loss: 0.0252, F1 Score: 0.8280\n","Epoch [51/100] Training Loss: 0.0243, F1 Score: 0.8060 | Validation Loss: 0.0250, F1 Score: 0.8310\n","Epoch [52/100] Training Loss: 0.0240, F1 Score: 0.8073 | Validation Loss: 0.0248, F1 Score: 0.8299\n","Epoch [53/100] Training Loss: 0.0238, F1 Score: 0.8050 | Validation Loss: 0.0245, F1 Score: 0.8297\n","Epoch [54/100] Training Loss: 0.0236, F1 Score: 0.8049 | Validation Loss: 0.0243, F1 Score: 0.8315\n","Epoch [55/100] Training Loss: 0.0234, F1 Score: 0.8059 | Validation Loss: 0.0240, F1 Score: 0.8333\n","Epoch [56/100] Training Loss: 0.0232, F1 Score: 0.8047 | Validation Loss: 0.0238, F1 Score: 0.8320\n","Epoch [57/100] Training Loss: 0.0230, F1 Score: 0.8026 | Validation Loss: 0.0237, F1 Score: 0.8320\n","Epoch [58/100] Training Loss: 0.0228, F1 Score: 0.8021 | Validation Loss: 0.0235, F1 Score: 0.8320\n","Epoch [59/100] Training Loss: 0.0226, F1 Score: 0.8021 | Validation Loss: 0.0233, F1 Score: 0.8320\n","Epoch [60/100] Training Loss: 0.0225, F1 Score: 0.8040 | Validation Loss: 0.0231, F1 Score: 0.8313\n","Epoch [61/100] Training Loss: 0.0223, F1 Score: 0.8014 | Validation Loss: 0.0230, F1 Score: 0.8313\n","Epoch [62/100] Training Loss: 0.0222, F1 Score: 0.8016 | Validation Loss: 0.0228, F1 Score: 0.8287\n","Epoch [63/100] Training Loss: 0.0220, F1 Score: 0.8002 | Validation Loss: 0.0227, F1 Score: 0.8274\n","Epoch [64/100] Training Loss: 0.0219, F1 Score: 0.8009 | Validation Loss: 0.0225, F1 Score: 0.8279\n","Epoch [65/100] Training Loss: 0.0218, F1 Score: 0.7991 | Validation Loss: 0.0224, F1 Score: 0.8279\n","Epoch [66/100] Training Loss: 0.0216, F1 Score: 0.7975 | Validation Loss: 0.0223, F1 Score: 0.8274\n","Epoch [67/100] Training Loss: 0.0215, F1 Score: 0.7974 | Validation Loss: 0.0222, F1 Score: 0.8279\n","Epoch [68/100] Training Loss: 0.0214, F1 Score: 0.7947 | Validation Loss: 0.0221, F1 Score: 0.8287\n","Epoch [69/100] Training Loss: 0.0213, F1 Score: 0.8021 | Validation Loss: 0.0219, F1 Score: 0.8272\n","Epoch [70/100] Training Loss: 0.0212, F1 Score: 0.8007 | Validation Loss: 0.0218, F1 Score: 0.8308\n","Epoch [71/100] Training Loss: 0.0211, F1 Score: 0.7954 | Validation Loss: 0.0217, F1 Score: 0.8308\n","Epoch [72/100] Training Loss: 0.0210, F1 Score: 0.7949 | Validation Loss: 0.0216, F1 Score: 0.8290\n","Epoch [73/100] Training Loss: 0.0209, F1 Score: 0.7947 | Validation Loss: 0.0215, F1 Score: 0.8308\n","Epoch [74/100] Training Loss: 0.0208, F1 Score: 0.7970 | Validation Loss: 0.0214, F1 Score: 0.8344\n","Epoch [75/100] Training Loss: 0.0207, F1 Score: 0.7954 | Validation Loss: 0.0213, F1 Score: 0.8318\n","Epoch [76/100] Training Loss: 0.0206, F1 Score: 0.7925 | Validation Loss: 0.0213, F1 Score: 0.8344\n","Epoch [77/100] Training Loss: 0.0206, F1 Score: 0.7933 | Validation Loss: 0.0212, F1 Score: 0.8311\n","Epoch [78/100] Training Loss: 0.0205, F1 Score: 0.7879 | Validation Loss: 0.0211, F1 Score: 0.8318\n","Epoch [79/100] Training Loss: 0.0204, F1 Score: 0.7947 | Validation Loss: 0.0210, F1 Score: 0.8336\n","Epoch [80/100] Training Loss: 0.0203, F1 Score: 0.7914 | Validation Loss: 0.0210, F1 Score: 0.8336\n","Epoch [81/100] Training Loss: 0.0203, F1 Score: 0.7938 | Validation Loss: 0.0209, F1 Score: 0.8311\n","Epoch [82/100] Training Loss: 0.0202, F1 Score: 0.7959 | Validation Loss: 0.0208, F1 Score: 0.8298\n","Epoch [83/100] Training Loss: 0.0201, F1 Score: 0.7889 | Validation Loss: 0.0207, F1 Score: 0.8311\n","Epoch [84/100] Training Loss: 0.0201, F1 Score: 0.7931 | Validation Loss: 0.0207, F1 Score: 0.8311\n","Epoch [85/100] Training Loss: 0.0200, F1 Score: 0.7931 | Validation Loss: 0.0206, F1 Score: 0.8298\n","Epoch [86/100] Training Loss: 0.0199, F1 Score: 0.7906 | Validation Loss: 0.0206, F1 Score: 0.8316\n","Epoch [87/100] Training Loss: 0.0199, F1 Score: 0.7909 | Validation Loss: 0.0205, F1 Score: 0.8316\n","Epoch [88/100] Training Loss: 0.0198, F1 Score: 0.7902 | Validation Loss: 0.0204, F1 Score: 0.8316\n","Epoch [89/100] Training Loss: 0.0198, F1 Score: 0.7925 | Validation Loss: 0.0204, F1 Score: 0.8361\n","Epoch [90/100] Training Loss: 0.0197, F1 Score: 0.7854 | Validation Loss: 0.0203, F1 Score: 0.8316\n","Epoch [91/100] Training Loss: 0.0197, F1 Score: 0.7891 | Validation Loss: 0.0203, F1 Score: 0.8351\n","Epoch [92/100] Training Loss: 0.0196, F1 Score: 0.7889 | Validation Loss: 0.0202, F1 Score: 0.8369\n","Epoch [93/100] Training Loss: 0.0196, F1 Score: 0.7847 | Validation Loss: 0.0202, F1 Score: 0.8316\n","Epoch [94/100] Training Loss: 0.0195, F1 Score: 0.7893 | Validation Loss: 0.0201, F1 Score: 0.8369\n","Epoch [95/100] Training Loss: 0.0195, F1 Score: 0.7887 | Validation Loss: 0.0201, F1 Score: 0.8369\n","Epoch [96/100] Training Loss: 0.0194, F1 Score: 0.7842 | Validation Loss: 0.0201, F1 Score: 0.8316\n","Epoch [97/100] Training Loss: 0.0194, F1 Score: 0.7905 | Validation Loss: 0.0200, F1 Score: 0.8356\n","Epoch [98/100] Training Loss: 0.0194, F1 Score: 0.7878 | Validation Loss: 0.0200, F1 Score: 0.8361\n","Epoch [99/100] Training Loss: 0.0193, F1 Score: 0.7838 | Validation Loss: 0.0199, F1 Score: 0.8369\n","Epoch [100/100] Training Loss: 0.0193, F1 Score: 0.7891 | Validation Loss: 0.0199, F1 Score: 0.8348\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x500 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAA1cAAAHACAYAAABOPpIiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABoFklEQVR4nO3de5xN9f7H8fdaa++5YcZ9Zki5537JLal0UUMlQklO5FROJSV1lC4oFakcv9LR6XLSnepISCShaELkLuE4iHHPjNvM7L3W+v0xZjPMYMbM7L15PR+P/TCz1tprfxdLzdvn+/0sw3VdVwAAAACAs2IGewAAAAAAcC4gXAEAAABAISBcAQAAAEAhIFwBAAAAQCEgXAEAAABAISBcAQAAAEAhIFwBAAAAQCEgXAEAAABAIfAEewChyHEcbd++XaVKlZJhGMEeDgAAAIAgcV1XBw4cUKVKlWSap65NEa5ysX37dlWpUiXYwwAAAAAQIrZu3aoLLrjglMcQrnJRqlQpSVm/gbGxsUEeDQAAAIBgSUtLU5UqVQIZ4VQIV7nIngoYGxtLuAIAAABwRsuFaGgBAAAAAIWAcAUAAAAAhYBwBQAAAACFgDVXAAAACAu2bcvn8wV7GDjHWJYlj8dTKI9gIlwBAAAg5B08eFB//PGHXNcN9lBwDoqJiVFiYqIiIiLO6jyEKwAAAIQ027b1xx9/KCYmRhUqVCiUCgMgZT0gODMzU7t379amTZtUq1at0z4o+FQIVwAAAAhpPp9PruuqQoUKio6ODvZwcI6Jjo6W1+vV5s2blZmZqaioqAKfi4YWAAAACAtUrFBUzqZaleM8hXIWAAAAADjPEa5CmO24St64V18t26bkjXtlOyzgBAAAOJ9VrVpVY8aMOePj586dK8MwtH///iIbE45hzVWImrEqRc9OXaOU1PTAtsS4KA3tWE/tGyQGcWQAAADhyXZcLdq0T7sOpKtiqSi1rFZWllk0Uw1PN4Vx6NChGjZsWL7Pu3jxYpUoUeKMj7/sssuUkpKiuLi4fH9WfsydO1dXX321/vzzT5UuXbpIPyuUEa5C0IxVKbr/o6U6sU61IzVd93+0VOP+cgkBCwAAIB+K+x+uU1JSAl9PnDhRQ4YM0bp16wLbSpYsGfjadV3Zti2P5/Q/mleoUCFf44iIiFBCQkK+3oOCC4lpgW+88YaqVq2qqKgotWrVSosWLcrz2LfffltXXHGFypQpozJlyqhdu3YnHX/XXXfJMIwcr/bt2xf1ZRQK23H17NQ1JwUrSYFtz05dwxRBAACAM5T9D9fHByvp2D9cz1iVksc7Cy4hISHwiouLk2EYge9/++03lSpVSt98842aNWumyMhIzZ8/Xxs3blSnTp0UHx+vkiVLqkWLFvruu+9ynPfEaYGGYeidd97RLbfcopiYGNWqVUtTpkwJ7D9xWuD48eNVunRpzZw5U3Xr1lXJkiXVvn37HGHQ7/froYceUunSpVWuXDk9/vjj6t27tzp37lzg348///xTvXr1UpkyZRQTE6MOHTpo/fr1gf2bN29Wx44dVaZMGZUoUUL169fX9OnTA+/t2bNnoFtkrVq19N577xV4LEUp6OFq4sSJGjhwoIYOHaqlS5eqcePGSkpK0q5du3I9fu7cuerRo4fmzJmj5ORkValSRddff722bduW47jsmyT79emnnxbH5Zy1RZv2nfQX/3iupJTUdC3atK/4BgUAABBCXNfV4Uz/Gb0OpPs0dMrqU/7D9bApa3Qg3XdG5yvMhxg/8cQTGjlypNauXatGjRrp4MGDuuGGGzR79mz9+uuvat++vTp27KgtW7ac8jzPPvusbrvtNq1YsUI33HCDevbsqX378v5Z8fDhw3rllVf04Ycf6ocfftCWLVv02GOPBfa/9NJL+vjjj/Xee+9pwYIFSktL0+TJk8/qWu+66y798ssvmjJlipKTk+W6rm644Qb5fD5JUr9+/ZSRkaEffvhBK1eu1EsvvRSo7j3zzDNas2aNvvnmG61du1bjxo1T+fLlz2o8RSXo0wJHjx6te++9V3369JEkvfnmm/r666/173//W0888cRJx3/88cc5vn/nnXf0n//8R7Nnz1avXr0C2yMjI8OyBLrrQN7BqiDHAQAAnGuO+GzVGzKzUM7lStqRlq6Gw749o+PXPJekmIjC+RH6ueee03XXXRf4vmzZsmrcuHHg++HDh+vLL7/UlClT9OCDD+Z5nrvuuks9evSQJL344ot67bXXtGjRojxnbvl8Pr355puqUaOGJOnBBx/Uc889F9j/+uuva/DgwbrlllskSWPHjg1UkQpi/fr1mjJlihYsWKDLLrtMUtbP9FWqVNHkyZN16623asuWLeratasaNmwoSapevXrg/Vu2bFHTpk3VvHlzSVnVu1AV1MpVZmamlixZonbt2gW2maapdu3aKTk5+YzOcfjwYfl8PpUtWzbH9rlz56pixYq6+OKLdf/992vv3r2FOvaiUrHUmT207EyPAwAAQGjKDgvZDh48qMcee0x169ZV6dKlVbJkSa1du/a0latGjRoFvi5RooRiY2PznAUmSTExMYFgJUmJiYmB41NTU7Vz5061bNkysN+yLDVr1ixf13a8tWvXyuPxqFWrVoFt5cqV08UXX6y1a9dKkh566CE9//zzatOmjYYOHaoVK1YEjr3//vs1YcIENWnSRIMGDdJPP/1U4LEUtaBWrvbs2SPbthUfH59je3x8vH777bczOsfjjz+uSpUq5Qho7du3V5cuXVStWjVt3LhRTz75pDp06KDk5GRZlnXSOTIyMpSRkRH4Pi0trYBXdPZaViurxLgo7UhNz7V8bUhKiMvqbgMAAHA+ivZaWvNc0hkdu2jTPt313uLTHje+T4sz+vkq2nvyz5IFdWLXv8cee0yzZs3SK6+8opo1ayo6OlrdunVTZmbmKc/j9XpzfG8YhhzHydfxhTndsSDuueceJSUl6euvv9a3336rESNG6NVXX1X//v3VoUMHbd68WdOnT9esWbN07bXXql+/fnrllVeCOubcBH3N1dkYOXKkJkyYoC+//FJRUccqObfffrtuvvlmNWzYUJ07d9a0adO0ePFizZ07N9fzjBgxQnFxcYFXlSpViukKTmaZhoZ2rCcpK0gdL/v7oR3rFVnbUAAAgFBnGIZiIjxn9LqiVgUlxkWd9HNV4FzK6hp4Ra0KZ3S+07VYPxsLFizQXXfdpVtuuUUNGzZUQkKC/ve//xXZ5+UmLi5O8fHxWrz4WCC1bVtLly4t8Dnr1q0rv9+vhQsXBrbt3btX69atU7169QLbqlSpovvuu0+TJk3So48+qrfffjuwr0KFCurdu7c++ugjjRkzRm+99VaBx1OUghquypcvL8uytHPnzhzbd+7cedr1Uq+88opGjhypb7/9NkcpNDfVq1dX+fLltWHDhlz3Dx48WKmpqYHX1q1b83chhax9g0SN+8slSojLOfUvIS6KNuwAAAD5EE7/cF2rVi1NmjRJy5Yt0/Lly3XHHXecsgJVVPr3768RI0boq6++0rp16/Twww/rzz//PKNguXLlSi1btizwWr58uWrVqqVOnTrp3nvv1fz587V8+XL95S9/UeXKldWpUydJ0oABAzRz5kxt2rRJS5cu1Zw5c1S3bl1J0pAhQ/TVV19pw4YNWr16taZNmxbYF2qCGq4iIiLUrFkzzZ49O7DNcRzNnj1brVu3zvN9o0aN0vDhwzVjxoyT5qrm5o8//tDevXuVmJh7KImMjFRsbGyOV7C1b5Co+Y9fo2vqZD3L4NZmF2j+49cQrAAAAPIpXP7hevTo0SpTpowuu+wydezYUUlJSbrkkkuKfRyPP/64evTooV69eql169YqWbKkkpKScswUy8uVV16ppk2bBl7Za7Xee+89NWvWTDfddJNat24t13U1ffr0wBRF27bVr18/1a1bV+3bt1ft2rX1z3/+U1JWZhg8eLAaNWqkK6+8UpZlacKECUX3G3AWDDfIEywnTpyo3r1761//+pdatmypMWPG6LPPPtNvv/2m+Ph49erVS5UrV9aIESMkZbWGHDJkiD755BO1adMmcJ6SJUuqZMmSOnjwoJ599ll17dpVCQkJ2rhxowYNGqQDBw5o5cqVioyMPO2Y0tLSFBcXp9TU1KAHrWFTVmv8T//TA1fV0KD2dYI6FgAAgGBIT0/Xpk2bVK1atTP6AT8vtuNq0aZ92nUgXRVLZa1hD4WKVahzHEd169bVbbfdpuHDhwd7OEXiVPdYfrJB0Fuxd+/eXbt379aQIUO0Y8cONWnSRDNmzAg0udiyZYtM81iBbdy4ccrMzFS3bt1ynGfo0KEaNmyYLMvSihUr9P7772v//v2qVKmSrr/+eg0fPvyMglWoiY7IWjSZ7iv+kjAAAMC5xDINta5RLtjDCHmbN2/Wt99+q7Zt2yojI0Njx47Vpk2bdMcddwR7aCEv6OFKyuqtn1fv/hObUJxuUV90dLRmziyc5x6EgijP0XDlt4M8EgAAAJwPTNPU+PHj9dhjj8l1XTVo0EDfffddyK5zCiUhEa6QtyhvVtUu3Ue4AgAAQNGrUqWKFixYEOxhhKWwbsV+PojyZk8LJFwBAAAAoYxwFeKOVa5YcwUAAACEMsJViKNyBQAAAIQHwlWII1wBAAAA4YFwFeKyw9URpgUCAAAAIY1wFeKiPFl/RBlUrgAAAICQRrgKccceIky4AgAAON9cddVVGjBgQOD7qlWrasyYMad8j2EYmjx58ll/dmGd53xCuApxgTVXfqYFAgAAhIuOHTuqffv2ue778ccfZRiGVqxYke/zLl68WH379j3b4eUwbNgwNWnS5KTtKSkp6tChQ6F+1onGjx+v0qVLF+lnFCfCVYiL8lC5AgAAOCtzRkjzRuW+b96orP2F7O6779asWbP0xx9/nLTvvffeU/PmzdWoUaN8n7dChQqKiYkpjCGeVkJCgiIjI4vls84VhKsQl/2cqyM+W67rBnk0AAAAYci0pDkvnByw5o3K2m5ahf6RN910kypUqKDx48fn2H7w4EF9/vnnuvvuu7V371716NFDlStXVkxMjBo2bKhPP/30lOc9cVrg+vXrdeWVVyoqKkr16tXTrFmzTnrP448/rtq1aysmJkbVq1fXM888I5/PJymrcvTss89q+fLlMgxDhmEExnzitMCVK1fqmmuuUXR0tMqVK6e+ffvq4MGDgf133XWXOnfurFdeeUWJiYkqV66c+vXrF/isgtiyZYs6deqkkiVLKjY2Vrfddpt27twZ2L98+XJdffXVKlWqlGJjY9WsWTP98ssvkqTNmzerY8eOKlOmjEqUKKH69etr+vTpBR7LmfAU6dlx1iKPTgt0XSnTdhTpKfy//AAAAGHFdSXf4TM/vnU/yc7MClJ2pnT5I9L8f0g/vCxd+fes/ZmHzuxc3hjJME57mMfjUa9evTR+/Hg99dRTMo6+5/PPP5dt2+rRo4cOHjyoZs2a6fHHH1dsbKy+/vpr3XnnnapRo4Zatmx52s9wHEddunRRfHy8Fi5cqNTU1Bzrs7KVKlVK48ePV6VKlbRy5Urde++9KlWqlAYNGqTu3btr1apVmjFjhr777jtJUlxc3EnnOHTokJKSktS6dWstXrxYu3bt0j333KMHH3wwR4CcM2eOEhMTNWfOHG3YsEHdu3dXkyZNdO+99572enK7vuxgNW/ePPn9fvXr10/du3fX3LlzJUk9e/ZU06ZNNW7cOFmWpWXLlsnr9UqS+vXrp8zMTP3www8qUaKE1qxZo5IlS+Z7HPlBuApx0d5jYSrdR7gCAACQ77D0YqWCvfeHl7NeeX1/Ok9ulyJKnNGhf/3rX/Xyyy9r3rx5uuqqqyRlTQns2rWr4uLiFBcXp8ceeyxwfP/+/TVz5kx99tlnZxSuvvvuO/3222+aOXOmKlXK+v148cUXT1on9fTTTwe+rlq1qh577DFNmDBBgwYNUnR0tEqWLCmPx6OEhIQ8P+uTTz5Renq6PvjgA5UokXX9Y8eOVceOHfXSSy8pPj5eklSmTBmNHTtWlmWpTp06uvHGGzV79uwChavZs2dr5cqV2rRpk6pUqSJJ+uCDD1S/fn0tXrxYLVq00JYtW/T3v/9dderUkSTVqlUr8P4tW7aoa9euatiwoSSpevXq+R5DfjEtMMR5LUPm0X8coR07AABA+KhTp44uu+wy/fvf/5YkbdiwQT/++KPuvvtuSZJt2xo+fLgaNmyosmXLqmTJkpo5c6a2bNlyRudfu3atqlSpEghWktS6deuTjps4caLatGmjhIQElSxZUk8//fQZf8bxn9W4ceNAsJKkNm3ayHEcrVu3LrCtfv36sqxjxYDExETt2rUrX591/GdWqVIlEKwkqV69eipdurTWrl0rSRo4cKDuuecetWvXTiNHjtTGjRsDxz700EN6/vnn1aZNGw0dOrRADUTyi8pViDMMQ1FeS4czbR0hXAEAAGRNzXtye/7flz0V0IrImh545d+zpgjm97Pz4e6771b//v31xhtv6L333lONGjXUtm1bSdLLL7+s//u//9OYMWPUsGFDlShRQgMGDFBmZmb+xnQKycnJ6tmzp5599lklJSUpLi5OEyZM0Kuvvlpon3G87Cl52QzDkOMUXdfrYcOG6Y477tDXX3+tb775RkOHDtWECRN0yy236J577lFSUpK+/vprffvttxoxYoReffVV9e/fv8jGQ+UqDATasftoxw4AACDDyJqal59X8htZwerqp6Rndmf9+sPLWdvzc54zWG91vNtuu02maeqTTz7RBx98oL/+9a+B9VcLFixQp06d9Je//EWNGzdW9erV9fvvv5/xuevWrautW7cqJSUlsO3nn3/OccxPP/2kiy66SE899ZSaN2+uWrVqafPmzTmOiYiIkG2f+h/x69atq+XLl+vQoWNr0xYsWCDTNHXxxRef8ZjzI/v6tm7dGti2Zs0a7d+/X/Xq1Qtsq127th555BF9++236tKli957773AvipVqui+++7TpEmT9Oijj+rtt98ukrFmI1yFgWgv7dgBAAAKLLsr4NVPSW0HZW1rOyjr+9y6CBaikiVLqnv37ho8eLBSUlJ01113BfbVqlVLs2bN0k8//aS1a9fqb3/7W45OeKfTrl071a5dW71799by5cv1448/6qmnnspxTK1atbRlyxZNmDBBGzdu1GuvvaYvv/wyxzFVq1bVpk2btGzZMu3Zs0cZGRknfVbPnj0VFRWl3r17a9WqVZozZ4769++vO++8M7DeqqBs29ayZctyvNauXat27dqpYcOG6tmzp5YuXapFixapV69eatu2rZo3b64jR47owQcf1Ny5c7V582YtWLBAixcvVt26dSVJAwYM0MyZM7Vp0yYtXbpUc+bMCewrKoSrMBB5tB074QoAAKAAHDtnsMqWHbCcov0Z6+6779aff/6ppKSkHOujnn76aV1yySVKSkrSVVddpYSEBHXu3PmMz2uapr788ksdOXJELVu21D333KMXXnghxzE333yzHnnkET344INq0qSJfvrpJz3zzDM5junatavat2+vq6++WhUqVMi1HXxMTIxmzpypffv2qUWLFurWrZuuvfZajR07Nn+/Gbk4ePCgmjZtmuPVsWNHGYahr776SmXKlNGVV16pdu3aqXr16po4caIkybIs7d27V7169VLt2rV12223qUOHDnr22WclZYW2fv36qW7dumrfvr1q166tf/7zn2c93lMxXB6edJK0tDTFxcUpNTVVsbGxwR6Obvi/H7UmJU3v/7Wl2tauEOzhAAAAFKv09HRt2rRJ1apVU1RUVLCHg3PQqe6x/GQDKldhIPAg4UwqVwAAAECoIlyFgeyGFhl+whUAAAAQqghXYYCGFgAAAEDoI1yFAVqxAwAAAKGPcBUGsrsF8hBhAAAAIHQRrsJAFNMCAQAARJNrFJXCurcIV2EgmmmBAADgPGZZWT8LZWZmBnkkOFcdPnxYkuT1es/qPJ7CGAyKVhQPEQYAAOcxj8ejmJgY7d69W16vV6ZJfQCFw3VdHT58WLt27VLp0qUDQb6gCFdhIMpDK3YAAHD+MgxDiYmJ2rRpkzZv3hzs4eAcVLp0aSUkJJz1eQhXYSB7zRUPEQYAAOeriIgI1apVi6mBKHRer/esK1bZCFdhICqCNVcAAACmaSoqKirYwwDyxITVMBDlObrmimmBAAAAQMgiXIUBWrEDAAAAoY9wFQYCa66YFggAAACELMJVGMhuxZ5B5QoAAAAIWYSrMBDNtEAAAAAg5BGuwsCxNVdMCwQAAABCFeEqDGRPC6RbIAAAABC6CFdhINLDQ4QBAACAUEe4CgPRRx8inOF35LpukEcDAAAAIDeEqzCQveZKygpYAAAAAEIP4SoMRHmO/THRMRAAAAAITYSrMOCxTHlMQ5J0hHAFAAAAhCTCVZigHTsAAAAQ2ghXYSKKBwkDAAAAIY1wFSYCz7oiXAEAAAAhiXAVJpgWCAAAAIQ2wlWYoHIFAAAAhDbCVZiIZs0VAAAAENIIV2EiMC3QT7gCAAAAQhHhKkxEelhzBQAAAIQywlWYyF5zdSSTyhUAAAAQighXYYJpgQAAAEBoI1yFiWhasQMAAAAhjXAVJrKnBWbQLRAAAAAISYSrMJE9LfAI4QoAAAAISYSrMBHFc64AAACAkEa4ChNRrLkCAAAAQhrhKkxkr7micgUAAACEJsJVmIjKfoiwn8oVAAAAEIoIV2EiMC2QhwgDAAAAIYlwFSaiI45OC+QhwgAAAEBIIlyFicC0QNZcAQAAACGJcBUmIukWCAAAAIQ0wlWYyO4WyEOEAQAAgNBEuAoTPEQYAAAACG0hEa7eeOMNVa1aVVFRUWrVqpUWLVqU57Fvv/22rrjiCpUpU0ZlypRRu3btTjredV0NGTJEiYmJio6OVrt27bR+/fqivowiFX00XGUwLRAAAAAISUEPVxMnTtTAgQM1dOhQLV26VI0bN1ZSUpJ27dqV6/Fz585Vjx49NGfOHCUnJ6tKlSq6/vrrtW3btsAxo0aN0muvvaY333xTCxcuVIkSJZSUlKT09PTiuqxCl125yrQd2Y4b5NEAAAAAOJHhum5Qf1Jv1aqVWrRoobFjx0qSHMdRlSpV1L9/fz3xxBOnfb9t2ypTpozGjh2rXr16yXVdVapUSY8++qgee+wxSVJqaqri4+M1fvx43X777ac9Z1pamuLi4pSamqrY2Nizu8BCcjjTr3pDZkqS1jyXpJgIT5BHBAAAAJz78pMNglq5yszM1JIlS9SuXbvANtM01a5dOyUnJ5/ROQ4fPiyfz6eyZctKkjZt2qQdO3bkOGdcXJxatWqV5zkzMjKUlpaW4xVqsluxS9IRHiQMAAAAhJyghqs9e/bItm3Fx8fn2B4fH68dO3ac0Tkef/xxVapUKRCmst+Xn3OOGDFCcXFxgVeVKlXyeylFzjQNRXiyHyTMuisAAAAg1AR9zdXZGDlypCZMmKAvv/xSUVFRBT7P4MGDlZqaGnht3bq1EEdZeKKywxUdAwEAAICQE9RwVb58eVmWpZ07d+bYvnPnTiUkJJzyva+88opGjhypb7/9Vo0aNQpsz35ffs4ZGRmp2NjYHK9QRDt2AAAAIHQFNVxFRESoWbNmmj17dmCb4ziaPXu2Wrdunef7Ro0apeHDh2vGjBlq3rx5jn3VqlVTQkJCjnOmpaVp4cKFpzxnOCBcAQAAAKEr6C3nBg4cqN69e6t58+Zq2bKlxowZo0OHDqlPnz6SpF69eqly5coaMWKEJOmll17SkCFD9Mknn6hq1aqBdVQlS5ZUyZIlZRiGBgwYoOeff161atVStWrV9Mwzz6hSpUrq3LlzsC6zUER5s6cFsuYKAAAACDVBD1fdu3fX7t27NWTIEO3YsUNNmjTRjBkzAg0ptmzZItM8VmAbN26cMjMz1a1btxznGTp0qIYNGyZJGjRokA4dOqS+fftq//79uvzyyzVjxoyzWpcVCqKpXAEAAAAhK+jPuQpFoficK0m67V/JWrRpn9644xLd2Cgx2MMBAAAAznlh85wr5A9rrgAAAIDQRbgKI9mt2I8QrgAAAICQQ7gKI9ERVK4AAACAUEW4CiNRnqxwleGnWyAAAAAQaghXYeRYK3YqVwAAAECoIVyFkeyGFkcyCVcAAABAqCFchZHI7G6BfsIVAAAAEGoIV2Hk2EOEWXMFAAAAhBrCVRhhzRUAAAAQughXYSSKyhUAAAAQsghXYYTKFQAAABC6CFdh5NiaK8IVAAAAEGoIV2GEboEAAABA6CJchZEoD2uuAAAAgFBFuAoj2WuueIgwAAAAEHoIV2EkOiKrcpXBtEAAAAAg5BCuwgjTAgEAAIDQRbgKI1F0CwQAAABCFuEqjGSvufI7rnw21SsAAAAglBCuwkh25UqiegUAAACEGsJVGIn0HPvjYt0VAAAAEFoIV2HEMIzA1EAqVwAAAEBoIVyFmeypgbRjBwAAAEIL4SrMZLdjP5LJtEAAAAAglBCuwkz2g4TTqVwBAAAAIYVwFWaym1qw5goAAAAILYSrMHPsQcJMCwQAAABCCeEqzNAtEAAAAAhNhKswk125OkK4AgAAAEIK4SrMRGe3YidcAQAAACGFcBVmWHMFAAAAhCbCVZhhzRUAAAAQmghXYSbSw5orAAAAIBQRrsJM4CHCTAsEAAAAQgrhKsxEHa1cpfupXAEAAAChhHAVZlhzBQAAAIQmwlWYOdYtkHAFAAAAhBLCVZg5VrlizRUAAAAQSghXYYbKFQAAABCaCFdhhnAFAAAAhCbCVZg5Fq6YFggAAACEEsJVmIny0C0QAAAACEWEqzBz7CHChCsAAAAglBCuwkxgWqCfaYEAAABAKCFchZkoD5UrAAAAIBQRrsJM9nOujvhsua4b5NEAAAAAyEa4CjNRR9dcua6UaTM1EAAAAAgVhKswkz0tUKIdOwAAABBKCFdhxmsZMo2srzNYdwUAAACEDMJVmDEMgwcJAwAAACGIcBWGssPVESpXAAAAQMggXIWhaC/t2AEAAIBQQ7gKQ5FH27ETrgAAAIDQQbgKQ4EHCftZcwUAAACECsJVGAo8SDiTyhUAAAAQKghXYSj66IOEM/yEKwAAACBUEK7CUGBaIGuuAAAAgJBBuApDPOcKAAAACD2EqzBEt0AAAAAg9BCuwhAPEQYAAABCD+EqDEUzLRAAAAAIOYSrMBTFtEAAAAAg5BCuwlB2t0BasQMAAAChg3AVhgJrrniIMAAAABAygh6u3njjDVWtWlVRUVFq1aqVFi1alOexq1evVteuXVW1alUZhqExY8acdMywYcNkGEaOV506dYrwCopfVARrrgAAAIBQE9RwNXHiRA0cOFBDhw7V0qVL1bhxYyUlJWnXrl25Hn/48GFVr15dI0eOVEJCQp7nrV+/vlJSUgKv+fPnF9UlBEWU5+iaK6YFAgAAACEjqOFq9OjRuvfee9WnTx/Vq1dPb775pmJiYvTvf/871+NbtGihl19+WbfffrsiIyPzPK/H41FCQkLgVb58+aK6hKA49hBhwhUAAAAQKoIWrjIzM7VkyRK1a9fu2GBMU+3atVNycvJZnXv9+vWqVKmSqlevrp49e2rLli2nPD4jI0NpaWk5XqEsilbsAAAAQMgJWrjas2ePbNtWfHx8ju3x8fHasWNHgc/bqlUrjR8/XjNmzNC4ceO0adMmXXHFFTpw4ECe7xkxYoTi4uICrypVqhT484sDrdgBAACA0BP0hhaFrUOHDrr11lvVqFEjJSUlafr06dq/f78+++yzPN8zePBgpaamBl5bt24txhHnXzTTAgEAAICQ4wnWB5cvX16WZWnnzp05tu/cufOUzSryq3Tp0qpdu7Y2bNiQ5zGRkZGnXMMVapgWCAAAAISeoFWuIiIi1KxZM82ePTuwzXEczZ49W61bty60zzl48KA2btyoxMTEQjtnsAWmBdItEAAAAAgZQatcSdLAgQPVu3dvNW/eXC1bttSYMWN06NAh9enTR5LUq1cvVa5cWSNGjJCU1QRjzZo1ga+3bdumZcuWqWTJkqpZs6Yk6bHHHlPHjh110UUXafv27Ro6dKgsy1KPHj2Cc5FFINLDQ4QBAACAUBPUcNW9e3ft3r1bQ4YM0Y4dO9SkSRPNmDEj0ORiy5YtMs1jxbXt27eradOmge9feeUVvfLKK2rbtq3mzp0rSfrjjz/Uo0cP7d27VxUqVNDll1+un3/+WRUqVCjWaytK0UcfIpzhd+S6rgzDCPKIAAAAABiu67rBHkSoSUtLU1xcnFJTUxUbGxvs4ZzkYIZfDYbOlCT9Nrx9YA0WAAAAgMKVn2xwznULPB9EeY79sdExEAAAAAgNhKsw5LFMecysqYB0DAQAAABCA+EqTGU/6+oIlSsAAAAgJBCuwlQkDxIGAAAAQkqBugVu3bpVhmHoggsukCQtWrRIn3zyierVq6e+ffsW6gDPS3NGSKYltR108r55oyTHVpS3lSTCFQAAABAqClS5uuOOOzRnzhxJ0o4dO3Tddddp0aJFeuqpp/Tcc88V6gDPS6YlzXkhK0gdb96orO2mFegQyJorAAAAIDQUKFytWrVKLVu2lCR99tlnatCggX766Sd9/PHHGj9+fGGO7/zUdpB09VNZQWrOSGnXb9L3L2Z9f/VTUttBivJm/dFRuQIAAABCQ4GmBfp8PkVGRkqSvvvuO918882SpDp16iglJaXwRnc+y54SOOcFad6IrK+PBivpWEMLwhUAAAAQGgpUuapfv77efPNN/fjjj5o1a5bat28vSdq+fbvKlStXqAM8r7UdJBlZLddPXIMVmBboJ1wBAAAAoaBA4eqll17Sv/71L1111VXq0aOHGjduLEmaMmVKYLogCsG8UZLrZn3t2DnWYEV6WHMFAAAAhJICTQu86qqrtGfPHqWlpalMmTKB7X379lVMTEyhDe68lt28on4XafUkqVRi1vcSa64AAACAEFSgcHXkyBG5rhsIVps3b9aXX36punXrKikpqVAHeF7KDlZXPyU16JoVrg7vk9oODgSsaG/W7zMPEQYAAABCQ4HCVadOndSlSxfdd9992r9/v1q1aiWv16s9e/Zo9OjRuv/++wt7nOcXxz7WvMJxpIhSUuYBqX4nyTSPPueKaYEAAABAKCnQmqulS5fqiiuukCR98cUXio+P1+bNm/XBBx/otddeK9QBnpeuHnyseYVpSgkNsr7esfJom/bBgWmBGVSuAAAAgJBQoHB1+PBhlSpVSpL07bffqkuXLjJNU5deeqk2b95cqAOEpISGWb+mLA9siqIVOwAAABBSChSuatasqcmTJ2vr1q2aOXOmrr/+eknSrl27FBsbW6gDhI6Fqx0rA5uywxVrrgAAAIDQUKBwNWTIED322GOqWrWqWrZsqdatW0vKqmI1bdq0UAcI5QxXR1uzs+YKAAAACC0FamjRrVs3XX755UpJSQk840qSrr32Wt1yyy2FNjgcVaGuZFjSkX1S2nYprjKt2AEAAIAQU6BwJUkJCQlKSEjQH3/8IUm64IILeIBwUfFGSRUulnatyapexVVWVPZDhP1UrgAAAIBQUKBpgY7j6LnnnlNcXJwuuugiXXTRRSpdurSGDx8ux+GH/SJxwrorGloAAAAAoaVAlaunnnpK7777rkaOHKk2bdpIkubPn69hw4YpPT1dL7zwQqEOEsoKVysmSjtWSJKiI5gWCAAAAISSAoWr999/X++8845uvvnmwLZGjRqpcuXKeuCBBwhXRSGhUdav2ZUrD5UrAAAAIJQUaFrgvn37VKdOnZO216lTR/v27TvrQSEX2dMC/9wkpacqkm6BAAAAQEgpULhq3Lixxo4de9L2sWPHqlGjRmc9KOQipqwUe0HW1ztX0y0QAAAACDEFmhY4atQo3Xjjjfruu+8Cz7hKTk7W1q1bNX369EIdII6T0FBK+0PasVJR1bNCLA8RBgAAAEJDgSpXbdu21e+//65bbrlF+/fv1/79+9WlSxetXr1aH374YWGPEdkCHQNXKProtMAMpgUCAAAAIaHAz7mqVKnSSY0rli9frnfffVdvvfXWWQ8MuTiuHXt2K/ZM25HtuLJMI4gDAwAAAFCgyhWCJDtc7VqrKPPYdMAMP1MDAQAAgGAjXIWT0hdJkbGSnamo/RsDm49kEq4AAACAYCNchRPTlOIbZH25a5UiPEc7BvpZdwUAAAAEW77WXHXp0uWU+/fv3382Y8GZSGwkbflJSlmhKE9bZfod2rEDAAAAISBf4SouLu60+3v16nVWA8JpHNcxMMp7jdLS/YQrAAAAIATkK1y99957RTUOnKnjOwZmTwukHTsAAAAQdKy5CjcV6kimR0rfrwrObknS0s1/ynbcIA8MAAAAOL8RrsKNJ1JppWpIksocWCdJemH6Wl3+0veasSolmCMDAAAAzmuEqzAzY1WKZu2rKEmqZ2wObN+Rmq77P1pKwAIAAACChHAVRmzH1bNT12iNc5EkqZ55LFxlTwp8duoapggCAAAAQUC4CiOLNu1TSmq61rhHw5Xxvxz7XUkpqelatGlf8Q8OAAAAOM8RrsLIrgPpkhSoXF1o7lasDuV5HAAAAIDiQ7gKIxVLRUmSUlVSf7jlJUl1jS15HgcAAACg+BCuwkjLamWVGBclQzpu3dX/AvsNSYlxUWpZrWxQxgcAAACczwhXYcQyDQ3tWE+Sjlt3tTnHMUM71pNlGsU+NgAAAOB8R7gKM+13j9e3l/yslKhaknJ2DHy32vdqv3t8kEYGAAAAnN8IV+HGtFRrzWsa0fyAJKmutU09msarvzVJ16S8I5lWkAcIAAAAnJ88wR4A8qntIEmSOecFyYqUaWfoae9HKuH9Qq/6uqlT3ftVM8hDBAAAAM5HVK7CUdtB0tVPSXaGJKnEivc0ufRdet3uogmLtgZ5cAAAAMD5iXAVrtoOksxjhceqjdpIkv6z9A9l+O1gjQoAAAA4bxGuwtW8UZLjl4ysP8LGCx5Ui1L79Odhn2au3hnkwQEAAADnH8JVOJo3SprzQtbUwKd2SrEXyLAz9L77tErpsCYsOvnBwgAAAACKFuEq3BwfrNoOkjwRUt85UmQpxfj3a3LEM0reuFub9x4K9kgBAACA8wrhKtw49rFgla1kRanXFMn0qIaZooGeLzRhMY0tAAAAgOJEuAo3Vw/OGayyVb5Eqt1ektTfM1m7f56gSUv/UPLGvbId92jFa0QxDxYAAAA4f/Ccq3NJYmPpt2mSpOfcf6rr5xW11r1IT5aYor72hKyKFwAAAIAiQeXqHDKj3J36h6+rJCnGyNDbEa9qkPWp+toTNNrXTTPK3RnkEQIAAADnLipX5wjbcfXs1DVKsbvKK58e9E7RBcYePeCdqjd8N+t1u4sSpq7RdfUSZJlGsIcLAAAAnHOoXJ0jFm3ap5TUdEnSK/btynStwL621grF6qBSUtO1aNO+YA0RAAAAOKcRrs4Ruw6kB77ub01ShGEHAlYD83/6MGKEYnUwx3EAAAAACg/h6hxRsVSUpKxg9aj3C73q66baGR/qff91kqRG5iZ9GDFSiZGZwRwmAAAAcM5izdU5omW1ske7AmYFq9ftLpKkof4+kqTenllqbP5X7vQOsi9K1qIUR7sOpKtiqSi1rFZW1o8vH32G1uBgXgYAAAAQtghX5wjLNHRN7XIavaKbxh4NVtmyA9Yd1mx5D6Ro76hL1Dd9lA4oRpJo1Q4AAAAUAqYFnkNqdn9R9Xo8r4S4qBzbE+OiNL/2E+qY+aIOuxGqqH2aGTFIpXRY/a1JtGoHAAAACoHhuq4b7EGEmrS0NMXFxSk1NVWxsbHBHk6+2Y6rRZv25Zj257quGg77VlX9/9WkiKGKNjLluJJpSK/6sqpdCXFRmv/4NbRqBwAAAI7KTzagcnUOskxDrWuUU6cmldW6RjlZpqHF//tTR3y21roXqWvmMLlHg5XjSu/b18uVaNUOAAAAnAXC1Xni+Bbs15pLZRgKBKxZEYMUp4MnHQcAAADgzAU9XL3xxhuqWrWqoqKi1KpVKy1atCjPY1evXq2uXbuqatWqMgxDY8aMOetzni9ya9WelPmSDrmRijf3a1bE31VGaYHjAAAAAORPUMPVxIkTNXDgQA0dOlRLly5V48aNlZSUpF27duV6/OHDh1W9enWNHDlSCQkJhXLO80V2q/bsYPW63UW/u1XUKXO4DrmRqmimakHUw2pW3lbyxr36atk2JW/cK9txpXmjpDkjgn0JAAAAQEgLakOLVq1aqUWLFho7dqwkyXEcValSRf3799cTTzxxyvdWrVpVAwYM0IABAwrtnNnCvaFFXjZMfFJTVuzU63YXHf+HXsPYpukRgxVp+LVPsbo+/SXtUZykE9q0tx0UnIEDAAAAQRIWDS0yMzO1ZMkStWvX7thgTFPt2rVTcnJyyJzzXJJXq/Ztnipqn/mSDrhRKqs0zYwYpAraT5t2AAAAIB+C9hDhPXv2yLZtxcfH59geHx+v3377rVjPmZGRoYyMjMD3aWlpBfr8cNC+QaKuq5eQo1V74wvidMnzs3RT5ouaGvGUypkHtCjyARnHt2mfukbX1UugTTsAAACQh6A3tAgFI0aMUFxcXOBVpUqVYA+pSJ3Yqn35H6lK9zna7CbopswX5boKdBOc6rSmTTsAAABwBoIWrsqXLy/LsrRz584c23fu3Jlns4qiOufgwYOVmpoaeG3durVAnx+ujm+/3slcEAhWhiF9HfGkLja2nHQcAAAAgJyCFq4iIiLUrFkzzZ49O7DNcRzNnj1brVu3LtZzRkZGKjY2NsfrfJJbm/YWGeO0y4lTCSND0yKe1Aued3Jv004nQQAAAEBSENdcSdLAgQPVu3dvNW/eXC1bttSYMWN06NAh9enTR5LUq1cvVa5cWSNGZP3wnpmZqTVr1gS+3rZtm5YtW6aSJUuqZs2aZ3ROnCy7TXtf+1ibdklql/myZkQ8oUrmPvX0fC97xTNK1vDAWq1WW9+ROffFrE6CAAAAwHkuqOGqe/fu2r17t4YMGaIdO3aoSZMmmjFjRqAhxZYtW2Sax4pr27dvV9OmTQPfv/LKK3rllVfUtm1bzZ0794zOiZNZpqFrapfT6BVZzSuypamkrst8Wd9EPKELzd2yln+slCWbNdD/gPpbk9Ta+4XW13tItWjRDgAAAAT3OVeh6lx9ztXpzFiVomenrlFK6rG1VaVjvEo/ckhjPf+ndtavkiSfa8prOBp9tMo17i+XqH2DxGANGwAAACgy+ckGhKtcnK/hSpJsx83Rpr3ZRWXU6sXZOnD4sP7h/ac6Wj9LkvyuqZoZH8mQlBAXpfmPX0ObdgAAAJxzwuIhwghNJ7ZpX7L5T/15OFN+ebTeqRw4zmM4muB9Tq5c2rQDAAAAIlzhNLLbr/e3Jmmg9z961ddNr/q6SZIutX7TNO9T8shPm3YAAACc94La0AKhr2KpqBwt2rM7Ce5SGY3wvK0G1v+0yHhA6yKTlbxxb2A6YctqZWX9+LLk2NLVg4N8FQAAAEDRI1zhlFpWK6vVUaZGpx8LVpI00b5ae9xYveUdrbLmQdWY2FZJ6S/qT2XNQ81q7T6BNu0AAAA4bzAtEKdkmYYuuOU5vW530YntKmY7zXRr5lAdcSNUUfs0O+IxXWDsUn9rkvraEzTa100zyt0ZlHEDAAAAxY1whdNq3yBR4/5yiRLionJsT4iN1Cqrjm7KfEGpbozKmgf1Y8SAHFMIn526RrZDQ0oAAACc+5gWiDPSvkGirquXkKNNu+O66vnOQm1UZV2X8bJ+juwn05BcV1rlVpMrBToJtq5RLtiXAAAAABQpKlc4Yye2ad9zMCOwr7s1R6YhOa4hw5De9b6sntZ3kkQnQQAAAJwXCFcosIqlsqYJHt9NsHbG+1ppV5VpSC94/63PvM+qfIxXyRv36qtl25S8cW/WNMF5o6Q5I4J8BQAAAEDhYVogCqxltbJHuwLmbNPe0feCPtYLamOtUUtrnTZ8eq1uODJcmfJKopMgAAAAzk1UrlBglmnomtrlNNrXTWOPa9MuGerpe1rf+FvIcaWa7hbNjnhUcTpIJ0EAAACcswzXdWnldoK0tDTFxcUpNTVVsbGxwR5OyJuxKkXPTl2jlNRja6viS0Vq76FMtdRK/ds7SlGGX64rGYb06tEwlhAXpfmPXyPLPLHJOwAAABAa8pMNmBaIs3aqToI/qYFuznxBMyMel3G0k+Aipy6dBAEAAHDOYVogCsWpOgkmmYtlGJJztHL1ccTzutWaK4lOggAAADh3EK5QJHLrJFg3Y7zWORfIY7h62fuWPvMOU/loD50EAQAAcE5gWiCKRF6dBNtnjtQn3hfU2lqrltbv+t+nV+uG9OE6rKwwRidBAAAAhCsqVygSeXUSdGWqh+8Zfe1vJds1VFXbNDfiESVqL50EAQAAENboFpgLugUWntw6CSbERmrfIZ/qO+v0UcSLKmFk0EkQAAAAIYlugQgZp+ok+Ktq6fqMUfox8mGZRzsJHlS0XLl0EgQAAEDYIVyhyGV3Esz21bJtga+7WD/KNCTbNWQZroZ6P1RTc4Oe8N1LJ0EAAACEFdZcodjl1kmwRsZH+t5uIkm62UrWDxEDdIG9nU6CAAAACBtUrlDs8uok+FffII1w31IPz1yVN9MUO7W9+mf210ynhSQ6CQIAACC0Ea5Q7AKdBFfk7CQoSYP9fZXqllQPz2zFGUf0r4h/aJy/o9LdCPW1/6PRvm6qV+5OtQ/S2AEAAIC80C0wF3QLLB55dRI8mGErPSNdE7zD1dxaH9j3pu8mvWTfQSdBAAAAFJv8ZAPCVS4IV8XHdtxcOwlmWx/5F3kNR5K0243TQ74HlezU16f3XkonQQAAABQ5WrEjbJyqk2B/a5K8hqNM11KEYauCkaqPvS/oJ6e+duyfoOSNCoSyltXKyvrxZcmxpasHB+NSAAAAcJ4jXCGk5NZJ8HW7ix6xPtfD3i9lGtLl1mptnnqdOqcP05/K+tcDml0AAAAg2GjFjpCS3Unw+GAlSf+wb9Wrvm6Ssp6JdZF2aF7kI7rE+F39rUnqa0/QaF83zSh3ZzCHDwAAgPMYlSuElFN1EswOWvHGn7rBXKiy5kH9J2KYDEMa7euq1+0uSpi6RtfVS6DZBQAAAIodlSuEnJrdX1S9Hs8rIS4qx/ayJbx63e6ip/1368rMMbJdQ8bRDNXc/F3l9adSUtO1aNO+IIwaAAAA5zsqVwhJ7Rsk6rp6CTk6Ce5IS9cjE5dJkvpYM2QZrvyuKY/h6Eprpb4xB2u+00ClFyfLrjY8x3tpeAEAAICiRrhCyDqxk2Dyxr2STm52MdQzXn0836q8kabO1k/Sbz/pnRd26vlDnQPvpeEFAAAAihrTAhE28mp28az/Lv2f75Ycx95jf6ahnvGSRMMLAAAAFAsqVwgbp2p28Q/7VvllqYa5XVeYK1XOOKA+nm91p/WdPIajV31Z76HhBQAAAIoKlSuElbyaXSTGRclz9eMa4HtQ7TNG6ke7gSTJYzhyXEMf2+3kSjS8AAAAQJGhcoWwk1uzi5bVymraiu2SpN0qo8XOxbrCWiXXlUzD1Q+RAzTLaab/OonakdpYyRv30uwCAAAAhYpwhbB0YrMLSapYKqua1d+apIHe/+hVXzd95zTTh94XVd48oFusBZIl/Wuq9MiRY9MKaXYBAACAwsC0QJwzcmt4sda9SG0yX9dSu0bguL+5X+hZz3uSaHYBAACAwmO4rusGexChJi0tTXFxcUpNTVVsbGywh4N82DDxSU1ZsVOv21104o092vNPJVmLVcLIkKTAM7ICzS7iojT/8WtodgEAAICA/GQDKlc4p+TV8KJsCa8G+h/QlRljNMu+RFJ2swtputOKZhcAAAA4a6y5wjknt4YXO9LS9cjEZdqrOK1wqus6a+nRZhfSzIjH9ZNTT784F9PsAgAAAAVGuMI56cSGF8kb90rKWmOVvSbrC7utPol4XtXMnbrSWqUrrVX6dOoR9Tjyl8D7aHYBAACAM8W0QJwXcmt2kaJyujpztGbazQPH9XCn633vCJlyaHYBAACAfKGhRS5oaHFuOlWziyetj3W99YuqmjslSc7RKYM0uwAAADi/5ScbEK5yQbg6d81YlaJnp65RSmp6YFvZEl7tO+ST5OpWa55Ged6SYUiuK71t3yifLKW7Ebr0rpdkmgbrsQAAAM4j+ckGrLnCeeVUzS4kQwnaJ8OQbNeQZbjq6/laaW60Yo0jeuNjSy+ndwqci/VYAAAAOB5rrnDeyW520alJZbWuUU4JsVlt249vdlEj42NN8l8uSYo1jkiS+mmiBlsfB45lPRYAAACOx7TAXDAt8PxiO67efeE+9bUnBJpdZHvE+lwPe78MVLIkHj4MAABwPmFaIJAPlmnomtrlNHpFVlg63j/sW+WXpYrGn6pnblEzc33g4cNL3No5Hj58fOt3AAAAnH8IV4Ckmt1fVL36KUo4odlF6WivXj+SFbgesv6jZub6wMOHP4l4UeudSprrNOHhwwAAACBcAdlya3bhuK56vrNQ/a1JGuj9j171ddP79vUa7x2lS6wNqmVuVy1zuxZP2aw70x9TuiIl0ewCAADgfES4Ao6T3ewim+24R4PSFznWY3XxPadn3ffU2zNLktRCq7Uwsp+e9N2j6sZ29bW/0GhfN9Urd6faB+VKAAAAUNwIV8ApnGo91lB/H+1x43SxuVVXmCsVZxzWGxGvSZIm+K+SaTja8uUwZdYZpyWb/2TKIAAAwDmOcAWcRl7rscqW8Or1Q10kW4pShlZF3i2P4UiSbvfM1Qankmra2/XPF1yNOsLzsQAAAM51hCvgDJz64cPSvdbX8hiOMl2PIgy/bNdQTXO7bNfQA5oo0zqkkfYdR5+PxZRBAACAcxHhCjhDJ67HSt64V1LOhw+/bncJfL/BqaSa5nZJ0n3eabrHMz3n87GmrtF19RJ4PhYAAMA5gnAFFFDLamVzbXaR/euj3i80wX+VLjb/UFNzgzyGI9eVMuTVo56Jyjjo1c8bG8s0DdZjAQAAnAMIV0ABnarZRXbAsgxH2+zyampukOtKhiE96f1UB90olTTSNe5j6aX0Y+9lPRYAAED4MoM9ACCc1ez+our1eF4JcVE5tpct4dXrdhfZrhmYMlgz40PNsJtLkkoaWY0x7tcXetM7Wpbso+uxJmi0r5tmlLuz2K8FAAAAZ8dwXdcN9iBCTVpamuLi4pSamqrY2NhgDwdhwHbcHM0uml1URuNH3K++9oQcUwYlaYD1hQZ4JwWqV5ICVa1/+LrqNburEuKiNP/xa1iPBQAAEGT5yQZMCwQKwYnNLiTlOWVwjN1NtkxFGj4dcGP0hOdTGUczVBfrRzUwN2n1waqsxwIAAAgzhCugiOT1fKzS0V69fiQrcPW3JskwJL9rymM4usjcpYu0S9dZS/XDx//TX9MfUoYiJLEeCwAAINQRroAilNvzsRzXVc93Fp7Uwn2g9Zke8k4OTBe8Uku1NPJves3fRSV1WH3tr3g+FgAAQAgjXAFF7MQpg7bj5trCfbR9m3zy6FHvF/rOvkQtzN8UZxzWYO+nkqRF9sUqZRzWli+HKbPOOC3Z/CdTBgEAAEJISHQLfOONN1S1alVFRUWpVatWWrRo0SmP//zzz1WnTh1FRUWpYcOGmj59eo79d911lwzDyPFq355/60doCLRw9+Xewv1VXzetcquqWcab8rvH/oq2tNapj/WN+toT9J8X7lCPt3/WwxOWqcfbP+vdF+6T5rwgmVZxXw4AAACOCnq4mjhxogYOHKihQ4dq6dKlaty4sZKSkrRr165cj//pp5/Uo0cP3X333fr111/VuXNnde7cWatWrcpxXPv27ZWSkhJ4ffrpp8VxOcAZyauFe+norBbuY/zddL81RR7DUYabVWD+wyknj5HV3LOH+41mRzyqFsZvtHAHAAAIEUFvxd6qVSu1aNFCY8eOlSQ5jqMqVaqof//+euKJJ046vnv37jp06JCmTZsW2HbppZeqSZMmevPNNyVlVa7279+vyZMnF2hMtGJHcTmxhXte67Gyv//Uf7XKGAd1vblYx3dpn2k30wDfg3q0xDf66xU15V45KMd5mTYIAABQMGHTij0zM1NLlizR4MHHftgzTVPt2rVTcnJyru9JTk7WwIEDc2xLSko6KUjNnTtXFStWVJkyZXTNNdfo+eefV7lyOVtlZ8vIyFBGRkbg+7S0tAJeEZA/Z7oeK/vX7MD1kv92fRfxmKyjlawka4l+NvtpfWZlmXM/01s//lcvHro5cF46DQIAABS9oE4L3LNnj2zbVnx8fI7t8fHx2rFjR67v2bFjx2mPb9++vT744APNnj1bL730kubNm6cOHTrItu1czzlixAjFxcUFXlWqVDnLKwMK5kzWY1mGo5vMZFmGq8yjUwb3OyUUZxxWc2u9JKmvPUFjPGNlymHaIAAAQDEJ+pqronD77bfr5ptvVsOGDdW5c2dNmzZNixcv1ty5c3M9fvDgwUpNTQ28tm7dWrwDBo6T13qssiWy1mPZrhmoYNXO+ECv+rqptHlIk/xtNNtuKsfNmi/Y2fOTNkb+RY96v9BbvhtlGk5Wp0G/o+SNe/XVsm1K3rhXtuNK80ZJc0YE43IBAADOGUGdFli+fHlZlqWdO3fm2L5z504lJCTk+p6EhIR8HS9J1atXV/ny5bVhwwZde+21J+2PjIxUZGRkAa4AKBq5PR+r2UVlNH7E/aedMjjM30s9rdn6mzVNxtF1WXd7put/boJq2Cl68wVHI490DnwWUwYBAAAKR1ArVxEREWrWrJlmz54d2OY4jmbPnq3WrVvn+p7WrVvnOF6SZs2alefxkvTHH39o7969SkxMLJyBA8Ugez1WpyaV1bpGOUV4zDynDI49bsrgVjdeh9woGYYCrdwtw1UNM0WSdJ/7mT71DtcFxu7AlMFku67W7zwg23GpagEAABRQ0B8iPHDgQPXu3VvNmzdXy5YtNWbMGB06dEh9+vSRJPXq1UuVK1fWiBFZP9w9/PDDatu2rV599VXdeOONmjBhgn755Re99dZbkqSDBw/q2WefVdeuXZWQkKCNGzdq0KBBqlmzppKSkoJ2nUBhqNn9RdWrn6KEqWuUkpoe2J4QFyVPi8f1j+/W59lpcLFdW9XNFJUzDqi1tVbzrYclSd/4W2iDW1n917ymf72wSyNohAEAAFAgQQ9X3bt31+7duzVkyBDt2LFDTZo00YwZMwJNK7Zs2SLTPFZgu+yyy/TJJ5/o6aef1pNPPqlatWpp8uTJatCggSTJsiytWLFC77//vvbv369KlSrp+uuv1/Dhw5n6h3NCblMGW1YrK0mKTn71lNMGx/i6aINbWa95x8o82mmwg2exDrkrtMq+SH/TBB2yfHrN7nq0qvWFRvu6qV65O8VjuAEAAE4t6M+5CkU85wrhasPEJzVlxU69bnfRiX+x+1uTZBlOoCFGpmspwrD1p1NCZcxDOY71u6Y8hhOYahgTGaG7Bo/Tks1/8uwsAABwXgmb51wBKFx5TRssW8Kr1w91OcXDia+SZOgm62eVMo7IYziSpOusJdrnltJV9gr98wVXo450CpyTKYMAAAA5UbnKBZUrhDvbcfPoNDghx5RBSTkCl0e2HvZ+Kcc1AtMGJclxJdOQZtrN9Hff39Tb+laPer9Qsl1X5Rtep+rdnjtpmiJVLQAAcC6gcgWc57I7DR7vmtrlNHpF7g8nlqTW5mpdZq0NhK9B1qd6wDtVfzjldIG5V5KUZC3R9WZfGYb0nd1UG53K+huNMAAAACQRroDzRp6dBmMjFeWzdJm7NkdVa5TdQ0cUqUe9X+htfwf96cbqMc9EmUefndXO+lXtrF+13Smrv2mCvJ4/9Zy/d6ARRrJdV+V3HlD1E6poVLUAAMC5immBuWBaIM5lJ04ZbFmtrDZ9/lS+G2Fsc8qqsrkvx7GuKxmG9Ln/Sm13y+th7yT9y7o976pW20HFcMUAAAAFx7RAAHnKbcpgQRthvOm7SVsUryRzsa40V8g4WtW61fODDrmR2uBU0t80QYZ1QC/aPalqAQCAcxqVq1xQucL5qqCNMKSs52j5XEtew9ZBN0oljfQc585uijHJ30bb3Arq751MVQsAAIQ8KlcACqQwGmFkh64P/e20wy2rq61lamb8Hlir1cWzQJmupa1Oef1NE1TKs0vP+PvoAesrqloAACCsEa4AnFJ+G2Fk/5pd1ZpnN1Jz7+/yuaa8hqNUJ0Zx5mFVMfZIku7wfK8e1vcyDGme3VDb3ApqTQdCAAAQhpgWmAumBQInK0gjjLyqWu/4O2iTm6g25ip1MBcF1mply26a8aNdX2P83XSFuVIDvJM02tdNNzeKV82E0rKv+DuVLQAAUOSYFgig0OWnEcaZVrXWOhfqBmtRYK3WBqeSyhupKm0ckiRdYa3WFdZqSdJWp7wiDZ9+X7dKNdfO07s/bNSLuVW2ql2ZaxAkeAEAgKJG5SoXVK6A/CnMqtZoX1d967RQK3Othng+kGWc/J+o7OYYS+0a+rd9gxoa/9XfvF9rgV1Pbaw1esu6PffgRaMMAACQT1SuABSrwq5qub6seYKW4SrD9SjS8Gum3Uxpbgm1MNepqrlTknSJtVGXWK9LklKdGO1UWc2yL1FfTdBBy6fX7K60fwcAAMWGylUuqFwBhacwq1rZ31fQn2pu/q6x3tdkGW7g4cUnclxDpuHqK39r7XLL6F7v9Lzbv1e7UvadUwheAAAgBypXAEJGYVe1sr+vaWzLUdn6wn+FtqmCmhvr1NTcoBgjQ+bRKYWdPMmSpMNuhP5mT1Bj7zKNt9urublO99jfZE0n3PSD3n3hPtZxAQCAAqNylQsqV0DxyE9Vy5D0oDVJluHIds0clawTK1sPW1/oEe8k+V1THsPRTqe0yhoH5DXsk8aQ7nr1q1NLXvnU3Fqv9/3Xabj/Tt1vTdGj3i9Ov46LihcAAOe0/GQDwlUuCFdAcM1YlaJnT6hqJcZF6Zkb6+qPr55VX3tCjsqWpEDAyg5DJwav//PdotnOJWpobtJznvdOOZ0we/vvTmXNdFqourbrRs8ivebrrNH2bSd9FsELAIBzF9MCAYS19g0SdV29hJNDiWlow9pyGr2im8YeF6ykrKmCl5prcgSr7O1S1pRCv8+SlLNRxgf+dlrpVlc9Y7Pqm/9TC2NdIHDVNreptrkt8BkPeServ2eyDENaaF+sz+yrtNGtpL6aoAOWPxDm+tpfMNUQAIDzEJWrXFC5AkJbXpWtUeW+1uLNqQVulJH9ffZDjOfajbTdLacaZopqGttUzjiQ63hs15BluIEGGjPt5nrHf4OuMX/V/d6pJ52fihcAAOGDaYFniXAFhL5cqz6mkWvwSoiN1J2+z9TPnZjv6YQnfp/9wONldnVlGBGqY2xRnHE4z3FmV8iyA9hMu7ne9XfQNeavus87Lf/Bq+oVWeHrir8TvgAAKAaEq7NEuALCW37bv3/sff6k6YTSmQavW/SE9anu804LNND4n1NRllxVNvYEOhbmJjuoZVe8ZttN9KF9va40l+uvnpm5PGC5mzo2rqRaa16j6gUAQDEhXJ0lwhVwbirIdMKzCV5v2TfpCc8n6uP5NkfwMiRVNvbIYzh5jtVxJdM49qyun+x6muRcof0RibrUt1D3eL4pvOmGH3TMOvCuaScPZN4oQhkA4LxGuDpLhCvg3JWf6YRFGbzG2TfrCc+nusfzTSB4rXcqyS+PLjR2qoSRccrrODF8LbJr62untS4xflcnT7LG+TrqJft29be+PLPgJcm56kktrHJP4Pem1dZ3ZM59kWoYAOC8Rrg6S4Qr4PwUKsHrdfsWPW5N0P3eqYHgtcKupv0qqcrGHl1g7FGk4Tvt9WS3lN/iVNBi92JV1h5dav2mSf42ese+UR3NZN3vnarRvm5qXrWMrtz29knj2VvhUpXb/XOBq2F2r6mEMgBAWCNcnSXCFYAThU7w6iJDjh63Jug+7zT5XFNew9ESu5Z2qowqGXtVydirisb+M7su19AexWmXW1oxylANM0W2a8oyHE31X6oP7evU3lqU6xqwM6mGFWht2H/nStWvomkHACAkEK7OEuEKQH4UZ/B61ddNknLtZJhXS/mv/S21yq2uBGOvKhn7dK25RKahPB+ifCrZ79ngJGqRU0fVjB1qba3VFH9rfWhfpxusn9XH863+4esqR0au4zqTtWHa9APVMgBASCBcnSXCFYDCUljBy5D0oDVJV3jXqqVWn3VL+ewW8W/6btJUp7UqGvvVw/pe11tLAm3j/3DKKVNelTdSFWscyfe1p7kxclxDpc1DgbVhi+3a+s5ppqbmerW3ftHH/ms0zu6k7uYc9fdO1mhfN2W0eVSRC17VwIIEMxWgWkYoAwCcAuHqLBGuABSH/AavoR3rqebq14ukpbx06mrYI9bnetj7ZaB9/Cz7Eq10qqu8kaoKxn4lmb/INNwCVcOy+V1DfypWf7ol9adKqazSVMvcHpimOMu+RJPty3WV+atu9fyot/0d9Lq/i+6yZmig9z+nvI5iD2UENgA4ZxCuzhLhCkCw5RW8pKJpKS+p0Kpho31d9aF9ncoaB3SP9bV6eOYGGnP8YtfSFsWrnNJU1khTA+N/BQ5jxzvierXbLa1UlVCsDukic3egAjffrq+ZTgu1NtboBs8iTfBfpffs9upq/qC+3uka7esqt6BTGHWKUHaqfQVdc0ZoA4BiR7g6S4QrAKGuMNd5feIdLkm6w/fMSZ9TlNWwE0PZW74bNdlpo9LGQZXRQd1izVc7a2mgcrXBqaS9ilWcDinOOKQE7SuUYCZJB9xouZJijSOBKYxrnSpa4tRWbeMPtbTW6Tu7qabZrXW1+as6eZL1qf9q+eRRL88sjfN11Gv2LbrHmn7a6z/rNWcqxiobYQ4ACFdni3AFIJzlN3jd3DhRb/2wSZJOWuf1sOcL2a6psUGqhp2+aYdHEYZf7/mv11T7MsUah3SrOU83ehblaGO/VRUUq8MqZRxWY+O/MgrY0ONMHHG92uOW1kFFq6QOq4q5J1BF+8WupQVuQzUx1quttVLT/S31ldNG15m/qJvnR33gv06HLvmbjCXv6z7vVI32ddVrdtczCq1FVmU71b6imDJ5Bt0i7bZP5FnZBYDCRrg6S4QrAOeqgqzzkpTv5hsfH62G9fQ9c9Zrw063/2yqZWN8XfShfZ1KGYd1jzVdf/HMDqwrm2M31nK3hkrpiErpsLpZP8g0XDmuoXXuBYpRhmKMDEUrQyWUXiRBTToWAvc7JZSisjqsKJVTqqqauwKhbaldUz+79dTY2KA21hp9ZzfVTKeF2hrLdZNnob7wXyG/LN3umav3/NfrXftG9TS/0/3eqfqHr4scmXn+vuX1e1qUUyZPVbnbW+FS3ZQ26KT7cVqpkSpXMrJwq3NnWdUjBALnBsLVWSJcATgfnWqdV3GFsv7WJHUts1H/+bNGsa4dk/IXyo7/jNyqaF/Zl6ukcUS3mXN0s+fnQBVtkX2xfnMvVAkjXSWUruuPNgJxXGmrW1ExRrpilKESRsbZ/nHmi981ZctUpOEPhLmdTmltVrzS3QhVMvaqprk9EOYW27WV7NbTJcZ6XW6tzjXM2TLV3TNP7/uv07v2Deppfqe/eb/Wa77OsmXqEe+kk35/z7Rb5Il/xg9ZkzTw6J9/sVbuTrEvrxD4QY25qnVoScHW1YXSPqaF4jxCuDpLhCsAOHOFHcraN0gsUKv6s6mWSYUfyk6173SBzZCjR6wv9JB3cuB5ZZ/6r9Y051KVULo6mQtyTH382a6jVW41RStTUUaGbjEXBKpsy90ailKGopSpKMNXqGvVzobjKsfz1vY7MdqtMsqQVxnyqoL260Jzd2AN3GrnQq1waqiOsUVNrY1aaF+sZLe+mhvrdLm1WnPsxrJlqp31q77xt9DXzqW6zvxFnTzJ+sx/pWyZ6uGZq/f91+kD+3rdYc3W3Z4Z+pfvRrkydJ93msb6btYbdmfda3192g6UZ1LVyysE7q1wqcrt/jlkgmCB9xX08QYFbdoSLvuOC56n+u8jwgfh6iwRrgCg6J3uh45wmMIo5R3KTrXvbNacSWdfZcve93++W/Rvu4OilKm+nmm62zMjMC1ykv9yfes0V5QydaP1s66zlh5XgautNW5VRcqnKCNTncyfAmFumVtDUfIpUpmKMjJVSXuLdI1bUfG7hg4rShmKUITrU5x5OBAItzrl9T83QT55VMXYrVrmtkBVb7ldXUvdWmpo/FfNrfVKtuvqJ6e+Wpq/6Qprlb63m+gnTwu19C/V9dYSfe1vpWnOpUoyF6uz5yd97r9CztGq38f+a/SRfZ1us+aoj+dbve27QbZM3eedptd9nTTWvkX3WVMCVUCpYGG/IPvO9vEGBW7aEi77ql6h9TFN1WvjVaE9hbWowmVRBOggVksJV2eJcAUAoS0UpjDmFcqKes2ZVLxVtlPty2+YG+3rqrfsmxQpn+63pug+77RAZe4T/9Wa4rRR5NFgdrP5k27yLAwEunl2Qy1y6irC8ClSft1rTZNluLJdQ5Ody+WVXx7Z8sqva81fA2FvtXuRIuRXhHyKMPw5wt4RRcqSLY9sWUZ4/zjkcy35ZcmQo6jjpnemOjHap1KyZSlOB1XBTMsREje5ifLL0oXGrhxTP1c7F2mVU022TNUz/qcm1n8D+xbaF+tnt56aG+vUxlqjeXZDzXWa6HJzpa61lulbu5lcGUqyftHX/lb62mmlJHOxOnmS9R//5cqsf6us1ZN029EA+Yl9rbpbc9XLM0v/9reXI0P3eL7Rv3w36h37RvWxvtED3qka6+skR4Ye8k7WGF8XvW7fogesr4r0Hi/IvtG+bmpetYyu3PZ2WExhLZJ9RRWgr35KajtIxY1wdZYIVwBwbiquUFYUa86CVWU71b6injJZGIHuTPc9ZP1HA73/Cayde8t3oz51rlGkfOplfas7PN8HqnpT/ZfqO+cSRRh+JZm/qN1xVb2f7Hpa6tY6GvRs3WXNCITAKc5l8h4Ncx755ZWtK8yVgXV3q92qgfd55deFxq5AEDyoaEXIL4/8YR8EC5vjSrYsOTJlyFGEYQfC5UE3SqkqIds1VUqHVcY8FAiXO5zSSlF5+WUqQftUxdwTmIa60UnUBreybJmqbmxXHfOPQLhcYVfTSre6bJlqYGzSJdaGwCMjfrbraKFbT7ZMtTDW6gprtebajfSD01iXmyt1jbVM39lN5crQddZSzbSba5bTTNcYS3WDZ7Gm+VvJkaGbPT9rsv8yTXEu003mz+rima/P/VfKlXSb5wd96r9Kn9tXqZs1T3d45uhj/zWSpJ6e7/WR/1p9al+r26w56u2ZpXf97eUeDaxv+m7SO/aN+qs1Pc/A2s+afFbTYk+3dvJszluvx/Nq3yCx2O8xwtVZIlwBAI5XkFB2qn0FXXNWnFW2UJkyebr9wapOnG1V7/hrOtsgOM7XUePtJHkNW32sb3S3Z0agIvix/xr9x75SHtm61ZqnWz0/BELiNH8rfec0k9fw63rzlxxTP3+wG+hnp54sOWptrtZl1tpAgFhi19Iqt6q8RyNNN2teIEDOcprLkhOoCF5urgpUEVe41QPbPXLkkV9VjZ2BALlPpbKqiHLkka1I+cJqKum5yHENSW6O9ZGZrqV0RciRqQj5FGNkHquUujFKdUvIMUw5rqHSOqiy5sFAoN3txGmXSsuRoQrarwRzf45K6hY3XrZMVTF2q5q5IxBoX/V101i7ixLiojT/8WuKfd1afrKBp5jGBABA2LJMQ61rlCu0fe0bJOq6egl5hrLT7c9937U6tCpFCScEr4S4KKV1/DLr60LalxgXJadca43eXE9jjwsLkjTW7qLW5urA1/nZZ0jqWmajRv/ZLdf9l5pr1MZao9HHBY3sX3MLbcHclz3WE4NW9nF5BbFsp9qXXVU4ft9hRUqS7vbMOGnfDresJOlWzw8n7VvnqyJJus5aetK+xU4dSdJl1tqT9s31NQ58bxluIASudi7KERCvtFYG9s32Nz1luBzvS8ozXP7D11Xj7JtlylE/6yv1904OhMs3fTdpvJ0kS476eGboHs83gXD5ob+dPrOvkke2brPmqIdn7nHrCttounOpLDm6yUxWx+M6e860m2me00SmHF1j/qprrGWBffPt+lrk1JVlOGplrNGl1m+B4LnUrqlVbjV5ZMuUI4/h6Bbzx0D4/MZpebTG5sqUq2vNpYHw+ZNTT5ZcmYYjS44uMX6XaWRV5n5zL5Ip5+h7HVU3UgKh9A+3goyj1UxDbo6pr/tVUlYgsDqKyGdgNY+rkma/L8KwFaEjOY7L3hdnHFaccfjoxuPPk/VrBTNVFZR6wmdk/VrF3KMq2pNjX/a9lX1fpKSma9GmfXn+NzcUEK4AAAiCU4Wy0+0vaGgr3H2FH+bqdXxeFzVIVL08zhtf/WqtN9rp841XScft+6LkHeoW8V9t23+kUMNeQfflFQINZYWmy72/qZVWhUwQLOi+UwXI7GMKM1w6R39a7++dfNK+Q4qSJN3j+eakfbvc0pKkHp65J+3b5MuaYtbR8/NJ+1Y51SRJ11jLTtq30Kkrv2vqUs9vJ+2b42uSIyRa1rHwuc6pkmPfddaSwL6FTt0c+5p7fw/s+8bfIs/g+Zm/bZ77/u1rf0aB9QHrq6PdSbMC6z99HfWufYMMSfdYXx9dH5m17x1/B31kt5MlR3das3SX59tAYP3Yf40+t6+SKUeGXN1qzdPtxwXaL/xX6CunjUy56mTOVxfPghzTbWc5zWXKUZK5WB08i+Vzsx4R0d+aFLiOXQeO/d0PRYQrAADOIYVdZTvVvqIKc3mf91pJ0vxcp1teq7XFVLk73b68QuDnJe9QxxqVVGtXskan5F6dK+4gWJB9rx8XIAsjlOXnveGyz8iaTZfrmqNsBa1cFua+7MD6UC6B9cjRauh93mkn7Ut1S0iS7vJ8m2ulNPv723MJtJt98ZKkLp4FJ+373XeBJKmDZ3GewbxiqSiFMtZc5YI1VwAAhKfCXh9XVPsKu1FKce8r6Bq/gjZtCad9/a1J6lL2v6p6YKlG+7rptVymQkqF32AmlPadTdfTU+17y7pddz/1JmuuAAAAikNxVu7OZl/xTuEMnWmhp5v6WdxVxqLYV6/j86q6e7zW77485KewFsW+062dPJvz3ly3XMg/hJnKVS6oXAEAAJxeQSt3Z/PecNl3qv3hXrk83b6Cdj09k/MGA63YzxLhCgAAAEUplIJgcYfLsz1vcSNcnSXCFQAAAAApf9nALKYxAQAAAMA5jXAFAAAAAIWAcAUAAAAAhYBwBQAAAACFgHAFAAAAAIWAcAUAAAAAhYBwBQAAAACFgHAFAAAAAIWAcAUAAAAAhYBwBQAAAACFwBPsAYQi13UlSWlpaUEeCQAAAIBgys4E2RnhVAhXuThw4IAkqUqVKkEeCQAAAIBQcODAAcXFxZ3yGMM9kwh2nnEcR9u3b1epUqVkGEZQx5KWlqYqVapo69atio2NDepYEF64d1AQ3DcoCO4bFBT3DgqiuO8b13V14MABVapUSaZ56lVVVK5yYZqmLrjggmAPI4fY2Fj+o4MC4d5BQXDfoCC4b1BQ3DsoiOK8b05XscpGQwsAAAAAKASEKwAAAAAoBISrEBcZGamhQ4cqMjIy2ENBmOHeQUFw36AguG9QUNw7KIhQvm9oaAEAAAAAhYDKFQAAAAAUAsIVAAAAABQCwhUAAAAAFALCFQAAAAAUAsJViHvjjTdUtWpVRUVFqVWrVlq0aFGwh4QQMmLECLVo0UKlSpVSxYoV1blzZ61bty7HMenp6erXr5/KlSunkiVLqmvXrtq5c2eQRoxQNHLkSBmGoQEDBgS2cd8gN9u2bdNf/vIXlStXTtHR0WrYsKF++eWXwH7XdTVkyBAlJiYqOjpa7dq10/r164M4YoQC27b1zDPPqFq1aoqOjlaNGjU0fPhwHd9TjXsHP/zwgzp27KhKlSrJMAxNnjw5x/4zuUf27dunnj17KjY2VqVLl9bdd9+tgwcPFuNVEK5C2sSJEzVw4EANHTpUS5cuVePGjZWUlKRdu3YFe2gIEfPmzVO/fv30888/a9asWfL5fLr++ut16NChwDGPPPKIpk6dqs8//1zz5s3T9u3b1aVLlyCOGqFk8eLF+te//qVGjRrl2M59gxP9+eefatOmjbxer7755hutWbNGr776qsqUKRM4ZtSoUXrttdf05ptvauHChSpRooSSkpKUnp4exJEj2F566SWNGzdOY8eO1dq1a/XSSy9p1KhRev311wPHcO/g0KFDaty4sd54441c95/JPdKzZ0+tXr1as2bN0rRp0/TDDz+ob9++xXUJWVyErJYtW7r9+vULfG/btlupUiV3xIgRQRwVQtmuXbtcSe68efNc13Xd/fv3u16v1/38888Dx6xdu9aV5CYnJwdrmAgRBw4ccGvVquXOmjXLbdu2rfvwww+7rst9g9w9/vjj7uWXX57nfsdx3ISEBPfll18ObNu/f78bGRnpfvrpp8UxRISoG2+80f3rX/+aY1uXLl3cnj17uq7LvYOTSXK//PLLwPdnco+sWbPGleQuXrw4cMw333zjGobhbtu2rdjGTuUqRGVmZmrJkiVq165dYJtpmmrXrp2Sk5ODODKEstTUVElS2bJlJUlLliyRz+fLcR/VqVNHF154IfcR1K9fP91444057g+J+wa5mzJlipo3b65bb71VFStWVNOmTfX2228H9m/atEk7duzIcd/ExcWpVatW3Dfnucsuu0yzZ8/W77//Lklavny55s+frw4dOkji3sHpnck9kpycrNKlS6t58+aBY9q1ayfTNLVw4cJiG6un2D4J+bJnzx7Ztq34+Pgc2+Pj4/Xbb78FaVQIZY7jaMCAAWrTpo0aNGggSdqxY4ciIiJUunTpHMfGx8drx44dQRglQsWECRO0dOlSLV68+KR93DfIzX//+1+NGzdOAwcO1JNPPqnFixfroYceUkREhHr37h24N3L7/xb3zfntiSeeUFpamurUqSPLsmTbtl544QX17NlTkrh3cFpnco/s2LFDFStWzLHf4/GobNmyxXofEa6Ac0S/fv20atUqzZ8/P9hDQYjbunWrHn74Yc2aNUtRUVHBHg7ChOM4at68uV588UVJUtOmTbVq1Sq9+eab6t27d5BHh1D22Wef6eOPP9Ynn3yi+vXra9myZRowYIAqVarEvYNzDtMCQ1T58uVlWdZJ3bl27typhISEII0KoerBBx/UtGnTNGfOHF1wwQWB7QkJCcrMzNT+/ftzHM99dH5bsmSJdu3apUsuuUQej0cej0fz5s3Ta6+9Jo/Ho/j4eO4bnCQxMVH16tXLsa1u3brasmWLJAXuDf6/hRP9/e9/1xNPPKHbb79dDRs21J133qlHHnlEI0aMkMS9g9M7k3skISHhpKZvfr9f+/btK9b7iHAVoiIiItSsWTPNnj07sM1xHM2ePVutW7cO4sgQSlzX1YMPPqgvv/xS33//vapVq5Zjf7NmzeT1enPcR+vWrdOWLVu4j85j1157rVauXKlly5YFXs2bN1fPnj0DX3Pf4ERt2rQ56VEPv//+uy666CJJUrVq1ZSQkJDjvklLS9PChQu5b85zhw8flmnm/JHTsiw5jiOJewendyb3SOvWrbV//34tWbIkcMz3338vx3HUqlWr4htssbXOQL5NmDDBjYyMdMePH++uWbPG7du3r1u6dGl3x44dwR4aQsT999/vxsXFuXPnznVTUlICr8OHDweOue+++9wLL7zQ/f77791ffvnFbd26tdu6desgjhqh6Phuga7LfYOTLVq0yPV4PO4LL7zgrl+/3v3444/dmJgY96OPPgocM3LkSLd06dLuV1995a5YscLt1KmTW61aNffIkSNBHDmCrXfv3m7lypXdadOmuZs2bXInTZrkli9f3h00aFDgGO4dHDhwwP3111/dX3/91ZXkjh492v3111/dzZs3u657ZvdI+/bt3aZNm7oLFy5058+f79aqVcvt0aNHsV4H4SrEvf766+6FF17oRkREuC1btnR//vnnYA8JIURSrq/33nsvcMyRI0fcBx54wC1TpowbExPj3nLLLW5KSkrwBo2QdGK44r5BbqZOneo2aNDAjYyMdOvUqeO+9dZbOfY7juM+88wzbnx8vBsZGelee+217rp164I0WoSKtLQ09+GHH3YvvPBCNyoqyq1evbr71FNPuRkZGYFjuHcwZ86cXH+m6d27t+u6Z3aP7N271+3Ro4dbsmRJNzY21u3Tp4974MCBYr0Ow3WPezw2AAAAAKBAWHMFAAAAAIWAcAUAAAAAhYBwBQAAAACFgHAFAAAAAIWAcAUAAAAAhYBwBQAAAACFgHAFAAAAAIWAcAUAQCEzDEOTJ08O9jAAAMWMcAUAOKfcddddMgzjpFf79u2DPTQAwDnOE+wBAABQ2Nq3b6/33nsvx7bIyMggjQYAcL6gcgUAOOdERkYqISEhx6tMmTKSsqbsjRs3Th06dFB0dLSqV6+uL774Isf7V65cqWuuuUbR0dEqV66c+vbtq4MHD+Y45t///rfq16+vyMhIJSYm6sEHH8yxf8+ePbrlllsUExOjWrVqacqUKUV70QCAoCNcAQDOO88884y6du2q5cuXq2fPnrr99tu1du1aSdKhQ4eUlJSkMmXKaPHixfr888/13Xff5QhP48aNU79+/dS3b1+tXLlSU6ZMUc2aNXN8xrPPPqvbbrtNK1as0A033KCePXtq3759xXqdAIDiZbiu6wZ7EAAAFJa77rpLH330kaKionJsf/LJJ/Xkk0/KMAzdd999GjduXGDfpZdeqksuuUT//Oc/9fbbb+vxxx/X1q1bVaJECUnS9OnT1bFjR23fvl3x8fGqXLmy+vTpo+effz7XMRiGoaefflrDhw+XlBXYSpYsqW+++Ya1XwBwDmPNFQDgnHP11VfnCE+SVLZs2cDXrVu3zrGvdevWWrZsmSRp7dq1aty4cSBYSVKbNm3kOI7WrVsnwzC0fft2XXvttaccQ6NGjQJflyhRQrGxsdq1a1dBLwkAEAYIVwCAc06JEiVOmqZXWKKjo8/oOK/Xm+N7wzDkOE5RDAkAECJYcwUAOO/8/PPPJ31ft25dSVLdunW1fPlyHTp0KLB/wYIFMk1TF198sUqVKqWqVatq9uzZxTpmAEDoo3IFADjnZGRkaMeOHTm2eTwelS9fXpL0+eefq3nz5rr88sv18ccfa9GiRXr33XclST179tTQoUPVu3dvDRs2TLt371b//v115513Kj4+XpI0bNgw3XfffapYsaI6dOigAwcOaMGCBerfv3/xXigAIKQQrgAA55wZM2YoMTExx7aLL75Yv/32m6SsTn4TJkzQAw88oMTERH366aeqV6+eJCkmJkYzZ87Uww8/rBYtWigmJkZdu3bV6NGjA+fq3bu30tPT9Y9//EOPPfaYypcvr27duhXfBQIAQhLdAgEA5xXDMPTll1+qc+fOwR4KAOAcw5orAAAAACgEhCsAAAAAKASsuQIAnFeYDQ8AKCpUrgAAAACgEBCuAAAAAKAQEK4AAAAAoBAQrgAAAACgEBCuAAAAAKAQEK4AAAAAoBAQrgAAAACgEBCuAAAAAKAQEK4AAAAAoBD8P+cK7RT4B6acAAAAAElFTkSuQmCC\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training complete! Total time: 3602.06 seconds\n"]}],"source":["# Train the GatedCombination model using training and validation data\n","trained_model = train_gated_combination_model(\n","    X1_train,          # Updated source embeddings (after applying the GNN model)\n","    X2_train,          # Original source embeddings (before applying the GNN model)\n","    X3_train,          # Updated target embeddings (after applying the GNN model)\n","    X4_train,          # Original target embeddings (before applying the GNN model)\n","    tensor_score_train, # Ground truth labels for the training set (1 for matched pairs, 0 for unmatched pairs)\n","\n","    X1_val,            # Updated source embeddings for the validation set\n","    X2_val,            # Original source embeddings for the validation set\n","    X3_val,            # Updated target embeddings for the validation set\n","    X4_val,            # Original target embeddings for the validation set\n","    tensor_score_val,  # Ground truth labels for the validation set (1 for matched pairs, 0 for unmatched pairs)\n","\n","    epochs=100,        # Number of epochs (iterations over the entire training dataset)\n","    batch_size=32,     # Number of training samples processed in one forward/backward pass\n","    learning_rate=0.001, # Learning rate for the optimizer (controls step size during optimization)\n","    weight_decay=1e-5  # Weight decay (L2 regularization) to prevent overfitting\n",")"]},{"cell_type":"markdown","metadata":{"id":"uAmLuMtGW9c2"},"source":["# **Mappings Selector**"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"lnFtpUAfJQHl","executionInfo":{"status":"ok","timestamp":1732285461274,"user_tz":-60,"elapsed":617,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Build an indexed dictionary for the source ontology classes\n","# src_class is the file path to the JSON file containing the source ontology classes\n","indexed_dict_src = build_indexed_dict(src_class)\n","\n","# Build an indexed dictionary for the target ontology classes\n","# tgt_class is the file path to the JSON file containing the target ontology classes\n","indexed_dict_tgt = build_indexed_dict(tgt_class)"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"beipwavuJQHl","executionInfo":{"status":"ok","timestamp":1732285461511,"user_tz":-60,"elapsed":239,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the candidate pairs from a Candidates CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(candidates_Prediction, index_col=0)\n","\n","# Extract the 'SrcEntity' column (source entity indices) and convert it to a NumPy array of integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)\n","\n","# Extract the 'TgtEntity' column (target entity indices) and convert it to a NumPy array of integers\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)\n","\n","# Convert the source entity indices to a PyTorch LongTensor\n","src_entity_tensor_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)\n","\n","# Convert the target entity indices to a PyTorch LongTensor\n","tgt_entity_tenso_or = torch.from_numpy(tensor_term2).type(torch.LongTensor)"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"ECLhmxyKJQHl","executionInfo":{"status":"ok","timestamp":1732285461764,"user_tz":-60,"elapsed":255,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Select rows from the updated source embeddings based on the indices in src_entity_tensor_o\n","X1_tt = select_rows_by_index(embeddings_src, src_entity_tensor_o)\n","\n","# Select rows from the original source embeddings based on the indices in src_entity_tensor_o\n","X2_tt = select_rows_by_index(x_src, src_entity_tensor_o)\n","\n","# Select rows from the updated target embeddings based on the indices in tgt_entity_tenso_or\n","X3_tt = select_rows_by_index(embeddings_tgt, tgt_entity_tenso_or)\n","\n","# Select rows from the original target embeddings based on the indices in tgt_entity_tenso_or\n","X4_tt = select_rows_by_index(x_tgt, tgt_entity_tenso_or)"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a799342e-4691-46f7-e681-2db27f6b3220","id":"UFP6OQR-7D4N","executionInfo":{"status":"ok","timestamp":1732285535852,"user_tz":-60,"elapsed":74090,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting time: 54.00 seconds\n","Predictions saved to /content/gdrive/My Drive/BioGITOM-VLDB/Experiments/neoplas/GIT_Ablation/Results/neoplas_all_predictions.tsv\n"]}],"source":["# Generate predictions for candidate mappings using the trained GatedCombination model\n","Prediction_with_candidates(\n","    model=trained_model,             # The trained GatedCombination model used to evaluate similarity\n","    X1_tt=X1_tt,                     # Updated source embeddings (after applying the GIT model)\n","    X2_tt=X2_tt,                     # Original source embeddings (before applying the GIT model)\n","    X3_tt=X3_tt,                     # Updated target embeddings (after applying the GIT model)\n","    X4_tt=X4_tt,                     # Original target embeddings (before applying the GIT model)\n","    src_entity_tensor_o=src_entity_tensor_o,  # Tensor of source entity indices used for evaluation\n","    tgt_entity_tensor_o=tgt_entity_tenso_or,  # Tensor of target entity indices used for evaluation\n","    indexed_dict_src=indexed_dict_src,        # Dictionary mapping source entity indices to their URIs\n","    indexed_dict_tgt=indexed_dict_tgt,        # Dictionary mapping target entity indices to their URIs\n","    all_predictions_path=all_predictions_path # Path to save all predictions with similarity scores in TSV format\n",")"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"mEc12J-B7D4N","colab":{"base_uri":"https://localhost:8080/"},"outputId":"36ca9d86-17c7-44a0-84b6-93ff14485419","executionInfo":{"status":"ok","timestamp":1732285548362,"user_tz":-60,"elapsed":12513,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Positive Predictions : 1935\n"]}],"source":["# Filter the highest scoring predictions from the predictions file and save the results to a new file\n","matching_results_df = filter_highest_predictions(\n","    all_predictions_path,  # Path to the file containing all predictions with scores for all candidate pairs\n","    prediction_path        # Path where the filtered predictions with highest scores will be saved\n",")"]},{"cell_type":"markdown","metadata":{"id":"BIx74lNV7D4O"},"source":["# **Evaluation**"]},{"cell_type":"markdown","source":["# Global metrics calculation"],"metadata":{"id":"Pp3IpBBfWn9m"}},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bkOewzXr7D4O","outputId":"f49f0481-2430-4164-d807-ede2b3ed4045","executionInfo":{"status":"ok","timestamp":1732285549332,"user_tz":-60,"elapsed":972,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Correct Predictions : 1542\n","{'P': 0.797, 'R': 0.579, 'F1': 0.671}\n"]}],"source":["# Retrieve the indices of the ignored classes (from source and target ontologies)\n","ignored_class_index = get_ignored_class_index(src_onto)  # Get ignored class indices from source ontology\n","ignored_class_index.update(get_ignored_class_index(tgt_onto))  # Update with ignored class indices from target ontology\n","\n","# Read the predicted mappings from the prediction results file\n","preds = EntityMapping.read_table_mappings(prediction_path)\n","\n","# Read the reference mappings from the ground truth test file\n","refs = ReferenceMapping.read_table_mappings(f\"{dataset_dir}/refs_equiv/test.tsv\")\n","\n","# Filter the predicted mappings to remove any mappings that involve ignored classes\n","preds = remove_ignored_mappings(preds, ignored_class_index)\n","\n","# Compute the precision, recall, and F1-score by comparing predictions with the reference mappings\n","results = AlignmentEvaluator.f1(preds, refs)\n","\n","preds2 = [p.to_tuple() for p in preds]\n","refs2 = [r.to_tuple() for r in refs]\n","\n","correct= len(set(preds2).intersection(set(refs2)))\n","\n","print(f\"Number of Correct Predictions : {correct}\")\n","\n","# Print the computed precision, recall, and F1-score metrics\n","print(results)"]},{"cell_type":"markdown","source":["# Ranked-based metrics calculation"],"metadata":{"id":"aECB6igZW04C"}},{"cell_type":"code","execution_count":39,"metadata":{"id":"-AK-jADkSbTa","executionInfo":{"status":"ok","timestamp":1732285549700,"user_tz":-60,"elapsed":371,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the candidate pairs from a Candidates CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(candidates_Rank, index_col=0)\n","\n","# Extract the 'SrcEntity' column (source entity indices) and convert it to a NumPy array of integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)\n","\n","# Extract the 'TgtEntity' column (target entity indices) and convert it to a NumPy array of integers\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)\n","\n","# Convert the source entity indices to a PyTorch LongTensor\n","src_entity_tensor_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)\n","\n","# Convert the target entity indices to a PyTorch LongTensor\n","tgt_entity_tenso_or = torch.from_numpy(tensor_term2).type(torch.LongTensor)"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"oyOzcLv-SbTb","executionInfo":{"status":"ok","timestamp":1732285550047,"user_tz":-60,"elapsed":349,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Select rows from the updated source embeddings based on the indices in src_entity_tensor_o\n","X1_tt = select_rows_by_index(embeddings_src, src_entity_tensor_o)\n","\n","# Select rows from the original source embeddings based on the indices in src_entity_tensor_o\n","X2_tt = select_rows_by_index(x_src, src_entity_tensor_o)\n","\n","# Select rows from the updated target embeddings based on the indices in tgt_entity_tenso_or\n","X3_tt = select_rows_by_index(embeddings_tgt, tgt_entity_tenso_or)\n","\n","# Select rows from the original target embeddings based on the indices in tgt_entity_tenso_or\n","X4_tt = select_rows_by_index(x_tgt, tgt_entity_tenso_or)"]},{"cell_type":"code","source":["# Perform ranking-based predictions using the trained GatedCombination model\n","# Generate predictions for candidate mappings using the trained GatedCombination model\n","Prediction_with_candidates(\n","    model=trained_model,             # The trained GatedCombination model used to evaluate similarity\n","    X1_tt=X1_tt,                     # Updated source embeddings (after applying the GIT model)\n","    X2_tt=X2_tt,                     # Original source embeddings (before applying the GIT model)\n","    X3_tt=X3_tt,                     # Updated target embeddings (after applying the GIT model)\n","    X4_tt=X4_tt,                     # Original target embeddings (before applying the GIT model)\n","    src_entity_tensor_o=src_entity_tensor_o,  # Tensor of source entity indices used for evaluation\n","    tgt_entity_tensor_o=tgt_entity_tenso_or,  # Tensor of target entity indices used for evaluation\n","    indexed_dict_src=indexed_dict_src,        # Dictionary mapping source entity indices to their URIs\n","    indexed_dict_tgt=indexed_dict_tgt,        # Dictionary mapping target entity indices to their URIs\n","    all_predictions_path=all_predictions_path_ranked, # Path where the ranked predictions will be saved in TSV format\n",")"],"metadata":{"id":"-O2f7X6cSb-m","executionInfo":{"status":"ok","timestamp":1732285619920,"user_tz":-60,"elapsed":69875,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d9c6a844-a9c3-4b46-84be-cb54c45f3a09"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting time: 51.46 seconds\n","Predictions saved to /content/gdrive/My Drive/BioGITOM-VLDB/Experiments/neoplas/GIT_Ablation/Results/neoplas_all_predictions_ranked.tsv\n"]}]},{"cell_type":"code","execution_count":42,"metadata":{"id":"_402seVv7D4O","executionInfo":{"status":"ok","timestamp":1732285634881,"user_tz":-60,"elapsed":14972,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"69bf55da-e138-44ee-a82f-4bff24f4858b"},"outputs":[{"output_type":"stream","name":"stdout","text":["MRR and Hits@k Results:\n","{'MRR': 0.8562348916406267, 'Hits@k': {1: 0.7840781073976718, 5: 0.9470521967705595, 10: 0.9778445362373264}}\n"]}],"source":["# Compute MRR and Hits@k metrics\n","# This function evaluates the predicted rankings against the reference mappings\n","results = compute_mrr_and_hits(\n","    reference_file=test_cands,             # Reference file with true ranks\n","    predicted_file=all_predictions_path_ranked,             # File containing predicted rankings\n","    output_file=formatted_predictions_path,    # File path to save formatted predictions\n","    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",")\n","\n","# Display the computed metrics\n","print(\"MRR and Hits@k Results:\")\n","print(results)  # Output the Mean Reciprocal Rank (MRR) and Hits@k metrics"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"wStfa4eZ7D4O","executionInfo":{"status":"ok","timestamp":1732285638056,"user_tz":-60,"elapsed":3186,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"aef57406-3bf7-49d4-fbda-d5dc194f2740"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ranking Evaluation Results at K=1, 5, and 10:\n","{'MRR': 0.8562348916406267, 'Hits@1': 0.7840781073976718, 'Hits@5': 0.9470521967705595, 'Hits@10': 0.9778445362373264}\n"]}],"source":["# Call the ranking evaluation function, passing the path to the formatted predictions file.\n","# Ks specifies the evaluation levels, checking if the correct target is within the top K candidates.\n","results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n","print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n","print(results)"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}