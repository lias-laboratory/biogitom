{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkAX88H3RNRW"
      },
      "source": [
        "# **Package Installation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bSuJvX5_qNhr",
        "outputId": "68048ea1-7969-4df6-da6c-229c8c6e13e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.6.0\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchvision==0.21.0\n",
            "  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting filelock (from torch==2.6.0)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch==2.6.0)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting networkx (from torch==2.6.0)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch==2.6.0)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch==2.6.0)\n",
            "  Downloading fsspec-2025.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.6.0)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch==2.6.0)\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting sympy==1.13.1 (from torch==2.6.0)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting numpy (from torchvision==0.21.0)\n",
            "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.21.0)\n",
            "  Downloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch==2.6.0)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.6.0)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m116.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m123.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m742.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2025.5.0-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m114.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.13.2\n",
            "    Uninstalling typing_extensions-4.13.2:\n",
            "      Successfully uninstalled typing_extensions-4.13.2\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.2.1\n",
            "    Uninstalling pillow-11.2.1:\n",
            "      Successfully uninstalled pillow-11.2.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.18.0\n",
            "    Uninstalling filelock-3.18.0:\n",
            "      Successfully uninstalled filelock-3.18.0\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cpu\n",
            "    Uninstalling torch-2.6.0+cpu:\n",
            "      Successfully uninstalled torch-2.6.0+cpu\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cpu\n",
            "    Uninstalling torchvision-0.21.0+cpu:\n",
            "      Successfully uninstalled torchvision-0.21.0+cpu\n",
            "Successfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.5.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 pillow-11.2.1 sympy-1.13.1 torch-2.6.0 torchvision-0.21.0 triton-3.2.0 typing-extensions-4.13.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "413a766688884535b7cdaa6031def320"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Reinstall a specific version of PyTorch (v2.6.0) and torchvision (v0.21.0)\n",
        "# The \"--force-reinstall\" flag ensures that the packages are reinstalled even if the correct version is already present.\n",
        "# This is useful to resolve environment issues or when dependencies need to be reset.\n",
        "!pip install torch==2.6.0 torchvision==0.21.0 --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ItSvFeEAfLBF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a717d74-32c4-4cdb-f031-2814a1078425"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.2.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.2.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.2.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\n",
            "Collecting torch-geometric==2.4.0\n",
            "  Using cached torch_geometric-2.4.0-py3-none-any.whl.metadata (63 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (2.2.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (1.15.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (3.1.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (3.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (1.6.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric==2.4.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.4.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.4.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.4.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.4.0) (2025.4.26)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->torch-geometric==2.4.0) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->torch-geometric==2.4.0) (3.6.0)\n",
            "Using cached torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "Installing collected packages: torch-geometric\n",
            "  Attempting uninstall: torch-geometric\n",
            "    Found existing installation: torch-geometric 2.7.0\n",
            "    Uninstalling torch-geometric-2.7.0:\n",
            "      Successfully uninstalled torch-geometric-2.7.0\n",
            "Successfully installed torch-geometric-2.4.0\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.11/dist-packages (2.1.2+pt20cpu)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.11/dist-packages (0.6.18+pt20cpu)\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.11/dist-packages (1.6.3+pt20cpu)\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.11/dist-packages (1.2.2+pt20cpu)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (2.2.6)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: deeponto in /usr/local/lib/python3.11/dist-packages (0.9.3)\n",
            "Requirement already satisfied: JPype1 in /usr/local/lib/python3.11/dist-packages (from deeponto) (1.5.2)\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.11/dist-packages (from deeponto) (0.1.8)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from deeponto) (2.6.0)\n",
            "Requirement already satisfied: anytree in /usr/local/lib/python3.11/dist-packages (from deeponto) (2.13.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from deeponto) (8.2.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from deeponto) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from deeponto) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deeponto) (2.2.6)\n",
            "Requirement already satisfied: scikit_learn in /usr/local/lib/python3.11/dist-packages (from deeponto) (1.6.1)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.11/dist-packages (from deeponto) (4.51.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from deeponto) (3.6.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (from deeponto) (3.8.5)\n",
            "Requirement already satisfied: pprintpp in /usr/local/lib/python3.11/dist-packages (from deeponto) (0.4.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from deeponto) (3.4.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from deeponto) (5.4.0)\n",
            "Requirement already satisfied: textdistance in /usr/local/lib/python3.11/dist-packages (from deeponto) (4.6.3)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from deeponto) (7.7.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from deeponto) (6.17.1)\n",
            "Requirement already satisfied: enlighten in /usr/local/lib/python3.11/dist-packages (from deeponto) (1.14.1)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.11/dist-packages (from deeponto) (7.1.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from deeponto) (3.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (20.0.0)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (0.31.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (6.0.2)\n",
            "Requirement already satisfied: blessed>=1.17.7 in /usr/local/lib/python3.11/dist-packages (from enlighten->deeponto) (1.21.0)\n",
            "Requirement already satisfied: prefixed>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from enlighten->deeponto) (0.9.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (6.4.2)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (5.7.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->deeponto) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->deeponto) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->deeponto) (3.0.15)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->deeponto) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->deeponto) (2024.11.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->deeponto) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->deeponto) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->deeponto) (2025.2)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from rdflib->deeponto) (3.2.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn->deeponto) (1.15.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn->deeponto) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (0.15.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (2.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (4.13.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->deeponto) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->deeponto) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->deeponto) (0.5.3)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->deeponto) (1.6.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.11/dist-packages (from blessed>=1.17.7->enlighten->deeponto) (0.2.13)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (3.11.15)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (5.2.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (4.9.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel->deeponto) (5.7.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->deeponto) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->deeponto) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->deeponto) (2025.4.26)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->deeponto) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->deeponto) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (14.0.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (7.1.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.5.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy->deeponto) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (1.20.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->deeponto) (0.8.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel->deeponto) (4.3.8)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.3.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->deeponto) (0.7.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (3.0.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->deeponto) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (0.1.2)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.23.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.24.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "# === Base Libraries ===\n",
        "!pip install numpy --upgrade\n",
        "!pip install pandas\n",
        "!pip install optuna\n",
        "\n",
        "# === FAISS (for Approximate Nearest Neighbor Search) ===\n",
        "!pip install faiss-cpu        # CPU version (recommended unless using GPU)\n",
        "# !pip install faiss-gpu      # Uncomment if running on CUDA-enabled GPU\n",
        "\n",
        "# === PyTorch Geometric and dependencies ===\n",
        "!pip install torch-geometric==2.4.0\n",
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
        "# Optional: latest dev version from GitHub\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "# === DeepOnto (Ontology Matching Toolkit) ===\n",
        "!pip install deeponto\n",
        "# Optionally install custom version from a GitHub repository\n",
        "# !pip install git+https://github.com/<username>/deeponto.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nFonRjT5fMCv"
      },
      "outputs": [],
      "source": [
        "# Import pandas for working with tabular data (e.g., CSV, TSV files)\n",
        "import pandas as pd\n",
        "\n",
        "# Import numpy for numerical operations and efficient array handling\n",
        "import numpy as np\n",
        "\n",
        "# Import json for reading and writing JSON-formatted files (useful for config or ontology structures)\n",
        "import json\n",
        "\n",
        "# Import pickle for serializing and deserializing Python objects (e.g., saving models or processed data)\n",
        "import pickle\n",
        "\n",
        "# Import warnings to control or suppress warning messages during runtime\n",
        "import warnings\n",
        "\n",
        "# Import gc (garbage collector) for managing memory manually when dealing with large datasets\n",
        "import gc\n",
        "\n",
        "# Ignore all warning messages to keep the output clean\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uchfZJP2fZwe"
      },
      "outputs": [],
      "source": [
        "# Import PyTorch core library for tensor operations and model definition\n",
        "import torch\n",
        "\n",
        "# Import commonly used PyTorch components\n",
        "from torch import Tensor, optim  # Tensor type and optimization algorithms (e.g., SGD, Adam)\n",
        "\n",
        "# Import PyTorch's neural network module (base class for defining models)\n",
        "import torch.nn as nn\n",
        "\n",
        "# Import PyTorch's functional API for operations like activations and loss functions\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Import DataLoader utilities for batching and loading datasets during training\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# === PyTorch Geometric (PyG) modules for graph-based learning ===\n",
        "\n",
        "# Basic graph data structure from PyG\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# PyG-specific DataLoader for batching graphs\n",
        "from torch_geometric.loader import DataLoader as GeoDataLoader\n",
        "\n",
        "# Import graph convolution layers and pooling functions from PyG\n",
        "from torch_geometric.nn import (\n",
        "    GCNConv,             # Graph Convolutional Network layer\n",
        "    GINConv,             # Graph Isomorphism Network convolution\n",
        "    global_mean_pool,    # Global mean pooling over node embeddings\n",
        "    global_add_pool,     # Global sum pooling over node embeddings\n",
        "    MessagePassing       # Base class for defining custom GNN layers\n",
        ")\n",
        "\n",
        "# Explicitly re-import MessagePassing (optional if already above)\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "\n",
        "# Graph utility functions from PyG\n",
        "from torch_geometric.utils import (\n",
        "    to_undirected,       # Converts a directed graph to undirected\n",
        "    softmax              # Softmax over edges (e.g., for attention)\n",
        ")\n",
        "\n",
        "# Initialization utilities for GNN layers\n",
        "from torch_geometric.nn.inits import (\n",
        "    reset,               # Reset parameters\n",
        "    glorot,              # Glorot (Xavier) weight initialization\n",
        "    zeros                # Zero initialization\n",
        ")\n",
        "\n",
        "# Typing utilities from PyG for adjacency and tensor specifications\n",
        "from torch_geometric.typing import (\n",
        "    Adj, OptTensor, PairTensor, SparseTensor\n",
        ")\n",
        "\n",
        "# Dense linear transformation layer from PyG (alternative to torch.nn.Linear)\n",
        "from torch_geometric.nn.dense.linear import Linear\n",
        "\n",
        "# Additional PyTorch neural network components\n",
        "from torch.nn import (\n",
        "    Linear,             # Fully connected (dense) layer\n",
        "    PReLU,              # Parametric ReLU activation\n",
        "    Sequential,         # Layer container for building sequential models\n",
        "    BatchNorm1d,        # Batch normalization for 1D inputs\n",
        "    Dropout             # Dropout regularization\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ziMBSWE8ff1N"
      },
      "outputs": [],
      "source": [
        "# Import matplotlib for creating visualizations (e.g., loss curves, evaluation metrics, embedding projections)\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JeAvp6PNfiLh"
      },
      "outputs": [],
      "source": [
        "# Import function to split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import encoder to convert categorical labels into integer values (useful for classification tasks)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Import evaluation metrics for classification and regression tasks\n",
        "from sklearn.metrics import (\n",
        "    f1_score,            # Harmonic mean of precision and recall; useful for imbalanced classification\n",
        "    precision_score,     # Measures the proportion of true positives among all predicted positives\n",
        "    accuracy_score,      # Measures overall correctness of predictions (classification)\n",
        "    mean_squared_error,  # Measures average squared difference between predicted and actual values (regression)\n",
        "    mean_absolute_error  # Measures average absolute difference between predicted and actual values (regression)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jm1rMZvmfl2M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "befa1291-a8fc-4b3f-a4fb-be8efce8bdd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter the maximum memory located to JVM [8g]: 8g\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import the Ontology class for loading and manipulating OWL ontologies\n",
        "from deeponto.onto import Ontology\n",
        "\n",
        "# Import all components related to OAEI (Ontology Alignment Evaluation Initiative) benchmarking\n",
        "from deeponto.align.oaei import *\n",
        "\n",
        "# Import data structures for representing mappings between ontology entities\n",
        "from deeponto.align.mapping import EntityMapping, ReferenceMapping\n",
        "# - EntityMapping: represents a predicted alignment (one or more mappings)\n",
        "# - ReferenceMapping: represents the gold standard/reference alignments\n",
        "\n",
        "# Import the evaluator to compute Precision, Recall, and F1-score for alignments\n",
        "from deeponto.align.evaluation import AlignmentEvaluator\n",
        "\n",
        "# Utility function to read TSV/CSV tables as mapping or data frames\n",
        "from deeponto.utils import read_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JYhwr3Q_ft2N"
      },
      "outputs": [],
      "source": [
        "# Import Optuna, a hyperparameter optimization framework for automating model tuning using strategies like Bayesian optimization\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UmSCo5Olfzuz"
      },
      "outputs": [],
      "source": [
        "# Import the math module for mathematical functions (e.g., sqrt, log, exp)\n",
        "import math\n",
        "\n",
        "# Import the time module for measuring execution time of code blocks or functions\n",
        "import time\n",
        "\n",
        "# Import typing annotations for function signatures and code clarity\n",
        "from typing import Optional, Tuple, Union, Callable\n",
        "# - Optional[T]: denotes a value that could be of type T or None\n",
        "# - Tuple: fixed-size ordered collection of elements\n",
        "# - Union: allows multiple possible types (e.g., Union[int, str])\n",
        "# - Callable: represents a function or method type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9WNn0OMQW2CS"
      },
      "outputs": [],
      "source": [
        "# Import Python's built-in random module for generating pseudo-random numbers\n",
        "import random\n",
        "\n",
        "# Set the seed for PyTorch's random number generator to ensure reproducibility\n",
        "import torch\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Set the seed for NumPy's random number generator to ensure reproducibility\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "\n",
        "# Set the seed for Python's built-in random module to ensure reproducibility\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-abbBHOoRdWl"
      },
      "source": [
        "# **Paths Definition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AVgl_Bb42naS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ff01177-5663-46ef-cf8d-d172add8ffca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Importing the 'drive' module from Google Colab to interact with Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount the user's Google Drive to the Colab environment\n",
        "# After running this, a link will appear to authorize access, and Google Drive will be mounted at '/content/gdrive'\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "36ttssQ3W7cx"
      },
      "outputs": [],
      "source": [
        "# Define the source ontology name\n",
        "src_ent = \"snomed.neoplas\"\n",
        "\n",
        "# Define the target ontology name\n",
        "tgt_ent = \"ncit.neoplas\"\n",
        "\n",
        "# Define the task name for this ontology matching process\n",
        "task = \"neoplas\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SJpvkdwVSQye"
      },
      "outputs": [],
      "source": [
        "dir = \"/content/gdrive/My Drive/BioGITOM-VLDB/\"\n",
        "\n",
        "# Define the directory for the dataset containing source and target ontologies\n",
        "dataset_dir = f\"{dir}/Datasets/{task}\"\n",
        "\n",
        "# Define the data directory for storing embeddings, adjacency matrices, and related files\n",
        "data_dir = f\"{dir}/{task}/Data\"\n",
        "\n",
        "# Define the directory for storing the results\n",
        "results_dir = f\"{dir}/{task}/Results\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "eFDNSFef23er"
      },
      "outputs": [],
      "source": [
        "# Load the Source ontology using the Ontology class from DeepOnto\n",
        "# This initializes the source ontology by loading its .owl file.\n",
        "src_onto = Ontology(f\"{dataset_dir}/{src_ent}.owl\")\n",
        "\n",
        "# Load the Target ontology using the Ontology class from DeepOnto\n",
        "# This initializes the target ontology by loading its .owl file.\n",
        "tgt_onto = Ontology(f\"{dataset_dir}/{tgt_ent}.owl\")\n",
        "\n",
        "# Define the file path for the Source embeddings CSV file\n",
        "# Embeddings for the source ontology entities are stored in this file.\n",
        "src_Emb = f\"{data_dir}/{src_ent}_Sentence_SapBERT_emb.csv\"\n",
        "\n",
        "# Define the file path for the Target embeddings CSV file\n",
        "# Embeddings for the target ontology entities are stored in this file.\n",
        "tgt_Emb = f\"{data_dir}/{tgt_ent}_Sentence_SapBERT_emb.csv\"\n",
        "\n",
        "# Define the file path for the Source adjacency matrix\n",
        "# This file represents the relationships (edges) between entities in the source ontology.\n",
        "src_Adjacence = f\"{data_dir}/{src_ent}_adjacence.csv\"\n",
        "\n",
        "# Define the file path for the Target adjacency matrix\n",
        "# This file represents the relationships (edges) between entities in the target ontology.\n",
        "tgt_Adjacence = f\"{data_dir}/{tgt_ent}_adjacence.csv\"\n",
        "\n",
        "# Define the file path for the JSON file containing the Source ontology class labels\n",
        "# This file maps the source ontology entities to their labels or names.\n",
        "src_class = f\"{data_dir}/{src_ent}_classes.json\"\n",
        "\n",
        "# Define the file path for the JSON file containing the Target ontology class labels\n",
        "# This file maps the target ontology entities to their labels or names.\n",
        "tgt_class = f\"{data_dir}/{tgt_ent}_classes.json\"\n",
        "\n",
        "# Define the file path for the train data\n",
        "train_file = f\"{data_dir}/{task}_train_50.csv\"\n",
        "\n",
        "# Define the file path for the test data\n",
        "# The test file contains reference mappings (ground truth) between the source and target ontologies.\n",
        "test_file = f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "\n",
        "# Define the file path for the candidate mappings used during testing\n",
        "# This file includes the candidate pairs (source and target entities) for ranking based metrics.\n",
        "test_cands = f\"{dataset_dir}/refs_equiv/test.cands.tsv\"\n",
        "cands_path = f\"{data_dir}/{task}_cands.csv\"\n",
        "\n",
        "# Define the path where the prediction results will be saved in TSV format\n",
        "# This file will store the final predictions (mappings) between source and target entities.\n",
        "prediction_path = f\"{results_dir}/{task}_matching_results.tsv\"\n",
        "\n",
        "# Define the path where all prediction results will be saved in TSV format\n",
        "# This file will store detailed prediction results, including all candidate scores.\n",
        "all_predictions_path = f\"{results_dir}/{task}_all_predictions.tsv\"\n",
        "\n",
        "# Define the path where formatted ranking predictions will be saved in TSV format\n",
        "# This file will contain predictions formatted for evaluation using ranking-based metrics.\n",
        "formatted_predictions_path = f\"{results_dir}/{task}_formatted_predictions.tsv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqEXsgPGMVhw"
      },
      "source": [
        "# **GIT Architecture**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "A_d6XCsUMVhx"
      },
      "outputs": [],
      "source": [
        "# RGIT class definition which inherits from PyTorch Geometric's MessagePassing class\n",
        "class RGIT(MessagePassing):\n",
        "\n",
        "    _alpha: OptTensor  # Define _alpha as an optional tensor for storing attention weights\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        nn: Callable,  # Neural network to be used in the final layer of the GNN\n",
        "        in_channels: Union[int, Tuple[int, int]],  # Input dimension, can be a single or pair of integers\n",
        "        out_channels: int,  # Output dimension of the GNN\n",
        "        eps: float = 0.,  # GIN parameter: epsilon for GIN aggregation\n",
        "        train_eps: bool = False,  # GIN parameter: whether epsilon should be learnable\n",
        "        heads: int = 1,  # Transformer parameter: number of attention heads\n",
        "        dropout: float = 0.,  # Dropout rate for attention weights\n",
        "        edge_dim: Optional[int] = None,  # Dimension for edge attributes (optional)\n",
        "        bias: bool = True,  # Whether to use bias in linear layers\n",
        "        root_weight: bool = True,  # GIN parameter: whether to apply root weight in aggregation\n",
        "        **kwargs,  # Additional arguments passed to the parent class\n",
        "    ):\n",
        "        # Set the aggregation type to 'add' and initialize the parent class with node_dim=0\n",
        "        kwargs.setdefault('aggr', 'add')\n",
        "        super().__init__(node_dim=0, **kwargs)\n",
        "\n",
        "        # Initialize input/output dimensions, neural network, and GIN/transformer parameters\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.nn = nn  # Neural network used by the GNN\n",
        "        self.initial_eps = eps  # Initial value of epsilon for GIN\n",
        "\n",
        "        # Set epsilon to be learnable or fixed\n",
        "        if train_eps:\n",
        "            self.eps = torch.nn.Parameter(torch.empty(1))  # Learnable epsilon\n",
        "        else:\n",
        "            self.register_buffer('eps', torch.empty(1))  # Non-learnable epsilon (fixed)\n",
        "\n",
        "        # Initialize transformer-related parameters\n",
        "        self.heads = heads\n",
        "        self.dropout = dropout\n",
        "        self.edge_dim = edge_dim\n",
        "        self._alpha = None  # Placeholder for attention weights\n",
        "\n",
        "        # Handle case where in_channels is a single integer or a tuple\n",
        "        if isinstance(in_channels, int):\n",
        "            in_channels = (in_channels, in_channels)\n",
        "\n",
        "        # Define the linear layers for key, query, and value for the transformer mechanism\n",
        "        self.lin_key = Linear(in_channels[0], heads * out_channels)\n",
        "        self.lin_query = Linear(in_channels[1], heads * out_channels)\n",
        "        self.lin_value = Linear(in_channels[0], heads * out_channels)\n",
        "\n",
        "        # Define linear transformation for edge embeddings if provided\n",
        "        if edge_dim is not None:\n",
        "            self.lin_edge = Linear(edge_dim, heads * out_channels, bias=False)\n",
        "        else:\n",
        "            self.lin_edge = self.register_parameter('lin_edge', None)\n",
        "\n",
        "        # Reset all parameters to their initial values\n",
        "        self.reset_parameters()\n",
        "\n",
        "    # Function to reset model parameters\n",
        "    def reset_parameters(self):\n",
        "        super().reset_parameters()  # Call parent class reset method\n",
        "        self.lin_key.reset_parameters()  # Reset key linear layer\n",
        "        self.lin_query.reset_parameters()  # Reset query linear layer\n",
        "        self.lin_value.reset_parameters()  # Reset value linear layer\n",
        "        if self.edge_dim:\n",
        "            self.lin_edge.reset_parameters()  # Reset edge linear layer if used\n",
        "        reset(self.nn)  # Reset the neural network provided\n",
        "        self.eps.data.fill_(self.initial_eps)  # Initialize epsilon with the starting value\n",
        "\n",
        "    # Forward function defining how the input data flows through the model\n",
        "    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj,\n",
        "                edge_attr: OptTensor = None, return_attention_weights=None):\n",
        "        # Unpack number of heads and output channels\n",
        "        H, C = self.heads, self.out_channels\n",
        "\n",
        "        # If x is a tensor, treat it as a pair of tensors (source and target embeddings)\n",
        "        if isinstance(x, Tensor):\n",
        "            x: PairTensor = (x, x)\n",
        "\n",
        "        # Extract source node embeddings\n",
        "        x_t = x[0]\n",
        "\n",
        "        # Apply linear transformations and reshape query, key, and value for multi-head attention\n",
        "        query = self.lin_query(x[1]).view(-1, H, C)\n",
        "        key = self.lin_key(x[0]).view(-1, H, C)\n",
        "        value = self.lin_value(x[0]).view(-1, H, C)\n",
        "\n",
        "        # Propagate messages through the graph using the propagate function\n",
        "        out = self.propagate(edge_index, query=query, key=key, value=value,\n",
        "                             edge_attr=edge_attr, size=None)\n",
        "\n",
        "        # Retrieve attention weights and reset them\n",
        "        alpha = self._alpha\n",
        "        self._alpha = None  # Reset _alpha after use\n",
        "        out = out.mean(dim=1)  # Take the mean over all attention heads\n",
        "\n",
        "        # Apply GIN aggregation by adding epsilon-scaled original node embeddings\n",
        "        out = out + (1 + self.eps) * x_t\n",
        "        return self.nn(out)  # Pass through the neural network\n",
        "\n",
        "    # Message passing function which calculates attention and combines messages\n",
        "    def message(self, query_i: Tensor, key_j: Tensor, value_j: Tensor,\n",
        "                edge_attr: OptTensor, index: Tensor, ptr: OptTensor,\n",
        "                size_i: Optional[int]) -> Tensor:\n",
        "        # If edge attributes are used, apply linear transformation and add them to the key\n",
        "        if self.lin_edge is not None:\n",
        "            assert edge_attr is not None\n",
        "            edge_attr = self.lin_edge(edge_attr).view(-1, self.heads, self.out_channels)\n",
        "            key_j = key_j + edge_attr\n",
        "\n",
        "        # Calculate attention (alpha) using the dot product between query and key\n",
        "        alpha = (query_i * key_j).sum(dim=-1) / math.sqrt(self.out_channels)\n",
        "        alpha = softmax(alpha, index, ptr, size_i)  # Apply softmax to normalize attention\n",
        "        self._alpha = alpha  # Store attention weights\n",
        "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)  # Apply dropout\n",
        "\n",
        "        # Calculate the output message by applying attention to the value\n",
        "        out = value_j\n",
        "        if edge_attr is not None:\n",
        "            out = out + edge_attr  # Add edge embeddings to the output if present\n",
        "        out = out * alpha.view(-1, self.heads, 1)  # Scale by attention weights\n",
        "        return out\n",
        "\n",
        "    # String representation function for debugging or printing\n",
        "    def __repr__(self) -> str:\n",
        "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
        "                f'{self.out_channels}, heads={self.heads})')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qwFv6RgHmGCf"
      },
      "outputs": [],
      "source": [
        "# Define the RGIT_mod class, a multi-layer GNN that uses both RGIT and linear layers\n",
        "class RGIT_mod(torch.nn.Module):\n",
        "    \"\"\"Multi-layer RGIT with optional linear layers\"\"\"\n",
        "\n",
        "    # Initialize the model with hidden dimension, number of RGIT layers, and number of linear layers\n",
        "    def __init__(self, dim_h, num_layers, num_linear_layers=1):\n",
        "        super(RGIT_mod, self).__init__()\n",
        "        self.num_layers = num_layers  # Number of RGIT layers\n",
        "        self.num_linear_layers = num_linear_layers  # Number of linear layers\n",
        "        self.linears = torch.nn.ModuleList()  # List to store linear layers\n",
        "        self.rgit_layers = torch.nn.ModuleList()  # List to store RGIT layers\n",
        "\n",
        "        # Create a list of Linear and PReLU layers (for encoding entity names)\n",
        "        for _ in range(num_linear_layers):\n",
        "            self.linears.append(Linear(dim_h, dim_h))  # Linear transformation layer\n",
        "            self.linears.append(PReLU(num_parameters=dim_h))  # Parametric ReLU activation function\n",
        "\n",
        "        # Create a list of RGIT layers\n",
        "        for _ in range(num_layers):\n",
        "            self.rgit_layers.append(RGIT(  # Each RGIT layer contains a small MLP with Linear and PReLU\n",
        "                Sequential(Linear(dim_h, dim_h), PReLU(num_parameters=dim_h),\n",
        "                           Linear(dim_h, dim_h), PReLU(num_parameters=dim_h)), dim_h, dim_h))\n",
        "\n",
        "    # Forward pass through the model\n",
        "    def forward(self, x, edge_index):\n",
        "        # Apply the linear layers first to the input\n",
        "        for layer in self.linears:\n",
        "            x = layer(x)\n",
        "\n",
        "        # Then apply the RGIT layers for message passing\n",
        "        for layer in self.rgit_layers:\n",
        "            x = layer(x, edge_index)\n",
        "\n",
        "        return x  # Return the final node embeddings after all layers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxCn5ztKVztw"
      },
      "source": [
        "# **Gated Network Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7MKQUv7o7zay"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GatedCombination(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(GatedCombination, self).__init__()\n",
        "        self.gate_A_fc = nn.Linear(input_dim, input_dim)\n",
        "        self.gate_B_fc = nn.Linear(input_dim, input_dim)\n",
        "        self.fc = nn.Linear(1, 1)\n",
        "\n",
        "    def euclidean_distance(self, a, b):\n",
        "        \"\"\"\n",
        "        Compute the Euclidean distance between two tensors.\n",
        "        Args:\n",
        "            a: Tensor of shape [batch, dim]\n",
        "            b: Tensor of shape [batch, dim]\n",
        "        Returns:\n",
        "            Tensor of shape [batch] representing the L2 distance.\n",
        "        \"\"\"\n",
        "        return torch.norm(a - b, p=2, dim=1)\n",
        "\n",
        "    def forward(self, x1, x2, x3, x4, return_embeddings=False):\n",
        "        gate_values1 = torch.sigmoid(self.gate_A_fc(x1))\n",
        "        a = x1 * gate_values1 + x2 * (1 - gate_values1)\n",
        "\n",
        "        gate_values2 = torch.sigmoid(self.gate_B_fc(x3))\n",
        "        b = x3 * gate_values2 + x4 * (1 - gate_values2)\n",
        "\n",
        "        if return_embeddings:\n",
        "            return a, b\n",
        "\n",
        "        # Utilisation de la distance Euclidienne\n",
        "        distance = self.euclidean_distance(a, b)\n",
        "\n",
        "        # Passage dans couche de classification\n",
        "        out = torch.sigmoid(self.fc(distance.unsqueeze(1)))\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLJ5j9FNMVhy"
      },
      "source": [
        "# **Utility functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "k0L86DgUQjMU"
      },
      "outputs": [],
      "source": [
        "def adjacency_matrix_to_undirected_edge_index(adjacency_matrix):\n",
        "    \"\"\"\n",
        "    Converts an adjacency matrix into an undirected edge index for use in graph-based neural networks.\n",
        "\n",
        "    Args:\n",
        "        adjacency_matrix: A 2D list or array representing the adjacency matrix of a graph.\n",
        "\n",
        "    Returns:\n",
        "        edge_index_undirected: A PyTorch tensor representing the undirected edges.\n",
        "    \"\"\"\n",
        "    # Convert each element in the adjacency matrix to an integer (from boolean or float)\n",
        "    adjacency_matrix = [[int(element) for element in sublist] for sublist in adjacency_matrix]\n",
        "\n",
        "    # Convert the adjacency matrix into a PyTorch LongTensor (used for indexing)\n",
        "    edge_index = torch.tensor(adjacency_matrix, dtype=torch.long)\n",
        "\n",
        "    # Transpose the edge_index tensor so that rows represent edges in the form [source, target]\n",
        "    edge_index = edge_index.t().contiguous()\n",
        "\n",
        "    # Convert the directed edge_index into an undirected edge_index, meaning both directions are added (i.e., (i, j) and (j, i))\n",
        "    edge_index_undirected = to_undirected(edge_index)\n",
        "\n",
        "    return edge_index_undirected  # Return the undirected edge index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YvmOxkLcpf9w"
      },
      "outputs": [],
      "source": [
        "def build_indexed_dict(file_path):\n",
        "    \"\"\"\n",
        "    Builds a dictionary with numeric indexes for each key from a JSON file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): The path to the JSON file.\n",
        "\n",
        "    Returns:\n",
        "        indexed_dict (dict): A new dictionary where each key from the JSON file is assigned a numeric index.\n",
        "    \"\"\"\n",
        "    # Load the JSON file into a Python dictionary\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    # Create a new dictionary with numeric indexes as keys and the original JSON keys as values\n",
        "    indexed_dict = {index: key for index, key in enumerate(data.keys())}\n",
        "\n",
        "    return indexed_dict  # Return the newly created dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QgFINoPGl9Wg"
      },
      "outputs": [],
      "source": [
        "def select_rows_by_index(embedding_vector, index_vector):\n",
        "    \"\"\"\n",
        "    Select rows from an embedding vector using an index vector.\n",
        "\n",
        "    Args:\n",
        "        embedding_vector (torch.Tensor): 2D tensor representing the embedding vector with shape [num_rows, embedding_size].\n",
        "        index_vector (torch.Tensor): 1D tensor representing the index vector.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: New tensor with selected rows from the embedding vector.\n",
        "    \"\"\"\n",
        "    # Use torch.index_select to select the desired rows\n",
        "    new_tensor = torch.index_select(embedding_vector, 0, index_vector)\n",
        "\n",
        "    return new_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "a12L7vEmmCJq"
      },
      "outputs": [],
      "source": [
        "def contrastive_loss(source_embeddings, target_embeddings, labels, margin=1.0):\n",
        "    \"\"\"\n",
        "    Computes the contrastive loss, a type of loss function used to train models in tasks like matching or similarity learning.\n",
        "\n",
        "    Args:\n",
        "        source_embeddings (torch.Tensor): Embeddings of the source graphs, shape [batch_size, embedding_size].\n",
        "        target_embeddings (torch.Tensor): Embeddings of the target graphs, shape [batch_size, embedding_size].\n",
        "        labels (torch.Tensor): Binary labels indicating if the pairs are matched (1) or not (0), shape [batch_size].\n",
        "        margin (float): Margin value for the contrastive loss. Defaults to 1.0.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The contrastive loss value.\n",
        "    \"\"\"\n",
        "    # Calculate the pairwise Euclidean distance between source and target embeddings\n",
        "    distances = F.pairwise_distance(source_embeddings, target_embeddings)\n",
        "\n",
        "    # Compute the contrastive loss:\n",
        "    # - For matched pairs (label == 1), the loss is the squared distance between embeddings.\n",
        "    # - For non-matched pairs (label == 0), the loss is based on how far apart the embeddings are,\n",
        "    #   but penalizes them only if the distance is less than the margin.\n",
        "    loss = torch.mean(\n",
        "        labels * 0.4 * distances.pow(2) +  # For positive pairs, minimize the distance (squared)\n",
        "        (1 - labels) * 0.4 * torch.max(torch.zeros_like(distances), margin - distances).pow(2)  # For negative pairs, maximize the distance (up to the margin)\n",
        "    )\n",
        "\n",
        "    return loss  # Return the computed contrastive loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_ggVYlTiO_WA"
      },
      "outputs": [],
      "source": [
        "def compute_mrr_and_hits(reference_file, predicted_file, output_file, k_values=[1, 5, 10]):\n",
        "    \"\"\"\n",
        "    Compute Mean Reciprocal Rank (MRR) and Hits@k metrics for ontology matching results.\n",
        "\n",
        "    Args:\n",
        "        reference_file (str): Path to the reference test candidate file (usually 'test.cands.tsv').\n",
        "        predicted_file (str): Path to the prediction results (with columns: SrcEntity, TgtEntity, Score).\n",
        "        output_file (str): Path to save ranked candidate predictions with scores.\n",
        "        k_values (list): List of integers specifying which Hits@k metrics to compute.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary with MRR and Hits@k scores.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load reference candidate mappings: each row = (SrcEntity, CorrectTgtEntity, [CandidateTgtEntities])\n",
        "    test_candidate_mappings = read_table(reference_file).values.tolist()\n",
        "\n",
        "    # Load predictions and ensure Score is float\n",
        "    predicted_data = pd.read_csv(predicted_file, sep=\"\\t\")\n",
        "    predicted_data[\"Score\"] = predicted_data[\"Score\"].apply(\n",
        "        lambda x: float(x.strip(\"[]\")) if isinstance(x, str) else float(x)\n",
        "    )\n",
        "\n",
        "    # Create a dictionary mapping (SrcEntity, TgtEntity) -> predicted score\n",
        "    score_lookup = {\n",
        "        (row[\"SrcEntity\"], row[\"TgtEntity\"]): row[\"Score\"]\n",
        "        for _, row in predicted_data.iterrows()\n",
        "    }\n",
        "\n",
        "    ranking_results = []\n",
        "\n",
        "    # Rank the candidates for each source entity\n",
        "    for src_ref_class, tgt_ref_class, tgt_cands in test_candidate_mappings:\n",
        "        # Safely parse the candidate list (tgt_cands is a stringified list)\n",
        "        try:\n",
        "            tgt_cands = eval(tgt_cands)\n",
        "        except Exception:\n",
        "            tgt_cands = []\n",
        "\n",
        "        # Score each candidate (use a large negative default if not found)\n",
        "        scored_cands = [\n",
        "            (tgt_cand, score_lookup.get((src_ref_class, tgt_cand), -1e9))\n",
        "            for tgt_cand in tgt_cands\n",
        "        ]\n",
        "\n",
        "        # Sort candidates by score descending\n",
        "        scored_cands = sorted(scored_cands, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Store the ranking result\n",
        "        ranking_results.append((src_ref_class, tgt_ref_class, scored_cands))\n",
        "\n",
        "    # Save ranked predictions for inspection/debugging\n",
        "    pd.DataFrame(ranking_results, columns=[\"SrcEntity\", \"TgtEntity\", \"TgtCandidates\"]).to_csv(\n",
        "        output_file, sep=\"\\t\", index=False\n",
        "    )\n",
        "\n",
        "    # === Evaluation: compute MRR and Hits@k ===\n",
        "    total_entities = len(ranking_results)\n",
        "    reciprocal_ranks = []\n",
        "    hits_at_k = {k: 0 for k in k_values}\n",
        "\n",
        "    for src_entity, tgt_ref_class, tgt_cands in ranking_results:\n",
        "        ranked_candidates = [cand[0] for cand in tgt_cands]  # candidate URIs only\n",
        "        if tgt_ref_class in ranked_candidates:\n",
        "            rank = ranked_candidates.index(tgt_ref_class) + 1\n",
        "            reciprocal_ranks.append(1 / rank)\n",
        "            for k in k_values:\n",
        "                if rank <= k:\n",
        "                    hits_at_k[k] += 1\n",
        "        else:\n",
        "            reciprocal_ranks.append(0)  # No correct match in candidate list\n",
        "\n",
        "    # Compute final metrics\n",
        "    mrr = sum(reciprocal_ranks) / total_entities\n",
        "    hits_at_k = {k: hits / total_entities for k, hits in hits_at_k.items()}\n",
        "\n",
        "    return {\"MRR\": mrr, \"Hits@k\": hits_at_k}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "kh1zdPJQe_vy"
      },
      "outputs": [],
      "source": [
        "def save_gated_embeddings(gated_model, embeddings_src, x_src, embeddings_tgt, x_tgt,\n",
        "                          indexed_dict_src, indexed_dict_tgt,\n",
        "                          output_file_src, output_file_tgt):\n",
        "    \"\"\"\n",
        "    Compute and save the final entity embeddings generated by the GatedCombination model\n",
        "    for both source and target ontologies. Outputs include entity URIs and their final vectors.\n",
        "    Measures and prints the execution time of the entire operation.\n",
        "\n",
        "    Args:\n",
        "        gated_model (nn.Module): The trained GatedCombination model.\n",
        "        embeddings_src (Tensor): Structural embeddings for the source ontology.\n",
        "        x_src (Tensor): Semantic embeddings for the source ontology.\n",
        "        embeddings_tgt (Tensor): Structural embeddings for the target ontology.\n",
        "        x_tgt (Tensor): Semantic embeddings for the target ontology.\n",
        "        indexed_dict_src (dict): Index-to-URI mapping for the source ontology.\n",
        "        indexed_dict_tgt (dict): Index-to-URI mapping for the target ontology.\n",
        "        output_file_src (str): Path to save source embeddings (TSV).\n",
        "        output_file_tgt (str): Path to save target embeddings (TSV).\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "    import torch\n",
        "    import time\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Use GPU if available\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    gated_model = gated_model.to(device)\n",
        "    gated_model.eval()\n",
        "\n",
        "    # Move inputs to the same device\n",
        "    embeddings_src = embeddings_src.to(device)\n",
        "    x_src = x_src.to(device)\n",
        "    embeddings_tgt = embeddings_tgt.to(device)\n",
        "    x_tgt = x_tgt.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # === Source ontology ===\n",
        "        gate_src = torch.sigmoid(gated_model.gate_A_fc(embeddings_src))\n",
        "        final_src = embeddings_src * gate_src + x_src * (1 - gate_src)\n",
        "        final_src = final_src.cpu().numpy()\n",
        "\n",
        "        # === Target ontology ===\n",
        "        gate_tgt = torch.sigmoid(gated_model.gate_B_fc(embeddings_tgt))\n",
        "        final_tgt = embeddings_tgt * gate_tgt + x_tgt * (1 - gate_tgt)\n",
        "        final_tgt = final_tgt.cpu().numpy()\n",
        "\n",
        "    # Create DataFrames with Concept URI and embedding values\n",
        "    df_src = pd.DataFrame(final_src)\n",
        "    df_src.insert(0, \"Concept\", [indexed_dict_src[i] for i in range(len(df_src))])\n",
        "\n",
        "    df_tgt = pd.DataFrame(final_tgt)\n",
        "    df_tgt.insert(0, \"Concept\", [indexed_dict_tgt[i] for i in range(len(df_tgt))])\n",
        "\n",
        "    # Save embeddings to file\n",
        "    df_src.to_csv(output_file_src, sep='\\t', index=False)\n",
        "    df_tgt.to_csv(output_file_tgt, sep='\\t', index=False)\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"✅ Gated embeddings saved:\\n- Source: {output_file_src}\\n- Target: {output_file_tgt}\")\n",
        "    print(f\"⏱️ Execution time: {elapsed_time:.2f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "LXvbHTVfe_vz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def filter_ignored_class(src_emb_path, tgt_emb_path, src_onto, tgt_onto):\n",
        "    \"\"\"\n",
        "    Filters the source and target embedding files by removing concepts considered \"ignored classes\"\n",
        "    (e.g., owl:Thing, deprecated entities, etc.) based on both source and target ontologies.\n",
        "\n",
        "    Args:\n",
        "        src_emb_path (str): Path to the TSV file containing source embeddings with 'Concept' column.\n",
        "        tgt_emb_path (str): Path to the TSV file containing target embeddings with 'Concept' column.\n",
        "        src_onto (Ontology): Source ontology object loaded with DeepOnto.\n",
        "        tgt_onto (Ontology): Target ontology object loaded with DeepOnto.\n",
        "\n",
        "    Returns:\n",
        "        (str, str): Paths to the cleaned source and target embedding files.\n",
        "    \"\"\"\n",
        "\n",
        "    # === Load the embedding files ===\n",
        "    df_src = pd.read_csv(src_emb_path, sep='\\t', dtype=str)\n",
        "    print(f\"🔍 Initial source file: {len(df_src)} rows\")\n",
        "\n",
        "    df_tgt = pd.read_csv(tgt_emb_path, sep='\\t', dtype=str)\n",
        "    print(f\"🔍 Initial target file: {len(df_tgt)} rows\")\n",
        "\n",
        "    # === Step 1: Retrieve ignored classes from both ontologies ===\n",
        "    ignored_class_index = get_ignored_class_index(src_onto)  # e.g., owl:Thing, non-usable classes\n",
        "    ignored_class_index.update(get_ignored_class_index(tgt_onto))  # Merge with target ontology's ignored classes\n",
        "    ignored_uris = set(str(uri).strip() for uri in ignored_class_index)\n",
        "\n",
        "    # === Step 2: Remove rows where the 'Concept' column matches ignored URIs ===\n",
        "    df_src_cleaned = df_src[~df_src['Concept'].isin(ignored_uris)].reset_index(drop=True)\n",
        "    df_tgt_cleaned = df_tgt[~df_tgt['Concept'].isin(ignored_uris)].reset_index(drop=True)\n",
        "\n",
        "    print(f\"✅ Source after removing ignored classes: {len(df_src_cleaned)} rows\")\n",
        "    print(f\"✅ Target after removing ignored classes: {len(df_tgt_cleaned)} rows\")\n",
        "\n",
        "    # === Step 3: Save the cleaned embedding files ===\n",
        "    output_file_src = src_emb_path.replace(\".tsv\", \"_cleaned.tsv\")\n",
        "    output_file_tgt = tgt_emb_path.replace(\".tsv\", \"_cleaned.tsv\")\n",
        "\n",
        "    df_src_cleaned.to_csv(output_file_src, sep='\\t', index=False)\n",
        "    df_tgt_cleaned.to_csv(output_file_tgt, sep='\\t', index=False)\n",
        "\n",
        "    print(f\"📁 Cleaned source file saved to: {output_file_src}\")\n",
        "    print(f\"📁 Cleaned target file saved to: {output_file_tgt}\")\n",
        "\n",
        "    return output_file_src, output_file_tgt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBAlDrOpe_vz"
      },
      "source": [
        "# **FAISS Similarity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "CyG7ztCne_vz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import faiss\n",
        "import time\n",
        "\n",
        "def load_embeddings(src_emb_path, tgt_emb_path):\n",
        "    \"\"\"\n",
        "    Load the embeddings for the source and target ontologies from TSV files.\n",
        "\n",
        "    Args:\n",
        "        src_emb_path (str): Path to the source embeddings file.\n",
        "        tgt_emb_path (str): Path to the target embeddings file.\n",
        "\n",
        "    Returns:\n",
        "        uris_src (np.ndarray): URIs of source entities.\n",
        "        uris_tgt (np.ndarray): URIs of target entities.\n",
        "        src_vecs (np.ndarray): Embedding vectors for source entities.\n",
        "        tgt_vecs (np.ndarray): Embedding vectors for target entities.\n",
        "    \"\"\"\n",
        "    df_src = pd.read_csv(src_emb_path, sep='\\t')  # Read source embeddings\n",
        "    df_tgt = pd.read_csv(tgt_emb_path, sep='\\t')  # Read target embeddings\n",
        "    uris_src = df_src[\"Concept\"].values           # Extract source URIs\n",
        "    uris_tgt = df_tgt[\"Concept\"].values           # Extract target URIs\n",
        "    src_vecs = df_src.drop(columns=[\"Concept\"]).values.astype('float32')  # Extract and convert source vectors\n",
        "    tgt_vecs = df_tgt.drop(columns=[\"Concept\"]).values.astype('float32')  # Extract and convert target vectors\n",
        "    return uris_src, uris_tgt, src_vecs, tgt_vecs\n",
        "\n",
        "def save_results(uris_src, uris_tgt, indices, scores, output_file, top_k):\n",
        "    \"\"\"\n",
        "    Save the top-k mapping results to a TSV file.\n",
        "\n",
        "    Args:\n",
        "        uris_src (np.ndarray): URIs of source entities.\n",
        "        uris_tgt (np.ndarray): URIs of target entities.\n",
        "        indices (np.ndarray): Indices of top-k matched target entities.\n",
        "        scores (np.ndarray): Corresponding similarity scores.\n",
        "        output_file (str): Output TSV file path.\n",
        "        top_k (int): Number of top matches per source entity.\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for i, (ind_row, score_row) in enumerate(zip(indices, scores)):\n",
        "        src_uri = uris_src[i]\n",
        "        for j, tgt_idx in enumerate(ind_row):\n",
        "            tgt_uri = uris_tgt[tgt_idx]\n",
        "            score = score_row[j]\n",
        "            rows.append((src_uri, tgt_uri, score))  # Store each top-k match\n",
        "    df_result = pd.DataFrame(rows, columns=[\"SrcEntity\", \"TgtEntity\", \"Score\"])\n",
        "    df_result.to_csv(output_file, sep='\\t', index=False)  # Save to file\n",
        "    print(f\"Top-{top_k} FAISS similarity results saved to: {output_file}\")\n",
        "\n",
        "def topk_faiss_l2(src_emb_path, tgt_emb_path, top_k=15, output_file=\"topk_l2.tsv\"):\n",
        "    \"\"\"\n",
        "    Compute the top-k most similar target entities for each source entity using FAISS with L2 distance.\n",
        "\n",
        "    Args:\n",
        "        src_emb_path (str): Path to the source embeddings file.\n",
        "        tgt_emb_path (str): Path to the target embeddings file.\n",
        "        top_k (int): Number of top matches to retrieve.\n",
        "        output_file (str): Path to save the top-k results.\n",
        "    \"\"\"\n",
        "    print(\"🔹 Using L2 (Euclidean) distance with FAISS\")\n",
        "    start = time.time()  # Start timing\n",
        "\n",
        "    # Load embeddings\n",
        "    uris_src, uris_tgt, src_vecs, tgt_vecs = load_embeddings(src_emb_path, tgt_emb_path)\n",
        "\n",
        "    # Build FAISS index using L2 distance\n",
        "    dim = src_vecs.shape[1]\n",
        "    index = faiss.IndexFlatL2(dim)  # Create FAISS index for L2 distance\n",
        "    index.add(tgt_vecs)             # Add target vectors to index\n",
        "\n",
        "    # Perform nearest neighbor search\n",
        "    distances, indices = index.search(src_vecs, top_k)\n",
        "\n",
        "    # Convert distances to similarity scores (optional: inverse of distance)\n",
        "    similarity_scores = 1 / (1 + distances)\n",
        "\n",
        "    # Save the results\n",
        "    save_results(uris_src, uris_tgt, indices, similarity_scores, output_file, top_k)\n",
        "\n",
        "    # Display execution time\n",
        "    print(f\"⏱️ Execution time: {time.time() - start:.2f} seconds\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zq0p_64e_vz"
      },
      "source": [
        "# **Mappings Evaluation Functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "repA9zGMe_vz"
      },
      "source": [
        "# **Precision, Recall, F1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GW0Am-TmVMR"
      },
      "source": [
        "### Evaluation Strategy and Filtering Justification\n",
        "\n",
        "### Filtering Justification\n",
        "\n",
        "In the `evaluate_predictions` function, two important filtering steps are applied to ensure that the evaluation metrics (such as Precision, Recall, and F1-score) accurately reflect the model's performance:\n",
        "\n",
        "\n",
        "#### 1. Filtering Out Training-Only Entities\n",
        "\n",
        "We remove all predicted mappings involving source or target entities that are present **only in the training set** and not in the test set.\n",
        "\n",
        "This step is critical because:\n",
        "\n",
        "- In some datasets like **Bio-ML**, the same entity can appear in both training and test sets, although with **different correspondences**.\n",
        "- If we don't remove training-only entities, it can lead to **label leakage** and **metric distortion**.\n",
        "\n",
        "#### 2. Filtering on `SrcEntity` present in the test set\n",
        "\n",
        "The second step keeps only the predictions where the `SrcEntity` is included in the test reference set.\n",
        "\n",
        "- This eliminates **non-evaluable false positives**, i.e., predicted mappings for source entities that do not appear in the test set and therefore have no ground-truth correspondences. Including such predictions **unfairly penalizes precision and F1-score**, even though they are technically not verifiable errors.\n",
        "\n",
        "- It focuses the evaluation on entities with defined ground-truth mappings, which is critical for computing metrics such as :\n",
        "\n",
        "$P_{\\text{test}} = \\frac{|\\mathcal{M}_{\\text{out}} \\cap \\mathcal{M}_{\\text{test}}|}{|\\mathcal{M}_{\\text{out}} \\setminus (\\mathcal{M}_{\\text{ref}} \\setminus \\mathcal{M}_{\\text{test}})|}$.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "eOQkhXEVOQDT"
      },
      "outputs": [],
      "source": [
        "def select_best_candidates_per_src_with_margin(df, score_margin=0.01):\n",
        "    \"\"\"\n",
        "    For each SrcEntity, retain all candidate mappings whose similarity score is\n",
        "    within 99% of the best score (default margin = 0.01).\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing columns ['SrcEntity', 'TgtEntity', 'Score'].\n",
        "        score_margin (float): Score margin. 0.01 means keep scores ≥ 99% of best score.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Filtered DataFrame with multiple high-quality candidates per SrcEntity.\n",
        "    \"\"\"\n",
        "    selected_rows = []\n",
        "\n",
        "    for src, group in df.groupby(\"SrcEntity\"):\n",
        "        group_sorted = group.sort_values(by=\"Score\", ascending=False)\n",
        "        best_score = group_sorted.iloc[0][\"Score\"]\n",
        "        threshold = best_score * (1 - score_margin)\n",
        "\n",
        "        # Keep all target entities with score >= threshold\n",
        "        close_matches = group_sorted[group_sorted[\"Score\"] >= threshold]\n",
        "        selected_rows.append(close_matches)\n",
        "\n",
        "    result_df = pd.concat(selected_rows).reset_index(drop=True)\n",
        "    print(f\"🏆 Selected candidates within {(1 - score_margin) * 100:.1f}% of best score per SrcEntity: {len(result_df)} rows\")\n",
        "    return result_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-4deIPBfOQDU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "def evaluate_predictions(\n",
        "    pred_file, train_file, test_file,\n",
        "    threshold=0.0, margin_ratio=0.997\n",
        "):\n",
        "    \"\"\"\n",
        "    Evaluate predicted mappings by applying filtering, thresholding, top-1 selection with margin,\n",
        "    and computing precision, recall, and F1-score against the test set.\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 1: Load prediction, train, and test data\n",
        "    df = pd.read_csv(pred_file, sep='\\t')\n",
        "    train_df = pd.read_csv(train_file, sep='\\t')\n",
        "    test_df = pd.read_csv(test_file, sep='\\t')\n",
        "    print(f\"🔍 Initial file: {len(df)} rows\")\n",
        "\n",
        "    # Step 2: Remove entities that appear only in the training set\n",
        "    train_uris = set(train_df['SrcEntity']) | set(train_df['TgtEntity'])\n",
        "    test_uris = set(test_df['SrcEntity']) | set(test_df['TgtEntity'])\n",
        "    uris_to_exclude = train_uris - test_uris\n",
        "    df = df[~df['SrcEntity'].isin(uris_to_exclude) & ~df['TgtEntity'].isin(uris_to_exclude)]\n",
        "    print(f\"✅ After removing train-only URIs: {len(df)} rows\")\n",
        "\n",
        "    # Step 3: Keep only predictions where SrcEntity is part of the test set\n",
        "    test_src_entities = set(test_df['SrcEntity'])\n",
        "    df = df[df['SrcEntity'].isin(test_src_entities)]\n",
        "    print(f\"✅ After keeping only test SrcEntities: {len(df)} rows\")\n",
        "\n",
        "    # Step 4: Apply a minimum score threshold\n",
        "    df = df[df[\"Score\"] >= threshold]\n",
        "    print(f\"✅ After applying threshold ≥ {threshold}: {len(df)} rows\")\n",
        "\n",
        "    # Step 5: Save filtered predictions to file\n",
        "    output_file_all = pred_file.replace(\".tsv\", f\"_filtered.tsv\")\n",
        "    df.to_csv(output_file_all, sep='\\t', index=False)\n",
        "    print(f\"📁 Filtered predictions saved: {output_file_all}\")\n",
        "\n",
        "    # Step 6: Select best predictions per SrcEntity using a relaxed top-1 margin\n",
        "    df_top1 = select_best_candidates_per_src_with_margin(df, score_margin=0.0075)\n",
        "\n",
        "    # Step 7: Save the top-1 filtered predictions\n",
        "    output_file_top1 = pred_file.replace(\".tsv\", f\"_filtered_top1_th{threshold}.tsv\")\n",
        "    df_top1.to_csv(output_file_top1, sep='\\t', index=False)\n",
        "    print(f\"📁 Filtered Top-1 file saved: {output_file_top1}\")\n",
        "\n",
        "    # Step 8: Evaluate using gold standard test mappings\n",
        "    preds = EntityMapping.read_table_mappings(output_file_top1)   # Read predicted mappings\n",
        "    refs = ReferenceMapping.read_table_mappings(test_file)        # Read reference (gold standard) mappings\n",
        "\n",
        "    results = AlignmentEvaluator.f1(preds, refs)  # Compute precision, recall, and F1\n",
        "\n",
        "    # Optional: Count correct predictions (intersection)\n",
        "    preds2 = [p.to_tuple() for p in preds]\n",
        "    refs2 = [r.to_tuple() for r in refs]\n",
        "    correct = len(set(preds2).intersection(set(refs2)))\n",
        "\n",
        "    print(f\"🎯 Correct mappings (Top-1): {correct}\")\n",
        "    print(f\"📊 Evaluation (P / R / F1): {results}\")\n",
        "\n",
        "    return output_file_top1, results, correct\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVyzng3Pe_v0"
      },
      "source": [
        "# **Precision@k, Recall@k, F1@k**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "FstoSsHPe_v0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "def evaluate_topk(topk_file, train_file, test_file, k=1, threshold=0.0):\n",
        "    \"\"\"\n",
        "    Evaluate Top-K predictions using Precision, Recall, and F1-score,\n",
        "    after filtering out training-only URIs, keeping only test sources, and applying 1-1 constraint.\n",
        "\n",
        "    Args:\n",
        "        topk_file (str): Path to the top-k prediction file (TSV with SrcEntity, TgtEntity, Score)\n",
        "        train_file (str): Path to the training mappings file (TSV)\n",
        "        test_file (str): Path to the test mappings file (TSV)\n",
        "        k (int): Value of K for top-k evaluation\n",
        "        threshold (float): Minimum score to consider a prediction valid\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing Precision@K, Recall@K, and F1@K\n",
        "    \"\"\"\n",
        "\n",
        "    # === Step 1: Load input files ===\n",
        "    df = pd.read_csv(topk_file, sep='\\t', dtype=str)\n",
        "    train_df = pd.read_csv(train_file, sep='\\t', dtype=str)\n",
        "    test_df = pd.read_csv(test_file, sep='\\t', dtype=str)\n",
        "\n",
        "    # === Step 2: Remove URIs only present in the training set ===\n",
        "    train_uris = set(train_df['SrcEntity']) | set(train_df['TgtEntity'])\n",
        "    test_uris = set(test_df['SrcEntity']) | set(test_df['TgtEntity'])\n",
        "    uris_to_exclude = train_uris - test_uris\n",
        "    df = df[~(df['SrcEntity'].isin(uris_to_exclude) | df['TgtEntity'].isin(uris_to_exclude))].reset_index(drop=True)\n",
        "\n",
        "    # === Step 3: Keep only source entities from the test set ===\n",
        "    src_entities_test = set(test_df['SrcEntity'])\n",
        "    df = df[df['SrcEntity'].isin(src_entities_test)].reset_index(drop=True)\n",
        "\n",
        "    # === Step 4: Convert score column to float and sort ===\n",
        "    df['Score'] = df['Score'].apply(lambda x: float(x.strip(\"[]\")) if isinstance(x, str) else float(x))\n",
        "    df_sorted = df.sort_values(by='Score', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    # === Step 5: Apply 1-to-1 constraint (greedy strategy with optional threshold)\n",
        "    matched_sources = set()\n",
        "    matched_targets = set()\n",
        "    result = []\n",
        "\n",
        "    for _, row in df_sorted.iterrows():\n",
        "        src, tgt, score = row['SrcEntity'], row['TgtEntity'], row['Score']\n",
        "        if src not in matched_sources and tgt not in matched_targets and score >= threshold:\n",
        "            result.append((src, tgt, score))\n",
        "            matched_sources.add(src)\n",
        "            matched_targets.add(tgt)\n",
        "\n",
        "    # === Step 6: Create and save Top-K prediction dataframe\n",
        "    matching_results_df = pd.DataFrame(result, columns=['SrcEntity', 'TgtEntity', 'Score'])\n",
        "    output_file = topk_file.replace(\".tsv\", \"_predictions.tsv\")\n",
        "    matching_results_df.to_csv(output_file, sep='\\t', index=False)\n",
        "\n",
        "    # === Step 7: Build reference dictionary from test set\n",
        "    ref_dict = defaultdict(set)\n",
        "    for _, row in test_df.iterrows():\n",
        "        ref_dict[row['SrcEntity']].add(row['TgtEntity'])\n",
        "\n",
        "    # === Step 8: Select Top-K predictions for each source entity\n",
        "    matching_results_df['Score'] = matching_results_df['Score'].astype(float)\n",
        "    topk_df = matching_results_df.sort_values(by='Score', ascending=False).groupby('SrcEntity').head(k)\n",
        "\n",
        "    # === Step 9: Compute Precision@K, Recall@K, F1@K\n",
        "    total_tp = total_pred = total_ref = 0\n",
        "\n",
        "    for src, group in topk_df.groupby('SrcEntity'):\n",
        "        predicted = set(group['TgtEntity'])\n",
        "        true = ref_dict.get(src, set())\n",
        "        tp = len(predicted & true)\n",
        "        total_tp += tp\n",
        "        total_pred += len(predicted)\n",
        "        total_ref += len(true)\n",
        "\n",
        "    precision = total_tp / total_pred if total_pred else 0.0\n",
        "    recall = total_tp / total_ref if total_ref else 0.0\n",
        "    f1 = 2 * precision * recall / (precision + recall + 1e-8) if precision + recall > 0 else 0.0\n",
        "\n",
        "    # === Step 10: Print metrics\n",
        "\n",
        "    print(f\"📊 Precision@{k}:            {precision:.3f}\")\n",
        "    print(f\"📊 Recall@{k}:               {recall:.3f}\")\n",
        "    print(f\"📊 F1@{k}:                   {f1:.3f}\\n\")\n",
        "\n",
        "    return {\n",
        "        f'Precision@{k}': round(precision, 3),\n",
        "        f'Recall@{k}': round(recall, 3),\n",
        "        f'F1@{k}': round(f1, 3)\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HyWMsw1MVhz"
      },
      "source": [
        "# **Main Code**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC37FlwGDqGM"
      },
      "source": [
        "\n",
        "\n",
        "# Reading semantic node embeddings provided by the ENE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "FuEfSnw5mod0"
      },
      "outputs": [],
      "source": [
        "# Read the source embeddings from a CSV file into a pandas DataFrame\n",
        "df_embbedings_src = pd.read_csv(src_Emb, index_col=0)\n",
        "\n",
        "# Convert the DataFrame to a NumPy array, which will remove the index and store the data as a raw matrix\n",
        "numpy_array = df_embbedings_src.to_numpy()\n",
        "\n",
        "# Convert the NumPy array into a PyTorch FloatTensor, which is the format required for PyTorch operations\n",
        "x_src = torch.FloatTensor(numpy_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "STUwqMUXmlG2"
      },
      "outputs": [],
      "source": [
        "# Read the target embeddings from a CSV file into a pandas DataFrame\n",
        "df_embbedings_tgt = pd.read_csv(tgt_Emb, index_col=0)\n",
        "\n",
        "# Convert the DataFrame to a NumPy array, which removes the index and converts the data to a raw matrix\n",
        "numpy_array = df_embbedings_tgt.to_numpy()\n",
        "\n",
        "# Convert the NumPy array into a PyTorch FloatTensor, which is required for PyTorch operations\n",
        "x_tgt = torch.FloatTensor(numpy_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZIu9P08DqGN"
      },
      "source": [
        "# Reading adjacency Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "pH69Up40mycz"
      },
      "outputs": [],
      "source": [
        "# Read the source adjacency matrix from a CSV file into a pandas DataFrame\n",
        "df_ma1 = pd.read_csv(src_Adjacence, index_col=0)\n",
        "\n",
        "# Convert the DataFrame to a list of lists (Python native list format)\n",
        "ma1 = df_ma1.values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "hYCmAO5Ymzpl"
      },
      "outputs": [],
      "source": [
        "# Read the target adjacency matrix from a CSV file into a pandas DataFrame\n",
        "df_ma2 = pd.read_csv(tgt_Adjacence, index_col=0)\n",
        "\n",
        "# Convert the DataFrame to a list of lists (Python native list format)\n",
        "ma2 = df_ma2.values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSyksqh3TrU-"
      },
      "source": [
        "# Convert Adjacency matrix (in list format) to an undirected edge index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "uVt-Pce5m5ll"
      },
      "outputs": [],
      "source": [
        "# Convert the source adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n",
        "edge_src = adjacency_matrix_to_undirected_edge_index(ma1)\n",
        "\n",
        "# Convert the target adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n",
        "edge_tgt = adjacency_matrix_to_undirected_edge_index(ma2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9wMTRdqT4aY"
      },
      "source": [
        "# GIT Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "eqiEKCLSMVh3"
      },
      "outputs": [],
      "source": [
        "def train_model_gnn(model, x_src, edge_src, x_tgt, edge_tgt,\n",
        "                    tensor_term1, tensor_term2, tensor_score,\n",
        "                    learning_rate, weight_decay_value, num_epochs, print_interval=10):\n",
        "    \"\"\"\n",
        "    Trains a graph neural network (GNN) model using source and target embeddings and contrastive loss.\n",
        "\n",
        "    Args:\n",
        "        model: The GNN model to be trained.\n",
        "        x_src (torch.Tensor): Source node embeddings.\n",
        "        edge_src (torch.Tensor): Source graph edges.\n",
        "        x_tgt (torch.Tensor): Target node embeddings.\n",
        "        edge_tgt (torch.Tensor): Target graph edges.\n",
        "        tensor_term1 (torch.Tensor): Indices of the source nodes to be compared.\n",
        "        tensor_term2 (torch.Tensor): Indices of the target nodes to be compared.\n",
        "        tensor_score (torch.Tensor): Labels indicating if the pairs are matched (1) or not (0).\n",
        "        learning_rate (float): Learning rate for the optimizer.\n",
        "        weight_decay_value (float): Weight decay (L2 regularization) value for the optimizer.\n",
        "        num_epochs (int): Number of epochs for training.\n",
        "        print_interval (int): Interval at which training progress is printed (every `print_interval` epochs).\n",
        "\n",
        "    Returns:\n",
        "        model: The trained GNN model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 1: Set device (GPU or CPU) for computation\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Step 2: Move the model and all inputs to the selected device\n",
        "    model.to(device)\n",
        "    x_tgt = x_tgt.to(device)               # Target node embeddings\n",
        "    edge_tgt = edge_tgt.to(device)         # Target graph edges\n",
        "    x_src = x_src.to(device)               # Source node embeddings\n",
        "    edge_src = edge_src.to(device)         # Source graph edges\n",
        "    tensor_term1 = tensor_term1.to(device) # Indices for source nodes\n",
        "    tensor_term2 = tensor_term2.to(device) # Indices for target nodes\n",
        "    tensor_score = tensor_score.to(device) # Ground truth labels\n",
        "\n",
        "    # Step 3: Define optimizer with learning rate and regularization\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay_value)\n",
        "\n",
        "    # Step 4: Initialize list to store training losses\n",
        "    train_losses = []\n",
        "\n",
        "    # Record the start time of training\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Step 5: Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        # Zero out gradients from the previous iteration\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass: Compute embeddings for source and target graphs\n",
        "        out1 = model(x_src, edge_src)  # Updated source embeddings\n",
        "        out2 = model(x_tgt, edge_tgt)  # Updated target embeddings\n",
        "\n",
        "        # Extract specific rows of embeddings for terms being compared\n",
        "        src_embeddings = select_rows_by_index(out1, tensor_term1)\n",
        "        tgt_embeddings = select_rows_by_index(out2, tensor_term2)\n",
        "\n",
        "        # Compute contrastive loss based on the embeddings and ground truth labels\n",
        "        loss = contrastive_loss(src_embeddings, tgt_embeddings, tensor_score)\n",
        "\n",
        "        # Backward pass: Compute gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the model's parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Append the loss for this iteration to the list\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        # Print loss every `print_interval` epochs\n",
        "        if (epoch + 1) % print_interval == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item()}\")\n",
        "\n",
        "    # Step 6: Record end time of training\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Step 7: Plot the training loss over time\n",
        "    plt.semilogy(range(1, num_epochs + 1), train_losses, label=\"Training Loss\", marker='o')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Print the total training time\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training complete! Total training time: {training_time:.2f} seconds\")\n",
        "\n",
        "    # Step 8: Return the trained model\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "6_tzUG_emtBg"
      },
      "outputs": [],
      "source": [
        "# Initialize the GIT_mod model with the dimensionality of the target embeddings\n",
        "# The first argument is the dimensionality of the target node embeddings (x_tgt.shape[1])\n",
        "# The second argument (1) represents the number of RGIT layers in the model\n",
        "GIT_model = RGIT_mod(x_tgt.shape[1], 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "wVo-s7UQssSp"
      },
      "outputs": [],
      "source": [
        "# Reading the training pairs from a CSV file into a pandas DataFrame\n",
        "df_embbedings = pd.read_csv(train_file, index_col=0)\n",
        "\n",
        "# Extract the 'SrcEntity' and 'TgtEntity' columns as NumPy arrays and convert them to integers\n",
        "tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)  # Source entity indices\n",
        "tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)  # Target entity indices\n",
        "\n",
        "# Extract the 'Score' column as a NumPy array and convert it to floats\n",
        "tensor_score = df_embbedings['Score'].values.astype(float)  # Scores (labels) indicating if pairs match (1) or not (0)\n",
        "\n",
        "# Convert the NumPy arrays to PyTorch LongTensors (for indices) and FloatTensors (for scores)\n",
        "tensor_term1_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)  # Source entity tensor\n",
        "tensor_term2_o = torch.from_numpy(tensor_term2).type(torch.LongTensor)  # Target entity tensor\n",
        "tensor_score_o = torch.from_numpy(tensor_score).type(torch.FloatTensor)  # Score tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "agHlFNesMVh3",
        "outputId": "b51eee09-6ba8-4dcb-a697-827ca1b25d46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/1000], Training Loss: 0.0012123034102842212\n",
            "Epoch [20/1000], Training Loss: 0.0010304513853043318\n",
            "Epoch [30/1000], Training Loss: 0.000922683859243989\n",
            "Epoch [40/1000], Training Loss: 0.0008444595732726157\n",
            "Epoch [50/1000], Training Loss: 0.0007805270724929869\n",
            "Epoch [60/1000], Training Loss: 0.0007267699693329632\n",
            "Epoch [70/1000], Training Loss: 0.0006807245663367212\n",
            "Epoch [80/1000], Training Loss: 0.000640719779767096\n",
            "Epoch [90/1000], Training Loss: 0.0006054445402696729\n",
            "Epoch [100/1000], Training Loss: 0.0005741395871154964\n",
            "Epoch [110/1000], Training Loss: 0.0005460011307150126\n",
            "Epoch [120/1000], Training Loss: 0.0005211669486016035\n",
            "Epoch [130/1000], Training Loss: 0.000499123998451978\n",
            "Epoch [140/1000], Training Loss: 0.0004799136077053845\n",
            "Epoch [150/1000], Training Loss: 0.0004630741022992879\n",
            "Epoch [160/1000], Training Loss: 0.00044837803579866886\n",
            "Epoch [170/1000], Training Loss: 0.00043549068504944444\n",
            "Epoch [180/1000], Training Loss: 0.00042408856097608805\n",
            "Epoch [190/1000], Training Loss: 0.00041416374733671546\n",
            "Epoch [200/1000], Training Loss: 0.00040542930946685374\n",
            "Epoch [210/1000], Training Loss: 0.00039780267979949713\n",
            "Epoch [220/1000], Training Loss: 0.0003911228268407285\n",
            "Epoch [230/1000], Training Loss: 0.0003853179805446416\n",
            "Epoch [240/1000], Training Loss: 0.0003802028077188879\n",
            "Epoch [250/1000], Training Loss: 0.0003757262893486768\n",
            "Epoch [260/1000], Training Loss: 0.00037175844772718847\n",
            "Epoch [270/1000], Training Loss: 0.0003682056558318436\n",
            "Epoch [280/1000], Training Loss: 0.00036500132409855723\n",
            "Epoch [290/1000], Training Loss: 0.00036207702942192554\n",
            "Epoch [300/1000], Training Loss: 0.0003594862064346671\n",
            "Epoch [310/1000], Training Loss: 0.00035704844049178064\n",
            "Epoch [320/1000], Training Loss: 0.0003547942324075848\n",
            "Epoch [330/1000], Training Loss: 0.00035260512959212065\n",
            "Epoch [340/1000], Training Loss: 0.00035047432174906135\n",
            "Epoch [350/1000], Training Loss: 0.0003484491026028991\n",
            "Epoch [360/1000], Training Loss: 0.0003465679183136672\n",
            "Epoch [370/1000], Training Loss: 0.0003447774506639689\n",
            "Epoch [380/1000], Training Loss: 0.0003430855867918581\n",
            "Epoch [390/1000], Training Loss: 0.0003415444225538522\n",
            "Epoch [400/1000], Training Loss: 0.00034014342236332595\n",
            "Epoch [410/1000], Training Loss: 0.00033889408223330975\n",
            "Epoch [420/1000], Training Loss: 0.00033771528978832066\n",
            "Epoch [430/1000], Training Loss: 0.00033659086329862475\n",
            "Epoch [440/1000], Training Loss: 0.0003355196095071733\n",
            "Epoch [450/1000], Training Loss: 0.00033448581234551966\n",
            "Epoch [460/1000], Training Loss: 0.00033356781932525337\n",
            "Epoch [470/1000], Training Loss: 0.00033257133327424526\n",
            "Epoch [480/1000], Training Loss: 0.00033159033046104014\n",
            "Epoch [490/1000], Training Loss: 0.00033056814572773874\n",
            "Epoch [500/1000], Training Loss: 0.00032949596061371267\n",
            "Epoch [510/1000], Training Loss: 0.0003284012491349131\n",
            "Epoch [520/1000], Training Loss: 0.00032730132807046175\n",
            "Epoch [530/1000], Training Loss: 0.0003262317040935159\n",
            "Epoch [540/1000], Training Loss: 0.0003251936286687851\n",
            "Epoch [550/1000], Training Loss: 0.0003241970553062856\n",
            "Epoch [560/1000], Training Loss: 0.000323270884109661\n",
            "Epoch [570/1000], Training Loss: 0.00032235702383331954\n",
            "Epoch [580/1000], Training Loss: 0.0003214458411093801\n",
            "Epoch [590/1000], Training Loss: 0.0003205552638974041\n",
            "Epoch [600/1000], Training Loss: 0.00031968593248166144\n",
            "Epoch [610/1000], Training Loss: 0.000318849750328809\n",
            "Epoch [620/1000], Training Loss: 0.0003180327476002276\n",
            "Epoch [630/1000], Training Loss: 0.0003172179276589304\n",
            "Epoch [640/1000], Training Loss: 0.0003164220543112606\n",
            "Epoch [650/1000], Training Loss: 0.000315623648930341\n",
            "Epoch [660/1000], Training Loss: 0.0003148293762933463\n",
            "Epoch [670/1000], Training Loss: 0.0003140484623145312\n",
            "Epoch [680/1000], Training Loss: 0.00031328038312494755\n",
            "Epoch [690/1000], Training Loss: 0.0003124825016129762\n",
            "Epoch [700/1000], Training Loss: 0.0003116842999588698\n",
            "Epoch [710/1000], Training Loss: 0.0003108513483311981\n",
            "Epoch [720/1000], Training Loss: 0.00030997704016044736\n",
            "Epoch [730/1000], Training Loss: 0.00030908011831343174\n",
            "Epoch [740/1000], Training Loss: 0.0003081075847148895\n",
            "Epoch [750/1000], Training Loss: 0.0003070564125664532\n",
            "Epoch [760/1000], Training Loss: 0.00030590035021305084\n",
            "Epoch [770/1000], Training Loss: 0.00030471451464109123\n",
            "Epoch [780/1000], Training Loss: 0.00030354491900652647\n",
            "Epoch [790/1000], Training Loss: 0.00030244316440075636\n",
            "Epoch [800/1000], Training Loss: 0.0003013741516042501\n",
            "Epoch [810/1000], Training Loss: 0.0003003632591571659\n",
            "Epoch [820/1000], Training Loss: 0.0002993904345203191\n",
            "Epoch [830/1000], Training Loss: 0.00029843629454262555\n",
            "Epoch [840/1000], Training Loss: 0.00029754580464214087\n",
            "Epoch [850/1000], Training Loss: 0.00029663523309864104\n",
            "Epoch [860/1000], Training Loss: 0.0002957559481728822\n",
            "Epoch [870/1000], Training Loss: 0.000294870522338897\n",
            "Epoch [880/1000], Training Loss: 0.0002940138801932335\n",
            "Epoch [890/1000], Training Loss: 0.00029317461303435266\n",
            "Epoch [900/1000], Training Loss: 0.000292320444714278\n",
            "Epoch [910/1000], Training Loss: 0.00029148676549084485\n",
            "Epoch [920/1000], Training Loss: 0.00029068425646983087\n",
            "Epoch [930/1000], Training Loss: 0.00028989327256567776\n",
            "Epoch [940/1000], Training Loss: 0.00028913028654642403\n",
            "Epoch [950/1000], Training Loss: 0.00028835071134380996\n",
            "Epoch [960/1000], Training Loss: 0.0002875739592127502\n",
            "Epoch [970/1000], Training Loss: 0.00028678556554950774\n",
            "Epoch [980/1000], Training Loss: 0.000286014168523252\n",
            "Epoch [990/1000], Training Loss: 0.00028523715445771813\n",
            "Epoch [1000/1000], Training Loss: 0.00028446625219658017\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete! Total training time: 1441.66 seconds\n"
          ]
        }
      ],
      "source": [
        "# Train the GNN model using the provided source and target graph embeddings, edges, and training data\n",
        "trained_model = train_model_gnn(\n",
        "    model=GIT_model,                # The GNN model to be trained (initialized earlier)\n",
        "    x_src=x_src,                    # Source node embeddings (tensor for source graph)\n",
        "    edge_src=edge_src,              # Source graph edges (undirected edge index for source graph)\n",
        "    x_tgt=x_tgt,                    # Target node embeddings (tensor for target graph)\n",
        "    edge_tgt=edge_tgt,              # Target graph edges (undirected edge index for target graph)\n",
        "    tensor_term1=tensor_term1_o,    # Indices of source entities for training\n",
        "    tensor_term2=tensor_term2_o,    # Indices of target entities for training\n",
        "    tensor_score=tensor_score_o,    # Scores (labels) indicating if pairs match (1) or not (0)\n",
        "    learning_rate=0.0001,            # Learning rate for the Adam optimizer\n",
        "    weight_decay_value=1e-4,        # Weight decay for L2 regularization to prevent overfitting\n",
        "    num_epochs=1000,                # Number of training epochs\n",
        "    print_interval=10               # Interval at which to print training progress (every 10 epochs)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYyhvjcTUaae"
      },
      "source": [
        "# GIT Application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "BZ_VqP6tq6iD"
      },
      "outputs": [],
      "source": [
        "# Determine if a GPU is available and move the computations to it; otherwise, use the CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Assuming the model has been trained and hyperparameters (x_src, edge_src, x_tgt, edge_tgt) are set\n",
        "\n",
        "# Move the trained GIT_model to the device (GPU or CPU)\n",
        "GIT_model.to(device)\n",
        "\n",
        "# Move the data tensors to the same device (GPU or CPU)\n",
        "x_tgt = x_tgt.to(device)         # Target node embeddings\n",
        "edge_tgt = edge_tgt.to(device)   # Target graph edges\n",
        "x_src = x_src.to(device)         # Source node embeddings\n",
        "edge_src = edge_src.to(device)   # Source graph edges\n",
        "\n",
        "# Set the model to evaluation mode; this disables dropout and batch normalization\n",
        "GIT_model.eval()\n",
        "\n",
        "# Pass the source and target embeddings through the trained GNN model to update the embeddings\n",
        "with torch.no_grad():  # Disable gradient computation (inference mode)\n",
        "    embeddings_tgt = GIT_model(x_tgt, edge_tgt)  # Get updated embeddings for the target graph\n",
        "    embeddings_src = GIT_model(x_src, edge_src)  # Get updated embeddings for the source graph\n",
        "\n",
        "# Detach the embeddings from the computation graph and move them back to the CPU\n",
        "# This step is useful if you need to use the embeddings for tasks outside PyTorch (e.g., saving to disk)\n",
        "embeddings_tgt = embeddings_tgt.detach().cpu()  # Target graph embeddings\n",
        "embeddings_src = embeddings_src.detach().cpu()  # Source graph embeddings\n",
        "\n",
        "# At this point, embeddings_tgt and embeddings_src contain the updated embeddings, ready for downstream tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og5fdoGJrTCG"
      },
      "source": [
        "# Selecting embedding pairs to train the Gated Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "J0nTwc-dnjLn"
      },
      "outputs": [],
      "source": [
        "# Read the training pairs from a CSV file into a pandas DataFrame\n",
        "df_embeddings = pd.read_csv(train_file, index_col=0)\n",
        "\n",
        "# Extract columns and convert to NumPy arrays\n",
        "tensor_term1 = df_embeddings['SrcEntity'].values.astype(int)  # Source entity indices\n",
        "tensor_term2 = df_embeddings['TgtEntity'].values.astype(int)  # Target entity indices\n",
        "tensor_score = df_embeddings['Score'].values.astype(float)  # Matching scores\n",
        "\n",
        "# Split data into training and validation sets\n",
        "tensor_term1_train, tensor_term1_val, tensor_term2_train, tensor_term2_val, tensor_score_train, tensor_score_val = train_test_split(\n",
        "    tensor_term1, tensor_term2, tensor_score, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Convert split data to PyTorch tensors\n",
        "tensor_term1_train = torch.from_numpy(tensor_term1_train).type(torch.LongTensor)\n",
        "tensor_term2_train = torch.from_numpy(tensor_term2_train).type(torch.LongTensor)\n",
        "tensor_score_train = torch.from_numpy(tensor_score_train).type(torch.FloatTensor)\n",
        "\n",
        "tensor_term1_val = torch.from_numpy(tensor_term1_val).type(torch.LongTensor)\n",
        "tensor_term2_val = torch.from_numpy(tensor_term2_val).type(torch.LongTensor)\n",
        "tensor_score_val = torch.from_numpy(tensor_score_val).type(torch.FloatTensor)\n",
        "\n",
        "# Move the embeddings back to the CPU if not already there\n",
        "x_tgt = x_tgt.cpu()  # Target node embeddings\n",
        "x_src = x_src.cpu()  # Source node embeddings\n",
        "\n",
        "# Select embeddings for the training set\n",
        "X1_train = select_rows_by_index(embeddings_src, tensor_term1_train)\n",
        "X2_train = select_rows_by_index(x_src, tensor_term1_train)\n",
        "X3_train = select_rows_by_index(embeddings_tgt, tensor_term2_train)\n",
        "X4_train = select_rows_by_index(x_tgt, tensor_term2_train)\n",
        "\n",
        "# Select embeddings for the validation set\n",
        "X1_val = select_rows_by_index(embeddings_src, tensor_term1_val)\n",
        "X2_val = select_rows_by_index(x_src, tensor_term1_val)\n",
        "X3_val = select_rows_by_index(embeddings_tgt, tensor_term2_val)\n",
        "X4_val = select_rows_by_index(x_tgt, tensor_term2_val)\n",
        "\n",
        "# Now you have:\n",
        "# - Training tensors: X1_train, X2_train, X3_train, X4_train, tensor_score_train\n",
        "# - Validation tensors: X1_val, X2_val, X3_val, X4_val, tensor_score_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNdCgaTMExPK"
      },
      "source": [
        "# Gated Network Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Gof1eIPIWSVU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def train_gated_combination_model(X1_t, X2_t, X3_t, X4_t, tensor_score_o,\n",
        "                                  X1_val, X2_val, X3_val, X4_val, tensor_score_val,\n",
        "                                  epochs=120, batch_size=32, learning_rate=0.001, weight_decay=1e-5):\n",
        "    \"\"\"\n",
        "    Trains the GatedCombination model with training and validation data, using ReduceLROnPlateau scheduler.\n",
        "    Also calculates and displays F1-score during training and validation.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create datasets and DataLoaders\n",
        "    train_dataset = TensorDataset(X1_t, X2_t, X3_t, X4_t, tensor_score_o)\n",
        "    val_dataset = TensorDataset(X1_val, X2_val, X3_val, X4_val, tensor_score_val)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = GatedCombination(X1_t.shape[1]).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # Use ReduceLROnPlateau scheduler\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_train_loss = 0.0\n",
        "        y_true_train, y_pred_train = [], []\n",
        "\n",
        "        for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in train_loader:\n",
        "            batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (\n",
        "                batch_X1.to(device),\n",
        "                batch_X2.to(device),\n",
        "                batch_X3.to(device),\n",
        "                batch_X4.to(device),\n",
        "                batch_y.to(device),\n",
        "            )\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = F.binary_cross_entropy(outputs, batch_y.unsqueeze(1).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # Store true labels and predictions for F1-score\n",
        "            y_true_train.extend(batch_y.cpu().numpy())\n",
        "            y_pred_train.extend((outputs > 0.5).float().cpu().numpy())\n",
        "\n",
        "        train_loss = total_train_loss / len(train_loader)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # Calculate F1-score for training\n",
        "        train_f1 = f1_score(y_true_train, y_pred_train)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        total_val_loss = 0.0\n",
        "        y_true_val, y_pred_val = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in val_loader:\n",
        "                batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (\n",
        "                    batch_X1.to(device),\n",
        "                    batch_X2.to(device),\n",
        "                    batch_X3.to(device),\n",
        "                    batch_X4.to(device),\n",
        "                    batch_y.to(device),\n",
        "                )\n",
        "                outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n",
        "\n",
        "                # Compute loss\n",
        "                val_loss = F.binary_cross_entropy(outputs, batch_y.unsqueeze(1).float())\n",
        "                total_val_loss += val_loss.item()\n",
        "\n",
        "                # Store true labels and predictions for F1-score\n",
        "                y_true_val.extend(batch_y.cpu().numpy())\n",
        "                y_pred_val.extend((outputs > 0.5).float().cpu().numpy())\n",
        "\n",
        "        avg_val_loss = total_val_loss / len(val_loader)\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        # Calculate F1-score for validation\n",
        "        val_f1 = f1_score(y_true_val, y_pred_val)\n",
        "\n",
        "        # Step the scheduler with validation loss\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        # Print training and validation metrics\n",
        "        print(f\"Epoch [{epoch + 1}/{epochs}] Training Loss: {train_loss:.4f}, F1 Score: {train_f1:.4f} | \"\n",
        "              f\"Validation Loss: {avg_val_loss:.4f}, F1 Score: {val_f1:.4f}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Plotting training and validation loss\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label=\"Training Loss\", marker='o')\n",
        "    plt.plot(val_losses, label=\"Validation Loss\", marker='x')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Training complete! Total time: {end_time - start_time:.2f} seconds\")\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QrpFp6aDbtSW",
        "outputId": "59ed1c43-0b5b-414d-aff4-b3949a61fa4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100] Training Loss: 0.0282, F1 Score: 0.0000 | Validation Loss: 0.0277, F1 Score: 0.0000\n",
            "Epoch [2/100] Training Loss: 0.0250, F1 Score: 0.0076 | Validation Loss: 0.0246, F1 Score: 0.0056\n",
            "Epoch [3/100] Training Loss: 0.0222, F1 Score: 0.0851 | Validation Loss: 0.0216, F1 Score: 0.1022\n",
            "Epoch [4/100] Training Loss: 0.0196, F1 Score: 0.2506 | Validation Loss: 0.0193, F1 Score: 0.2906\n",
            "Epoch [5/100] Training Loss: 0.0175, F1 Score: 0.3963 | Validation Loss: 0.0169, F1 Score: 0.4415\n",
            "Epoch [6/100] Training Loss: 0.0158, F1 Score: 0.4967 | Validation Loss: 0.0160, F1 Score: 0.4652\n",
            "Epoch [7/100] Training Loss: 0.0145, F1 Score: 0.5597 | Validation Loss: 0.0144, F1 Score: 0.6449\n",
            "Epoch [8/100] Training Loss: 0.0132, F1 Score: 0.6140 | Validation Loss: 0.0140, F1 Score: 0.6985\n",
            "Epoch [9/100] Training Loss: 0.0123, F1 Score: 0.6616 | Validation Loss: 0.0121, F1 Score: 0.6667\n",
            "Epoch [10/100] Training Loss: 0.0116, F1 Score: 0.6941 | Validation Loss: 0.0114, F1 Score: 0.6865\n",
            "Epoch [11/100] Training Loss: 0.0110, F1 Score: 0.7214 | Validation Loss: 0.0111, F1 Score: 0.7207\n",
            "Epoch [12/100] Training Loss: 0.0104, F1 Score: 0.7403 | Validation Loss: 0.0103, F1 Score: 0.7276\n",
            "Epoch [13/100] Training Loss: 0.0100, F1 Score: 0.7632 | Validation Loss: 0.0099, F1 Score: 0.7299\n",
            "Epoch [14/100] Training Loss: 0.0096, F1 Score: 0.7741 | Validation Loss: 0.0098, F1 Score: 0.7344\n",
            "Epoch [15/100] Training Loss: 0.0093, F1 Score: 0.7779 | Validation Loss: 0.0094, F1 Score: 0.7456\n",
            "Epoch [16/100] Training Loss: 0.0090, F1 Score: 0.7823 | Validation Loss: 0.0088, F1 Score: 0.7884\n",
            "Epoch [17/100] Training Loss: 0.0088, F1 Score: 0.7918 | Validation Loss: 0.0090, F1 Score: 0.8442\n",
            "Epoch [18/100] Training Loss: 0.0086, F1 Score: 0.8003 | Validation Loss: 0.0084, F1 Score: 0.8114\n",
            "Epoch [19/100] Training Loss: 0.0083, F1 Score: 0.8128 | Validation Loss: 0.0083, F1 Score: 0.8114\n",
            "Epoch [20/100] Training Loss: 0.0083, F1 Score: 0.8080 | Validation Loss: 0.0083, F1 Score: 0.8460\n",
            "Epoch [21/100] Training Loss: 0.0081, F1 Score: 0.8201 | Validation Loss: 0.0079, F1 Score: 0.8087\n",
            "Epoch [22/100] Training Loss: 0.0079, F1 Score: 0.8244 | Validation Loss: 0.0081, F1 Score: 0.8094\n",
            "Epoch [23/100] Training Loss: 0.0079, F1 Score: 0.8241 | Validation Loss: 0.0079, F1 Score: 0.7966\n",
            "Epoch [24/100] Training Loss: 0.0078, F1 Score: 0.8249 | Validation Loss: 0.0080, F1 Score: 0.8047\n",
            "Epoch [25/100] Training Loss: 0.0077, F1 Score: 0.8212 | Validation Loss: 0.0075, F1 Score: 0.8423\n",
            "Epoch [26/100] Training Loss: 0.0076, F1 Score: 0.8286 | Validation Loss: 0.0079, F1 Score: 0.8662\n",
            "Epoch [27/100] Training Loss: 0.0075, F1 Score: 0.8315 | Validation Loss: 0.0075, F1 Score: 0.8366\n",
            "Epoch [28/100] Training Loss: 0.0075, F1 Score: 0.8313 | Validation Loss: 0.0072, F1 Score: 0.8460\n",
            "Epoch [29/100] Training Loss: 0.0075, F1 Score: 0.8341 | Validation Loss: 0.0073, F1 Score: 0.8347\n",
            "Epoch [30/100] Training Loss: 0.0074, F1 Score: 0.8402 | Validation Loss: 0.0073, F1 Score: 0.8385\n",
            "Epoch [31/100] Training Loss: 0.0074, F1 Score: 0.8368 | Validation Loss: 0.0072, F1 Score: 0.8608\n",
            "Epoch [32/100] Training Loss: 0.0073, F1 Score: 0.8377 | Validation Loss: 0.0070, F1 Score: 0.8516\n",
            "Epoch [33/100] Training Loss: 0.0072, F1 Score: 0.8429 | Validation Loss: 0.0072, F1 Score: 0.8212\n",
            "Epoch [34/100] Training Loss: 0.0073, F1 Score: 0.8457 | Validation Loss: 0.0071, F1 Score: 0.8385\n",
            "Epoch [35/100] Training Loss: 0.0073, F1 Score: 0.8337 | Validation Loss: 0.0072, F1 Score: 0.8366\n",
            "Epoch [36/100] Training Loss: 0.0072, F1 Score: 0.8395 | Validation Loss: 0.0070, F1 Score: 0.8442\n",
            "Epoch [37/100] Training Loss: 0.0072, F1 Score: 0.8471 | Validation Loss: 0.0078, F1 Score: 0.8186\n",
            "Epoch [38/100] Training Loss: 0.0071, F1 Score: 0.8440 | Validation Loss: 0.0076, F1 Score: 0.8047\n",
            "Epoch [39/100] Training Loss: 0.0071, F1 Score: 0.8344 | Validation Loss: 0.0068, F1 Score: 0.8498\n",
            "Epoch [40/100] Training Loss: 0.0071, F1 Score: 0.8481 | Validation Loss: 0.0071, F1 Score: 0.8460\n",
            "Epoch [41/100] Training Loss: 0.0071, F1 Score: 0.8409 | Validation Loss: 0.0069, F1 Score: 0.8680\n",
            "Epoch [42/100] Training Loss: 0.0071, F1 Score: 0.8465 | Validation Loss: 0.0071, F1 Score: 0.8309\n",
            "Epoch [43/100] Training Loss: 0.0072, F1 Score: 0.8454 | Validation Loss: 0.0071, F1 Score: 0.8644\n",
            "Epoch [44/100] Training Loss: 0.0071, F1 Score: 0.8423 | Validation Loss: 0.0069, F1 Score: 0.8590\n",
            "Epoch [45/100] Training Loss: 0.0070, F1 Score: 0.8484 | Validation Loss: 0.0068, F1 Score: 0.8535\n",
            "Epoch [46/100] Training Loss: 0.0070, F1 Score: 0.8520 | Validation Loss: 0.0068, F1 Score: 0.8626\n",
            "Epoch [47/100] Training Loss: 0.0070, F1 Score: 0.8479 | Validation Loss: 0.0070, F1 Score: 0.8347\n",
            "Epoch [48/100] Training Loss: 0.0071, F1 Score: 0.8451 | Validation Loss: 0.0069, F1 Score: 0.8738\n",
            "Epoch [49/100] Training Loss: 0.0070, F1 Score: 0.8440 | Validation Loss: 0.0073, F1 Score: 0.8251\n",
            "Epoch [50/100] Training Loss: 0.0070, F1 Score: 0.8490 | Validation Loss: 0.0071, F1 Score: 0.8328\n",
            "Epoch [51/100] Training Loss: 0.0070, F1 Score: 0.8463 | Validation Loss: 0.0067, F1 Score: 0.8571\n",
            "Epoch [52/100] Training Loss: 0.0069, F1 Score: 0.8498 | Validation Loss: 0.0077, F1 Score: 0.8074\n",
            "Epoch [53/100] Training Loss: 0.0071, F1 Score: 0.8435 | Validation Loss: 0.0068, F1 Score: 0.8479\n",
            "Epoch [54/100] Training Loss: 0.0070, F1 Score: 0.8409 | Validation Loss: 0.0069, F1 Score: 0.8479\n",
            "Epoch [55/100] Training Loss: 0.0070, F1 Score: 0.8463 | Validation Loss: 0.0066, F1 Score: 0.8752\n",
            "Epoch [56/100] Training Loss: 0.0070, F1 Score: 0.8428 | Validation Loss: 0.0068, F1 Score: 0.8553\n",
            "Epoch [57/100] Training Loss: 0.0070, F1 Score: 0.8403 | Validation Loss: 0.0068, F1 Score: 0.8535\n",
            "Epoch [58/100] Training Loss: 0.0070, F1 Score: 0.8459 | Validation Loss: 0.0068, F1 Score: 0.8442\n",
            "Epoch [59/100] Training Loss: 0.0070, F1 Score: 0.8506 | Validation Loss: 0.0071, F1 Score: 0.8251\n",
            "Epoch [60/100] Training Loss: 0.0070, F1 Score: 0.8457 | Validation Loss: 0.0067, F1 Score: 0.8698\n",
            "Epoch [61/100] Training Loss: 0.0069, F1 Score: 0.8463 | Validation Loss: 0.0067, F1 Score: 0.8680\n",
            "Epoch [62/100] Training Loss: 0.0070, F1 Score: 0.8467 | Validation Loss: 0.0067, F1 Score: 0.8752\n",
            "Epoch [63/100] Training Loss: 0.0070, F1 Score: 0.8430 | Validation Loss: 0.0068, F1 Score: 0.8460\n",
            "Epoch [64/100] Training Loss: 0.0069, F1 Score: 0.8492 | Validation Loss: 0.0073, F1 Score: 0.8251\n",
            "Epoch [65/100] Training Loss: 0.0070, F1 Score: 0.8465 | Validation Loss: 0.0066, F1 Score: 0.8787\n",
            "Epoch [66/100] Training Loss: 0.0070, F1 Score: 0.8477 | Validation Loss: 0.0068, F1 Score: 0.8662\n",
            "Epoch [67/100] Training Loss: 0.0065, F1 Score: 0.8569 | Validation Loss: 0.0063, F1 Score: 0.8680\n",
            "Epoch [68/100] Training Loss: 0.0065, F1 Score: 0.8608 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [69/100] Training Loss: 0.0065, F1 Score: 0.8577 | Validation Loss: 0.0064, F1 Score: 0.8716\n",
            "Epoch [70/100] Training Loss: 0.0065, F1 Score: 0.8598 | Validation Loss: 0.0065, F1 Score: 0.8571\n",
            "Epoch [71/100] Training Loss: 0.0065, F1 Score: 0.8614 | Validation Loss: 0.0064, F1 Score: 0.8680\n",
            "Epoch [72/100] Training Loss: 0.0065, F1 Score: 0.8586 | Validation Loss: 0.0064, F1 Score: 0.8680\n",
            "Epoch [73/100] Training Loss: 0.0065, F1 Score: 0.8586 | Validation Loss: 0.0065, F1 Score: 0.8716\n",
            "Epoch [74/100] Training Loss: 0.0065, F1 Score: 0.8584 | Validation Loss: 0.0064, F1 Score: 0.8805\n",
            "Epoch [75/100] Training Loss: 0.0065, F1 Score: 0.8577 | Validation Loss: 0.0064, F1 Score: 0.8571\n",
            "Epoch [76/100] Training Loss: 0.0065, F1 Score: 0.8565 | Validation Loss: 0.0064, F1 Score: 0.8716\n",
            "Epoch [77/100] Training Loss: 0.0065, F1 Score: 0.8584 | Validation Loss: 0.0064, F1 Score: 0.8734\n",
            "Epoch [78/100] Training Loss: 0.0065, F1 Score: 0.8569 | Validation Loss: 0.0064, F1 Score: 0.8716\n",
            "Epoch [79/100] Training Loss: 0.0064, F1 Score: 0.8630 | Validation Loss: 0.0064, F1 Score: 0.8680\n",
            "Epoch [80/100] Training Loss: 0.0064, F1 Score: 0.8614 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [81/100] Training Loss: 0.0064, F1 Score: 0.8592 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [82/100] Training Loss: 0.0064, F1 Score: 0.8616 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [83/100] Training Loss: 0.0064, F1 Score: 0.8608 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [84/100] Training Loss: 0.0064, F1 Score: 0.8600 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [85/100] Training Loss: 0.0064, F1 Score: 0.8614 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [86/100] Training Loss: 0.0064, F1 Score: 0.8608 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [87/100] Training Loss: 0.0064, F1 Score: 0.8614 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [88/100] Training Loss: 0.0064, F1 Score: 0.8614 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [89/100] Training Loss: 0.0064, F1 Score: 0.8598 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [90/100] Training Loss: 0.0064, F1 Score: 0.8616 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [91/100] Training Loss: 0.0064, F1 Score: 0.8616 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [92/100] Training Loss: 0.0064, F1 Score: 0.8616 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [93/100] Training Loss: 0.0064, F1 Score: 0.8616 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [94/100] Training Loss: 0.0064, F1 Score: 0.8616 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [95/100] Training Loss: 0.0064, F1 Score: 0.8616 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [96/100] Training Loss: 0.0064, F1 Score: 0.8616 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [97/100] Training Loss: 0.0064, F1 Score: 0.8616 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [98/100] Training Loss: 0.0064, F1 Score: 0.8616 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [99/100] Training Loss: 0.0064, F1 Score: 0.8616 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [100/100] Training Loss: 0.0064, F1 Score: 0.8616 | Validation Loss: 0.0064, F1 Score: 0.8698\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete! Total time: 1348.16 seconds\n"
          ]
        }
      ],
      "source": [
        "# Train the GatedCombination model using training and validation data\n",
        "trained_model = train_gated_combination_model(\n",
        "    X1_train,          # Updated source embeddings (after applying the GNN model)\n",
        "    X2_train,          # Original source embeddings (before applying the GNN model)\n",
        "    X3_train,          # Updated target embeddings (after applying the GNN model)\n",
        "    X4_train,          # Original target embeddings (before applying the GNN model)\n",
        "    tensor_score_train, # Ground truth labels for the training set (1 for matched pairs, 0 for unmatched pairs)\n",
        "\n",
        "    X1_val,            # Updated source embeddings for the validation set\n",
        "    X2_val,            # Original source embeddings for the validation set\n",
        "    X3_val,            # Updated target embeddings for the validation set\n",
        "    X4_val,            # Original target embeddings for the validation set\n",
        "    tensor_score_val,  # Ground truth labels for the validation set (1 for matched pairs, 0 for unmatched pairs)\n",
        "\n",
        "    epochs=100,        # Number of epochs (iterations over the entire training dataset)\n",
        "    batch_size=32,     # Number of training samples processed in one forward/backward pass\n",
        "    learning_rate=0.001, # Learning rate for the optimizer (controls step size during optimization)\n",
        "    weight_decay=1e-4 # Weight decay (L2 regularization) to prevent overfitting\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAmLuMtGW9c2"
      },
      "source": [
        "# **Second Round Modifications**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVDqN5AxFu9m"
      },
      "source": [
        "# **Generate Embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "ITZZcElm8qRN"
      },
      "outputs": [],
      "source": [
        "# Build an indexed dictionary for the source ontology classes\n",
        "# src_class is the file path to the JSON file containing the source ontology classes\n",
        "indexed_dict_src = build_indexed_dict(src_class)\n",
        "\n",
        "# Build an indexed dictionary for the target ontology classes\n",
        "# tgt_class is the file path to the JSON file containing the target ontology classes\n",
        "indexed_dict_tgt = build_indexed_dict(tgt_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbSbmPlRDOs3",
        "outputId": "7853a17b-1cb1-4db5-b188-1bbffb003683"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Gated embeddings saved:\n",
            "- Source: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings.tsv\n",
            "- Target: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings.tsv\n",
            "⏱️ Execution time: 54.03 seconds\n"
          ]
        }
      ],
      "source": [
        "# Define output file paths for final embeddings of source and target ontologies\n",
        "output_file_src = f\"{data_dir}/{src_ent}_final_embeddings.tsv\"\n",
        "output_file_tgt = f\"{data_dir}/{tgt_ent}_final_embeddings.tsv\"\n",
        "\n",
        "# Save the final gated embeddings for all concepts in source and target ontologies\n",
        "save_gated_embeddings(\n",
        "    gated_model=trained_model,          # The trained GatedCombination model\n",
        "    embeddings_src=embeddings_src,      # GNN-transformed embeddings for source entities\n",
        "    x_src=x_src,                        # Initial semantic embeddings for source entities\n",
        "    embeddings_tgt=embeddings_tgt,      # GNN-transformed embeddings for target entities\n",
        "    x_tgt=x_tgt,                        # Initial semantic embeddings for target entities\n",
        "    indexed_dict_src=indexed_dict_src,  # Index-to-URI mapping for source ontology\n",
        "    indexed_dict_tgt=indexed_dict_tgt,  # Index-to-URI mapping for target ontology\n",
        "    output_file_src=output_file_src,    # Destination file path for source embeddings\n",
        "    output_file_tgt=output_file_tgt     # Destination file path for target embeddings\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIDvbZj2GIGo"
      },
      "source": [
        "# **Filter No Used Concepts**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Gl_wUG9KADo",
        "outputId": "02ea2e95-608d-4394-d140-c733ea8b37ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Initial source file: 23107 rows\n",
            "🔍 Initial target file: 20498 rows\n",
            "✅ Source after removing ignored classes: 11407 rows\n",
            "✅ Target after removing ignored classes: 14207 rows\n",
            "📁 Cleaned source file saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_cleaned.tsv\n",
            "📁 Cleaned target file saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_cleaned.tsv\n"
          ]
        }
      ],
      "source": [
        "# Call the function to filter out ignored concepts (e.g., owl:Thing, deprecated, etc.)\n",
        "# from the source and target ontology embeddings.\n",
        "\n",
        "# Input:\n",
        "# - src_emb_path: Path to the TSV file containing embeddings for the source ontology\n",
        "# - tgt_emb_path: Path to the TSV file containing embeddings for the target ontology\n",
        "# - src_onto / tgt_onto: DeepOnto ontology objects used to identify ignored concepts\n",
        "\n",
        "# Output:\n",
        "# - src_file: Path to the cleaned source embeddings (with ignored concepts removed)\n",
        "# - tgt_file: Path to the cleaned target embeddings (with ignored concepts removed)\n",
        "\n",
        "src_file, tgt_file = filter_ignored_class(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings.tsv\",\n",
        "    src_onto=src_onto,\n",
        "    tgt_onto=tgt_onto\n",
        "\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpUklR4xnVMH"
      },
      "source": [
        "# **Mappings Generation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP5o60scKn2e"
      },
      "source": [
        "# **Using faiss l2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOSRYREwerBi",
        "outputId": "693c3f23-67ee-4b79-b0fe-2881cd42a0f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-10 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2.tsv\n",
            "⏱️ Execution time: 12.99 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using l2 distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the l2 distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_l2(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_cleaned.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_cleaned.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD-mvVjaerBh"
      },
      "source": [
        "# **Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Global Metrics: Precision, Recall and F1 score**"
      ],
      "metadata": {
        "id": "r8GRfT_pR1kD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WZKJM46erBi",
        "outputId": "e952e4b5-0114-4804-aefd-51baffbbeef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 93984 rows\n",
            "✅ After keeping only test SrcEntities: 22353 rows\n",
            "✅ After applying threshold ≥ 0.0: 22353 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_filtered.tsv\n",
            "🏆 Selected candidates within 99.2% of best score per SrcEntity: 2525 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1879\n",
            "📊 Evaluation (P / R / F1): {'P': 0.744, 'R': 0.706, 'F1': 0.724}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = evaluate_predictions(\n",
        "    pred_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE3WArY1SAWO"
      },
      "source": [
        "# **Metrics@1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "h0y9PGOjerBh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c419af94-0db0-48ef-feb2-6a1fbd01beab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-1 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings.tsv\n",
            "⏱️ Execution time: 6.03 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-1 most similar mappings using l2 distance\n",
        "# and the similarity score is computed as the inverse of the l2 distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_l2(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_cleaned.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_cleaned.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "wk-B3ayYerBh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaf6e110-5644-44b5-d876-ae2dbcc5456c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Precision@1:            0.792\n",
            "📊 Recall@1:               0.746\n",
            "📊 F1@1:                   0.768\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# === Evaluate Top-1 Mappings ===\n",
        "\n",
        "results = evaluate_topk(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings.tsv\",\n",
        "    # Path to the file containing the predicted mappings with scores.\n",
        "    # This file may include unfiltered predictions (e.g., over all candidates).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference mappings file.\n",
        "    # Used to remove mappings that involve entities appearing only in training.\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference mappings file.\n",
        "    # Ground-truth correspondences are extracted from this file for evaluation.\n",
        "\n",
        "    k=1  # Evaluate top-1 predictions per source entity.\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf6vZML-KewM"
      },
      "source": [
        "# **Local MRR and Hit@k**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "7xXm15EQKeE_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# === Step 1: Load input files ===\n",
        "\n",
        "# Define paths to cleaned embedding files\n",
        "src_emb_path = f\"{data_dir}/{src_ent}_final_embeddings_cleaned.tsv\"\n",
        "tgt_emb_path = f\"{data_dir}/{tgt_ent}_final_embeddings_cleaned.tsv\"\n",
        "\n",
        "# Load candidate mappings (SrcEntity, TgtEntity) and source/target embeddings\n",
        "df_cands = pd.read_csv(cands_path)\n",
        "src_emb_df = pd.read_csv(src_emb_path, sep=\"\\t\")\n",
        "tgt_emb_df = pd.read_csv(tgt_emb_path, sep=\"\\t\")\n",
        "\n",
        "# === Step 2: Extract unique source and target URIs from the candidate pairs ===\n",
        "\n",
        "# Keep only distinct source and target entities (URIs) for which embeddings are needed\n",
        "unique_src_df = pd.DataFrame(df_cands[\"SrcEntity\"].unique(), columns=[\"Concept\"])\n",
        "unique_tgt_df = pd.DataFrame(df_cands[\"TgtEntity\"].unique(), columns=[\"Concept\"])\n",
        "\n",
        "# === Step 3: Join embeddings for each concept based on the \"Concept\" URI ===\n",
        "\n",
        "# Merge source entities with their corresponding embeddings (if available)\n",
        "merged_src_df = pd.merge(unique_src_df, src_emb_df, on=\"Concept\", how=\"left\")\n",
        "\n",
        "# Merge target entities with their corresponding embeddings (if available)\n",
        "merged_tgt_df = pd.merge(unique_tgt_df, tgt_emb_df, on=\"Concept\", how=\"left\")\n",
        "\n",
        "# === Step 4: Save the merged results to TSV files ===\n",
        "\n",
        "# Save the source concepts and their embeddings to file\n",
        "merged_src_df.to_csv(f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "# Save the target concepts and their embeddings to file\n",
        "merged_tgt_df.to_csv(f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\", sep=\"\\t\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "_BgQMQzperBl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae232067-b864-478f-c402-998ad5fe059b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-200 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_mrr_hit.tsv\n",
            "⏱️ Execution time: 6.72 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source entity embeddings (already filtered and linearly encoded)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target entity embeddings (already filtered and linearly encoded)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity (Top-K candidates)\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the resulting Top-K mappings sorted by FAISS L2 distance (converted to similarity)\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "DpzkN2-verBl"
      },
      "outputs": [],
      "source": [
        "test_cands = f\"{dataset_dir}/refs_equiv/test.cands.tsv\"\n",
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "quXigRGeerBl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35a3d679-d64d-4a56-c7e0-7f9753dc232b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9256683758753848, 'Hits@1': 0.8775816748028539, 'Hits@5': 0.9849793466015772, 'Hits@10': 0.9932407059707097}\n"
          ]
        }
      ],
      "source": [
        "# Evaluate ranking performance using standard metrics like MRR and Hits@K\n",
        "# 'formatted_predictions_path' should point to a TSV file with columns: SrcEntity, TgtEntity, TgtCandidates\n",
        "# This function computes how well the true targets are ranked among the candidates\n",
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "\n",
        "# Print the evaluation results for Hits@1, Hits@5, and Hits@10\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "KBAlDrOpe_vz"
      ],
      "gpuType": "V28",
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}