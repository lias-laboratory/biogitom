{"cells":[{"cell_type":"markdown","metadata":{"id":"MkAX88H3RNRW"},"source":["# **Package Installation**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SlL2v0xgmFJ-","outputId":"44e2f091-4b0a-4d03-c485-2d3552111f41","executionInfo":{"status":"ok","timestamp":1732187351665,"user_tz":-60,"elapsed":208469,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==2.0.0\n","  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.16.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n","  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n","  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n","  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n","  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n","  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n","  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.0.0 (from torch==2.0.0)\n","  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (75.1.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.45.0)\n","Collecting cmake (from triton==2.0.0->torch==2.0.0)\n","  Downloading cmake-3.31.0.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n","Collecting lit (from triton==2.0.0->torch==2.0.0)\n","  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n","Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m592.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m72.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m673.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cmake-3.31.0.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.8/27.8 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, cmake, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.1+cpu\n","    Uninstalling torch-2.5.1+cpu:\n","      Successfully uninstalled torch-2.5.1+cpu\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.5.1+cpu requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\n","torchvision 0.20.1+cpu requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed cmake-3.31.0.1 lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 triton-2.0.0\n","Collecting torch-geometric==2.4.0\n","  Downloading torch_geometric-2.4.0-py3-none-any.whl.metadata (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (4.66.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (3.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (2.32.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (3.2.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.5.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric==2.4.0) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (2024.8.30)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.4.0) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.4.0) (3.5.0)\n","Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-geometric\n","Successfully installed torch-geometric-2.4.0\n","Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_scatter-2.1.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (494 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_sparse-0.6.18%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-cluster\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_cluster-1.6.3%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (751 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.3/751.3 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-spline-conv\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (208 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n","Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n","Installing collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster\n","Successfully installed torch-cluster-1.6.3+pt20cpu torch-scatter-2.1.2+pt20cpu torch-sparse-0.6.18+pt20cpu torch-spline-conv-1.2.2+pt20cpu\n","Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.5.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.6/66.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.9/208.9 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.2/319.2 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting deeponto\n","  Downloading deeponto-0.9.2-py3-none-any.whl.metadata (15 kB)\n","Collecting JPype1 (from deeponto)\n","  Downloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting yacs (from deeponto)\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deeponto) (2.0.0)\n","Collecting anytree (from deeponto)\n","  Downloading anytree-2.12.1-py3-none-any.whl.metadata (8.1 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from deeponto) (8.1.7)\n","Collecting dill (from deeponto)\n","  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from deeponto) (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deeponto) (1.26.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deeponto) (1.5.2)\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (from deeponto) (4.46.2)\n","Collecting datasets (from deeponto)\n","  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.7.5)\n","Collecting pprintpp (from deeponto)\n","  Downloading pprintpp-0.4.0-py2.py3-none-any.whl.metadata (7.9 kB)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.4.2)\n","Collecting lxml (from deeponto)\n","  Downloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n","Collecting textdistance (from deeponto)\n","  Downloading textdistance-4.6.3-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from deeponto) (7.7.1)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from deeponto) (5.5.6)\n","Collecting enlighten (from deeponto)\n","  Downloading enlighten-1.12.4-py2.py3-none-any.whl.metadata (18 kB)\n","Collecting rdflib (from deeponto)\n","  Downloading rdflib-7.1.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.9.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anytree->deeponto) (1.16.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (18.0.0)\n","Collecting dill (from deeponto)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (4.66.6)\n","Collecting xxhash (from datasets->deeponto)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets->deeponto)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->deeponto)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (3.11.6)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (0.26.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (6.0.2)\n","Collecting blessed>=1.17.7 (from enlighten->deeponto)\n","  Downloading blessed-1.20.0-py2.py3-none-any.whl.metadata (13 kB)\n","Collecting prefixed>=0.3.2 (from enlighten->deeponto)\n","  Downloading prefixed-0.9.0-py2.py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (0.2.0)\n","Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (7.34.0)\n","Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (5.7.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (6.1.12)\n","Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (6.3.3)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->deeponto) (3.6.10)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->deeponto) (3.0.13)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->deeponto) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->deeponto) (2024.11.6)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2024.2)\n","Collecting isodate<1.0.0,>=0.7.2 (from rdflib->deeponto)\n","  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib->deeponto) (3.2.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deeponto) (1.13.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deeponto) (3.5.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (0.13.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.9.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.1.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (75.1.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.4.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (1.13.1)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (2.0.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->deeponto) (0.45.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deeponto) (3.31.0.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deeponto) (18.1.8)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (0.20.3)\n","Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (1.1.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->transformers[torch]->deeponto) (5.9.5)\n","Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.7->enlighten->deeponto) (0.2.13)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (0.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.17.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (5.0.1)\n","Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->deeponto)\n","  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (5.1.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (3.0.48)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (2.18.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (4.9.0)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.2.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (2024.8.30)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->deeponto) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->deeponto) (0.1.5)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (0.20.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (7.0.5)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.5.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy->deeponto) (3.0.2)\n","Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->deeponto) (5.7.2)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->deeponto) (24.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deeponto) (1.3.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->deeponto) (0.8.4)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel->deeponto) (4.3.6)\n","Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.2.1)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (23.1.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (5.10.4)\n","Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (7.16.4)\n","Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.6.0)\n","Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.3)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.18.1)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.21.0)\n","Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.1.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel->deeponto) (0.7.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (3.0.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->deeponto) (1.14.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (0.1.2)\n","Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.2.4)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.12.3)\n","Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.2.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.7.1)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.3.0)\n","Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.0.2)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.10.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.5.1)\n","Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.4.0)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.20.0)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.23.0)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (21.2.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.5.1)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.21.0)\n","Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.24.0)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.17.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.6)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.22)\n","Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.7.1)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.2.2)\n","Downloading deeponto-0.9.2-py3-none-any.whl (89.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading anytree-2.12.1-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading enlighten-1.12.4-py2.py3-none-any.whl (41 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.8/493.8 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n","Downloading rdflib-7.1.1-py3-none-any.whl (562 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m562.4/562.4 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading textdistance-4.6.3-py3-none-any.whl (31 kB)\n","Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n","Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading prefixed-0.9.0-py2.py3-none-any.whl (13 kB)\n","Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: prefixed, pprintpp, yacs, xxhash, textdistance, lxml, JPype1, jedi, isodate, fsspec, dill, blessed, anytree, rdflib, multiprocess, enlighten, datasets, deeponto\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","Successfully installed JPype1-1.5.1 anytree-2.12.1 blessed-1.20.0 datasets-3.1.0 deeponto-0.9.2 dill-0.3.8 enlighten-1.12.4 fsspec-2024.9.0 isodate-0.7.2 jedi-0.19.2 lxml-5.3.0 multiprocess-0.70.16 pprintpp-0.4.0 prefixed-0.9.0 rdflib-7.1.1 textdistance-4.6.3 xxhash-3.5.0 yacs-0.1.8\n","/bin/bash: line 1: username: No such file or directory\n"]}],"source":["# We assume that PyTorch is already installed in the environment.\n","# If not, this command installs it.\n","!pip install torch==2.0.0\n","\n","# Install PyTorch Geometric, a library for creating graph neural networks using PyTorch.\n","!pip install torch-geometric==2.4.0\n","\n","# Import PyTorch to access its functionalities.\n","import torch\n","\n","# Install additional PyTorch Geometric dependencies for graph processing (scatter, sparse, cluster, spline-conv).\n","# These packages enable operations like sparse tensors and convolutions on graphs.\n","!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","\n","# Reinstall PyTorch Geometric to ensure all dependencies are correctly loaded.\n","!pip install torch-geometric\n","\n","# Retrieve the installed version of PyTorch to ensure compatibility with other packages.\n","torchversion = torch.__version__\n","\n","# Install the latest version of PyTorch Geometric directly from the GitHub repository.\n","# This allows access to the most recent updates and features for graph-based neural networks.\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","\n","# Install DeepOnto, a package specifically designed for ontology matching, particularly useful in biomedical applications.\n","!pip install deeponto\n","\n","# Install a custom version of DeepOnto from a GitHub repository.\n","# The '<username>' part should be replaced with the actual GitHub username of the repository maintainer.\n","!pip install git+https://github.com/<username>/deeponto.git\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HPAlAgjLMVhw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732187581555,"user_tz":-60,"elapsed":229894,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"bf829225-1f00-476c-fa2a-882d3d9a5533"},"outputs":[{"output_type":"stream","name":"stdout","text":["Please enter the maximum memory located to JVM [8g]: 8g\n","\n"]}],"source":["# Import pandas for data manipulation and analysis, such as loading, processing, and saving tabular data.\n","import pandas as pd\n","\n","# Import pickle for saving and loading serialized objects (e.g., trained models or preprocessed data).\n","import pickle\n","\n","# Import function to convert a directed graph to an undirected one, useful for certain graph algorithms.\n","from torch_geometric.utils import to_undirected\n","\n","# Import optimizer module from PyTorch for training models using gradient-based optimization techniques.\n","import torch.optim as optim\n","\n","# Import PyTorch's modules for defining neural network architectures and operations:\n","from torch.nn import (\n","    Linear,       # For linear transformations (dense layers).\n","    Sequential,   # For stacking layers sequentially.\n","    BatchNorm1d,  # For normalizing input within mini-batches.\n","    PReLU,        # Parametric ReLU activation function.\n","    Dropout       # For regularization by randomly dropping connections during training.\n",")\n","\n","# Import functional API from PyTorch for operations like activations and loss functions.\n","import torch.nn.functional as F\n","\n","# Import Matplotlib for visualizations, such as plotting training loss curves.\n","import matplotlib.pyplot as plt\n","\n","# Import PyTorch Geometric's graph convolutional layers:\n","from torch_geometric.nn import GCNConv, GINConv\n","\n","# Import pooling operations for aggregating node embeddings to graph-level representations:\n","from torch_geometric.nn import global_mean_pool, global_add_pool\n","\n","# Import NumPy for numerical operations, such as working with arrays and matrices.\n","import numpy as np\n","\n","# Import time module for measuring execution time of code blocks.\n","import time\n","\n","# Import typing module for specifying types in function arguments and return values.\n","from typing import Optional, Tuple, Union, Callable\n","\n","# Import PyTorch's DataLoader and TensorDataset for handling data batching and loading during training.\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","# Import PyTorch's Parameter class for defining learnable parameters in custom models.\n","from torch.nn import Parameter\n","\n","# Import math module for performing mathematical computations.\n","import math\n","\n","# Import Tensor type from PyTorch for defining and manipulating tensors.\n","from torch import Tensor\n","\n","# Import PyTorch's nn module for defining and building neural network architectures.\n","import torch.nn as nn\n","\n","# Import initialization utilities from PyTorch Geometric for resetting weights and biases in layers.\n","from torch_geometric.nn.inits import reset\n","\n","# Import the base class for defining message-passing layers in graph neural networks (GNNs).\n","from torch_geometric.nn.conv import MessagePassing\n","\n","# Import linear transformation utilities for creating dense representations in graph models.\n","from torch_geometric.nn.dense.linear import Linear\n","\n","# Import typing utilities for defining adjacency matrices and tensor types specific to PyTorch Geometric.\n","from torch_geometric.typing import Adj, OptTensor, PairTensor, SparseTensor\n","\n","# Import softmax function for normalizing attention scores in GNNs.\n","from torch_geometric.utils import softmax\n","\n","# Import initialization utilities for weight initialization (e.g., Glorot initialization).\n","from torch_geometric.nn.inits import glorot, zeros\n","\n","# Import F1 score metric from scikit-learn for evaluating model performance in binary/multi-class tasks.\n","from sklearn.metrics import f1_score\n","\n","# Import JSON module for reading and writing JSON files, useful for storing configuration or ontology data.\n","import json\n","\n","# Import Ontology class from DeepOnto for representing and manipulating ontologies in the pipeline.\n","from deeponto.onto import Ontology\n","\n","# Import tools from DeepOnto for handling Ontology Alignment Evaluation Initiative (OAEI) tasks.\n","from deeponto.align.oaei import *\n","\n","# Import evaluation tools from DeepOnto for assessing alignment results using metrics like precision, recall, and F1.\n","from deeponto.align.evaluation import AlignmentEvaluator\n","\n","# Import mapping utilities from DeepOnto for working with reference mappings and entity pairs.\n","from deeponto.align.mapping import ReferenceMapping, EntityMapping\n","\n","# Import utility function for reading tables (e.g., TSV, CSV) from DeepOnto.\n","from deeponto.utils import read_table\n","\n","# Importing the train_test_split function from sklearn's model_selection module.\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"-abbBHOoRdWl"},"source":["# **Paths Definition**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AVgl_Bb42naS","outputId":"5e578975-d756-4622-b40c-45f5c4a17f25","executionInfo":{"status":"ok","timestamp":1732187602036,"user_tz":-60,"elapsed":20485,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# Importing the 'drive' module from Google Colab to interact with Google Drive\n","from google.colab import drive\n","\n","# Mount the user's Google Drive to the Colab environment\n","# After running this, a link will appear to authorize access, and Google Drive will be mounted at '/content/gdrive'\n","drive.mount('/content/gdrive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"36ttssQ3W7cx"},"outputs":[],"source":["# Define the source ontology name\n","src_ent = \"snomed.neoplas\"\n","\n","# Define the target ontology name\n","tgt_ent = \"ncit.neoplas\"\n","\n","# Define the task name for this ontology matching process\n","task = \"neoplas\"\n","\n","# Define the weight for the training data\n","# This weight is likely used to balance the training process, giving more emphasis to certain examples.\n","# For instance, a weight of 10.0 could be applied to penalize errors in certain types of predictions more heavily.\n","weight_train= 50.0\n","\n","# Define the similarity threshold for validating matches\n","thres = 0.80"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SJpvkdwVSQye"},"outputs":[],"source":["dir = f\"/content/gdrive/My Drive/BioGITOM-VLDB/Experiments/{task}\"\n","\n","dataset=\"/content/gdrive/My Drive/BioGITOM-VLDB/\"\n","\n","# Define the directory for the dataset containing source and target ontologies\n","dataset_dir = f\"{dataset}/Datasets/{task}\"\n","\n","# Define the data directory for storing embeddings, adjacency matrices, and related files\n","data_dir = f\"{dir}/Data\"\n","\n","# Define the directory for storing the results\n","results_dir = f\"{dir}/Negative_Number_Ajdustment/Results\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eFDNSFef23er"},"outputs":[],"source":["# Load the Source ontology using the Ontology class from DeepOnto\n","# This initializes the source ontology by loading its .owl file.\n","src_onto = Ontology(f\"{dataset_dir}/{src_ent}.owl\")\n","\n","# Load the Target ontology using the Ontology class from DeepOnto\n","# This initializes the target ontology by loading its .owl file.\n","tgt_onto = Ontology(f\"{dataset_dir}/{tgt_ent}.owl\")\n","\n","# Define the file path for the Source embeddings CSV file\n","# Embeddings for the source ontology entities are stored in this file.\n","src_Emb = f\"{data_dir}/{src_ent}_emb.csv\"\n","\n","# Define the file path for the Target embeddings CSV file\n","# Embeddings for the target ontology entities are stored in this file.\n","tgt_Emb = f\"{data_dir}/{tgt_ent}_emb.csv\"\n","\n","# Define the file path for the Source adjacency matrix\n","# This file represents the relationships (edges) between entities in the source ontology.\n","src_Adjacence = f\"{data_dir}/{src_ent}_adjacence.csv\"\n","\n","# Define the file path for the Target adjacency matrix\n","# This file represents the relationships (edges) between entities in the target ontology.\n","tgt_Adjacence = f\"{data_dir}/{tgt_ent}_adjacence.csv\"\n","\n","# Define the file path for the JSON file containing the Source ontology class labels\n","# This file maps the source ontology entities to their labels or names.\n","src_class = f\"{data_dir}/{src_ent}_classes.json\"\n","\n","# Define the file path for the JSON file containing the Target ontology class labels\n","# This file maps the target ontology entities to their labels or names.\n","tgt_class = f\"{data_dir}/{tgt_ent}_classes.json\"\n","\n","# Define the file path for the train data\n","train_file = f\"{data_dir}/{task}_train_50.csv\"\n","\n","# Define the file path for the test data\n","# The test file contains reference mappings (ground truth) between the source and target ontologies.\n","test_file = f\"{dataset_dir}/refs_equiv/test.tsv\"\n","\n","# Define the file path for the candidate mappings used during testing\n","# This file includes the candidate pairs (source and target entities) for ranking and evaluation.\n","test_cands = f\"{dataset_dir}/refs_equiv/test.cands.tsv\"\n","\n","# Define the file path for the candidate mappings between Source to Target entities\n","# This file contains cleaned, combined, and encoded candidates used for predictions.\n","candidates_Prediction = f\"{data_dir}/{task}_candidates_prediction.csv\"\n","\n","# Define the file path for the candidate mappings between Source to Target entities for ranking-based metrics\n","# This file is used to compute ranking-based metrics like MRR and Hits@k.\n","candidates_Rank = f\"{data_dir}/{task}_candidates.csv\"\n","\n","# Define the path where the prediction results will be saved in TSV format\n","# This file will store the final predictions (mappings) between source and target entities.\n","prediction_path = f\"{results_dir}/{task}_matching_results.tsv\"\n","\n","# Define the path where all prediction results will be saved in TSV format\n","# This file will store detailed prediction results, including all candidate scores.\n","all_predictions_path = f\"{results_dir}/{task}_all_predictions.tsv\"\n","\n","# Define the path where all ranking prediction results will be saved in TSV format\n","# This file will store predictions sorted by rank based on their scores.\n","all_predictions_path_ranked = f\"{results_dir}/{task}_all_predictions_ranked.tsv\"\n","\n","# Define the path where formatted ranking predictions will be saved in TSV format\n","# This file will contain predictions formatted for evaluation using ranking-based metrics.\n","formatted_predictions_path = f\"{results_dir}/{task}_formatted_predictions.tsv\""]},{"cell_type":"markdown","metadata":{"id":"zqEXsgPGMVhw"},"source":["# **GIT Architecture**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A_d6XCsUMVhx"},"outputs":[],"source":["# RGIT class definition which inherits from PyTorch Geometric's MessagePassing class\n","class RGIT(MessagePassing):\n","\n","    _alpha: OptTensor  # Define _alpha as an optional tensor for storing attention weights\n","\n","    def __init__(\n","        self,\n","        nn: Callable,  # Neural network to be used in the final layer of the GNN\n","        in_channels: Union[int, Tuple[int, int]],  # Input dimension, can be a single or pair of integers\n","        out_channels: int,  # Output dimension of the GNN\n","        eps: float = 0.,  # GIN parameter: epsilon for GIN aggregation\n","        train_eps: bool = False,  # GIN parameter: whether epsilon should be learnable\n","        heads: int = 1,  # Transformer parameter: number of attention heads\n","        dropout: float = 0.,  # Dropout rate for attention weights\n","        edge_dim: Optional[int] = None,  # Dimension for edge attributes (optional)\n","        bias: bool = True,  # Whether to use bias in linear layers\n","        root_weight: bool = True,  # GIN parameter: whether to apply root weight in aggregation\n","        **kwargs,  # Additional arguments passed to the parent class\n","    ):\n","        # Set the aggregation type to 'add' and initialize the parent class with node_dim=0\n","        kwargs.setdefault('aggr', 'add')\n","        super().__init__(node_dim=0, **kwargs)\n","\n","        # Initialize input/output dimensions, neural network, and GIN/transformer parameters\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.nn = nn  # Neural network used by the GNN\n","        self.initial_eps = eps  # Initial value of epsilon for GIN\n","\n","        # Set epsilon to be learnable or fixed\n","        if train_eps:\n","            self.eps = torch.nn.Parameter(torch.empty(1))  # Learnable epsilon\n","        else:\n","            self.register_buffer('eps', torch.empty(1))  # Non-learnable epsilon (fixed)\n","\n","        # Initialize transformer-related parameters\n","        self.heads = heads\n","        self.dropout = dropout\n","        self.edge_dim = edge_dim\n","        self._alpha = None  # Placeholder for attention weights\n","\n","        # Handle case where in_channels is a single integer or a tuple\n","        if isinstance(in_channels, int):\n","            in_channels = (in_channels, in_channels)\n","\n","        # Define the linear layers for key, query, and value for the transformer mechanism\n","        self.lin_key = Linear(in_channels[0], heads * out_channels)\n","        self.lin_query = Linear(in_channels[1], heads * out_channels)\n","        self.lin_value = Linear(in_channels[0], heads * out_channels)\n","\n","        # Define linear transformation for edge embeddings if provided\n","        if edge_dim is not None:\n","            self.lin_edge = Linear(edge_dim, heads * out_channels, bias=False)\n","        else:\n","            self.lin_edge = self.register_parameter('lin_edge', None)\n","\n","        # Reset all parameters to their initial values\n","        self.reset_parameters()\n","\n","    # Function to reset model parameters\n","    def reset_parameters(self):\n","        super().reset_parameters()  # Call parent class reset method\n","        self.lin_key.reset_parameters()  # Reset key linear layer\n","        self.lin_query.reset_parameters()  # Reset query linear layer\n","        self.lin_value.reset_parameters()  # Reset value linear layer\n","        if self.edge_dim:\n","            self.lin_edge.reset_parameters()  # Reset edge linear layer if used\n","        reset(self.nn)  # Reset the neural network provided\n","        self.eps.data.fill_(self.initial_eps)  # Initialize epsilon with the starting value\n","\n","    # Forward function defining how the input data flows through the model\n","    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj,\n","                edge_attr: OptTensor = None, return_attention_weights=None):\n","        # Unpack number of heads and output channels\n","        H, C = self.heads, self.out_channels\n","\n","        # If x is a tensor, treat it as a pair of tensors (source and target embeddings)\n","        if isinstance(x, Tensor):\n","            x: PairTensor = (x, x)\n","\n","        # Extract source node embeddings\n","        x_t = x[0]\n","\n","        # Apply linear transformations and reshape query, key, and value for multi-head attention\n","        query = self.lin_query(x[1]).view(-1, H, C)\n","        key = self.lin_key(x[0]).view(-1, H, C)\n","        value = self.lin_value(x[0]).view(-1, H, C)\n","\n","        # Propagate messages through the graph using the propagate function\n","        out = self.propagate(edge_index, query=query, key=key, value=value,\n","                             edge_attr=edge_attr, size=None)\n","\n","        # Retrieve attention weights and reset them\n","        alpha = self._alpha\n","        self._alpha = None  # Reset _alpha after use\n","        out = out.mean(dim=1)  # Take the mean over all attention heads\n","\n","        # Apply GIN aggregation by adding epsilon-scaled original node embeddings\n","        out = out + (1 + self.eps) * x_t\n","        return self.nn(out)  # Pass through the neural network\n","\n","    # Message passing function which calculates attention and combines messages\n","    def message(self, query_i: Tensor, key_j: Tensor, value_j: Tensor,\n","                edge_attr: OptTensor, index: Tensor, ptr: OptTensor,\n","                size_i: Optional[int]) -> Tensor:\n","        # If edge attributes are used, apply linear transformation and add them to the key\n","        if self.lin_edge is not None:\n","            assert edge_attr is not None\n","            edge_attr = self.lin_edge(edge_attr).view(-1, self.heads, self.out_channels)\n","            key_j = key_j + edge_attr\n","\n","        # Calculate attention (alpha) using the dot product between query and key\n","        alpha = (query_i * key_j).sum(dim=-1) / math.sqrt(self.out_channels)\n","        alpha = softmax(alpha, index, ptr, size_i)  # Apply softmax to normalize attention\n","        self._alpha = alpha  # Store attention weights\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)  # Apply dropout\n","\n","        # Calculate the output message by applying attention to the value\n","        out = value_j\n","        if edge_attr is not None:\n","            out = out + edge_attr  # Add edge embeddings to the output if present\n","        out = out * alpha.view(-1, self.heads, 1)  # Scale by attention weights\n","        return out\n","\n","    # String representation function for debugging or printing\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}({self.in_channels}, '\n","                f'{self.out_channels}, heads={self.heads})')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qwFv6RgHmGCf"},"outputs":[],"source":["# Define the RGIT_mod class, a multi-layer GNN that uses both RGIT and linear layers\n","class RGIT_mod(torch.nn.Module):\n","    \"\"\"Multi-layer RGIT with optional linear layers\"\"\"\n","\n","    # Initialize the model with hidden dimension, number of RGIT layers, and number of linear layers\n","    def __init__(self, dim_h, num_layers, num_linear_layers=1):\n","        super(RGIT_mod, self).__init__()\n","        self.num_layers = num_layers  # Number of RGIT layers\n","        self.num_linear_layers = num_linear_layers  # Number of linear layers\n","        self.linears = torch.nn.ModuleList()  # List to store linear layers\n","        self.rgit_layers = torch.nn.ModuleList()  # List to store RGIT layers\n","\n","        # Create a list of Linear and PReLU layers (for encoding entity names)\n","        for _ in range(num_linear_layers):\n","            self.linears.append(Linear(dim_h, dim_h))  # Linear transformation layer\n","            self.linears.append(PReLU(num_parameters=dim_h))  # Parametric ReLU activation function\n","\n","        # Create a list of RGIT layers\n","        for _ in range(num_layers):\n","            self.rgit_layers.append(RGIT(  # Each RGIT layer contains a small MLP with Linear and PReLU\n","                Sequential(Linear(dim_h, dim_h), PReLU(num_parameters=dim_h),\n","                           Linear(dim_h, dim_h), PReLU(num_parameters=dim_h)), dim_h, dim_h))\n","\n","    # Forward pass through the model\n","    def forward(self, x, edge_index):\n","        # Apply the linear layers first to the input\n","        for layer in self.linears:\n","            x = layer(x)\n","\n","        # Then apply the RGIT layers for message passing\n","        for layer in self.rgit_layers:\n","            x = layer(x, edge_index)\n","\n","        return x  # Return the final node embeddings after all layers\n"]},{"cell_type":"markdown","metadata":{"id":"zxCn5ztKVztw"},"source":["# **Gated Network Architecture**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7MKQUv7o7zay"},"outputs":[],"source":["# Define the GatedCombination class for combining two pairs of embeddings using a gating mechanism\n","class GatedCombination(nn.Module):\n","    def __init__(self, input_dim):\n","        \"\"\"\n","        Initialize the GatedCombination model.\n","\n","        Args:\n","            input_dim (int): The dimensionality of the input embeddings (x1, x2, x3, x4).\n","        \"\"\"\n","        super(GatedCombination, self).__init__()\n","\n","        # Define a linear layer (gate) for combining embeddings x1 and x2 (first pair)\n","        self.gate_A_fc = nn.Linear(input_dim, input_dim)\n","\n","        # Define a linear layer (gate) for combining embeddings x3 and x4 (second pair)\n","        self.gate_B_fc = nn.Linear(input_dim, input_dim)\n","\n","        # A final fully connected layer that outputs a single neuron (binary classification)\n","        self.fc = nn.Linear(1, 1)\n","\n","    def forward(self, x1, x2, x3, x4):\n","        \"\"\"\n","        Forward pass through the gating mechanism and cosine similarity.\n","\n","        Args:\n","            x1 (torch.Tensor): First set of embeddings (source embeddings after update).\n","            x2 (torch.Tensor): Second set of embeddings (original source embeddings).\n","            x3 (torch.Tensor): Third set of embeddings (target embeddings after update).\n","            x4 (torch.Tensor): Fourth set of embeddings (original target embeddings).\n","\n","        Returns:\n","            torch.Tensor: Output of the model (probability score for binary classification).\n","        \"\"\"\n","        # Compute gate values for the first pair (x1 and x2) using a sigmoid activation\n","        gate_values1 = torch.sigmoid(self.gate_A_fc(x1))\n","\n","        # Combine x1 and x2 using the gate values\n","        # The result is a weighted combination of x1 and x2\n","        a = x1 * gate_values1 + x2 * (1 - gate_values1)\n","\n","        # Compute gate values for the second pair (x3 and x4) using a sigmoid activation\n","        gate_values2 = torch.sigmoid(self.gate_B_fc(x3))\n","\n","        # Combine x3 and x4 using the gate values\n","        # The result is a weighted combination of x3 and x4\n","        b = x3 * gate_values2 + x4 * (1 - gate_values2)\n","\n","        # Compute cosine similarity between the combined vectors a and b\n","        x = torch.cosine_similarity(a, b, dim=1)\n","\n","        # Pass the cosine similarity result through a fully connected layer (fc) for classification\n","        # Use a sigmoid activation to output a probability for binary classification\n","        out = torch.sigmoid(self.fc(x.unsqueeze(1)))  # unsqueeze(1) to match the input shape for the fc layer\n","        return out\n","\n"]},{"cell_type":"code","source":["class WeightedBCELoss(nn.Module):\n","    def __init__(self, pos_weight):\n","        \"\"\"\n","        Weighted Binary Cross-Entropy Loss.\n","\n","        Args:\n","            pos_weight (float): Weight for the positive class.\n","        \"\"\"\n","        super(WeightedBCELoss, self).__init__()\n","        self.pos_weight = pos_weight\n","\n","    def forward(self, outputs, targets):\n","        \"\"\"\n","        Args:\n","            outputs (torch.Tensor): Predicted probabilities from the model (after sigmoid).\n","            targets (torch.Tensor): Ground truth labels (0 or 1).\n","\n","        Returns:\n","            torch.Tensor: Computed weighted binary cross-entropy loss.\n","        \"\"\"\n","        # Compute weighted BCE loss\n","        loss = - (self.pos_weight * targets * torch.log(outputs + 1e-8) +\n","                  (1 - targets) * torch.log(1 - outputs + 1e-8))\n","        return loss.mean()"],"metadata":{"id":"PCzq6hHCD8vg"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4kO42TTCqQZ8"},"outputs":[],"source":["class FocalLoss(nn.Module):\n","    def __init__(self, alpha=0.25, gamma=2):\n","        \"\"\"\n","        Focal Loss for binary classification.\n","\n","        Args:\n","            alpha (float): Balancing factor for positive/negative classes.\n","            gamma (float): Focusing parameter for hard examples.\n","        \"\"\"\n","        super(FocalLoss, self).__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","\n","    def forward(self, outputs, targets):\n","        \"\"\"\n","        Args:\n","            outputs (torch.Tensor): Predicted probabilities from the model (after sigmoid).\n","            targets (torch.Tensor): Ground truth labels (0 or 1).\n","\n","        Returns:\n","            torch.Tensor: Computed focal loss.\n","        \"\"\"\n","        # Compute binary cross-entropy loss\n","        bce_loss = F.binary_cross_entropy(outputs, targets, reduction='none')\n","\n","        # Compute modulating factor (1 - p_t)^gamma\n","        pt = torch.where(targets == 1, outputs, 1 - outputs)  # pt = p if y==1 else 1-p\n","        modulating_factor = (1 - pt) ** self.gamma\n","\n","        # Apply alpha and modulating factor\n","        focal_loss = self.alpha * modulating_factor * bce_loss\n","        return focal_loss.mean()"]},{"cell_type":"markdown","metadata":{"id":"aLJ5j9FNMVhy"},"source":["# **Utility functions**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k0L86DgUQjMU"},"outputs":[],"source":["def adjacency_matrix_to_undirected_edge_index(adjacency_matrix):\n","    \"\"\"\n","    Converts an adjacency matrix into an undirected edge index for use in graph-based neural networks.\n","\n","    Args:\n","        adjacency_matrix: A 2D list or array representing the adjacency matrix of a graph.\n","\n","    Returns:\n","        edge_index_undirected: A PyTorch tensor representing the undirected edges.\n","    \"\"\"\n","    # Convert each element in the adjacency matrix to an integer (from boolean or float)\n","    adjacency_matrix = [[int(element) for element in sublist] for sublist in adjacency_matrix]\n","\n","    # Convert the adjacency matrix into a PyTorch LongTensor (used for indexing)\n","    edge_index = torch.tensor(adjacency_matrix, dtype=torch.long)\n","\n","    # Transpose the edge_index tensor so that rows represent edges in the form [source, target]\n","    edge_index = edge_index.t().contiguous()\n","\n","    # Convert the directed edge_index into an undirected edge_index, meaning both directions are added (i.e., (i, j) and (j, i))\n","    edge_index_undirected = to_undirected(edge_index)\n","\n","    return edge_index_undirected  # Return the undirected edge index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YvmOxkLcpf9w"},"outputs":[],"source":["def build_indexed_dict(file_path):\n","    \"\"\"\n","    Builds a dictionary with numeric indexes for each key from a JSON file.\n","\n","    Args:\n","        file_path (str): The path to the JSON file.\n","\n","    Returns:\n","        indexed_dict (dict): A new dictionary where each key from the JSON file is assigned a numeric index.\n","    \"\"\"\n","    # Load the JSON file into a Python dictionary\n","    with open(file_path, 'r') as file:\n","        data = json.load(file)\n","\n","    # Create a new dictionary with numeric indexes as keys and the original JSON keys as values\n","    indexed_dict = {index: key for index, key in enumerate(data.keys())}\n","\n","    return indexed_dict  # Return the newly created dictionary"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QgFINoPGl9Wg"},"outputs":[],"source":["def select_rows_by_index(embedding_vector, index_vector):\n","    \"\"\"\n","    Select rows from an embedding vector using an index vector.\n","\n","    Args:\n","        embedding_vector (torch.Tensor): 2D tensor representing the embedding vector with shape [num_rows, embedding_size].\n","        index_vector (torch.Tensor): 1D tensor representing the index vector.\n","\n","    Returns:\n","        torch.Tensor: New tensor with selected rows from the embedding vector.\n","    \"\"\"\n","    # Use torch.index_select to select the desired rows\n","    new_tensor = torch.index_select(embedding_vector, 0, index_vector)\n","\n","    return new_tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a12L7vEmmCJq"},"outputs":[],"source":["def contrastive_loss(source_embeddings, target_embeddings, labels, margin=1.0):\n","    \"\"\"\n","    Computes the contrastive loss, a type of loss function used to train models in tasks like matching or similarity learning.\n","\n","    Args:\n","        source_embeddings (torch.Tensor): Embeddings of the source graphs, shape [batch_size, embedding_size].\n","        target_embeddings (torch.Tensor): Embeddings of the target graphs, shape [batch_size, embedding_size].\n","        labels (torch.Tensor): Binary labels indicating if the pairs are matched (1) or not (0), shape [batch_size].\n","        margin (float): Margin value for the contrastive loss. Defaults to 1.0.\n","\n","    Returns:\n","        torch.Tensor: The contrastive loss value.\n","    \"\"\"\n","    # Calculate the pairwise Euclidean distance between source and target embeddings\n","    distances = F.pairwise_distance(source_embeddings, target_embeddings)\n","\n","    # Compute the contrastive loss:\n","    # - For matched pairs (label == 1), the loss is the squared distance between embeddings.\n","    # - For non-matched pairs (label == 0), the loss is based on how far apart the embeddings are,\n","    #   but penalizes them only if the distance is less than the margin.\n","    loss = torch.mean(\n","        labels * 0.4 * distances.pow(2) +  # For positive pairs, minimize the distance (squared)\n","        (1 - labels) * 0.4 * torch.max(torch.zeros_like(distances), margin - distances).pow(2)  # For negative pairs, maximize the distance (up to the margin)\n","    )\n","\n","    return loss  # Return the computed contrastive loss\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZhCizXEb7D4N"},"outputs":[],"source":["def Prediction_with_candidates(model, X1_tt, X2_tt, X3_tt, X4_tt, src_entity_tensor_o, tgt_entity_tensor_o,\n","                                   indexed_dict_src, indexed_dict_tgt, all_predictions_path):\n","    \"\"\"\n","    Evaluates the GatedCombination model using the given embeddings and candidate entity pairs.\n","    Saves the predictions and evaluation results to a file.\n","\n","    Args:\n","        model: Trained GatedCombination model.\n","        X1_tt, X2_tt, X3_tt, X4_tt (torch.Tensor): Tensors of source and target entity embeddings (updated and original).\n","        src_entity_tensor_o, tgt_entity_tensor_o (torch.Tensor): Tensors of source and target entity indices.\n","        indexed_dict_src, indexed_dict_tgt (dict): Dictionaries mapping entity indices to URIs for source and target.\n","        output_file (str): Path to save the predictions and results.\n","        hits_at_k_values (list): List of k-values for which hits@k is evaluated.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    # Move the model to CPU and set it to evaluation mode\n","    model = model.to(\"cpu\")\n","    model.eval()\n","\n","    # Set batch size for evaluation\n","    batch_size_test = 32\n","\n","    # Create a DataLoader for the evaluation data\n","    test_dataset = TensorDataset(X1_tt, X2_tt, X3_tt, X4_tt)\n","    test_dataloader = DataLoader(test_dataset, batch_size=batch_size_test)\n","\n","    # Prepare for collecting predictions and results\n","    predictions = []\n","    results = []\n","    count_predictions = 0  # Counter for predictions above threshold (0.5)\n","\n","    # Measure prediction time\n","    start_time = time.time()\n","\n","    # Disable gradient computation for evaluation\n","    with torch.no_grad():\n","        # Iterate over batches and compute model predictions\n","        for batch_X1, batch_X2, batch_X3, batch_X4 in test_dataloader:\n","            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","            predictions.extend(outputs.cpu().numpy())  # Collect predictions in CPU memory\n","\n","    end_time = time.time()\n","    predicting_time = end_time - start_time\n","    print(f\"Predicting time: {predicting_time:.2f} seconds\")\n","\n","    # Convert tensors to lists for easier iteration\n","    src_indices = src_entity_tensor_o.tolist()\n","    tgt_indices = tgt_entity_tensor_o.tolist()\n","\n","    # Prepare results\n","    for i in range(len(predictions)):\n","        if predictions[i] >= 0.00:  # Consider only predictions greater than 0.5\n","            count_predictions += 1  # Increment the counter\n","\n","            # Map the source and target entity indices to their URIs\n","            src_code = src_indices[i]\n","            tgt_code = tgt_indices[i]\n","\n","            src_uri = indexed_dict_src.get(int(src_code), \"Unknown URI\")\n","            tgt_uri = indexed_dict_tgt.get(int(tgt_code), \"Unknown URI\")\n","\n","            # Get the model's predicted score for the current pair\n","            score = predictions[i]\n","\n","            # Append the results (with URIs instead of entity indices)\n","            results.append({\n","                'SrcEntity': src_uri,\n","                'TgtEntity': tgt_uri,\n","                'Score': score\n","            })\n","\n","    # Convert the results into a pandas DataFrame\n","    df_results = pd.DataFrame(results)\n","\n","    # Save the results to a TSV file\n","    df_results.to_csv(all_predictions_path, sep='\\t', index=False)\n","\n","    print(f\"Predictions saved to {all_predictions_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TslUdYHBcGVj"},"outputs":[],"source":["def filter_highest_predictions(input_file_path, output_file_path, threshold=thres):\n","    # Load the all predictions file\n","    df = pd.read_csv(input_file_path, sep='\\t')\n","\n","    # Extract the similarity score from the list in the 'Score' column\n","    df['Score'] = df['Score'].apply(lambda x: float(x.strip('[]')))\n","\n","    # Sorting the dataframe by similarity score in descending order\n","    df_sorted = df.sort_values(by='Score', ascending=False).reset_index(drop=True)\n","\n","    # Initialize variables with threshold value\n","    source_concepts = set(df_sorted['SrcEntity'])\n","    target_concepts = set(df_sorted['TgtEntity'])\n","    matched_sources = set()\n","    matched_targets = set()\n","    result = []\n","\n","    # Iterate through the sorted dataframe and find highest correspondences\n","    for _, row in df_sorted.iterrows():\n","        source, target, similarity = row['SrcEntity'], row['TgtEntity'], row['Score']\n","\n","        # Check if the source or target has already been matched and if the similarity is above the threshold\n","        if source not in matched_sources and target not in matched_targets and similarity >= threshold:\n","            # Add the match to the result list\n","            result.append((source, target, similarity))\n","            # Mark the source and target as matched\n","            matched_sources.add(source)\n","            matched_targets.add(target)\n","\n","    # Create a dataframe for the matching results with threshold applied\n","    matching_results_df_threshold = pd.DataFrame(result, columns=['SrcEntity', 'TgtEntity', 'Score'])\n","\n","    # Save the matching results with the updated column names to a new TSV file\n","    matching_results_df_threshold.to_csv(output_file_path, sep='\\t', index=False)\n","\n","    # Print the number of predictions saved\n","    print(f\"Number of Positive Predictions : {len(matching_results_df_threshold)}\")\n","\n","    return matching_results_df_threshold, len(matching_results_df_threshold)"]},{"cell_type":"code","source":["def compute_mrr_and_hits(reference_file, predicted_file, output_file, k_values=[1, 5, 10]):\n","    \"\"\"\n","    Compute MRR and Hits@k for ontology matching predictions based on a reference file.\n","\n","    Args:\n","        reference_file (str): Path to the reference file (test.cands.tsv format).\n","        predicted_file (str): Path to the predictions file with scores.\n","        output_file (str): Path to save the scored results.\n","        k_values (list): List of k values for Hits@k.\n","\n","    Returns:\n","        dict: A dictionary containing MRR and Hits@k metrics.\n","    \"\"\"\n","    # Read the reference mappings\n","    test_candidate_mappings = read_table(reference_file).values.tolist()\n","    ranking_results = []\n","\n","    # Read the predicted scores\n","    predicted_data = pd.read_csv(predicted_file, sep=\"\\t\")\n","    predicted_data[\"Score\"] = predicted_data[\"Score\"].apply(lambda x: float(x.strip(\"[]\")))\n","\n","    # Create a lookup dictionary for predicted scores\n","    score_lookup = {}\n","    for _, row in predicted_data.iterrows():\n","        score_lookup[(row[\"SrcEntity\"], row[\"TgtEntity\"])] = row[\"Score\"]\n","\n","    for src_ref_class, tgt_ref_class, tgt_cands in test_candidate_mappings:\n","        tgt_cands = eval(tgt_cands)  # Convert string to list of candidates\n","        scored_cands = []\n","        for tgt_cand in tgt_cands:\n","            # Retrieve score for each candidate, defaulting to a very low score if not found\n","            matching_score = score_lookup.get((src_ref_class, tgt_cand), -1e9)\n","            scored_cands.append((tgt_cand, matching_score))\n","\n","        # Sort candidates by score in descending order\n","        scored_cands = sorted(scored_cands, key=lambda x: x[1], reverse=True)\n","        ranking_results.append((src_ref_class, tgt_ref_class, scored_cands))\n","\n","    # Save the ranked results to a file\n","    pd.DataFrame(ranking_results, columns=[\"SrcEntity\", \"TgtEntity\", \"TgtCandidates\"]).to_csv(output_file, sep=\"\\t\", index=False)\n","\n","    # Compute MRR and Hits@k\n","    total_entities = len(ranking_results)\n","    reciprocal_ranks = []\n","    hits_at_k = {k: 0 for k in k_values}\n","\n","    for src_entity, tgt_ref_class, tgt_cands in ranking_results:\n","        ranked_candidates = [candidate[0] for candidate in tgt_cands]\n","        if tgt_ref_class in ranked_candidates:\n","            rank = ranked_candidates.index(tgt_ref_class) + 1\n","            reciprocal_ranks.append(1 / rank)\n","            for k in k_values:\n","                if rank <= k:\n","                    hits_at_k[k] += 1\n","        else:\n","            reciprocal_ranks.append(0)\n","\n","    mrr = sum(reciprocal_ranks) / total_entities\n","    hits_at_k = {k: hits / total_entities for k, hits in hits_at_k.items()}\n","\n","    return {\"MRR\": mrr, \"Hits@k\": hits_at_k}"],"metadata":{"id":"_ggVYlTiO_WA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1HyWMsw1MVhz"},"source":["# **Main Code**\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"IC37FlwGDqGM"},"source":["\n","\n","# Reading semantic node embeddings provided by the ENE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FuEfSnw5mod0"},"outputs":[],"source":["# Read the source embeddings from a CSV file into a pandas DataFrame\n","df_embbedings_src = pd.read_csv(src_Emb, index_col=0)\n","\n","# Convert the DataFrame to a NumPy array, which will remove the index and store the data as a raw matrix\n","numpy_array = df_embbedings_src.to_numpy()\n","\n","# Convert the NumPy array into a PyTorch FloatTensor, which is the format required for PyTorch operations\n","x_src = torch.FloatTensor(numpy_array)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"STUwqMUXmlG2"},"outputs":[],"source":["# Read the target embeddings from a CSV file into a pandas DataFrame\n","df_embbedings_tgt = pd.read_csv(tgt_Emb, index_col=0)\n","\n","# Convert the DataFrame to a NumPy array, which removes the index and converts the data to a raw matrix\n","numpy_array = df_embbedings_tgt.to_numpy()\n","\n","# Convert the NumPy array into a PyTorch FloatTensor, which is required for PyTorch operations\n","x_tgt = torch.FloatTensor(numpy_array)"]},{"cell_type":"markdown","metadata":{"id":"jZIu9P08DqGN"},"source":["# Reading adjacency Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pH69Up40mycz"},"outputs":[],"source":["# Read the source adjacency matrix from a CSV file into a pandas DataFrame\n","df_ma1 = pd.read_csv(src_Adjacence, index_col=0)\n","\n","# Convert the DataFrame to a list of lists (Python native list format)\n","ma1 = df_ma1.values.tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hYCmAO5Ymzpl"},"outputs":[],"source":["# Read the target adjacency matrix from a CSV file into a pandas DataFrame\n","df_ma2 = pd.read_csv(tgt_Adjacence, index_col=0)\n","\n","# Convert the DataFrame to a list of lists (Python native list format)\n","ma2 = df_ma2.values.tolist()"]},{"cell_type":"markdown","metadata":{"id":"PSyksqh3TrU-"},"source":["# Convert Adjacency matrix (in list format) to an undirected edge index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uVt-Pce5m5ll"},"outputs":[],"source":["# Convert the source adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n","edge_src = adjacency_matrix_to_undirected_edge_index(ma1)\n","\n","# Convert the target adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n","edge_tgt = adjacency_matrix_to_undirected_edge_index(ma2)"]},{"cell_type":"markdown","metadata":{"id":"H9wMTRdqT4aY"},"source":["# GIT Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eqiEKCLSMVh3"},"outputs":[],"source":["def train_model_gnn(model, x_src, edge_src, x_tgt, edge_tgt,\n","                    tensor_term1, tensor_term2, tensor_score,\n","                    learning_rate, weight_decay_value, num_epochs, print_interval=10):\n","    \"\"\"\n","    Trains a graph neural network (GNN) model using source and target embeddings and contrastive loss.\n","\n","    Args:\n","        model: The GNN model to be trained.\n","        x_src (torch.Tensor): Source node embeddings.\n","        edge_src (torch.Tensor): Source graph edges.\n","        x_tgt (torch.Tensor): Target node embeddings.\n","        edge_tgt (torch.Tensor): Target graph edges.\n","        tensor_term1 (torch.Tensor): Indices of the source nodes to be compared.\n","        tensor_term2 (torch.Tensor): Indices of the target nodes to be compared.\n","        tensor_score (torch.Tensor): Labels indicating if the pairs are matched (1) or not (0).\n","        learning_rate (float): Learning rate for the optimizer.\n","        weight_decay_value (float): Weight decay (L2 regularization) value for the optimizer.\n","        num_epochs (int): Number of epochs for training.\n","        print_interval (int): Interval at which training progress is printed (every `print_interval` epochs).\n","\n","    Returns:\n","        model: The trained GNN model.\n","    \"\"\"\n","\n","    # Step 1: Set device (GPU or CPU) for computation\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    # Step 2: Move the model and all inputs to the selected device\n","    model.to(device)\n","    x_tgt = x_tgt.to(device)               # Target node embeddings\n","    edge_tgt = edge_tgt.to(device)         # Target graph edges\n","    x_src = x_src.to(device)               # Source node embeddings\n","    edge_src = edge_src.to(device)         # Source graph edges\n","    tensor_term1 = tensor_term1.to(device) # Indices for source nodes\n","    tensor_term2 = tensor_term2.to(device) # Indices for target nodes\n","    tensor_score = tensor_score.to(device) # Ground truth labels\n","\n","    # Step 3: Define optimizer with learning rate and regularization\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay_value)\n","\n","    # Step 4: Initialize list to store training losses\n","    train_losses = []\n","\n","    # Record the start time of training\n","    start_time = time.time()\n","\n","    # Step 5: Training loop\n","    for epoch in range(num_epochs):\n","        # Zero out gradients from the previous iteration\n","        optimizer.zero_grad()\n","\n","        # Forward pass: Compute embeddings for source and target graphs\n","        out1 = model(x_src, edge_src)  # Updated source embeddings\n","        out2 = model(x_tgt, edge_tgt)  # Updated target embeddings\n","\n","        # Extract specific rows of embeddings for terms being compared\n","        src_embeddings = select_rows_by_index(out1, tensor_term1)\n","        tgt_embeddings = select_rows_by_index(out2, tensor_term2)\n","\n","        # Compute contrastive loss based on the embeddings and ground truth labels\n","        loss = contrastive_loss(src_embeddings, tgt_embeddings, tensor_score)\n","\n","        # Backward pass: Compute gradients\n","        loss.backward()\n","\n","        # Update the model's parameters\n","        optimizer.step()\n","\n","        # Append the loss for this iteration to the list\n","        train_losses.append(loss.item())\n","\n","        # Print loss every `print_interval` epochs\n","        if (epoch + 1) % print_interval == 0:\n","            print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item()}\")\n","\n","    # Step 6: Record end time of training\n","    end_time = time.time()\n","\n","    # Step 7: Plot the training loss over time\n","    plt.semilogy(range(1, num_epochs + 1), train_losses, label=\"Training Loss\", marker='o')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    # Print the total training time\n","    training_time = end_time - start_time\n","    print(f\"Training complete! Total training time: {training_time:.2f} seconds\")\n","\n","    # Step 8: Return the trained model\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6_tzUG_emtBg"},"outputs":[],"source":["# Initialize the GIT_mod model with the dimensionality of the target embeddings\n","# The first argument is the dimensionality of the target node embeddings (x_tgt.shape[1])\n","# The second argument (1) represents the number of RGIT layers in the model\n","GIT_model = RGIT_mod(x_tgt.shape[1], 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wVo-s7UQssSp"},"outputs":[],"source":["# Reading the training pairs from a CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(train_file, index_col=0)\n","\n","# Extract the 'SrcEntity' and 'TgtEntity' columns as NumPy arrays and convert them to integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)  # Source entity indices\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)  # Target entity indices\n","\n","# Extract the 'Score' column as a NumPy array and convert it to floats\n","tensor_score = df_embbedings['Score'].values.astype(float)  # Scores (labels) indicating if pairs match (1) or not (0)\n","\n","# Convert the NumPy arrays to PyTorch LongTensors (for indices) and FloatTensors (for scores)\n","tensor_term1_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)  # Source entity tensor\n","tensor_term2_o = torch.from_numpy(tensor_term2).type(torch.LongTensor)  # Target entity tensor\n","tensor_score_o = torch.from_numpy(tensor_score).type(torch.FloatTensor)  # Score tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"agHlFNesMVh3","outputId":"f362389a-0bc3-4dc6-9b66-2bb724bf6844","executionInfo":{"status":"ok","timestamp":1732189213702,"user_tz":-60,"elapsed":1568099,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [10/1000], Training Loss: 0.002963071223348379\n","Epoch [20/1000], Training Loss: 0.0023939632810652256\n","Epoch [30/1000], Training Loss: 0.0020542985294014215\n","Epoch [40/1000], Training Loss: 0.0018247058615088463\n","Epoch [50/1000], Training Loss: 0.0016575857298448682\n","Epoch [60/1000], Training Loss: 0.0015269757714122534\n","Epoch [70/1000], Training Loss: 0.0014193363022059202\n","Epoch [80/1000], Training Loss: 0.0013281089486554265\n","Epoch [90/1000], Training Loss: 0.0012495910050347447\n","Epoch [100/1000], Training Loss: 0.001181063475087285\n","Epoch [110/1000], Training Loss: 0.0011202185414731503\n","Epoch [120/1000], Training Loss: 0.001065949909389019\n","Epoch [130/1000], Training Loss: 0.001016879454255104\n","Epoch [140/1000], Training Loss: 0.0009727264405228198\n","Epoch [150/1000], Training Loss: 0.0009319361997768283\n","Epoch [160/1000], Training Loss: 0.0008942876593209803\n","Epoch [170/1000], Training Loss: 0.0008591570076532662\n","Epoch [180/1000], Training Loss: 0.0008264543721452355\n","Epoch [190/1000], Training Loss: 0.0007956732297316194\n","Epoch [200/1000], Training Loss: 0.000766659330110997\n","Epoch [210/1000], Training Loss: 0.0007391003891825676\n","Epoch [220/1000], Training Loss: 0.000712831795681268\n","Epoch [230/1000], Training Loss: 0.0006878690328449011\n","Epoch [240/1000], Training Loss: 0.0006642481894232333\n","Epoch [250/1000], Training Loss: 0.000641738239210099\n","Epoch [260/1000], Training Loss: 0.0006202247459441423\n","Epoch [270/1000], Training Loss: 0.0005997155094519258\n","Epoch [280/1000], Training Loss: 0.0005799538921564817\n","Epoch [290/1000], Training Loss: 0.0005611057858914137\n","Epoch [300/1000], Training Loss: 0.0005431571626104414\n","Epoch [310/1000], Training Loss: 0.0005260170437395573\n","Epoch [320/1000], Training Loss: 0.0005097732646390796\n","Epoch [330/1000], Training Loss: 0.0004942857776768506\n","Epoch [340/1000], Training Loss: 0.00047954649198800325\n","Epoch [350/1000], Training Loss: 0.0004654497024603188\n","Epoch [360/1000], Training Loss: 0.0004519537615124136\n","Epoch [370/1000], Training Loss: 0.00043908608495257795\n","Epoch [380/1000], Training Loss: 0.00042673651478253305\n","Epoch [390/1000], Training Loss: 0.00041470848373137414\n","Epoch [400/1000], Training Loss: 0.00040316296508535743\n","Epoch [410/1000], Training Loss: 0.0003925756027456373\n","Epoch [420/1000], Training Loss: 0.00038194950320757926\n","Epoch [430/1000], Training Loss: 0.0003716626961249858\n","Epoch [440/1000], Training Loss: 0.0003623470838647336\n","Epoch [450/1000], Training Loss: 0.0003537733864504844\n","Epoch [460/1000], Training Loss: 0.0003452472446952015\n","Epoch [470/1000], Training Loss: 0.000336559081915766\n","Epoch [480/1000], Training Loss: 0.0003280519740656018\n","Epoch [490/1000], Training Loss: 0.0003199003404006362\n","Epoch [500/1000], Training Loss: 0.0003122068883385509\n","Epoch [510/1000], Training Loss: 0.00030492592486552894\n","Epoch [520/1000], Training Loss: 0.0002983259910251945\n","Epoch [530/1000], Training Loss: 0.00029264556360431015\n","Epoch [540/1000], Training Loss: 0.00028725946322083473\n","Epoch [550/1000], Training Loss: 0.00028211961034685373\n","Epoch [560/1000], Training Loss: 0.00027643266366794705\n","Epoch [570/1000], Training Loss: 0.0002708582323975861\n","Epoch [580/1000], Training Loss: 0.0002656391588971019\n","Epoch [590/1000], Training Loss: 0.00026093030464835465\n","Epoch [600/1000], Training Loss: 0.00025668222224339843\n","Epoch [610/1000], Training Loss: 0.00025324770831502974\n","Epoch [620/1000], Training Loss: 0.0002493086503818631\n","Epoch [630/1000], Training Loss: 0.0002458545786794275\n","Epoch [640/1000], Training Loss: 0.00024169070820789784\n","Epoch [650/1000], Training Loss: 0.00023724026686977595\n","Epoch [660/1000], Training Loss: 0.00023317242448683828\n","Epoch [670/1000], Training Loss: 0.0002296709135407582\n","Epoch [680/1000], Training Loss: 0.00022695257212035358\n","Epoch [690/1000], Training Loss: 0.0002249107783427462\n","Epoch [700/1000], Training Loss: 0.00022219876700546592\n","Epoch [710/1000], Training Loss: 0.00021887008915655315\n","Epoch [720/1000], Training Loss: 0.00021535847918130457\n","Epoch [730/1000], Training Loss: 0.0002124505554093048\n","Epoch [740/1000], Training Loss: 0.00021000175911467522\n","Epoch [750/1000], Training Loss: 0.00020884009427390993\n","Epoch [760/1000], Training Loss: 0.00020661337475758046\n","Epoch [770/1000], Training Loss: 0.00020306464284658432\n","Epoch [780/1000], Training Loss: 0.0001999520609388128\n","Epoch [790/1000], Training Loss: 0.00019753797096200287\n","Epoch [800/1000], Training Loss: 0.0001960846275324002\n","Epoch [810/1000], Training Loss: 0.0001947285927599296\n","Epoch [820/1000], Training Loss: 0.0001921065413625911\n","Epoch [830/1000], Training Loss: 0.00018938643916044384\n","Epoch [840/1000], Training Loss: 0.00018697668565437198\n","Epoch [850/1000], Training Loss: 0.00018535763956606388\n","Epoch [860/1000], Training Loss: 0.00018488551722839475\n","Epoch [870/1000], Training Loss: 0.000183748867129907\n","Epoch [880/1000], Training Loss: 0.00018202538194600493\n","Epoch [890/1000], Training Loss: 0.000179681766894646\n","Epoch [900/1000], Training Loss: 0.00017818741616792977\n","Epoch [910/1000], Training Loss: 0.00017684120393823832\n","Epoch [920/1000], Training Loss: 0.00017635460244491696\n","Epoch [930/1000], Training Loss: 0.00017608318012207747\n","Epoch [940/1000], Training Loss: 0.0001738911960273981\n","Epoch [950/1000], Training Loss: 0.00017188070341944695\n","Epoch [960/1000], Training Loss: 0.00017097959062084556\n","Epoch [970/1000], Training Loss: 0.00017022078100126237\n","Epoch [980/1000], Training Loss: 0.00016964029055088758\n","Epoch [990/1000], Training Loss: 0.00016825972124934196\n","Epoch [1000/1000], Training Loss: 0.00016632303595542908\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAkIAAAGwCAYAAABFFQqPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA8NklEQVR4nO3daXRUZb7+/auqMgeSAIEMEAaRBkIgTAER0FZQIEArTn8VbVCPPiIotkOj0ojKQT1ttwOQxtajeGxRHI4gIo6gMoiAQpAQQFAmJSEiZIAQklTt5wWdOgSBVFV2zd/PWlmLVN2186vNUBf3aDEMwxAAAEAYsvq7AAAAAH8hCAEAgLBFEAIAAGGLIAQAAMIWQQgAAIQtghAAAAhbBCEAABC2IvxdQKBzOBzav3+/mjZtKovF4u9yAACACwzDUEVFhdLT02W1nrnfhyDUgP379ysjI8PfZQAAAA/s27dPbdq0OePzBKEGNG3aVNKJG5mQkODnagAAgCvKy8uVkZHh/Bw/E4JQA+qGwxISEghCAAAEmYamtTBZGgAAhC2CEAAACFsEIQAAELaYIwQACEh2u101NTX+LgMBKjIyUjabrdHXIQgBAAKKYRgqLi5WaWmpv0tBgEtKSlJqamqj9vkjCAEAAkpdCGrVqpXi4uLYzBa/YRiGKisrVVJSIklKS0vz+FoEIQBAwLDb7c4Q1KJFC3+XgwAWGxsrSSopKVGrVq08HiZjsjQAIGDUzQmKi4vzcyUIBnV/Thozl4wgdAZ5eXnKzMxUTk6Ov0sBgLDDcBhcYcafE4LQGUycOFGFhYVav3696de2Owyt+eFXvZf/s9b88KvsDsP0nwEAABrGHCEf+6igSI++X6iisirnY2mJMZo+OlPDszyf7AUAANxHj5APfVRQpAmvbagXgiSpuKxKE17boI8KivxUGQCEllDoeW/fvr2effZZl9t/8cUXslgsbDvgJnqEfMTuMPTo+4U63V9FQ5JF0qPvF+qSzFTZrIyNA4CnfN3z3tA8lenTp+uRRx5x+7rr169XfHy8y+3PP/98FRUVKTEx0e2f5Y4vvvhCF110kQ4fPqykpCSv/ixfIAj5yLpdh37TE3QyQ1JRWZXW7TqkAR1ZMgoAnqjreT/1P511Pe9zb+htehgqKvq/3vw333xTDz/8sLZv3+58rEmTJs5fG4Yhu92uiIiGP35btmzpVh1RUVFKTU116zVgaMxnSirOHII8aQcA4cIwDFVW1zb4VVFVo+mLt5yx512SHllcqIqqGpeuZxiuDaelpqY6vxITE2WxWJzfb9u2TU2bNtWHH36oPn36KDo6WqtWrdIPP/ygyy67TCkpKWrSpIlycnL02Wef1bvuqUNjFotF//3f/60xY8YoLi5OnTp10uLFi53Pnzo09sorrygpKUkff/yxunbtqiZNmmj48OH1glttba3uuusuJSUlqUWLFpoyZYrGjRunyy+/3KX3fjqHDx/WH//4RzVr1kxxcXEaMWKEduzY4Xx+z549Gj16tJo1a6b4+Hh169ZNS5cudb527NixatmypWJjY9WpUyfNmzfP41pcQY+Qj7RqGmNqOwAIF8dq7Mp8+ONGX8eQVFxepe6PfOJS+8LHhikuypyPyQceeEB/+9vfdM4556hZs2bat2+fcnNzNXPmTEVHR+vVV1/V6NGjtX37drVt2/aM13n00Uf117/+VU899ZRmz56tsWPHas+ePWrevPlp21dWVupvf/ub/vWvf8lqteqGG27Qfffdp/nz50uS/uu//kvz58/XvHnz1LVrVz333HNatGiRLrroIo/f6/jx47Vjxw4tXrxYCQkJmjJlinJzc1VYWKjIyEhNnDhR1dXVWrFiheLj41VYWOjsNZs2bZoKCwv14YcfKjk5WTt37tSxY8c8rsUVBCEf6dehudISY1RcVnXa/61YJKUmxqhfh9P/YQYABK/HHntMl1xyifP75s2bKzs72/n9jBkztHDhQi1evFiTJk0643XGjx+v6667TpL0+OOPa9asWVq3bp2GDx9+2vY1NTV6/vnn1bFjR0nSpEmT9Nhjjzmfnz17th588EGNGTNGkjRnzhxn74wn6gLQ6tWrdf7550uS5s+fr4yMDC1atEhXX3219u7dqyuvvFLdu3eXJJ1zzjnO1+/du1e9evVS3759JZ3oFfM2gpCP2KwWTR+dqQmvbZBFqheG6qbZTR+dyURpADhFbKRNhY8Na7Ddul2HNH5ew3u/vXJTjkv/6YyNbPzJ5nXqPtjrHDlyRI888og++OADFRUVqba2VseOHdPevXvPep0ePXo4fx0fH6+EhATneVunExcX5wxB0okzueral5WV6cCBA+rXr5/zeZvNpj59+sjhcLj1/ups3bpVERER6t+/v/OxFi1aqHPnztq6dask6a677tKECRP0ySefaOjQobryyiud72vChAm68sortWHDBl166aW6/PLLnYHKW5gj5EPDs9I094beSk2sP/yVmhjjlQl8ABAKLBaL4qIiGvwa3Kml0hJjdKb/Tlp0YvXY4E4tXbqembtbn7r667777tPChQv1+OOPa+XKlcrPz1f37t1VXV191utERkbWf08Wy1lDy+nauzr3yVv+4z/+Qz/++KNuvPFGbd68WX379tXs2bMlSSNGjNCePXv0pz/9Sfv379eQIUN03333ebUegpCPDc9K06opF6tHmxPLG2+/sKNWTbmYEAQAjVTX8y7pN2Eo0HreV69erfHjx2vMmDHq3r27UlNTtXv3bp/WkJiYqJSUlHonKNjtdm3YsMHja3bt2lW1tbVau3at87Fff/1V27dvV2ZmpvOxjIwM3X777Xr33Xd177336sUXX3Q+17JlS40bN06vvfaann32Wb3wwgse1+MKhsb8wGa1KDUhRt+pTG2axQbEX0oACAV1Pe+n7iOUGmA7+Hfq1EnvvvuuRo8eLYvFomnTpnk8HNUYd955p5544gmde+656tKli2bPnq3Dhw+71Bu2efNmNW3a1Pm9xWJRdna2LrvsMt1666365z//qaZNm+qBBx5Q69atddlll0mS7r77bo0YMUK/+93vdPjwYX3++efq2rWrJOnhhx9Wnz591K1bNx0/flxLlixxPuctBCE/ifn32HNVjd3PlQBAaBmelaZLMlO1btchlVRUqVXTEwtRAuk/nU8//bRuvvlmnX/++UpOTtaUKVNUXl7u8zqmTJmi4uJi/fGPf5TNZtNtt92mYcOGyWZreH7UBRdcUO97m82m2tpazZs3T5MnT9aoUaNUXV2tCy64QEuXLnUO09ntdk2cOFE//fSTEhISNHz4cD3zzDOSTuyF9OCDD2r37t2KjY3V4MGDtWDBAvPf+Ekshr8HCwNceXm5EhMTVVZWpoSEBNOue9/b+Xrn2581qkeaxvZvF3B/SQHAH6qqqrRr1y516NBBMTFsJ+JrDodDXbt21TXXXKMZM2b4u5wGne3Pi6uf3/QI+cFHBUVaurlYkrTkuyIt+a6Ig1cBAD63Z88effLJJ7rwwgt1/PhxzZkzR7t27dL111/v79J8hsnSPla3/Xtldf0hMQ5eBQD4mtVq1SuvvKKcnBwNHDhQmzdv1meffeb1eTmBhB4hH+LgVQBAIMnIyNDq1av9XYZf0SPkQ+4cvAoA4Yzpq3CFGX9OCEI+xMGrAHB2dSuLKisr/VwJgkHdn5NTN450B0NjPsTBqwBwdjabTUlJSc5jIOLi4kzd4RmhwTAMVVZWqqSkRElJSS4t9z8TgpAP1R28erbhsTQOXgUQ5lJTUyXprGdoAZKUlJTk/PPiKYLQGeTl5SkvL092u3kbHtqsFv0hO03/XLHrjG3+kJ3GRGkAYc1isSgtLU2tWrVSTU2Nv8tBgIqMjGxUT1AdNlRsgJkbKtodhgb91/IGe4RWTbmYMAQAQCO4+vnNZGkfamjVmMSqMQAAfIkg5EOsGgMAILAQhHyIVWMAAAQWgpAP1a0aO9PsH4tYNQYAgC8RhHzIZrVo+ujM0x6xIZ3YWXr66EwmSgMA4CMEIQAAELYIQj5Ud+jqmdQdump3sKMBAAC+QBDyIQ5dBQAgsBCEfIjl8wAABBaCkA+xfB4AgMBCEPKhuuXzDTl8tNoH1QAAAIKQD9msFk0b2bXBdjM+YMI0AAC+QBDysWbx0Q22YcI0AAC+QRDyMSZMAwAQOAhCPpbsQo+QO+0AAIDnCEK+5urpGZyyAQCA1xGEfOzgkeMutVu29YCXKwEAAAQhH3N1j6D38vezcgwAAC8jCPlYvw7N1Tw+ssF2vx6tZuUYAABeRhDyMZvVojE9W7vUlpVjAAB4F0HID4ZmprrUjqM2AADwLoKQH/Rp10zWBlaFWS0n2gEAAO8hCPnBt3sOq6F50A7jRDsAAOA9BCE/cHXuz6eFxV6uBACA8EYQ8gOW0AMAEBgIQn7AEnoAAAIDQcgPWEIPAEBgIAidQV5enjIzM5WTk+OV61/cJcWldhy+CgCA9xCEzmDixIkqLCzU+vXrvfMDXDxUdf1uhsYAAPAWgpCfuHr46itrdjNhGgAALyEI+YmrK8dKK2uYMA0AgJcQhPykX4fmSoyJcKltcdkxL1cDAEB4Igj5ic1q0SWZrk2YPnS02svVAAAQnghCfjSwU0uX2v1USo8QAADeQBDyo9QE1+YJLWaHaQAAvIIg5EfsMA0AgH8RhPzIZrXosux0l9oyYRoAAPMRhPysTbM4l9oxYRoAAPMRhPwsKS7K1HYAAMB1BCE/K610radnzQ8HvVwJAADhhyDkZ82buHao6mdbS1g5BgCAyQhCfubqEvrSYxy1AQCA2QhCfsZRGwAA+A9ByM/cOWpj9U7mCQEAYCaCUABw9agN5gkBAGAuglAAYJ4QAAD+QRAKAMwTAgDAPwhCAYB5QgAA+AdBKEAwTwgAAN8jCAUI5gkBAOB7BKEA4c48oU+2FHm5GgAAwgNBKEC4M0/ofzf8zPAYAAAmIAgFEFfnCZVX1TI8BgCACQhCAcTVeUISw2MAAJiBIBRA+nVorqYxNpfaMjwGAEDjEYQCiM1q0VW927jUluExAAAajyAUYC7tluZyW3aZBgCgcQhCAcad4bFDR6u9XA0AAKGNIBRgbFaLrujV2qW2ew9VerkaAABCG0EoALVtHu9Su4UbmTANAEBjEIQCUPMm0S61Y8I0AACNQxAKQOwnBACAbxCEApA7E6YXrN/H8BgAAB4iCAUgd/YTOlbj0Nc//OrligAACE0EoQDlzn5Cr63d7b1CAAAIYQShANWvQ3PFR7s2PPZZYQnDYwAAeIAgFKBsVotuHdTBpbY1DkOzl+3wckUAAIQeglAAu3PI7xTp4u/Q81/+QK8QAABuIgidQV5enjIzM5WTk+O3GmxWi4ZmprrUtqqWSdMAALiLIHQGEydOVGFhodavX+/XOm44r53Lbdf8eNCLlQAAEHoIQgHuvHNaKMq1OdPaUXLEu8UAABBiCEIBzma1aHR2ukttP9/G6jEAANxBEAoCgzq1cqldtZ3VYwAAuIMgFATcOXss7/Od9AoBAOAiglAQcGdzRfYUAgDAdQShIODO5ooSvUIAALiKIBQkTmyuaHGpLb1CAAC4hiAUJGxWiyZe1NHl9vQKAQDQMIJQEKFXCAAAcxGEgoi7vUKcPwYAwNkRhIKMO71CnD8GAMDZEYSCjLu9Qq9+vdt7xQAAEOQIQkHoziG/k821TiEt23qA4TEAAM6AIBSEbFaLLslMcaltrUNMmgYA4AwIQkHqxgHtXW7LUnoAAE6PIBSkzjunhaIjWEoPAEBjEISClM1q0YQLXZ80PWvZDnqFAAA4BUEoiLmzlN4h6Zrnv/JuQQAABBmCUBBzdyn9t3tL9f6m/V6sCACA4EIQCnLu9ApJ0p/f2cQQGQAA/0YQCnLu9godq2G3aQAA6hCEQoC7vUJTF232YjUAAAQPglAIsFkteuaabJfb7/61krlCAACIIBQyRvVsrfYtYl1uf/eCjcwVAgCEPYJQCJk5pofLbe0Gy+kBACAIhZDzzmmhmEjXf0tZTg8ACHcEoRBis1r0tytd7xWSpHvfymeIDAAQtghCIWZUz9bq3TbR5fbVds4hAwCEL4JQCHr79oGyub6aXnOWcw4ZACA8EYRCkM1q0XP/r6fL7WsNafIbG71XEAAAAYogFKLcXU6/ZHORln5X5MWKAAAIPAShEObOcnpJuuuNDQyRAQDCCkEohJ13TgvFR7n+W1zL3kIAgDBDEAphNqtFT13l+tEbEnsLAQDCC0EoxOX2SNfI7iluvYbjNwAA4YIgFAZmXddH0W6sp7cb0qT533qxIgAAAgNBKAzYrBY948Zyekn6cMsBzfyg0DsFAQAQIAhCYSK3R7puGdTOrde8uHIXS+oBACGNIBRGpo3KUqeW8W69ZjLzhQAAIYwgFGY+mHyBW+1rHAa7TgMAQhZBKMxERVjdXkW2ZHORqmsdXqoIAAD/IQiFoVnX9VGEm7/zg59c5p1iAADwI4JQGLJZLZp1bS+3XnPgSLVGzVrhpYoAAPAPglCYyu2RrlsHt3frNQX7K3TzvHXeKQgAAD8gCIWxqSO7aXiWe/OFlm//RTOWsL8QACA0EITCXN71feTGptOSpJdWsb8QACA0EITCnM1q0XNu7jotSZNe38D+QgCAoEcQgkb1bK0hXZLdeo1D0lX/WO2dggAA8BGCECRJL43vr6y0Jm69ZuNPZXr0/S1eqggAAO8jCMFpyeQL1b5FrFuvmbd6t2YsIQwBAIITQQj1LLv3Ilndnjy9m5PqAQBBiSCEemxWi2Z5MHmak+oBAMGIIITf8GTytCRNZCUZACDIEIRwWi+N768Obs4XMiRd/NRy7xQEAIAXEIRwRp/de5Hbh7PuOVylkc996Z2CAAAwGUEIZ+TJ4ayStKXoCAe0AgCCAkEIZ+XJ4awSB7QCAIIDQQgNmjqym24a2M7t1y3f/gsbLgIAAhpBCC6ZPjpLF3d2fyUZGy4CAAIZQQgue/km94/hkE5suEgYAgAEIoIQ3LJk8oXq5mEYYvdpAECgIQjBbR9MvlDtm8e4/boXV+7Skvz9XqgIAADPhHwQKi0tVd++fdWzZ09lZWXpxRdf9HdJIWHZfRd79Idn0oKNhCEAQMCwGIYR0mci2O12HT9+XHFxcTp69KiysrL0zTffqEWLFi69vry8XImJiSorK1NCQoKXqw0uS7/brzte3+jRa28d3F5TR3YzuSIAAE5w9fM75HuEbDab4uLiJEnHjx+XYRgK8eznM57uMSRJL65kAjUAwP/8HoRWrFih0aNHKz09XRaLRYsWLfpNm7y8PLVv314xMTHq37+/1q1zb6O+0tJSZWdnq02bNrr//vuVnOz+MnCc3tSR3XTLoPYevZbVZAAAf/N7EDp69Kiys7OVl5d32ufffPNN3XPPPZo+fbo2bNig7OxsDRs2TCUlJc42dfN/Tv3av//EXJSkpCRt2rRJu3bt0uuvv64DBw745L2Fi2mjCEMAgOAUUHOELBaLFi5cqMsvv9z5WP/+/ZWTk6M5c+ZIkhwOhzIyMnTnnXfqgQcecPtn3HHHHbr44ot11VVXnfb548eP6/jx487vy8vLlZGRwRwhFzz6foHmrd7j0WtvGdRe00YxZwgAYI6QmCNUXV2tb7/9VkOHDnU+ZrVaNXToUK1Zs8alaxw4cEAVFRWSpLKyMq1YsUKdO3c+Y/snnnhCiYmJzq+MjIzGvYkw4unu0xI9QwAA//AoCO3bt08//fST8/t169bp7rvv1gsvvGBaYZJ08OBB2e12paSk1Hs8JSVFxcXFLl1jz549Gjx4sLKzszV48GDdeeed6t69+xnbP/jggyorK3N+7du3r1HvIdy8fFN/dU9v6tFrCUMAAF+L8ORF119/vW677TbdeOONKi4u1iWXXKJu3bpp/vz5Ki4u1sMPP2x2nR7r16+f8vPzXW4fHR2t6Oho7xUUBt6/6wLdPG+dlm//xe3XvrRqtyQxTAYA8AmPeoQKCgrUr18/SdJbb72lrKwsffXVV5o/f75eeeUV04pLTk6WzWb7zeTmAwcOKDU11bSfA/O9fFM/3TSwvUevfWnVbj36foG5BQEAcBoeBaGamhpnr8lnn32mP/zhD5KkLl26qKioyLTioqKi1KdPHy1btsz5mMPh0LJlyzRgwADTfg68Y/robrppYDuPXjtv9R7dPG+tyRUBAFCfR0GoW7duev7557Vy5Up9+umnGj58uCRp//79Lu/YXOfIkSPKz893Dl/t2rVL+fn52rt3ryTpnnvu0Ysvvqj/+Z//0datWzVhwgQdPXpUN910kyelw8emj87SkC4tPXrt8u0HNeq5L02uCACA/+PR8vkvvvhCY8aMUXl5ucaNG6eXX35ZkvTQQw9p27Ztevfdd9261kUXXfSbx8eNG+ccZpszZ46eeuopFRcXq2fPnpo1a5b69+/vbtke4YgNc9zyyjot2+b+nCFJ6pbWRB9MvtDkigAAoczVz2+P9xGy2+0qLy9Xs2bNnI/t3r1bcXFxatWqlSeXDEgEIfM8+v4WzVu926PXEoYAAO7w6j5Cx44d0/Hjx50haM+ePXr22We1ffv2kApBMFdj5gxtKTqi3/91meyOgNn/EwAQAjwKQpdddpleffVVSSfO8erfv7/+/ve/6/LLL9fcuXNNLRChpTFzhnYfqlKnh5Zq6Xf7Ta4KABCuPApCGzZs0ODBgyVJ77zzjlJSUrRnzx69+uqrmjVrlqkF+kteXp4yMzOVk5Pj71JCzkvj+3kchhyS7nh9o2Z+wMaLAIDG8ygIVVZWqmnTE7sHf/LJJ7riiitktVp13nnnac8ez86aCjQTJ05UYWGh1q9f7+9SQtJL4/vplkEdPH79iyvZhRoA0HgeBaFzzz1XixYt0r59+/Txxx/r0ksvlSSVlJQwoRgumzYqU/+4vrfHr2fjRQBAY3kUhB5++GHdd999at++vfr16+fc3PCTTz5Rr169TC0QoS23R5q+/88Rsnj4+nmr9+iml782tSYAQPjwePl8cXGxioqKlJ2dLav1RJ5at26dEhIS1KVLF1OL9CeWz/vGRwVFuv21DR6/PiMpWisfGGpiRQCAYOb1fYTq1J1C36ZNm8ZcJmARhHzno4Ii3fHaBjk8fH1yfKTWTr1ENqun/UsAgFDh1X2EHA6HHnvsMSUmJqpdu3Zq166dkpKSNGPGDDkcnn6MIdwNz0rTjsdz1b55rEevP3i0huX1AAC3eBSEpk6dqjlz5ujJJ5/Uxo0btXHjRj3++OOaPXu2pk2bZnaNCCM2q0Vf/PliXfS7ZI9eX7e8fsYSJlEDABrm0dBYenq6nn/+eeep83Xee+893XHHHfr5559NK9DfGBrzn5vnrdPy7Z6dTyZJF3dO1ss3+eZMOgBAYPHq0NihQ4dOOyG6S5cuOnTokCeXBH7j5Zs833hR4vR6AEDDPApC2dnZmjNnzm8enzNnjnr06NHoooA6jd14sYAzygAAZ+HR0NiXX36pkSNHqm3bts49hNasWaN9+/Zp6dKlzuM3QgFDY4Fh6XdFuuN1z5fXWyTNvranRvVsbV5RAICA5dWhsQsvvFDff/+9xowZo9LSUpWWluqKK67Qli1b9K9//cvjogMJZ40Fltweafrh8Vwlx0V49HpD0qQF+brllbXmFgYACGqN3kfoZJs2bVLv3r1lt9vNuqTf0SMUeEbOWqEt+ys8fn1WWhMtmXyhiRUBAAKNV3uEAH/64K4LdHFnzydRM28IAFCHIISg9PJN/XTTwPYev373oSo2XwQAEIQQvKaP7qZbB3u+oqxu88WZH2wxrygAQFBxa+bpFVdccdbnS0tLG1ML4LapIzPVK6OZJr6+QZ4OdL24crdqHYamj84ytTYAQOBzKwglJiY2+Pwf//jHRhUEuCu3R5p2ZuVqyN8+1+5Dxzy6xrzVe5S/97DemTCIQ1sBIIyYumosFLFqLLg09lgOq6Q51/dSbo9084oCAPgcq8YQll6+qXE7UXNoKwCEF4IQQs60UZn6x/W91ZgBrpdW7dHN89h8EQBCHUEIISm3R5p2Pp6rds1iPL7G8u0HNfLZL8wrCgAQcAhCCFk2q0VfThmirPSmHl9jS/FR9Z3xCZsvAkCIIggh5C1p5E7UB4/WqONDS7Uk/2cTqwIABAKCEMJCYydRSycObb0ibyW9QwAQQghCZ8Dp86HHjEnUG/aVczQHAIQQ9hFqAPsIhR67w2jU5ot1bh3cXlNHdjOpKgCAmdhHCDgDm9WiL/58sYZ0adWo67y4crcefZ/9hgAgmBGEELZeGp+j2df1atQ15q3eozHMGwKAoEUQQlgbnZ2uHx7PVXKcW8fu1bOReUMAELQIQgh7NqtF3zw8TBmN2HyRozkAIDgRhIB/WzlliC7u4vl+Q9KJozkYKgOA4EEQAk7y8vh+jZ43xFAZAAQPghBwirp5Q+2bx3p8DYbKACA4EISA06hbYt+YozkkhsoAINARhICzMONojo37ynUuZ5UBQEAiCAENMONoDkMnziq75ZW1ZpUFADABQQhwQW6PNO1s5LwhSVq27aB+/9dlDJUBQIAgCAEuMutojt2HqhgqA4AAQRAC3GTG0Rx1Q2U3z/vanKIAAB4hCJ1BXl6eMjMzlZOT4+9SEIDMWGIvScu3/6qcGZ8wVAYAfmIxDIN/gc+ivLxciYmJKisrU0JCgr/LQQC65ZX1WratpNHXmXNtT43q2dqEigAArn5+0yMENFLdUFljVpVJDJUBgD8QhAATjM5O187Hc9WrTWKjrsNQGQD4FkEIMInNatHCSYMavQHjL0dr1JFVZQDgEwQhwGR1GzA29i/XpAX5uoLjOQDAqwhCgBfk9kjTjsdz1TsjqVHX2cBJ9gDgVQQhwEtsVovenTiw0XsOcZI9AHgPQQjwsro9h1rGRzbqOpxkDwDmIwgBPmCzWrR+2qW6uEvLRl1n475ydXxoqRZv+MmkygAgvBGEAB96eXy/Rg+VSdJdb23S75/i8FYAaCyCEOBjZg2V7f61imX2ANBIBCHAD8waKpPYkRoAGoMgBPiRWUNl7EgNAJ4hCAF+ZtZJ9nU7Uj/98TYCEQC4iCAEBACb1aIv/nyxhnRp1ehrzfr8B3WaytwhAHAFQQgIIGadZO8wTswduuWVtabUBQChiiAEBJi6k+wbezyHJC3bdlD9Z36i6lpH4wsDgBBEEDqDvLw8ZWZmKicnx9+lIAyZdTyHJB2oqNHv/vKhHn1/swmVAUBosRiGwazKsygvL1diYqLKysqUkJDg73IQhuwOQ1fNXa2N+8oafa2WTSL19UOXyGZt7OAbAAQ2Vz+/6RECApzNatHCiYNM6R365QgrywDgZAQhIEiYtSO1xMoyAKhDEAKCiJk7UrOyDAAIQkBQqtuR2oypPqwsAxDOCEJAkBqdna4dM3OVm5Xa6GvVrSy747VvmDsEIKwQhIAgZrNa9I8b+ugf1/eWzYTeoaUFB3QuJ9oDCCMEISAE5PZI0/cm9Q4ZOjF36Iq8lfQOAQh5BCEgRNT1Dn3/nyOUGGNr9PU27CtXx4eWavGGn0yoDgACE0EICDFREVZtemS4KSvLJOmutzbp908to3cIQEgiCAEhysyVZbt/rWIjRgAhiSAEhDAzV5ZJbMQIIPQQhIAQZ/bKMjZiBBBKCEJAmDBzZZnERowAQgOnzzeA0+cRiqprHbrwr8tVVH7clOvlZqVo9vV9ONUeQMDg9HkAZxQVYdWah4bqlkEdTLkeGzECCFb0CDWAHiGEuupah0bOWqEdJUdNuV6nlnH6YPKFiorg/1kA/IceIQAuiYqw6tN7fq/Z1/Uy5Xo7fqnU7/7yoW5/bT1L7QEEPIIQAEknltr/8HiuemUkmnK9jwpK1JHhMgABjiAEwMlmtWjhxEGmbcQonVhqf8nfP2d1GYCARBAC8Btmb8TIcBmAQEUQAnBaZm/EKDFcBiDwEITOIC8vT5mZmcrJyfF3KYBfmb0Ro8RwGYDAwfL5BrB8Hvg/Zm/EKEnDs1op7/q+bMYIwFQsnwdgOrM3YpQYLgPgX/QINYAeIeD0qmsduvGlr7V212HTrtk6MVqf3XuRYqNspl0TQHhy9fObINQAghBwdt4YLuudkaC3JwxiuAyAxxgaA+ATdcNlz13bU2bFlg37yhkuA+ATBCEAprisZ2vtfNz81WUDn/hMx6rtpl0TAE7G0FgDGBoD3OeN4TIOcwXgDobGAPiNN4bL6nanvuO1b9idGoBpCEIAvMYbw2VLCw6o40NL9ac3NrIhI4BGY2isAQyNAebwxnCZJOVmpWj29X1YYQagHobGAAQUbwyXSSd6iM5lhRkADxGEAPiUN4bLDHF+GQDPMDTWAIbGAO+prnUo97kvtfOXSlOvy3AZAIbGAAS8qAirPrv3Is2+rpfMzCx1E6r//tE2VpgBOCt6hBpAjxDgG3aHoTtf36ClBcWmX/uKnul68qps9iACwghnjZmEIAT4VnWtQzf89xqt211q+rVvGdRO00ZlmX5dAIGHIGQSghDgH9W1Do2ctUI7So6aet2EWJvyruuj889NZg4REMIIQiYhCAH+9f6m/br7zY2ym7wYLNIqPXNNT43q2drcCwMICAQhkxCEAP+zOwyt2v6L7npzg8qqzD2AtVdGgt6ZMIjeISDEEIRMQhACAsuMJYV6adUu06+b0y5Jdw35HUNmQIggCJmEIAQEnqXfFemet/JV5YXNExkyA0IDQcgkBCEgMNkdhr7acVD3/W++DpRXm379Ti3j9MHkC1lyDwQpgpBJCEJA4Ht/035NXrBR3tg7sWtKE707cZBio2zmXxyA1xCETEIQAoKD3WHo2U+2a84XP8gb/6j1zkjQ20yqBoIGQcgkBCEguNgdhp779HvN+nynV65/TnKcrs1pq/EDOzBsBgQwgpBJCEJAcPqooEj3vLVJldXmLrc/GTtVA4GLIGQSghAQvOomVD+3/Ht9s6fUKz8jNtKiPw3tTA8REGAIQiYhCAGhwe4wNPTvX2jXr5Ve+xnDs1op7/q+zCMCAoCrn9/89+UM8vLylJmZqZycHH+XAsAENqtFn99/kZ67tqcivBRUPiooUceHlurpj7fJ7o0lbABMR49QA+gRAkJP3ZDZI0sK9MMv3ush6ts2SZOHsls14A8MjZmEIASENm/uUl2H3aoB3yMImYQgBIQ+X/UQxdgsurRbqq7um0EvEeBlBCGTEISA8FJd61Duc19qpxcDkUQvEeBtBCGTEISA8PT+pv2656181di9+08kvUSAdxCETEIQAsKXL/YhOhm9RIB5CEImIQgBkE6Eojtf36ClBcVe/1nRNouyWidqWLdUNmoEPEQQMglBCMDJqmsdmrf6Rz372Q4dq/HeSrOT5WalaPb1fRg2A9xAEDIJQQjAmbyX/7P+9Ga+fLV3Ige+Aq4jCJmEIATgbOpOu5/zxU6fBSKJ4zyAhhCETEIQAuAKu8PQqu2/aOaHhfq+5KjPfm5aQrT6dWihq/q0YdUZcBKCkEkIQgDc5cuJ1SeLsEjP/j9WnQESQcg0BCEAnqqudeilVT/of77areLyap/93PhIq4ZmptJLhLBGEDIJQQiAGfzVSyQxfIbwRBAyCUEIgJn81UtUh+EzhAuCkEkIQgC8xe4wdPXcr7RhX6nPf3akVWrTLE7nd2yhv4zqptgom89rALyJIGQSghAAbztWbddjSwr01c6D+ulwlbx8vNlp9c5I0NsTBjFshpBBEDIJQQiAr81YUqiXVu3yy89Oio1Qt/QE3XZBRw3q1JJghKBFEDIJQQiAP9Qd5fFxQbG++7lMtb45zaMeq0WaxXwiBCmCkEkIQgACwXv5P+vetzap1pfbV/9bhEXqkByvzPREVp4haBCETEIQAhAo7A5DX+04qLe/3asVOw6q9FitX+qItErPXENPEQIbQcgkBCEAgaq61qEbX/paa3cd9svPj7ZZlNU6UcO6pXIQLAIOQcgkBCEAga5uPtFLK3ep5Ijv9yaqE22T2jZnCA2BgSBkEoIQgGBy8iTr7QcqdLTaD7Os/40hNPgTQcgkBCEAwczfw2eSFGWRWiXGKCUhhmE0+AxByCQEIQCh4OSeooKiclXX+vef/rhIq9o0i1XXNIbR4B0EIZMQhACEovc37dc9b+Wrxh/bWJ9GlFV69tpeyu2R7u9SECIIQiYhCAEIVScvx1+765AOVPhvonWdKKvUKiFGvds209V9M+gpgscIQiYhCAEIF3aHoTtf36ClBcX+LqWe+CirWifF6orebXTzoHOYXwSXEIRMQhACEG6qax16adUP+t9vf9L+0ipV1vhv5dnp5GalaPb1fegpwlkRhExCEAIQ7uwOQ1fP/Uob9pX6u5R6kmIj1KppNBOucVoEIZMQhADghGPVdj22pEBf7TyoA+XHVeXnlWenQzhCHYKQSQhCAHB6Jw+h7T10TNUBsgLtZGzqGL4IQiYhCAGAa5Z+V6R73spXVW1gzSmSpAiLlNw0Wh1bxuu2CzpqUKeW9BSFOIKQSQhCAOC6k5fkFxaV69ej1TpcWevvsk6rSZRVTWIiCUchiiBkEoIQADTOqeFo3+FjOh6A84sirNIsNnUMGQQhkxCEAMB8gbaz9cnY1DE0EIRMQhACAO84uadoy/4yHSg/riPVgTe/SDoxjJaWGKvMdFajBQuCkEkIQgDgO6eGo72HjinA9nOUJFkk9c5IVEW1XQkxEbo0M1XjB3Zg1+sAQhBqpLy8POXl5clut+v7778nCAGAn7y/ab/ufnOj7AEYiE51y6B2mjYqy99lQAQh09AjBAD+Z3cYWrX9Fz2/Yqd++OWIKqvtATuMZpHUIj5STWMidX7HFvrLqG6KjbL5u6ywQxAyCUEIAALTqeGovKo2IHe7lqRISYmEI58iCJmEIAQAwSOQN3U8lU1S09gINYmOYIWaFxCETEIQAoDgcuq+RQePHFfpMbu/y3JZbIQUHx2pts3jNTyLSdieIgiZhCAEAMHv1HC0v6xKlQE6x+h0Ii1SQmyEmsdHs4TfRQQhkxCEACA0BdMw2pkkxtgUH2WT1WpVSkKMLslMUbf0RB2qrFarpjHq16F52IYlgpBJCEIAELqCaVNHT0RYpdHd03R5rzZav+eQJIsGdGyh885pEfIBiSBkEoIQAISXunD01jd79O3ewyqtrFVlIO7q2AgRFum2CzqoaWyUlm0tkWSE3KaQBCGTEIQAAHaHoavnfqUN+0r9XYrXNYm0KC4mUlE2a1CvZiMImYQgBACoc6zarv/8YIu++6lMibGROlJVq/yfyvxdlk+0ToxSbKRNVXZDKU1jNKxbYPcgEYRMQhACAJzNsWq7HltSoK92HtSRqhodqzFCbijtbGIjpBZNYpSSEFjhiCBkEoIQAMBd1bUOzVv9oz4uKFZx+bGQnGd0NjE2KT46QpERNnVsGa/bLuioQZ1a+nR4jSBkEoIQAMAMJ4ejorJKVVQF7nlp3hIfaVFkhM0nu2kThExCEAIAeMupy/cPV1bryHGHqu3h89FskTSmZ7qevCrb1CE1gpBJCEIAAF+r6z36aHOR9hw6qqowmXf0/13QQQ/mZppyLYKQSQhCAIBAYHcYWrX9Fz2/Yqd++OWIau0OOQyLSqtq/V2aqcwKQwQhkxCEAACB7OThta3FFaqoqtGB8moF64e71SJtmzGi0cNkrn5+RzTqpwAAAL+yWS0a3LmlBndu6Xzs1HBkGA5V1Rj6ubQq4AOSw5D+tWa3bhl8jk9+HkEIAIAQc7pwJP02IFksUudWTXWoslrrdh9WTYBM0t5zqNJnP4sgBABAmDhTQJJOhKR1uw6ppKJKyfHR+vrHg3p+xY9+CUftmsf57GcxR6gBzBECAIQru8PQ1z/8qjU/HlTdyfXZbZI0c+kWfbXzoH49Um36XkjMEQIAAAHBZrVoYKdkDeyUXO/xJ67Idv765OG2wqJyVVbXqvK4XaVVdo9+5q2DfXtEB0EIAAB4zJX5SIVF5Tp6vOasu2lbJN1m4j5CriIIAQAA07kSkLYdOKKEmAhdmum/w1oJQgAAwGfONmHbH3wfvQAAAAIEQQgAAIQtghAAAAhbBCEAABC2CEIAACBsEYQAAEDYIggBAICwRRACAABhiyAEAADCFjtLN8AwDEknTrEFAADBoe5zu+5z/EwIQg2oqKiQJGVkZPi5EgAA4K6KigolJiae8XmL0VBUCnMOh0P79+9X06ZNZbFYTLtueXm5MjIytG/fPiUkJJh2XdTHffYN7rNvcJ99h3vtG968z4ZhqKKiQunp6bJazzwTiB6hBlitVrVp08Zr109ISOAvmQ9wn32D++wb3Gff4V77hrfu89l6guowWRoAAIQtghAAAAhbBCE/iY6O1vTp0xUdHe3vUkIa99k3uM++wX32He61bwTCfWayNAAACFv0CAEAgLBFEAIAAGGLIAQAAMIWQQgAAIQtgpAf5OXlqX379oqJiVH//v21bt06f5cUVJ544gnl5OSoadOmatWqlS6//HJt3769XpuqqipNnDhRLVq0UJMmTXTllVfqwIED9drs3btXI0eOVFxcnFq1aqX7779ftbW1vnwrQeXJJ5+UxWLR3Xff7XyM+2yOn3/+WTfccINatGih2NhYde/eXd98843zecMw9PDDDystLU2xsbEaOnSoduzYUe8ahw4d0tixY5WQkKCkpCTdcsstOnLkiK/fSkCz2+2aNm2aOnTooNjYWHXs2FEzZsyodxYV99p9K1as0OjRo5Weni6LxaJFixbVe96se/rdd99p8ODBiomJUUZGhv7617+a8wYM+NSCBQuMqKgo4+WXXza2bNli3HrrrUZSUpJx4MABf5cWNIYNG2bMmzfPKCgoMPLz843c3Fyjbdu2xpEjR5xtbr/9diMjI8NYtmyZ8c033xjnnXeecf755zufr62tNbKysoyhQ4caGzduNJYuXWokJycbDz74oD/eUsBbt26d0b59e6NHjx7G5MmTnY9znxvv0KFDRrt27Yzx48cba9euNX788Ufj448/Nnbu3Ols8+STTxqJiYnGokWLjE2bNhl/+MMfjA4dOhjHjh1zthk+fLiRnZ1tfP3118bKlSuNc88917juuuv88ZYC1syZM40WLVoYS5YsMXbt2mW8/fbbRpMmTYznnnvO2YZ77b6lS5caU6dONd59911DkrFw4cJ6z5txT8vKyoyUlBRj7NixRkFBgfHGG28YsbGxxj//+c9G108Q8rF+/foZEydOdH5vt9uN9PR044knnvBjVcGtpKTEkGR8+eWXhmEYRmlpqREZGWm8/fbbzjZbt241JBlr1qwxDOPEX1yr1WoUFxc728ydO9dISEgwjh8/7ts3EOAqKiqMTp06GZ9++qlx4YUXOoMQ99kcU6ZMMQYNGnTG5x0Oh5Gammo89dRTzsdKS0uN6Oho44033jAMwzAKCwsNScb69eudbT788EPDYrEYP//8s/eKDzIjR440br755nqPXXHFFcbYsWMNw+Bem+HUIGTWPf3HP/5hNGvWrN6/G1OmTDE6d+7c6JoZGvOh6upqffvttxo6dKjzMavVqqFDh2rNmjV+rCy4lZWVSZKaN28uSfr2229VU1NT7z536dJFbdu2dd7nNWvWqHv37kpJSXG2GTZsmMrLy7VlyxYfVh/4Jk6cqJEjR9a7nxL32SyLFy9W3759dfXVV6tVq1bq1auXXnzxRefzu3btUnFxcb37nJiYqP79+9e7z0lJSerbt6+zzdChQ2W1WrV27VrfvZkAd/7552vZsmX6/vvvJUmbNm3SqlWrNGLECEnca28w656uWbNGF1xwgaKiopxthg0bpu3bt+vw4cONqpFDV33o4MGDstvt9T4UJCklJUXbtm3zU1XBzeFw6O6779bAgQOVlZUlSSouLlZUVJSSkpLqtU1JSVFxcbGzzel+H+qewwkLFizQhg0btH79+t88x302x48//qi5c+fqnnvu0UMPPaT169frrrvuUlRUlMaNG+e8T6e7jyff51atWtV7PiIiQs2bN+c+n+SBBx5QeXm5unTpIpvNJrvdrpkzZ2rs2LGSxL32ArPuaXFxsTp06PCba9Q916xZM49rJAghqE2cOFEFBQVatWqVv0sJOfv27dPkyZP16aefKiYmxt/lhCyHw6G+ffvq8ccflyT16tVLBQUFev755zVu3Dg/Vxda3nrrLc2fP1+vv/66unXrpvz8fN19991KT0/nXocxhsZ8KDk5WTab7Terag4cOKDU1FQ/VRW8Jk2apCVLlujzzz9XmzZtnI+npqaqurpapaWl9dqffJ9TU1NP+/tQ9xxODH2VlJSod+/eioiIUEREhL788kvNmjVLERERSklJ4T6bIC0tTZmZmfUe69q1q/bu3Svp/+7T2f7dSE1NVUlJSb3na2trdejQIe7zSe6//3498MADuvbaa9W9e3fdeOON+tOf/qQnnnhCEvfaG8y6p978t4Qg5ENRUVHq06ePli1b5nzM4XBo2bJlGjBggB8rCy6GYWjSpElauHChli9f/pvu0j59+igyMrLefd6+fbv27t3rvM8DBgzQ5s2b6/3l+/TTT5WQkPCbD6VwNWTIEG3evFn5+fnOr759+2rs2LHOX3OfG2/gwIG/2f7h+++/V7t27SRJHTp0UGpqar37XF5errVr19a7z6Wlpfr222+dbZYvXy6Hw6H+/fv74F0Eh8rKSlmt9T/2bDabHA6HJO61N5h1TwcMGKAVK1aopqbG2ebTTz9V586dGzUsJonl8762YMECIzo62njllVeMwsJC47bbbjOSkpLqrarB2U2YMMFITEw0vvjiC6OoqMj5VVlZ6Wxz++23G23btjWWL19ufPPNN8aAAQOMAQMGOJ+vW9Z96aWXGvn5+cZHH31ktGzZkmXdDTh51ZhhcJ/NsG7dOiMiIsKYOXOmsWPHDmP+/PlGXFyc8dprrznbPPnkk0ZSUpLx3nvvGd99951x2WWXnXb5ca9evYy1a9caq1atMjp16hTWS7pPZ9y4cUbr1q2dy+ffffddIzk52fjzn//sbMO9dl9FRYWxceNGY+PGjYYk4+mnnzY2btxo7NmzxzAMc+5paWmpkZKSYtx4441GQUGBsWDBAiMuLo7l88Fq9uzZRtu2bY2oqCijX79+xtdff+3vkoKKpNN+zZs3z9nm2LFjxh133GE0a9bMiIuLM8aMGWMUFRXVu87u3buNESNGGLGxsUZycrJx7733GjU1NT5+N8Hl1CDEfTbH+++/b2RlZRnR0dFGly5djBdeeKHe8w6Hw5g2bZqRkpJiREdHG0OGDDG2b99er82vv/5qXHfddUaTJk2MhIQE46abbjIqKip8+TYCXnl5uTF58mSjbdu2RkxMjHHOOecYU6dOrbckm3vtvs8///y0/yaPGzfOMAzz7ummTZuMQYMGGdHR0Ubr1q2NJ5980pT6LYZx0paaAAAAYYQ5QgAAIGwRhAAAQNgiCAEAgLBFEAIAAGGLIAQAAMIWQQgAAIQtghAAAAhbBCEAABC2CEIA4CaLxaJFixb5uwwAJiAIAQgq48ePl8Vi+c3X8OHD/V0agCAU4e8CAMBdw4cP17x58+o9Fh0d7adqAAQzeoQABJ3o6GilpqbW+2rWrJmkE8NWc+fO1YgRIxQbG6tzzjlH77zzTr3Xb968WRdffLFiY2PVokUL3XbbbTpy5Ei9Ni+//LK6deum6OhopaWladKkSfWeP3jwoMaMGaO4uDh16tRJixcv9u6bBuAVBCEAIWfatGm68sortWnTJo0dO1bXXnuttm7dKkk6evSohg0bpmbNmmn9+vV6++239dlnn9ULOnPnztXEiRN12223afPmzVq8eLHOPffcej/j0Ucf1TXXXKPvvvtOubm5Gjt2rA4dOuTT9wnABKacYQ8APjJu3DjDZrMZ8fHx9b5mzpxpGIZhSDJuv/32eq/p37+/MWHCBMMwDOOFF14wmjVrZhw5csT5/AcffGBYrVajuLjYMAzDSE9PN6ZOnXrGGiQZf/nLX5zfHzlyxJBkfPjhh6a9TwC+wRwhAEHnoosu0ty5c+s91rx5c+evBwwYUO+5AQMGKD8/X5K0detWZWdnKz4+3vn8wIED5XA4tH37dlksFu3fv19Dhgw5aw09evRw/jo+Pl4JCQkqKSnx9C0B8BOCEICgEx8f/5uhKrPExsa61C4yMrLe9xaLRQ6HwxslAfAi5ggBCDlff/31b77v2rWrJKlr167atGmTjh496nx+9erVslqt6ty5s5o2bar27dtr2bJlPq0ZgH/QIwQg6Bw/flzFxcX1HouIiFBycrIk6e2331bfvn01aNAgzZ8/X+vWrdNLL70kSRo7dqymT5+ucePG6ZFHHtEvv/yiO++8UzfeeKNSUlIkSY888ohuv/12tWrVSiNGjFBFRYVWr16tO++807dvFIDXEYQABJ2PPvpIaWlp9R7r3Lmztm3bJunEiq4FCxbojjvuUFpamt544w1lZmZKkuLi4vTxxx9r8uTJysnJUVxcnK688ko9/fTTzmuNGzdOVVVVeuaZZ3TfffcpOTlZV111le/eIACfsRiGYfi7CAAwi8Vi0cKFC3X55Zf7uxQAQYA5QgAAIGwRhAAAQNhijhCAkMJoPwB30CMEAADCFkEIAACELYIQAAAIWwQhAAAQtghCAAAgbBGEAABA2CIIAQCAsEUQAgAAYev/B5vu2W7FZg0oAAAAAElFTkSuQmCC\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training complete! Total training time: 1566.76 seconds\n"]}],"source":["# Train the GNN model using the provided source and target graph embeddings, edges, and training data\n","trained_model = train_model_gnn(\n","    model=GIT_model,                # The GNN model to be trained (initialized earlier)\n","    x_src=x_src,                    # Source node embeddings (tensor for source graph)\n","    edge_src=edge_src,              # Source graph edges (undirected edge index for source graph)\n","    x_tgt=x_tgt,                    # Target node embeddings (tensor for target graph)\n","    edge_tgt=edge_tgt,              # Target graph edges (undirected edge index for target graph)\n","    tensor_term1=tensor_term1_o,    # Indices of source entities for training\n","    tensor_term2=tensor_term2_o,    # Indices of target entities for training\n","    tensor_score=tensor_score_o,    # Scores (labels) indicating if pairs match (1) or not (0)\n","    learning_rate=0.0001,            # Learning rate for the Adam optimizer\n","    weight_decay_value=1e-4,        # Weight decay for L2 regularization to prevent overfitting\n","    num_epochs=1000,                # Number of training epochs\n","    print_interval=10               # Interval at which to print training progress (every 10 epochs)\n",")"]},{"cell_type":"markdown","metadata":{"id":"MYyhvjcTUaae"},"source":["# GIT Application"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BZ_VqP6tq6iD"},"outputs":[],"source":["# Determine if a GPU is available and move the computations to it; otherwise, use the CPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Assuming the model has been trained and hyperparameters (x_src, edge_src, x_tgt, edge_tgt) are set\n","\n","# Move the trained GIT_model to the device (GPU or CPU)\n","GIT_model.to(device)\n","\n","# Move the data tensors to the same device (GPU or CPU)\n","x_tgt = x_tgt.to(device)         # Target node embeddings\n","edge_tgt = edge_tgt.to(device)   # Target graph edges\n","x_src = x_src.to(device)         # Source node embeddings\n","edge_src = edge_src.to(device)   # Source graph edges\n","\n","# Set the model to evaluation mode; this disables dropout and batch normalization\n","GIT_model.eval()\n","\n","# Pass the source and target embeddings through the trained GNN model to update the embeddings\n","with torch.no_grad():  # Disable gradient computation (inference mode)\n","    embeddings_tgt = GIT_model(x_tgt, edge_tgt)  # Get updated embeddings for the target graph\n","    embeddings_src = GIT_model(x_src, edge_src)  # Get updated embeddings for the source graph\n","\n","# Detach the embeddings from the computation graph and move them back to the CPU\n","# This step is useful if you need to use the embeddings for tasks outside PyTorch (e.g., saving to disk)\n","embeddings_tgt = embeddings_tgt.detach().cpu()  # Target graph embeddings\n","embeddings_src = embeddings_src.detach().cpu()  # Source graph embeddings\n","\n","# At this point, embeddings_tgt and embeddings_src contain the updated embeddings, ready for downstream tasks"]},{"cell_type":"markdown","metadata":{"id":"Og5fdoGJrTCG"},"source":["# Selecting embedding pairs to train the Gated Network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J0nTwc-dnjLn"},"outputs":[],"source":["# Read the training pairs from a CSV file into a pandas DataFrame\n","df_embeddings = pd.read_csv(train_file, index_col=0)\n","\n","# Extract columns and convert to NumPy arrays\n","tensor_term1 = df_embeddings['SrcEntity'].values.astype(int)  # Source entity indices\n","tensor_term2 = df_embeddings['TgtEntity'].values.astype(int)  # Target entity indices\n","tensor_score = df_embeddings['Score'].values.astype(float)  # Matching scores\n","\n","# Split data into training and validation sets\n","tensor_term1_train, tensor_term1_val, tensor_term2_train, tensor_term2_val, tensor_score_train, tensor_score_val = train_test_split(\n","    tensor_term1, tensor_term2, tensor_score, test_size=0.3, random_state=42\n",")\n","\n","# Convert split data to PyTorch tensors\n","tensor_term1_train = torch.from_numpy(tensor_term1_train).type(torch.LongTensor)\n","tensor_term2_train = torch.from_numpy(tensor_term2_train).type(torch.LongTensor)\n","tensor_score_train = torch.from_numpy(tensor_score_train).type(torch.FloatTensor)\n","\n","tensor_term1_val = torch.from_numpy(tensor_term1_val).type(torch.LongTensor)\n","tensor_term2_val = torch.from_numpy(tensor_term2_val).type(torch.LongTensor)\n","tensor_score_val = torch.from_numpy(tensor_score_val).type(torch.FloatTensor)\n","\n","# Move the embeddings back to the CPU if not already there\n","x_tgt = x_tgt.cpu()  # Target node embeddings\n","x_src = x_src.cpu()  # Source node embeddings\n","\n","# Select embeddings for the training set\n","X1_train = select_rows_by_index(embeddings_src, tensor_term1_train)\n","X2_train = select_rows_by_index(x_src, tensor_term1_train)\n","X3_train = select_rows_by_index(embeddings_tgt, tensor_term2_train)\n","X4_train = select_rows_by_index(x_tgt, tensor_term2_train)\n","\n","# Select embeddings for the validation set\n","X1_val = select_rows_by_index(embeddings_src, tensor_term1_val)\n","X2_val = select_rows_by_index(x_src, tensor_term1_val)\n","X3_val = select_rows_by_index(embeddings_tgt, tensor_term2_val)\n","X4_val = select_rows_by_index(x_tgt, tensor_term2_val)\n","\n","# Now you have:\n","# - Training tensors: X1_train, X2_train, X3_train, X4_train, tensor_score_train\n","# - Validation tensors: X1_val, X2_val, X3_val, X4_val, tensor_score_val"]},{"cell_type":"code","source":["positive_weight = len(tensor_score_train) / (weight_train * tensor_score_train.sum())"],"metadata":{"id":"wR3PbrbBETJA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fNdCgaTMExPK"},"source":["# Gated Network Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gof1eIPIWSVU"},"outputs":[],"source":["def train_gated_combination_model(X1_t, X2_t, X3_t, X4_t, tensor_score_o,\n","                                  X1_val, X2_val, X3_val, X4_val, tensor_score_val,\n","                                  epochs=120, batch_size=32, learning_rate=0.001, weight_decay=1e-5):\n","    \"\"\"\n","    Trains the GatedCombination model with training and validation data, using ReduceLROnPlateau scheduler.\n","    \"\"\"\n","\n","    # Create datasets and DataLoaders\n","    train_dataset = TensorDataset(X1_t, X2_t, X3_t, X4_t, tensor_score_o)\n","    val_dataset = TensorDataset(X1_val, X2_val, X3_val, X4_val, tensor_score_val)\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = GatedCombination(X1_t.shape[1]).to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","\n","    # Use ReduceLROnPlateau scheduler\n","    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n","\n","    criterion = WeightedBCELoss(pos_weight=positive_weight).to(device)\n","\n","    train_losses, val_losses = [], []\n","\n","    start_time = time.time()\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        total_train_loss, y_true_train, y_pred_train = 0.0, [], []\n","\n","        for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in train_loader:\n","            batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (batch_X1.to(device), batch_X2.to(device),\n","                                                               batch_X3.to(device), batch_X4.to(device), batch_y.to(device))\n","            optimizer.zero_grad()\n","            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","            loss = criterion(outputs, batch_y.unsqueeze(1).float())\n","            loss.backward()\n","            optimizer.step()\n","            total_train_loss += loss.item()\n","            y_true_train.extend(batch_y.cpu().numpy())\n","            y_pred_train.extend((outputs > 0.2).float().cpu().numpy())\n","\n","        train_f1 = f1_score(y_true_train, y_pred_train)\n","        train_loss = total_train_loss / len(train_loader)\n","        train_losses.append(train_loss)\n","\n","        # Validation phase\n","        model.eval()\n","        total_val_loss, y_true_val, y_pred_val = 0.0, [], []\n","        with torch.no_grad():\n","            for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in val_loader:\n","                batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (batch_X1.to(device), batch_X2.to(device),\n","                                                                   batch_X3.to(device), batch_X4.to(device), batch_y.to(device))\n","                outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","                val_loss = criterion(outputs, batch_y.unsqueeze(1).float())\n","                total_val_loss += val_loss.item()\n","                y_true_val.extend(batch_y.cpu().numpy())\n","                y_pred_val.extend((outputs > 0.4).float().cpu().numpy())\n","\n","        val_f1 = f1_score(y_true_val, y_pred_val)\n","        avg_val_loss = total_val_loss / len(val_loader)\n","        val_losses.append(avg_val_loss)\n","\n","        # Step the scheduler with validation loss\n","        scheduler.step(avg_val_loss)\n","\n","        # Print training and validation metrics\n","        print(f\"Epoch [{epoch + 1}/{epochs}] Training Loss: {train_loss:.4f}, F1 Score: {train_f1:.4f} | \"\n","              f\"Validation Loss: {avg_val_loss:.4f}, F1 Score: {val_f1:.4f}\")\n","\n","    end_time = time.time()\n","\n","    # Plotting\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(train_losses, label=\"Training Loss\", marker='o')\n","    plt.plot(val_losses, label=\"Validation Loss\", marker='x')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    print(f\"Training complete! Total time: {end_time - start_time:.2f} seconds\")\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"l11dgb8ei69T","outputId":"f22bda8d-4e66-4e83-b09c-1219d703a5cb","executionInfo":{"status":"ok","timestamp":1732189935801,"user_tz":-60,"elapsed":721679,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/100] Training Loss: 0.3916, F1 Score: 0.0386 | Validation Loss: 0.2512, F1 Score: 0.0000\n","Epoch [2/100] Training Loss: 0.1861, F1 Score: 0.3501 | Validation Loss: 0.1417, F1 Score: 0.0000\n","Epoch [3/100] Training Loss: 0.1158, F1 Score: 0.5495 | Validation Loss: 0.0980, F1 Score: 0.0000\n","Epoch [4/100] Training Loss: 0.0834, F1 Score: 0.7105 | Validation Loss: 0.0738, F1 Score: 0.0763\n","Epoch [5/100] Training Loss: 0.0645, F1 Score: 0.8298 | Validation Loss: 0.0587, F1 Score: 0.3619\n","Epoch [6/100] Training Loss: 0.0524, F1 Score: 0.8776 | Validation Loss: 0.0488, F1 Score: 0.4170\n","Epoch [7/100] Training Loss: 0.0445, F1 Score: 0.8991 | Validation Loss: 0.0424, F1 Score: 0.5952\n","Epoch [8/100] Training Loss: 0.0389, F1 Score: 0.9087 | Validation Loss: 0.0375, F1 Score: 0.6961\n","Epoch [9/100] Training Loss: 0.0345, F1 Score: 0.9188 | Validation Loss: 0.0336, F1 Score: 0.7535\n","Epoch [10/100] Training Loss: 0.0311, F1 Score: 0.9197 | Validation Loss: 0.0304, F1 Score: 0.7863\n","Epoch [11/100] Training Loss: 0.0283, F1 Score: 0.9270 | Validation Loss: 0.0280, F1 Score: 0.8352\n","Epoch [12/100] Training Loss: 0.0260, F1 Score: 0.9214 | Validation Loss: 0.0256, F1 Score: 0.8612\n","Epoch [13/100] Training Loss: 0.0239, F1 Score: 0.9243 | Validation Loss: 0.0242, F1 Score: 0.8820\n","Epoch [14/100] Training Loss: 0.0223, F1 Score: 0.9190 | Validation Loss: 0.0225, F1 Score: 0.8940\n","Epoch [15/100] Training Loss: 0.0208, F1 Score: 0.9229 | Validation Loss: 0.0212, F1 Score: 0.9024\n","Epoch [16/100] Training Loss: 0.0197, F1 Score: 0.9235 | Validation Loss: 0.0198, F1 Score: 0.8991\n","Epoch [17/100] Training Loss: 0.0186, F1 Score: 0.9179 | Validation Loss: 0.0190, F1 Score: 0.9024\n","Epoch [18/100] Training Loss: 0.0177, F1 Score: 0.9248 | Validation Loss: 0.0180, F1 Score: 0.9061\n","Epoch [19/100] Training Loss: 0.0168, F1 Score: 0.9213 | Validation Loss: 0.0174, F1 Score: 0.8980\n","Epoch [20/100] Training Loss: 0.0162, F1 Score: 0.9197 | Validation Loss: 0.0167, F1 Score: 0.9047\n","Epoch [21/100] Training Loss: 0.0156, F1 Score: 0.9179 | Validation Loss: 0.0160, F1 Score: 0.9115\n","Epoch [22/100] Training Loss: 0.0150, F1 Score: 0.9201 | Validation Loss: 0.0158, F1 Score: 0.9260\n","Epoch [23/100] Training Loss: 0.0146, F1 Score: 0.9197 | Validation Loss: 0.0151, F1 Score: 0.9212\n","Epoch [24/100] Training Loss: 0.0141, F1 Score: 0.9211 | Validation Loss: 0.0147, F1 Score: 0.9194\n","Epoch [25/100] Training Loss: 0.0139, F1 Score: 0.9203 | Validation Loss: 0.0142, F1 Score: 0.9298\n","Epoch [26/100] Training Loss: 0.0134, F1 Score: 0.9227 | Validation Loss: 0.0142, F1 Score: 0.9180\n","Epoch [27/100] Training Loss: 0.0131, F1 Score: 0.9220 | Validation Loss: 0.0140, F1 Score: 0.9162\n","Epoch [28/100] Training Loss: 0.0128, F1 Score: 0.9217 | Validation Loss: 0.0136, F1 Score: 0.9215\n","Epoch [29/100] Training Loss: 0.0125, F1 Score: 0.9219 | Validation Loss: 0.0137, F1 Score: 0.9196\n","Epoch [30/100] Training Loss: 0.0124, F1 Score: 0.9199 | Validation Loss: 0.0131, F1 Score: 0.9294\n","Epoch [31/100] Training Loss: 0.0121, F1 Score: 0.9267 | Validation Loss: 0.0128, F1 Score: 0.9267\n","Epoch [32/100] Training Loss: 0.0119, F1 Score: 0.9230 | Validation Loss: 0.0129, F1 Score: 0.9345\n","Epoch [33/100] Training Loss: 0.0117, F1 Score: 0.9226 | Validation Loss: 0.0123, F1 Score: 0.9316\n","Epoch [34/100] Training Loss: 0.0116, F1 Score: 0.9232 | Validation Loss: 0.0122, F1 Score: 0.9339\n","Epoch [35/100] Training Loss: 0.0114, F1 Score: 0.9239 | Validation Loss: 0.0124, F1 Score: 0.9292\n","Epoch [36/100] Training Loss: 0.0113, F1 Score: 0.9234 | Validation Loss: 0.0123, F1 Score: 0.9300\n","Epoch [37/100] Training Loss: 0.0110, F1 Score: 0.9237 | Validation Loss: 0.0124, F1 Score: 0.9240\n","Epoch [38/100] Training Loss: 0.0110, F1 Score: 0.9219 | Validation Loss: 0.0124, F1 Score: 0.9310\n","Epoch [39/100] Training Loss: 0.0108, F1 Score: 0.9228 | Validation Loss: 0.0117, F1 Score: 0.9314\n","Epoch [40/100] Training Loss: 0.0107, F1 Score: 0.9208 | Validation Loss: 0.0117, F1 Score: 0.9300\n","Epoch [41/100] Training Loss: 0.0107, F1 Score: 0.9215 | Validation Loss: 0.0118, F1 Score: 0.9302\n","Epoch [42/100] Training Loss: 0.0106, F1 Score: 0.9232 | Validation Loss: 0.0117, F1 Score: 0.9265\n","Epoch [43/100] Training Loss: 0.0104, F1 Score: 0.9233 | Validation Loss: 0.0115, F1 Score: 0.9233\n","Epoch [44/100] Training Loss: 0.0103, F1 Score: 0.9264 | Validation Loss: 0.0118, F1 Score: 0.9324\n","Epoch [45/100] Training Loss: 0.0103, F1 Score: 0.9241 | Validation Loss: 0.0110, F1 Score: 0.9360\n","Epoch [46/100] Training Loss: 0.0101, F1 Score: 0.9211 | Validation Loss: 0.0113, F1 Score: 0.9337\n","Epoch [47/100] Training Loss: 0.0101, F1 Score: 0.9199 | Validation Loss: 0.0114, F1 Score: 0.9360\n","Epoch [48/100] Training Loss: 0.0100, F1 Score: 0.9235 | Validation Loss: 0.0111, F1 Score: 0.9370\n","Epoch [49/100] Training Loss: 0.0101, F1 Score: 0.9243 | Validation Loss: 0.0114, F1 Score: 0.9274\n","Epoch [50/100] Training Loss: 0.0098, F1 Score: 0.9268 | Validation Loss: 0.0109, F1 Score: 0.9349\n","Epoch [51/100] Training Loss: 0.0098, F1 Score: 0.9233 | Validation Loss: 0.0110, F1 Score: 0.9383\n","Epoch [52/100] Training Loss: 0.0098, F1 Score: 0.9213 | Validation Loss: 0.0110, F1 Score: 0.9312\n","Epoch [53/100] Training Loss: 0.0097, F1 Score: 0.9229 | Validation Loss: 0.0105, F1 Score: 0.9440\n","Epoch [54/100] Training Loss: 0.0097, F1 Score: 0.9226 | Validation Loss: 0.0108, F1 Score: 0.9327\n","Epoch [55/100] Training Loss: 0.0096, F1 Score: 0.9229 | Validation Loss: 0.0109, F1 Score: 0.9345\n","Epoch [56/100] Training Loss: 0.0095, F1 Score: 0.9214 | Validation Loss: 0.0107, F1 Score: 0.9314\n","Epoch [57/100] Training Loss: 0.0096, F1 Score: 0.9244 | Validation Loss: 0.0106, F1 Score: 0.9296\n","Epoch [58/100] Training Loss: 0.0095, F1 Score: 0.9241 | Validation Loss: 0.0105, F1 Score: 0.9351\n","Epoch [59/100] Training Loss: 0.0093, F1 Score: 0.9222 | Validation Loss: 0.0105, F1 Score: 0.9364\n","Epoch [60/100] Training Loss: 0.0094, F1 Score: 0.9264 | Validation Loss: 0.0102, F1 Score: 0.9366\n","Epoch [61/100] Training Loss: 0.0093, F1 Score: 0.9280 | Validation Loss: 0.0105, F1 Score: 0.9343\n","Epoch [62/100] Training Loss: 0.0092, F1 Score: 0.9278 | Validation Loss: 0.0109, F1 Score: 0.9261\n","Epoch [63/100] Training Loss: 0.0092, F1 Score: 0.9243 | Validation Loss: 0.0103, F1 Score: 0.9366\n","Epoch [64/100] Training Loss: 0.0093, F1 Score: 0.9246 | Validation Loss: 0.0102, F1 Score: 0.9370\n","Epoch [65/100] Training Loss: 0.0091, F1 Score: 0.9229 | Validation Loss: 0.0105, F1 Score: 0.9314\n","Epoch [66/100] Training Loss: 0.0091, F1 Score: 0.9263 | Validation Loss: 0.0101, F1 Score: 0.9351\n","Epoch [67/100] Training Loss: 0.0091, F1 Score: 0.9257 | Validation Loss: 0.0101, F1 Score: 0.9393\n","Epoch [68/100] Training Loss: 0.0091, F1 Score: 0.9258 | Validation Loss: 0.0100, F1 Score: 0.9349\n","Epoch [69/100] Training Loss: 0.0090, F1 Score: 0.9193 | Validation Loss: 0.0104, F1 Score: 0.9298\n","Epoch [70/100] Training Loss: 0.0090, F1 Score: 0.9253 | Validation Loss: 0.0101, F1 Score: 0.9320\n","Epoch [71/100] Training Loss: 0.0089, F1 Score: 0.9265 | Validation Loss: 0.0103, F1 Score: 0.9357\n","Epoch [72/100] Training Loss: 0.0089, F1 Score: 0.9263 | Validation Loss: 0.0104, F1 Score: 0.9331\n","Epoch [73/100] Training Loss: 0.0088, F1 Score: 0.9276 | Validation Loss: 0.0099, F1 Score: 0.9324\n","Epoch [74/100] Training Loss: 0.0090, F1 Score: 0.9281 | Validation Loss: 0.0100, F1 Score: 0.9362\n","Epoch [75/100] Training Loss: 0.0089, F1 Score: 0.9264 | Validation Loss: 0.0099, F1 Score: 0.9380\n","Epoch [76/100] Training Loss: 0.0088, F1 Score: 0.9209 | Validation Loss: 0.0099, F1 Score: 0.9322\n","Epoch [77/100] Training Loss: 0.0088, F1 Score: 0.9253 | Validation Loss: 0.0099, F1 Score: 0.9302\n","Epoch [78/100] Training Loss: 0.0088, F1 Score: 0.9275 | Validation Loss: 0.0100, F1 Score: 0.9318\n","Epoch [79/100] Training Loss: 0.0086, F1 Score: 0.9287 | Validation Loss: 0.0105, F1 Score: 0.9364\n","Epoch [80/100] Training Loss: 0.0087, F1 Score: 0.9299 | Validation Loss: 0.0099, F1 Score: 0.9316\n","Epoch [81/100] Training Loss: 0.0087, F1 Score: 0.9224 | Validation Loss: 0.0099, F1 Score: 0.9383\n","Epoch [82/100] Training Loss: 0.0086, F1 Score: 0.9276 | Validation Loss: 0.0104, F1 Score: 0.9235\n","Epoch [83/100] Training Loss: 0.0086, F1 Score: 0.9280 | Validation Loss: 0.0097, F1 Score: 0.9424\n","Epoch [84/100] Training Loss: 0.0086, F1 Score: 0.9281 | Validation Loss: 0.0098, F1 Score: 0.9385\n","Epoch [85/100] Training Loss: 0.0086, F1 Score: 0.9240 | Validation Loss: 0.0099, F1 Score: 0.9383\n","Epoch [86/100] Training Loss: 0.0085, F1 Score: 0.9327 | Validation Loss: 0.0098, F1 Score: 0.9351\n","Epoch [87/100] Training Loss: 0.0085, F1 Score: 0.9273 | Validation Loss: 0.0096, F1 Score: 0.9372\n","Epoch [88/100] Training Loss: 0.0086, F1 Score: 0.9247 | Validation Loss: 0.0099, F1 Score: 0.9347\n","Epoch [89/100] Training Loss: 0.0086, F1 Score: 0.9274 | Validation Loss: 0.0096, F1 Score: 0.9433\n","Epoch [90/100] Training Loss: 0.0085, F1 Score: 0.9235 | Validation Loss: 0.0098, F1 Score: 0.9413\n","Epoch [91/100] Training Loss: 0.0085, F1 Score: 0.9253 | Validation Loss: 0.0099, F1 Score: 0.9322\n","Epoch [92/100] Training Loss: 0.0086, F1 Score: 0.9228 | Validation Loss: 0.0103, F1 Score: 0.9320\n","Epoch [93/100] Training Loss: 0.0084, F1 Score: 0.9208 | Validation Loss: 0.0100, F1 Score: 0.9318\n","Epoch [94/100] Training Loss: 0.0085, F1 Score: 0.9230 | Validation Loss: 0.0101, F1 Score: 0.9380\n","Epoch [95/100] Training Loss: 0.0084, F1 Score: 0.9259 | Validation Loss: 0.0095, F1 Score: 0.9353\n","Epoch [96/100] Training Loss: 0.0085, F1 Score: 0.9271 | Validation Loss: 0.0096, F1 Score: 0.9366\n","Epoch [97/100] Training Loss: 0.0084, F1 Score: 0.9276 | Validation Loss: 0.0096, F1 Score: 0.9378\n","Epoch [98/100] Training Loss: 0.0082, F1 Score: 0.9274 | Validation Loss: 0.0099, F1 Score: 0.9341\n","Epoch [99/100] Training Loss: 0.0084, F1 Score: 0.9305 | Validation Loss: 0.0100, F1 Score: 0.9302\n","Epoch [100/100] Training Loss: 0.0084, F1 Score: 0.9250 | Validation Loss: 0.0095, F1 Score: 0.9353\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x500 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training complete! Total time: 721.24 seconds\n"]}],"source":["# Train the GatedCombination model using training and validation data\n","trained_model = train_gated_combination_model(\n","    X1_train,          # Updated source embeddings (after applying the GNN model)\n","    X2_train,          # Original source embeddings (before applying the GNN model)\n","    X3_train,          # Updated target embeddings (after applying the GNN model)\n","    X4_train,          # Original target embeddings (before applying the GNN model)\n","    tensor_score_train, # Ground truth labels for the training set (1 for matched pairs, 0 for unmatched pairs)\n","\n","    X1_val,            # Updated source embeddings for the validation set\n","    X2_val,            # Original source embeddings for the validation set\n","    X3_val,            # Updated target embeddings for the validation set\n","    X4_val,            # Original target embeddings for the validation set\n","    tensor_score_val,  # Ground truth labels for the validation set (1 for matched pairs, 0 for unmatched pairs)\n","\n","    epochs=100,        # Number of epochs (iterations over the entire training dataset)\n","    batch_size=32,     # Number of training samples processed in one forward/backward pass\n","    learning_rate=0.001, # Learning rate for the optimizer (controls step size during optimization)\n","    weight_decay=1e-5  # Weight decay (L2 regularization) to prevent overfitting\n",")"]},{"cell_type":"markdown","metadata":{"id":"uAmLuMtGW9c2"},"source":["# **Mappings Selector**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lnFtpUAfJQHl"},"outputs":[],"source":["# Build an indexed dictionary for the source ontology classes\n","# src_class is the file path to the JSON file containing the source ontology classes\n","indexed_dict_src = build_indexed_dict(src_class)\n","\n","# Build an indexed dictionary for the target ontology classes\n","# tgt_class is the file path to the JSON file containing the target ontology classes\n","indexed_dict_tgt = build_indexed_dict(tgt_class)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"beipwavuJQHl"},"outputs":[],"source":["# Read the candidate pairs from a Candidates CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(candidates_Prediction, index_col=0)\n","\n","# Extract the 'SrcEntity' column (source entity indices) and convert it to a NumPy array of integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)\n","\n","# Extract the 'TgtEntity' column (target entity indices) and convert it to a NumPy array of integers\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)\n","\n","# Convert the source entity indices to a PyTorch LongTensor\n","src_entity_tensor_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)\n","\n","# Convert the target entity indices to a PyTorch LongTensor\n","tgt_entity_tenso_or = torch.from_numpy(tensor_term2).type(torch.LongTensor)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ECLhmxyKJQHl"},"outputs":[],"source":["# Select rows from the updated source embeddings based on the indices in src_entity_tensor_o\n","X1_tt = select_rows_by_index(embeddings_src, src_entity_tensor_o)\n","\n","# Select rows from the original source embeddings based on the indices in src_entity_tensor_o\n","X2_tt = select_rows_by_index(x_src, src_entity_tensor_o)\n","\n","# Select rows from the updated target embeddings based on the indices in tgt_entity_tenso_or\n","X3_tt = select_rows_by_index(embeddings_tgt, tgt_entity_tenso_or)\n","\n","# Select rows from the original target embeddings based on the indices in tgt_entity_tenso_or\n","X4_tt = select_rows_by_index(x_tgt, tgt_entity_tenso_or)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e20235a2-796d-4e07-b9b5-d41f463b711d","id":"UFP6OQR-7D4N","executionInfo":{"status":"ok","timestamp":1732190762944,"user_tz":-60,"elapsed":33267,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting time: 12.72 seconds\n","Predictions saved to /content/gdrive/My Drive/BioGITOM-VLDB/Experiments/Negative_Number_Ajdustment/neoplas/Results/neoplas_all_predictions.tsv\n"]}],"source":["# Generate predictions for candidate mappings using the trained GatedCombination model\n","Prediction_with_candidates(\n","    model=trained_model,             # The trained GatedCombination model used to evaluate similarity\n","    X1_tt=X1_tt,                     # Updated source embeddings (after applying the GIT model)\n","    X2_tt=X2_tt,                     # Original source embeddings (before applying the GIT model)\n","    X3_tt=X3_tt,                     # Updated target embeddings (after applying the GIT model)\n","    X4_tt=X4_tt,                     # Original target embeddings (before applying the GIT model)\n","    src_entity_tensor_o=src_entity_tensor_o,  # Tensor of source entity indices used for evaluation\n","    tgt_entity_tensor_o=tgt_entity_tenso_or,  # Tensor of target entity indices used for evaluation\n","    indexed_dict_src=indexed_dict_src,        # Dictionary mapping source entity indices to their URIs\n","    indexed_dict_tgt=indexed_dict_tgt,        # Dictionary mapping target entity indices to their URIs\n","    all_predictions_path=all_predictions_path # Path to save all predictions with similarity scores in TSV format\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mEc12J-B7D4N","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e52f7d6d-c719-40ac-b0aa-756d750c73f8","executionInfo":{"status":"ok","timestamp":1732191576014,"user_tz":-60,"elapsed":12815,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Positive Predictions : 1871\n"]}],"source":["# Filter the highest scoring predictions from the predictions file and save the results to a new file\n","matching_results_df = filter_highest_predictions(\n","    all_predictions_path,  # Path to the file containing all predictions with scores for all candidate pairs\n","    prediction_path        # Path where the filtered predictions with highest scores will be saved\n",")"]},{"cell_type":"markdown","metadata":{"id":"BIx74lNV7D4O"},"source":["# **Evaluation**"]},{"cell_type":"markdown","source":["# Global metrics calculation"],"metadata":{"id":"Pp3IpBBfWn9m"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bkOewzXr7D4O","outputId":"7d9c070f-056d-458d-9d5c-0fc85699d817","executionInfo":{"status":"ok","timestamp":1732191576900,"user_tz":-60,"elapsed":887,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Correct Predictions : 1618\n","{'P': 0.865, 'R': 0.608, 'F1': 0.714}\n"]}],"source":["# Retrieve the indices of the ignored classes (from source and target ontologies)\n","ignored_class_index = get_ignored_class_index(src_onto)  # Get ignored class indices from source ontology\n","ignored_class_index.update(get_ignored_class_index(tgt_onto))  # Update with ignored class indices from target ontology\n","\n","# Read the predicted mappings from the prediction results file\n","preds = EntityMapping.read_table_mappings(prediction_path)\n","\n","# Read the reference mappings from the ground truth test file\n","refs = ReferenceMapping.read_table_mappings(f\"{dataset_dir}/refs_equiv/test.tsv\")\n","\n","# Filter the predicted mappings to remove any mappings that involve ignored classes\n","preds = remove_ignored_mappings(preds, ignored_class_index)\n","\n","# Compute the precision, recall, and F1-score by comparing predictions with the reference mappings\n","results = AlignmentEvaluator.f1(preds, refs)\n","\n","preds2 = [p.to_tuple() for p in preds]\n","refs2 = [r.to_tuple() for r in refs]\n","\n","correct= len(set(preds2).intersection(set(refs2)))\n","\n","print(f\"Number of Correct Predictions : {correct}\")\n","\n","# Print the computed precision, recall, and F1-score metrics\n","print(results)"]},{"cell_type":"markdown","source":["# Ranked-based metrics calculation"],"metadata":{"id":"aECB6igZW04C"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-AK-jADkSbTa"},"outputs":[],"source":["# Read the candidate pairs from a Candidates CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(candidates_Rank, index_col=0)\n","\n","# Extract the 'SrcEntity' column (source entity indices) and convert it to a NumPy array of integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)\n","\n","# Extract the 'TgtEntity' column (target entity indices) and convert it to a NumPy array of integers\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)\n","\n","# Convert the source entity indices to a PyTorch LongTensor\n","src_entity_tensor_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)\n","\n","# Convert the target entity indices to a PyTorch LongTensor\n","tgt_entity_tenso_or = torch.from_numpy(tensor_term2).type(torch.LongTensor)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oyOzcLv-SbTb"},"outputs":[],"source":["# Select rows from the updated source embeddings based on the indices in src_entity_tensor_o\n","X1_tt = select_rows_by_index(embeddings_src, src_entity_tensor_o)\n","\n","# Select rows from the original source embeddings based on the indices in src_entity_tensor_o\n","X2_tt = select_rows_by_index(x_src, src_entity_tensor_o)\n","\n","# Select rows from the updated target embeddings based on the indices in tgt_entity_tenso_or\n","X3_tt = select_rows_by_index(embeddings_tgt, tgt_entity_tenso_or)\n","\n","# Select rows from the original target embeddings based on the indices in tgt_entity_tenso_or\n","X4_tt = select_rows_by_index(x_tgt, tgt_entity_tenso_or)"]},{"cell_type":"code","source":["# Perform ranking-based predictions using the trained GatedCombination model\n","# Generate predictions for candidate mappings using the trained GatedCombination model\n","Prediction_with_candidates(\n","    model=trained_model,             # The trained GatedCombination model used to evaluate similarity\n","    X1_tt=X1_tt,                     # Updated source embeddings (after applying the GIT model)\n","    X2_tt=X2_tt,                     # Original source embeddings (before applying the GIT model)\n","    X3_tt=X3_tt,                     # Updated target embeddings (after applying the GIT model)\n","    X4_tt=X4_tt,                     # Original target embeddings (before applying the GIT model)\n","    src_entity_tensor_o=src_entity_tensor_o,  # Tensor of source entity indices used for evaluation\n","    tgt_entity_tensor_o=tgt_entity_tenso_or,  # Tensor of target entity indices used for evaluation\n","    indexed_dict_src=indexed_dict_src,        # Dictionary mapping source entity indices to their URIs\n","    indexed_dict_tgt=indexed_dict_tgt,        # Dictionary mapping target entity indices to their URIs\n","    all_predictions_path=all_predictions_path_ranked, # Path where the ranked predictions will be saved in TSV format\n",")"],"metadata":{"id":"-O2f7X6cSb-m","executionInfo":{"status":"ok","timestamp":1732190806652,"user_tz":-60,"elapsed":29252,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e7f3a2c4-43c5-438c-ba70-a0572b864be4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting time: 11.50 seconds\n","Predictions saved to /content/gdrive/My Drive/BioGITOM-VLDB/Experiments/Negative_Number_Ajdustment/neoplas/Results/neoplas_all_predictions_ranked.tsv\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_402seVv7D4O","executionInfo":{"status":"ok","timestamp":1732190821756,"user_tz":-60,"elapsed":15106,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"abd2b609-8fb0-41ef-ba40-cbc3a303c9b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["MRR and Hits@k Results:\n","{'MRR': 0.8972681607181715, 'Hits@k': {1: 0.8419076229815997, 5: 0.9643259481787457, 10: 0.9861058956064589}}\n"]}],"source":["# Compute MRR and Hits@k metrics\n","# This function evaluates the predicted rankings against the reference mappings\n","results = compute_mrr_and_hits(\n","    reference_file=test_cands,             # Reference file with true ranks\n","    predicted_file=all_predictions_path_ranked,             # File containing predicted rankings\n","    output_file=formatted_predictions_path,    # File path to save formatted predictions\n","    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",")\n","\n","# Display the computed metrics\n","print(\"MRR and Hits@k Results:\")\n","print(results)  # Output the Mean Reciprocal Rank (MRR) and Hits@k metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wStfa4eZ7D4O","executionInfo":{"status":"ok","timestamp":1732190825331,"user_tz":-60,"elapsed":3577,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f63e9f11-5abe-4c61-beef-c1cddb5e556d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ranking Evaluation Results at K=1, 5, and 10:\n","{'MRR': 0.8972681607181715, 'Hits@1': 0.8419076229815997, 'Hits@5': 0.9643259481787457, 'Hits@10': 0.9861058956064589}\n"]}],"source":["# Call the ranking evaluation function, passing the path to the formatted predictions file.\n","# Ks specifies the evaluation levels, checking if the correct target is within the top K candidates.\n","results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n","print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n","print(results)"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}