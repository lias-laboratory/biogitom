{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkAX88H3RNRW"
      },
      "source": [
        "# **Package Installation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bSuJvX5_qNhr",
        "outputId": "9cd98b9f-d6ac-41c3-db35-2ca825a0d246"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.6.0\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchvision==0.21.0\n",
            "  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting filelock (from torch==2.6.0)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch==2.6.0)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting networkx (from torch==2.6.0)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch==2.6.0)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch==2.6.0)\n",
            "  Downloading fsspec-2025.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.6.0)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch==2.6.0)\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting sympy==1.13.1 (from torch==2.6.0)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting numpy (from torchvision==0.21.0)\n",
            "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.21.0)\n",
            "  Downloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch==2.6.0)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.6.0)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m107.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m471.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2025.5.0-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m113.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.13.2\n",
            "    Uninstalling typing_extensions-4.13.2:\n",
            "      Successfully uninstalled typing_extensions-4.13.2\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.2.1\n",
            "    Uninstalling pillow-11.2.1:\n",
            "      Successfully uninstalled pillow-11.2.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.18.0\n",
            "    Uninstalling filelock-3.18.0:\n",
            "      Successfully uninstalled filelock-3.18.0\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cpu\n",
            "    Uninstalling torch-2.6.0+cpu:\n",
            "      Successfully uninstalled torch-2.6.0+cpu\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cpu\n",
            "    Uninstalling torchvision-0.21.0+cpu:\n",
            "      Successfully uninstalled torchvision-0.21.0+cpu\n",
            "Successfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.5.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 pillow-11.2.1 sympy-1.13.1 torch-2.6.0 torchvision-0.21.0 triton-3.2.0 typing-extensions-4.13.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "faaff242b6ae4f959952b39c48125a98"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Reinstall a specific version of PyTorch (v2.6.0) and torchvision (v0.21.0)\n",
        "# The \"--force-reinstall\" flag ensures that the packages are reinstalled even if the correct version is already present.\n",
        "# This is useful to resolve environment issues or when dependencies need to be reset.\n",
        "!pip install torch==2.6.0 torchvision==0.21.0 --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ItSvFeEAfLBF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6db44935-5ec1-4492-9b84-cf10ac9858ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.2.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.2.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\n",
            "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
            "  Downloading sqlalchemy-2.0.41-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna)\n",
            "  Downloading greenlet-3.2.2-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.1-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sqlalchemy-2.0.41-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading greenlet-3.2.2-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (583 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m583.9/583.9 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: greenlet, colorlog, sqlalchemy, alembic, optuna\n",
            "Successfully installed alembic-1.16.1 colorlog-6.9.0 greenlet-3.2.2 optuna-4.3.0 sqlalchemy-2.0.41\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.2.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.11.0\n",
            "Collecting torch-geometric==2.4.0\n",
            "  Using cached torch_geometric-2.4.0-py3-none-any.whl.metadata (63 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (2.2.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (1.15.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (3.1.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (3.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (1.6.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric==2.4.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.4.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.4.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.4.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.4.0) (2025.4.26)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->torch-geometric==2.4.0) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->torch-geometric==2.4.0) (3.6.0)\n",
            "Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.4.0\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
            "Collecting torch-scatter\n",
            "  Using cached https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_scatter-2.1.2%2Bpt20cpu-cp311-cp311-linux_x86_64.whl (494 kB)\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_sparse-0.6.18%2Bpt20cpu-cp311-cp311-linux_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_cluster-1.6.3%2Bpt20cpu-cp311-cp311-linux_x86_64.whl (750 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.9/750.9 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt20cpu-cp311-cp311-linux_x86_64.whl (208 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (2.2.6)\n",
            "Installing collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt20cpu torch-scatter-2.1.2+pt20cpu torch-sparse-0.6.18+pt20cpu torch-spline-conv-1.2.2+pt20cpu\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting deeponto\n",
            "  Downloading deeponto-0.9.3-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting JPype1 (from deeponto)\n",
            "  Downloading jpype1-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting yacs (from deeponto)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from deeponto) (2.6.0)\n",
            "Collecting anytree (from deeponto)\n",
            "  Downloading anytree-2.13.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from deeponto) (8.2.0)\n",
            "Collecting dill (from deeponto)\n",
            "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from deeponto) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deeponto) (2.2.6)\n",
            "Requirement already satisfied: scikit_learn in /usr/local/lib/python3.11/dist-packages (from deeponto) (1.6.1)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.11/dist-packages (from deeponto) (4.51.3)\n",
            "Collecting datasets (from deeponto)\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (from deeponto) (3.8.5)\n",
            "Collecting pprintpp (from deeponto)\n",
            "  Downloading pprintpp-0.4.0-py2.py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from deeponto) (3.4.2)\n",
            "Collecting lxml (from deeponto)\n",
            "  Downloading lxml-5.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting textdistance (from deeponto)\n",
            "  Downloading textdistance-4.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from deeponto) (7.7.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from deeponto) (6.17.1)\n",
            "Collecting enlighten (from deeponto)\n",
            "  Downloading enlighten-1.14.1-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Collecting rdflib (from deeponto)\n",
            "  Downloading rdflib-7.1.4-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from deeponto) (3.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (20.0.0)\n",
            "Collecting dill (from deeponto)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (3.5.0)\n",
            "Collecting multiprocess<0.70.17 (from datasets->deeponto)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (0.31.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (6.0.2)\n",
            "Collecting blessed>=1.17.7 (from enlighten->deeponto)\n",
            "  Downloading blessed-1.21.0-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Collecting prefixed>=0.3.2 (from enlighten->deeponto)\n",
            "  Downloading prefixed-0.9.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (6.4.2)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (5.7.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->deeponto) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->deeponto) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->deeponto) (3.0.15)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->deeponto) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->deeponto) (2024.11.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->deeponto) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->deeponto) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->deeponto) (2025.2)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from rdflib->deeponto) (3.2.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn->deeponto) (1.15.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn->deeponto) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (0.15.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (2.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (4.13.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->deeponto) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->deeponto) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->deeponto) (0.5.3)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->deeponto) (1.6.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.11/dist-packages (from blessed>=1.17.7->enlighten->deeponto) (0.2.13)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (3.11.15)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->deeponto)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (5.2.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (4.9.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel->deeponto) (5.7.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->deeponto) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->deeponto) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->deeponto) (2025.4.26)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->deeponto) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->deeponto) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (14.0.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (7.1.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.5.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy->deeponto) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (1.20.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->deeponto) (0.8.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel->deeponto) (4.3.8)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.3.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->deeponto) (0.7.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (3.0.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->deeponto) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (0.1.2)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.23.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.24.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.3.1)\n",
            "Downloading deeponto-0.9.3-py3-none-any.whl (89.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anytree-2.13.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading enlighten-1.14.1-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jpype1-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (494 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lxml-5.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m112.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Downloading rdflib-7.1.4-py3-none-any.whl (565 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.1/565.1 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading textdistance-4.6.3-py3-none-any.whl (31 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading blessed-1.21.0-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.7/84.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prefixed-0.9.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: prefixed, pprintpp, yacs, textdistance, rdflib, lxml, JPype1, jedi, fsspec, dill, blessed, anytree, multiprocess, enlighten, datasets, deeponto\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.5.0\n",
            "    Uninstalling fsspec-2025.5.0:\n",
            "      Successfully uninstalled fsspec-2025.5.0\n",
            "Successfully installed JPype1-1.5.2 anytree-2.13.0 blessed-1.21.0 datasets-3.6.0 deeponto-0.9.3 dill-0.3.8 enlighten-1.14.1 fsspec-2025.3.0 jedi-0.19.2 lxml-5.4.0 multiprocess-0.70.16 pprintpp-0.4.0 prefixed-0.9.0 rdflib-7.1.4 textdistance-4.6.3 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "# === Base Libraries ===\n",
        "!pip install numpy --upgrade\n",
        "!pip install pandas\n",
        "!pip install optuna\n",
        "\n",
        "# === FAISS (for Approximate Nearest Neighbor Search) ===\n",
        "!pip install faiss-cpu        # CPU version (recommended unless using GPU)\n",
        "# !pip install faiss-gpu      # Uncomment if running on CUDA-enabled GPU\n",
        "\n",
        "# === PyTorch Geometric and dependencies ===\n",
        "!pip install torch-geometric==2.4.0\n",
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
        "# Optional: latest dev version from GitHub\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "# === DeepOnto (Ontology Matching Toolkit) ===\n",
        "!pip install deeponto\n",
        "# Optionally install custom version from a GitHub repository\n",
        "# !pip install git+https://github.com/<username>/deeponto.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nFonRjT5fMCv"
      },
      "outputs": [],
      "source": [
        "# Import pandas for working with tabular data (e.g., CSV, TSV files)\n",
        "import pandas as pd\n",
        "\n",
        "# Import numpy for numerical operations and efficient array handling\n",
        "import numpy as np\n",
        "\n",
        "# Import json for reading and writing JSON-formatted files (useful for config or ontology structures)\n",
        "import json\n",
        "\n",
        "# Import pickle for serializing and deserializing Python objects (e.g., saving models or processed data)\n",
        "import pickle\n",
        "\n",
        "# Import warnings to control or suppress warning messages during runtime\n",
        "import warnings\n",
        "\n",
        "# Import gc (garbage collector) for managing memory manually when dealing with large datasets\n",
        "import gc\n",
        "\n",
        "# Ignore all warning messages to keep the output clean\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uchfZJP2fZwe"
      },
      "outputs": [],
      "source": [
        "# Import PyTorch core library for tensor operations and model definition\n",
        "import torch\n",
        "\n",
        "# Import commonly used PyTorch components\n",
        "from torch import Tensor, optim  # Tensor type and optimization algorithms (e.g., SGD, Adam)\n",
        "\n",
        "# Import PyTorch's neural network module (base class for defining models)\n",
        "import torch.nn as nn\n",
        "\n",
        "# Import PyTorch's functional API for operations like activations and loss functions\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Import DataLoader utilities for batching and loading datasets during training\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# === PyTorch Geometric (PyG) modules for graph-based learning ===\n",
        "\n",
        "# Basic graph data structure from PyG\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# PyG-specific DataLoader for batching graphs\n",
        "from torch_geometric.loader import DataLoader as GeoDataLoader\n",
        "\n",
        "# Import graph convolution layers and pooling functions from PyG\n",
        "from torch_geometric.nn import (\n",
        "    GCNConv,             # Graph Convolutional Network layer\n",
        "    GINConv,             # Graph Isomorphism Network convolution\n",
        "    global_mean_pool,    # Global mean pooling over node embeddings\n",
        "    global_add_pool,     # Global sum pooling over node embeddings\n",
        "    MessagePassing       # Base class for defining custom GNN layers\n",
        ")\n",
        "\n",
        "# Explicitly re-import MessagePassing (optional if already above)\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "\n",
        "# Graph utility functions from PyG\n",
        "from torch_geometric.utils import (\n",
        "    to_undirected,       # Converts a directed graph to undirected\n",
        "    softmax              # Softmax over edges (e.g., for attention)\n",
        ")\n",
        "\n",
        "# Initialization utilities for GNN layers\n",
        "from torch_geometric.nn.inits import (\n",
        "    reset,               # Reset parameters\n",
        "    glorot,              # Glorot (Xavier) weight initialization\n",
        "    zeros                # Zero initialization\n",
        ")\n",
        "\n",
        "# Typing utilities from PyG for adjacency and tensor specifications\n",
        "from torch_geometric.typing import (\n",
        "    Adj, OptTensor, PairTensor, SparseTensor\n",
        ")\n",
        "\n",
        "# Dense linear transformation layer from PyG (alternative to torch.nn.Linear)\n",
        "from torch_geometric.nn.dense.linear import Linear\n",
        "\n",
        "# Additional PyTorch neural network components\n",
        "from torch.nn import (\n",
        "    Linear,             # Fully connected (dense) layer\n",
        "    PReLU,              # Parametric ReLU activation\n",
        "    Sequential,         # Layer container for building sequential models\n",
        "    BatchNorm1d,        # Batch normalization for 1D inputs\n",
        "    Dropout             # Dropout regularization\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ziMBSWE8ff1N"
      },
      "outputs": [],
      "source": [
        "# Import matplotlib for creating visualizations (e.g., loss curves, evaluation metrics, embedding projections)\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JeAvp6PNfiLh"
      },
      "outputs": [],
      "source": [
        "# Import function to split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import encoder to convert categorical labels into integer values (useful for classification tasks)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Import evaluation metrics for classification and regression tasks\n",
        "from sklearn.metrics import (\n",
        "    f1_score,            # Harmonic mean of precision and recall; useful for imbalanced classification\n",
        "    precision_score,     # Measures the proportion of true positives among all predicted positives\n",
        "    accuracy_score,      # Measures overall correctness of predictions (classification)\n",
        "    mean_squared_error,  # Measures average squared difference between predicted and actual values (regression)\n",
        "    mean_absolute_error  # Measures average absolute difference between predicted and actual values (regression)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jm1rMZvmfl2M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5ec8f63-c54d-4dfb-b219-4437fbb1cebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter the maximum memory located to JVM [8g]: 8g\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import the Ontology class for loading and manipulating OWL ontologies\n",
        "from deeponto.onto import Ontology\n",
        "\n",
        "# Import all components related to OAEI (Ontology Alignment Evaluation Initiative) benchmarking\n",
        "from deeponto.align.oaei import *\n",
        "\n",
        "# Import data structures for representing mappings between ontology entities\n",
        "from deeponto.align.mapping import EntityMapping, ReferenceMapping\n",
        "# - EntityMapping: represents a predicted alignment (one or more mappings)\n",
        "# - ReferenceMapping: represents the gold standard/reference alignments\n",
        "\n",
        "# Import the evaluator to compute Precision, Recall, and F1-score for alignments\n",
        "from deeponto.align.evaluation import AlignmentEvaluator\n",
        "\n",
        "# Utility function to read TSV/CSV tables as mapping or data frames\n",
        "from deeponto.utils import read_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JYhwr3Q_ft2N"
      },
      "outputs": [],
      "source": [
        "# Import Optuna, a hyperparameter optimization framework for automating model tuning using strategies like Bayesian optimization\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UmSCo5Olfzuz"
      },
      "outputs": [],
      "source": [
        "# Import the math module for mathematical functions (e.g., sqrt, log, exp)\n",
        "import math\n",
        "\n",
        "# Import the time module for measuring execution time of code blocks or functions\n",
        "import time\n",
        "\n",
        "# Import typing annotations for function signatures and code clarity\n",
        "from typing import Optional, Tuple, Union, Callable\n",
        "# - Optional[T]: denotes a value that could be of type T or None\n",
        "# - Tuple: fixed-size ordered collection of elements\n",
        "# - Union: allows multiple possible types (e.g., Union[int, str])\n",
        "# - Callable: represents a function or method type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9WNn0OMQW2CS"
      },
      "outputs": [],
      "source": [
        "# Import Python's built-in random module for generating pseudo-random numbers\n",
        "import random\n",
        "\n",
        "# Set the seed for PyTorch's random number generator to ensure reproducibility\n",
        "import torch\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Set the seed for NumPy's random number generator to ensure reproducibility\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "\n",
        "# Set the seed for Python's built-in random module to ensure reproducibility\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-abbBHOoRdWl"
      },
      "source": [
        "# **Paths Definition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AVgl_Bb42naS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b180e12a-4589-4be2-e54c-80cd1b88e7c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Importing the 'drive' module from Google Colab to interact with Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount the user's Google Drive to the Colab environment\n",
        "# After running this, a link will appear to authorize access, and Google Drive will be mounted at '/content/gdrive'\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "36ttssQ3W7cx"
      },
      "outputs": [],
      "source": [
        "# Define the source ontology name\n",
        "src_ent = \"snomed.neoplas\"\n",
        "\n",
        "# Define the target ontology name\n",
        "tgt_ent = \"ncit.neoplas\"\n",
        "\n",
        "# Define the task name for this ontology matching process\n",
        "task = \"neoplas\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SJpvkdwVSQye"
      },
      "outputs": [],
      "source": [
        "dir = \"/content/gdrive/My Drive/BioGITOM-VLDB/\"\n",
        "\n",
        "# Define the directory for the dataset containing source and target ontologies\n",
        "dataset_dir = f\"{dir}/Datasets/{task}\"\n",
        "\n",
        "# Define the data directory for storing embeddings, adjacency matrices, and related files\n",
        "data_dir = f\"{dir}/{task}/Data\"\n",
        "\n",
        "# Define the directory for storing the results\n",
        "results_dir = f\"{dir}/{task}/Results\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "eFDNSFef23er"
      },
      "outputs": [],
      "source": [
        "# Load the Source ontology using the Ontology class from DeepOnto\n",
        "# This initializes the source ontology by loading its .owl file.\n",
        "src_onto = Ontology(f\"{dataset_dir}/{src_ent}.owl\")\n",
        "\n",
        "# Load the Target ontology using the Ontology class from DeepOnto\n",
        "# This initializes the target ontology by loading its .owl file.\n",
        "tgt_onto = Ontology(f\"{dataset_dir}/{tgt_ent}.owl\")\n",
        "\n",
        "# Define the file path for the Source embeddings CSV file\n",
        "# Embeddings for the source ontology entities are stored in this file.\n",
        "src_Emb = f\"{data_dir}/{src_ent}_SapBERT_emb.csv\"\n",
        "\n",
        "# Define the file path for the Target embeddings CSV file\n",
        "# Embeddings for the target ontology entities are stored in this file.\n",
        "tgt_Emb = f\"{data_dir}/{tgt_ent}_SapBERT_emb.csv\"\n",
        "\n",
        "# Define the file path for the Source adjacency matrix\n",
        "# This file represents the relationships (edges) between entities in the source ontology.\n",
        "src_Adjacence = f\"{data_dir}/{src_ent}_adjacence.csv\"\n",
        "\n",
        "# Define the file path for the Target adjacency matrix\n",
        "# This file represents the relationships (edges) between entities in the target ontology.\n",
        "tgt_Adjacence = f\"{data_dir}/{tgt_ent}_adjacence.csv\"\n",
        "\n",
        "# Define the file path for the JSON file containing the Source ontology class labels\n",
        "# This file maps the source ontology entities to their labels or names.\n",
        "src_class = f\"{data_dir}/{src_ent}_classes.json\"\n",
        "\n",
        "# Define the file path for the JSON file containing the Target ontology class labels\n",
        "# This file maps the target ontology entities to their labels or names.\n",
        "tgt_class = f\"{data_dir}/{tgt_ent}_classes.json\"\n",
        "\n",
        "# Define the file path for the train data\n",
        "train_file = f\"{data_dir}/{task}_train.csv\"\n",
        "\n",
        "# Define the file path for the test data\n",
        "# The test file contains reference mappings (ground truth) between the source and target ontologies.\n",
        "test_file = f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "\n",
        "# Define the file path for the candidate mappings used during testing\n",
        "# This file includes the candidate pairs (source and target entities) for ranking based metrics.\n",
        "test_cands = f\"{dataset_dir}/refs_equiv/test.cands.tsv\"\n",
        "cands_path = f\"{data_dir}/{task}_cands.csv\"\n",
        "\n",
        "# Define the path where the prediction results will be saved in TSV format\n",
        "# This file will store the final predictions (mappings) between source and target entities.\n",
        "prediction_path = f\"{results_dir}/{task}_matching_results.tsv\"\n",
        "\n",
        "# Define the path where all prediction results will be saved in TSV format\n",
        "# This file will store detailed prediction results, including all candidate scores.\n",
        "all_predictions_path = f\"{results_dir}/{task}_all_predictions.tsv\"\n",
        "\n",
        "# Define the path where formatted ranking predictions will be saved in TSV format\n",
        "# This file will contain predictions formatted for evaluation using ranking-based metrics.\n",
        "formatted_predictions_path = f\"{results_dir}/{task}_formatted_predictions.tsv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqEXsgPGMVhw"
      },
      "source": [
        "# **GIT Architecture**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "A_d6XCsUMVhx"
      },
      "outputs": [],
      "source": [
        "# RGIT class definition which inherits from PyTorch Geometric's MessagePassing class\n",
        "class RGIT(MessagePassing):\n",
        "\n",
        "    _alpha: OptTensor  # Define _alpha as an optional tensor for storing attention weights\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        nn: Callable,  # Neural network to be used in the final layer of the GNN\n",
        "        in_channels: Union[int, Tuple[int, int]],  # Input dimension, can be a single or pair of integers\n",
        "        out_channels: int,  # Output dimension of the GNN\n",
        "        eps: float = 0.,  # GIN parameter: epsilon for GIN aggregation\n",
        "        train_eps: bool = False,  # GIN parameter: whether epsilon should be learnable\n",
        "        heads: int = 1,  # Transformer parameter: number of attention heads\n",
        "        dropout: float = 0.,  # Dropout rate for attention weights\n",
        "        edge_dim: Optional[int] = None,  # Dimension for edge attributes (optional)\n",
        "        bias: bool = True,  # Whether to use bias in linear layers\n",
        "        root_weight: bool = True,  # GIN parameter: whether to apply root weight in aggregation\n",
        "        **kwargs,  # Additional arguments passed to the parent class\n",
        "    ):\n",
        "        # Set the aggregation type to 'add' and initialize the parent class with node_dim=0\n",
        "        kwargs.setdefault('aggr', 'add')\n",
        "        super().__init__(node_dim=0, **kwargs)\n",
        "\n",
        "        # Initialize input/output dimensions, neural network, and GIN/transformer parameters\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.nn = nn  # Neural network used by the GNN\n",
        "        self.initial_eps = eps  # Initial value of epsilon for GIN\n",
        "\n",
        "        # Set epsilon to be learnable or fixed\n",
        "        if train_eps:\n",
        "            self.eps = torch.nn.Parameter(torch.empty(1))  # Learnable epsilon\n",
        "        else:\n",
        "            self.register_buffer('eps', torch.empty(1))  # Non-learnable epsilon (fixed)\n",
        "\n",
        "        # Initialize transformer-related parameters\n",
        "        self.heads = heads\n",
        "        self.dropout = dropout\n",
        "        self.edge_dim = edge_dim\n",
        "        self._alpha = None  # Placeholder for attention weights\n",
        "\n",
        "        # Handle case where in_channels is a single integer or a tuple\n",
        "        if isinstance(in_channels, int):\n",
        "            in_channels = (in_channels, in_channels)\n",
        "\n",
        "        # Define the linear layers for key, query, and value for the transformer mechanism\n",
        "        self.lin_key = Linear(in_channels[0], heads * out_channels)\n",
        "        self.lin_query = Linear(in_channels[1], heads * out_channels)\n",
        "        self.lin_value = Linear(in_channels[0], heads * out_channels)\n",
        "\n",
        "        # Define linear transformation for edge embeddings if provided\n",
        "        if edge_dim is not None:\n",
        "            self.lin_edge = Linear(edge_dim, heads * out_channels, bias=False)\n",
        "        else:\n",
        "            self.lin_edge = self.register_parameter('lin_edge', None)\n",
        "\n",
        "        # Reset all parameters to their initial values\n",
        "        self.reset_parameters()\n",
        "\n",
        "    # Function to reset model parameters\n",
        "    def reset_parameters(self):\n",
        "        super().reset_parameters()  # Call parent class reset method\n",
        "        self.lin_key.reset_parameters()  # Reset key linear layer\n",
        "        self.lin_query.reset_parameters()  # Reset query linear layer\n",
        "        self.lin_value.reset_parameters()  # Reset value linear layer\n",
        "        if self.edge_dim:\n",
        "            self.lin_edge.reset_parameters()  # Reset edge linear layer if used\n",
        "        reset(self.nn)  # Reset the neural network provided\n",
        "        self.eps.data.fill_(self.initial_eps)  # Initialize epsilon with the starting value\n",
        "\n",
        "    # Forward function defining how the input data flows through the model\n",
        "    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj,\n",
        "                edge_attr: OptTensor = None, return_attention_weights=None):\n",
        "        # Unpack number of heads and output channels\n",
        "        H, C = self.heads, self.out_channels\n",
        "\n",
        "        # If x is a tensor, treat it as a pair of tensors (source and target embeddings)\n",
        "        if isinstance(x, Tensor):\n",
        "            x: PairTensor = (x, x)\n",
        "\n",
        "        # Extract source node embeddings\n",
        "        x_t = x[0]\n",
        "\n",
        "        # Apply linear transformations and reshape query, key, and value for multi-head attention\n",
        "        query = self.lin_query(x[1]).view(-1, H, C)\n",
        "        key = self.lin_key(x[0]).view(-1, H, C)\n",
        "        value = self.lin_value(x[0]).view(-1, H, C)\n",
        "\n",
        "        # Propagate messages through the graph using the propagate function\n",
        "        out = self.propagate(edge_index, query=query, key=key, value=value,\n",
        "                             edge_attr=edge_attr, size=None)\n",
        "\n",
        "        # Retrieve attention weights and reset them\n",
        "        alpha = self._alpha\n",
        "        self._alpha = None  # Reset _alpha after use\n",
        "        out = out.mean(dim=1)  # Take the mean over all attention heads\n",
        "\n",
        "        # Apply GIN aggregation by adding epsilon-scaled original node embeddings\n",
        "        out = out + (1 + self.eps) * x_t\n",
        "        return self.nn(out)  # Pass through the neural network\n",
        "\n",
        "    # Message passing function which calculates attention and combines messages\n",
        "    def message(self, query_i: Tensor, key_j: Tensor, value_j: Tensor,\n",
        "                edge_attr: OptTensor, index: Tensor, ptr: OptTensor,\n",
        "                size_i: Optional[int]) -> Tensor:\n",
        "        # If edge attributes are used, apply linear transformation and add them to the key\n",
        "        if self.lin_edge is not None:\n",
        "            assert edge_attr is not None\n",
        "            edge_attr = self.lin_edge(edge_attr).view(-1, self.heads, self.out_channels)\n",
        "            key_j = key_j + edge_attr\n",
        "\n",
        "        # Calculate attention (alpha) using the dot product between query and key\n",
        "        alpha = (query_i * key_j).sum(dim=-1) / math.sqrt(self.out_channels)\n",
        "        alpha = softmax(alpha, index, ptr, size_i)  # Apply softmax to normalize attention\n",
        "        self._alpha = alpha  # Store attention weights\n",
        "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)  # Apply dropout\n",
        "\n",
        "        # Calculate the output message by applying attention to the value\n",
        "        out = value_j\n",
        "        if edge_attr is not None:\n",
        "            out = out + edge_attr  # Add edge embeddings to the output if present\n",
        "        out = out * alpha.view(-1, self.heads, 1)  # Scale by attention weights\n",
        "        return out\n",
        "\n",
        "    # String representation function for debugging or printing\n",
        "    def __repr__(self) -> str:\n",
        "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
        "                f'{self.out_channels}, heads={self.heads})')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qwFv6RgHmGCf"
      },
      "outputs": [],
      "source": [
        "# Define the RGIT_mod class, a multi-layer GNN that uses both RGIT and linear layers\n",
        "class RGIT_mod(torch.nn.Module):\n",
        "    \"\"\"Multi-layer RGIT with optional linear layers\"\"\"\n",
        "\n",
        "    # Initialize the model with hidden dimension, number of RGIT layers, and number of linear layers\n",
        "    def __init__(self, dim_h, num_layers, num_linear_layers=1):\n",
        "        super(RGIT_mod, self).__init__()\n",
        "        self.num_layers = num_layers  # Number of RGIT layers\n",
        "        self.num_linear_layers = num_linear_layers  # Number of linear layers\n",
        "        self.linears = torch.nn.ModuleList()  # List to store linear layers\n",
        "        self.rgit_layers = torch.nn.ModuleList()  # List to store RGIT layers\n",
        "\n",
        "        # Create a list of Linear and PReLU layers (for encoding entity names)\n",
        "        for _ in range(num_linear_layers):\n",
        "            self.linears.append(Linear(dim_h, dim_h))  # Linear transformation layer\n",
        "            self.linears.append(PReLU(num_parameters=dim_h))  # Parametric ReLU activation function\n",
        "\n",
        "        # Create a list of RGIT layers\n",
        "        for _ in range(num_layers):\n",
        "            self.rgit_layers.append(RGIT(  # Each RGIT layer contains a small MLP with Linear and PReLU\n",
        "                Sequential(Linear(dim_h, dim_h), PReLU(num_parameters=dim_h),\n",
        "                           Linear(dim_h, dim_h), PReLU(num_parameters=dim_h)), dim_h, dim_h))\n",
        "\n",
        "    # Forward pass through the model\n",
        "    def forward(self, x, edge_index):\n",
        "        # Apply the linear layers first to the input\n",
        "        for layer in self.linears:\n",
        "            x = layer(x)\n",
        "\n",
        "        # Then apply the RGIT layers for message passing\n",
        "        for layer in self.rgit_layers:\n",
        "            x = layer(x, edge_index)\n",
        "\n",
        "        return x  # Return the final node embeddings after all layers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxCn5ztKVztw"
      },
      "source": [
        "# **Gated Network Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7MKQUv7o7zay"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GatedCombination(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(GatedCombination, self).__init__()\n",
        "        self.gate_A_fc = nn.Linear(input_dim, input_dim)\n",
        "        self.gate_B_fc = nn.Linear(input_dim, input_dim)\n",
        "        self.fc = nn.Linear(1, 1)\n",
        "\n",
        "    def euclidean_distance(self, a, b):\n",
        "        \"\"\"\n",
        "        Compute the Euclidean distance between two tensors.\n",
        "        Args:\n",
        "            a: Tensor of shape [batch, dim]\n",
        "            b: Tensor of shape [batch, dim]\n",
        "        Returns:\n",
        "            Tensor of shape [batch] representing the L2 distance.\n",
        "        \"\"\"\n",
        "        return torch.norm(a - b, p=2, dim=1)\n",
        "\n",
        "    def forward(self, x1, x2, x3, x4, return_embeddings=False):\n",
        "        gate_values1 = torch.sigmoid(self.gate_A_fc(x1))\n",
        "        a = x1 * gate_values1 + x2 * (1 - gate_values1)\n",
        "\n",
        "        gate_values2 = torch.sigmoid(self.gate_B_fc(x3))\n",
        "        b = x3 * gate_values2 + x4 * (1 - gate_values2)\n",
        "\n",
        "        if return_embeddings:\n",
        "            return a, b\n",
        "\n",
        "        # Utilisation de la distance Euclidienne\n",
        "        distance = self.euclidean_distance(a, b)\n",
        "\n",
        "        # Passage dans couche de classification\n",
        "        out = torch.sigmoid(self.fc(distance.unsqueeze(1)))\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-niEvlkie_vx"
      },
      "source": [
        "\n",
        "\n",
        "# **Encoder Definition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8GHQKz8Re_vx"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# === Simple Linear Encoder ===\n",
        "class LinearEncoder(nn.Module):\n",
        "    def __init__(self, embedding_dim):\n",
        "        super(LinearEncoder, self).__init__()\n",
        "        # A single linear transformation layer: y = Wx + b\n",
        "        self.linear = nn.Linear(embedding_dim, embedding_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass: apply the linear transformation\n",
        "        return self.linear(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLJ5j9FNMVhy"
      },
      "source": [
        "# **Utility functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "k0L86DgUQjMU"
      },
      "outputs": [],
      "source": [
        "def adjacency_matrix_to_undirected_edge_index(adjacency_matrix):\n",
        "    \"\"\"\n",
        "    Converts an adjacency matrix into an undirected edge index for use in graph-based neural networks.\n",
        "\n",
        "    Args:\n",
        "        adjacency_matrix: A 2D list or array representing the adjacency matrix of a graph.\n",
        "\n",
        "    Returns:\n",
        "        edge_index_undirected: A PyTorch tensor representing the undirected edges.\n",
        "    \"\"\"\n",
        "    # Convert each element in the adjacency matrix to an integer (from boolean or float)\n",
        "    adjacency_matrix = [[int(element) for element in sublist] for sublist in adjacency_matrix]\n",
        "\n",
        "    # Convert the adjacency matrix into a PyTorch LongTensor (used for indexing)\n",
        "    edge_index = torch.tensor(adjacency_matrix, dtype=torch.long)\n",
        "\n",
        "    # Transpose the edge_index tensor so that rows represent edges in the form [source, target]\n",
        "    edge_index = edge_index.t().contiguous()\n",
        "\n",
        "    # Convert the directed edge_index into an undirected edge_index, meaning both directions are added (i.e., (i, j) and (j, i))\n",
        "    edge_index_undirected = to_undirected(edge_index)\n",
        "\n",
        "    return edge_index_undirected  # Return the undirected edge index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YvmOxkLcpf9w"
      },
      "outputs": [],
      "source": [
        "def build_indexed_dict(file_path):\n",
        "    \"\"\"\n",
        "    Builds a dictionary with numeric indexes for each key from a JSON file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): The path to the JSON file.\n",
        "\n",
        "    Returns:\n",
        "        indexed_dict (dict): A new dictionary where each key from the JSON file is assigned a numeric index.\n",
        "    \"\"\"\n",
        "    # Load the JSON file into a Python dictionary\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    # Create a new dictionary with numeric indexes as keys and the original JSON keys as values\n",
        "    indexed_dict = {index: key for index, key in enumerate(data.keys())}\n",
        "\n",
        "    return indexed_dict  # Return the newly created dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QgFINoPGl9Wg"
      },
      "outputs": [],
      "source": [
        "def select_rows_by_index(embedding_vector, index_vector):\n",
        "    \"\"\"\n",
        "    Select rows from an embedding vector using an index vector.\n",
        "\n",
        "    Args:\n",
        "        embedding_vector (torch.Tensor): 2D tensor representing the embedding vector with shape [num_rows, embedding_size].\n",
        "        index_vector (torch.Tensor): 1D tensor representing the index vector.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: New tensor with selected rows from the embedding vector.\n",
        "    \"\"\"\n",
        "    # Use torch.index_select to select the desired rows\n",
        "    new_tensor = torch.index_select(embedding_vector, 0, index_vector)\n",
        "\n",
        "    return new_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "a12L7vEmmCJq"
      },
      "outputs": [],
      "source": [
        "def contrastive_loss(source_embeddings, target_embeddings, labels, margin=1.0):\n",
        "    \"\"\"\n",
        "    Computes the contrastive loss, a type of loss function used to train models in tasks like matching or similarity learning.\n",
        "\n",
        "    Args:\n",
        "        source_embeddings (torch.Tensor): Embeddings of the source graphs, shape [batch_size, embedding_size].\n",
        "        target_embeddings (torch.Tensor): Embeddings of the target graphs, shape [batch_size, embedding_size].\n",
        "        labels (torch.Tensor): Binary labels indicating if the pairs are matched (1) or not (0), shape [batch_size].\n",
        "        margin (float): Margin value for the contrastive loss. Defaults to 1.0.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The contrastive loss value.\n",
        "    \"\"\"\n",
        "    # Calculate the pairwise Euclidean distance between source and target embeddings\n",
        "    distances = F.pairwise_distance(source_embeddings, target_embeddings)\n",
        "\n",
        "    # Compute the contrastive loss:\n",
        "    # - For matched pairs (label == 1), the loss is the squared distance between embeddings.\n",
        "    # - For non-matched pairs (label == 0), the loss is based on how far apart the embeddings are,\n",
        "    #   but penalizes them only if the distance is less than the margin.\n",
        "    loss = torch.mean(\n",
        "        labels * 0.4 * distances.pow(2) +  # For positive pairs, minimize the distance (squared)\n",
        "        (1 - labels) * 0.4 * torch.max(torch.zeros_like(distances), margin - distances).pow(2)  # For negative pairs, maximize the distance (up to the margin)\n",
        "    )\n",
        "\n",
        "    return loss  # Return the computed contrastive loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_ggVYlTiO_WA"
      },
      "outputs": [],
      "source": [
        "def compute_mrr_and_hits(reference_file, predicted_file, output_file, k_values=[1, 5, 10]):\n",
        "    \"\"\"\n",
        "    Compute Mean Reciprocal Rank (MRR) and Hits@k metrics for ontology matching results.\n",
        "\n",
        "    Args:\n",
        "        reference_file (str): Path to the reference test candidate file (usually 'test.cands.tsv').\n",
        "        predicted_file (str): Path to the prediction results (with columns: SrcEntity, TgtEntity, Score).\n",
        "        output_file (str): Path to save ranked candidate predictions with scores.\n",
        "        k_values (list): List of integers specifying which Hits@k metrics to compute.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary with MRR and Hits@k scores.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load reference candidate mappings: each row = (SrcEntity, CorrectTgtEntity, [CandidateTgtEntities])\n",
        "    test_candidate_mappings = read_table(reference_file).values.tolist()\n",
        "\n",
        "    # Load predictions and ensure Score is float\n",
        "    predicted_data = pd.read_csv(predicted_file, sep=\"\\t\")\n",
        "    predicted_data[\"Score\"] = predicted_data[\"Score\"].apply(\n",
        "        lambda x: float(x.strip(\"[]\")) if isinstance(x, str) else float(x)\n",
        "    )\n",
        "\n",
        "    # Create a dictionary mapping (SrcEntity, TgtEntity) -> predicted score\n",
        "    score_lookup = {\n",
        "        (row[\"SrcEntity\"], row[\"TgtEntity\"]): row[\"Score\"]\n",
        "        for _, row in predicted_data.iterrows()\n",
        "    }\n",
        "\n",
        "    ranking_results = []\n",
        "\n",
        "    # Rank the candidates for each source entity\n",
        "    for src_ref_class, tgt_ref_class, tgt_cands in test_candidate_mappings:\n",
        "        # Safely parse the candidate list (tgt_cands is a stringified list)\n",
        "        try:\n",
        "            tgt_cands = eval(tgt_cands)\n",
        "        except Exception:\n",
        "            tgt_cands = []\n",
        "\n",
        "        # Score each candidate (use a large negative default if not found)\n",
        "        scored_cands = [\n",
        "            (tgt_cand, score_lookup.get((src_ref_class, tgt_cand), -1e9))\n",
        "            for tgt_cand in tgt_cands\n",
        "        ]\n",
        "\n",
        "        # Sort candidates by score descending\n",
        "        scored_cands = sorted(scored_cands, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Store the ranking result\n",
        "        ranking_results.append((src_ref_class, tgt_ref_class, scored_cands))\n",
        "\n",
        "    # Save ranked predictions for inspection/debugging\n",
        "    pd.DataFrame(ranking_results, columns=[\"SrcEntity\", \"TgtEntity\", \"TgtCandidates\"]).to_csv(\n",
        "        output_file, sep=\"\\t\", index=False\n",
        "    )\n",
        "\n",
        "    # === Evaluation: compute MRR and Hits@k ===\n",
        "    total_entities = len(ranking_results)\n",
        "    reciprocal_ranks = []\n",
        "    hits_at_k = {k: 0 for k in k_values}\n",
        "\n",
        "    for src_entity, tgt_ref_class, tgt_cands in ranking_results:\n",
        "        ranked_candidates = [cand[0] for cand in tgt_cands]  # candidate URIs only\n",
        "        if tgt_ref_class in ranked_candidates:\n",
        "            rank = ranked_candidates.index(tgt_ref_class) + 1\n",
        "            reciprocal_ranks.append(1 / rank)\n",
        "            for k in k_values:\n",
        "                if rank <= k:\n",
        "                    hits_at_k[k] += 1\n",
        "        else:\n",
        "            reciprocal_ranks.append(0)  # No correct match in candidate list\n",
        "\n",
        "    # Compute final metrics\n",
        "    mrr = sum(reciprocal_ranks) / total_entities\n",
        "    hits_at_k = {k: hits / total_entities for k, hits in hits_at_k.items()}\n",
        "\n",
        "    return {\"MRR\": mrr, \"Hits@k\": hits_at_k}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "kh1zdPJQe_vy"
      },
      "outputs": [],
      "source": [
        "def save_gated_embeddings(gated_model, embeddings_src, x_src, embeddings_tgt, x_tgt,\n",
        "                          indexed_dict_src, indexed_dict_tgt,\n",
        "                          output_file_src, output_file_tgt):\n",
        "    \"\"\"\n",
        "    Compute and save the final entity embeddings generated by the GatedCombination model\n",
        "    for both source and target ontologies. Outputs include entity URIs and their final vectors.\n",
        "    Measures and prints the execution time of the entire operation.\n",
        "\n",
        "    Args:\n",
        "        gated_model (nn.Module): The trained GatedCombination model.\n",
        "        embeddings_src (Tensor): Structural embeddings for the source ontology.\n",
        "        x_src (Tensor): Semantic embeddings for the source ontology.\n",
        "        embeddings_tgt (Tensor): Structural embeddings for the target ontology.\n",
        "        x_tgt (Tensor): Semantic embeddings for the target ontology.\n",
        "        indexed_dict_src (dict): Index-to-URI mapping for the source ontology.\n",
        "        indexed_dict_tgt (dict): Index-to-URI mapping for the target ontology.\n",
        "        output_file_src (str): Path to save source embeddings (TSV).\n",
        "        output_file_tgt (str): Path to save target embeddings (TSV).\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "    import torch\n",
        "    import time\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Use GPU if available\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    gated_model = gated_model.to(device)\n",
        "    gated_model.eval()\n",
        "\n",
        "    # Move inputs to the same device\n",
        "    embeddings_src = embeddings_src.to(device)\n",
        "    x_src = x_src.to(device)\n",
        "    embeddings_tgt = embeddings_tgt.to(device)\n",
        "    x_tgt = x_tgt.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # === Source ontology ===\n",
        "        gate_src = torch.sigmoid(gated_model.gate_A_fc(embeddings_src))\n",
        "        final_src = embeddings_src * gate_src + x_src * (1 - gate_src)\n",
        "        final_src = final_src.cpu().numpy()\n",
        "\n",
        "        # === Target ontology ===\n",
        "        gate_tgt = torch.sigmoid(gated_model.gate_B_fc(embeddings_tgt))\n",
        "        final_tgt = embeddings_tgt * gate_tgt + x_tgt * (1 - gate_tgt)\n",
        "        final_tgt = final_tgt.cpu().numpy()\n",
        "\n",
        "    # Create DataFrames with Concept URI and embedding values\n",
        "    df_src = pd.DataFrame(final_src)\n",
        "    df_src.insert(0, \"Concept\", [indexed_dict_src[i] for i in range(len(df_src))])\n",
        "\n",
        "    df_tgt = pd.DataFrame(final_tgt)\n",
        "    df_tgt.insert(0, \"Concept\", [indexed_dict_tgt[i] for i in range(len(df_tgt))])\n",
        "\n",
        "    # Save embeddings to file\n",
        "    df_src.to_csv(output_file_src, sep='\\t', index=False)\n",
        "    df_tgt.to_csv(output_file_tgt, sep='\\t', index=False)\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"✅ Gated embeddings saved:\\n- Source: {output_file_src}\\n- Target: {output_file_tgt}\")\n",
        "    print(f\"⏱️ Execution time: {elapsed_time:.2f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "LXvbHTVfe_vz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def filter_ignored_class(src_emb_path, tgt_emb_path, src_onto, tgt_onto):\n",
        "    \"\"\"\n",
        "    Filters the source and target embedding files by removing concepts considered \"ignored classes\"\n",
        "    (e.g., owl:Thing, deprecated entities, etc.) based on both source and target ontologies.\n",
        "\n",
        "    Args:\n",
        "        src_emb_path (str): Path to the TSV file containing source embeddings with 'Concept' column.\n",
        "        tgt_emb_path (str): Path to the TSV file containing target embeddings with 'Concept' column.\n",
        "        src_onto (Ontology): Source ontology object loaded with DeepOnto.\n",
        "        tgt_onto (Ontology): Target ontology object loaded with DeepOnto.\n",
        "\n",
        "    Returns:\n",
        "        (str, str): Paths to the cleaned source and target embedding files.\n",
        "    \"\"\"\n",
        "\n",
        "    # === Load the embedding files ===\n",
        "    df_src = pd.read_csv(src_emb_path, sep='\\t', dtype=str)\n",
        "    print(f\"🔍 Initial source file: {len(df_src)} rows\")\n",
        "\n",
        "    df_tgt = pd.read_csv(tgt_emb_path, sep='\\t', dtype=str)\n",
        "    print(f\"🔍 Initial target file: {len(df_tgt)} rows\")\n",
        "\n",
        "    # === Step 1: Retrieve ignored classes from both ontologies ===\n",
        "    ignored_class_index = get_ignored_class_index(src_onto)  # e.g., owl:Thing, non-usable classes\n",
        "    ignored_class_index.update(get_ignored_class_index(tgt_onto))  # Merge with target ontology's ignored classes\n",
        "    ignored_uris = set(str(uri).strip() for uri in ignored_class_index)\n",
        "\n",
        "    # === Step 2: Remove rows where the 'Concept' column matches ignored URIs ===\n",
        "    df_src_cleaned = df_src[~df_src['Concept'].isin(ignored_uris)].reset_index(drop=True)\n",
        "    df_tgt_cleaned = df_tgt[~df_tgt['Concept'].isin(ignored_uris)].reset_index(drop=True)\n",
        "\n",
        "    print(f\"✅ Source after removing ignored classes: {len(df_src_cleaned)} rows\")\n",
        "    print(f\"✅ Target after removing ignored classes: {len(df_tgt_cleaned)} rows\")\n",
        "\n",
        "    # === Step 3: Save the cleaned embedding files ===\n",
        "    output_file_src = src_emb_path.replace(\".tsv\", \"_cleaned.tsv\")\n",
        "    output_file_tgt = tgt_emb_path.replace(\".tsv\", \"_cleaned.tsv\")\n",
        "\n",
        "    df_src_cleaned.to_csv(output_file_src, sep='\\t', index=False)\n",
        "    df_tgt_cleaned.to_csv(output_file_tgt, sep='\\t', index=False)\n",
        "\n",
        "    print(f\"📁 Cleaned source file saved to: {output_file_src}\")\n",
        "    print(f\"📁 Cleaned target file saved to: {output_file_tgt}\")\n",
        "\n",
        "    return output_file_src, output_file_tgt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "_9YDcnTbKaHk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "def encode_embeddings_with_concept_column(encoder_model, input_file, output_file):\n",
        "    \"\"\"\n",
        "    Applies an encoder model to a set of embeddings (while preserving the 'Concept' column),\n",
        "    and saves the encoded results in the same tabular format.\n",
        "\n",
        "    Args:\n",
        "        encoder_model: A PyTorch model (e.g., LinearEncoder, MLPEncoder, etc.)\n",
        "        input_file (str): Path to the input TSV file containing 'Concept' and embedding vectors.\n",
        "        output_file (str): Path to save the encoded embeddings.\n",
        "    \"\"\"\n",
        "\n",
        "    # Select device (GPU if available, else CPU)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Move the encoder model to the selected device and set it to evaluation mode\n",
        "    encoder_model = encoder_model.to(device)\n",
        "    encoder_model.eval()\n",
        "\n",
        "    # Load the input TSV file containing concept URIs and embeddings\n",
        "    df = pd.read_csv(input_file, sep='\\t')\n",
        "\n",
        "    # Extract the 'Concept' column to preserve URIs\n",
        "    concepts = df['Concept'].tolist()\n",
        "\n",
        "    # Extract the numerical embedding values (excluding the 'Concept' column)\n",
        "    embedding_values = df.drop(columns=['Concept']).values\n",
        "\n",
        "    # Convert the embedding matrix into a PyTorch tensor and move to the device\n",
        "    embeddings = torch.FloatTensor(embedding_values).to(device)\n",
        "\n",
        "    # Pass the embeddings through the encoder model without computing gradients\n",
        "    with torch.no_grad():\n",
        "        encoded = encoder_model(embeddings).cpu().numpy()\n",
        "\n",
        "    # Reconstruct a new DataFrame with the encoded vectors and corresponding URIs\n",
        "    df_encoded = pd.DataFrame(encoded, columns=[f'dim_{i}' for i in range(encoded.shape[1])])\n",
        "    df_encoded.insert(0, \"Concept\", concepts)  # Re-insert the 'Concept' column at the first position\n",
        "\n",
        "    # Save the encoded embeddings to a TSV file\n",
        "    df_encoded.to_csv(output_file, sep='\\t', index=False)\n",
        "    print(f\"✅ Encoded embeddings saved to: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBAlDrOpe_vz"
      },
      "source": [
        "# **FAISS Similarity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "CyG7ztCne_vz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import faiss\n",
        "import time\n",
        "\n",
        "def load_embeddings(src_emb_path, tgt_emb_path):\n",
        "    \"\"\"\n",
        "    Load the embeddings for the source and target ontologies from TSV files.\n",
        "\n",
        "    Args:\n",
        "        src_emb_path (str): Path to the source embeddings file.\n",
        "        tgt_emb_path (str): Path to the target embeddings file.\n",
        "\n",
        "    Returns:\n",
        "        uris_src (np.ndarray): URIs of source entities.\n",
        "        uris_tgt (np.ndarray): URIs of target entities.\n",
        "        src_vecs (np.ndarray): Embedding vectors for source entities.\n",
        "        tgt_vecs (np.ndarray): Embedding vectors for target entities.\n",
        "    \"\"\"\n",
        "    df_src = pd.read_csv(src_emb_path, sep='\\t')  # Read source embeddings\n",
        "    df_tgt = pd.read_csv(tgt_emb_path, sep='\\t')  # Read target embeddings\n",
        "    uris_src = df_src[\"Concept\"].values           # Extract source URIs\n",
        "    uris_tgt = df_tgt[\"Concept\"].values           # Extract target URIs\n",
        "    src_vecs = df_src.drop(columns=[\"Concept\"]).values.astype('float32')  # Extract and convert source vectors\n",
        "    tgt_vecs = df_tgt.drop(columns=[\"Concept\"]).values.astype('float32')  # Extract and convert target vectors\n",
        "    return uris_src, uris_tgt, src_vecs, tgt_vecs\n",
        "\n",
        "def save_results(uris_src, uris_tgt, indices, scores, output_file, top_k):\n",
        "    \"\"\"\n",
        "    Save the top-k mapping results to a TSV file.\n",
        "\n",
        "    Args:\n",
        "        uris_src (np.ndarray): URIs of source entities.\n",
        "        uris_tgt (np.ndarray): URIs of target entities.\n",
        "        indices (np.ndarray): Indices of top-k matched target entities.\n",
        "        scores (np.ndarray): Corresponding similarity scores.\n",
        "        output_file (str): Output TSV file path.\n",
        "        top_k (int): Number of top matches per source entity.\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for i, (ind_row, score_row) in enumerate(zip(indices, scores)):\n",
        "        src_uri = uris_src[i]\n",
        "        for j, tgt_idx in enumerate(ind_row):\n",
        "            tgt_uri = uris_tgt[tgt_idx]\n",
        "            score = score_row[j]\n",
        "            rows.append((src_uri, tgt_uri, score))  # Store each top-k match\n",
        "    df_result = pd.DataFrame(rows, columns=[\"SrcEntity\", \"TgtEntity\", \"Score\"])\n",
        "    df_result.to_csv(output_file, sep='\\t', index=False)  # Save to file\n",
        "    print(f\"Top-{top_k} FAISS similarity results saved to: {output_file}\")\n",
        "\n",
        "def topk_faiss_l2(src_emb_path, tgt_emb_path, top_k=15, output_file=\"topk_l2.tsv\"):\n",
        "    \"\"\"\n",
        "    Compute the top-k most similar target entities for each source entity using FAISS with L2 distance.\n",
        "\n",
        "    Args:\n",
        "        src_emb_path (str): Path to the source embeddings file.\n",
        "        tgt_emb_path (str): Path to the target embeddings file.\n",
        "        top_k (int): Number of top matches to retrieve.\n",
        "        output_file (str): Path to save the top-k results.\n",
        "    \"\"\"\n",
        "    print(\"🔹 Using L2 (Euclidean) distance with FAISS\")\n",
        "    start = time.time()  # Start timing\n",
        "\n",
        "    # Load embeddings\n",
        "    uris_src, uris_tgt, src_vecs, tgt_vecs = load_embeddings(src_emb_path, tgt_emb_path)\n",
        "\n",
        "    # Build FAISS index using L2 distance\n",
        "    dim = src_vecs.shape[1]\n",
        "    index = faiss.IndexFlatL2(dim)  # Create FAISS index for L2 distance\n",
        "    index.add(tgt_vecs)             # Add target vectors to index\n",
        "\n",
        "    # Perform nearest neighbor search\n",
        "    distances, indices = index.search(src_vecs, top_k)\n",
        "\n",
        "    # Convert distances to similarity scores (optional: inverse of distance)\n",
        "    similarity_scores = 1 / (1 + distances)\n",
        "\n",
        "    # Save the results\n",
        "    save_results(uris_src, uris_tgt, indices, similarity_scores, output_file, top_k)\n",
        "\n",
        "    # Display execution time\n",
        "    print(f\"⏱️ Execution time: {time.time() - start:.2f} seconds\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zq0p_64e_vz"
      },
      "source": [
        "# **Mappings Evaluation Functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "repA9zGMe_vz"
      },
      "source": [
        "# **Precision, Recall, F1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GW0Am-TmVMR"
      },
      "source": [
        "### Evaluation Strategy and Filtering Justification\n",
        "\n",
        "### Filtering Justification\n",
        "\n",
        "In the `evaluate_predictions` function, two important filtering steps are applied to ensure that the evaluation metrics (such as Precision, Recall, and F1-score) accurately reflect the model's performance:\n",
        "\n",
        "\n",
        "#### 1. Filtering Out Training-Only Entities\n",
        "\n",
        "We remove all predicted mappings involving source or target entities that are present **only in the training set** and not in the test set.\n",
        "\n",
        "This step is critical because:\n",
        "\n",
        "- In some datasets like **Bio-ML**, the same entity can appear in both training and test sets, although with **different correspondences**.\n",
        "- If we don't remove training-only entities, it can lead to **label leakage** and **metric distortion**.\n",
        "\n",
        "#### 2. Filtering on `SrcEntity` present in the test set\n",
        "\n",
        "The second step keeps only the predictions where the `SrcEntity` is included in the test reference set.\n",
        "\n",
        "- This eliminates **non-evaluable false positives**, i.e., predicted mappings for source entities that do not appear in the test set and therefore have no ground-truth correspondences. Including such predictions **unfairly penalizes precision and F1-score**, even though they are technically not verifiable errors.\n",
        "\n",
        "- It focuses the evaluation on entities with defined ground-truth mappings, which is critical for computing metrics such as :\n",
        "\n",
        "$P_{\\text{test}} = \\frac{|\\mathcal{M}_{\\text{out}} \\cap \\mathcal{M}_{\\text{test}}|}{|\\mathcal{M}_{\\text{out}} \\setminus (\\mathcal{M}_{\\text{ref}} \\setminus \\mathcal{M}_{\\text{test}})|}$.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "eOQkhXEVOQDT"
      },
      "outputs": [],
      "source": [
        "def select_best_candidates_per_src_with_margin(df, score_margin=0.01):\n",
        "    \"\"\"\n",
        "    For each SrcEntity, retain all candidate mappings whose similarity score is\n",
        "    within 99% of the best score (default margin = 0.01).\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing columns ['SrcEntity', 'TgtEntity', 'Score'].\n",
        "        score_margin (float): Score margin. 0.01 means keep scores ≥ 99% of best score.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Filtered DataFrame with multiple high-quality candidates per SrcEntity.\n",
        "    \"\"\"\n",
        "    selected_rows = []\n",
        "\n",
        "    for src, group in df.groupby(\"SrcEntity\"):\n",
        "        group_sorted = group.sort_values(by=\"Score\", ascending=False)\n",
        "        best_score = group_sorted.iloc[0][\"Score\"]\n",
        "        threshold = best_score * (1 - score_margin)\n",
        "\n",
        "        # Keep all target entities with score >= threshold\n",
        "        close_matches = group_sorted[group_sorted[\"Score\"] >= threshold]\n",
        "        selected_rows.append(close_matches)\n",
        "\n",
        "    result_df = pd.concat(selected_rows).reset_index(drop=True)\n",
        "    print(f\"🏆 Selected candidates within {(1 - score_margin) * 100:.1f}% of best score per SrcEntity: {len(result_df)} rows\")\n",
        "    return result_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "-4deIPBfOQDU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "def evaluate_predictions(\n",
        "    pred_file, train_file, test_file,\n",
        "    threshold=0.0, margin_ratio=0.997\n",
        "):\n",
        "    \"\"\"\n",
        "    Evaluate predicted mappings by applying filtering, thresholding, top-1 selection with margin,\n",
        "    and computing precision, recall, and F1-score against the test set.\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 1: Load prediction, train, and test data\n",
        "    df = pd.read_csv(pred_file, sep='\\t')\n",
        "    train_df = pd.read_csv(train_file, sep='\\t')\n",
        "    test_df = pd.read_csv(test_file, sep='\\t')\n",
        "    print(f\"🔍 Initial file: {len(df)} rows\")\n",
        "\n",
        "    # Step 2: Remove entities that appear only in the training set\n",
        "    train_uris = set(train_df['SrcEntity']) | set(train_df['TgtEntity'])\n",
        "    test_uris = set(test_df['SrcEntity']) | set(test_df['TgtEntity'])\n",
        "    uris_to_exclude = train_uris - test_uris\n",
        "    df = df[~df['SrcEntity'].isin(uris_to_exclude) & ~df['TgtEntity'].isin(uris_to_exclude)]\n",
        "    print(f\"✅ After removing train-only URIs: {len(df)} rows\")\n",
        "\n",
        "    # Step 3: Keep only predictions where SrcEntity is part of the test set\n",
        "    test_src_entities = set(test_df['SrcEntity'])\n",
        "    df = df[df['SrcEntity'].isin(test_src_entities)]\n",
        "    print(f\"✅ After keeping only test SrcEntities: {len(df)} rows\")\n",
        "\n",
        "    # Step 4: Apply a minimum score threshold\n",
        "    df = df[df[\"Score\"] >= threshold]\n",
        "    print(f\"✅ After applying threshold ≥ {threshold}: {len(df)} rows\")\n",
        "\n",
        "    # Step 5: Save filtered predictions to file\n",
        "    output_file_all = pred_file.replace(\".tsv\", f\"_filtered.tsv\")\n",
        "    df.to_csv(output_file_all, sep='\\t', index=False)\n",
        "    print(f\"📁 Filtered predictions saved: {output_file_all}\")\n",
        "\n",
        "    # Step 6: Select best predictions per SrcEntity using a relaxed top-1 margin\n",
        "    df_top1 = select_best_candidates_per_src_with_margin(df, score_margin=0.0075)\n",
        "\n",
        "    # Step 7: Save the top-1 filtered predictions\n",
        "    output_file_top1 = pred_file.replace(\".tsv\", f\"_filtered_top1_th{threshold}.tsv\")\n",
        "    df_top1.to_csv(output_file_top1, sep='\\t', index=False)\n",
        "    print(f\"📁 Filtered Top-1 file saved: {output_file_top1}\")\n",
        "\n",
        "    # Step 8: Evaluate using gold standard test mappings\n",
        "    preds = EntityMapping.read_table_mappings(output_file_top1)   # Read predicted mappings\n",
        "    refs = ReferenceMapping.read_table_mappings(test_file)        # Read reference (gold standard) mappings\n",
        "\n",
        "    results = AlignmentEvaluator.f1(preds, refs)  # Compute precision, recall, and F1\n",
        "\n",
        "    # Optional: Count correct predictions (intersection)\n",
        "    preds2 = [p.to_tuple() for p in preds]\n",
        "    refs2 = [r.to_tuple() for r in refs]\n",
        "    correct = len(set(preds2).intersection(set(refs2)))\n",
        "\n",
        "    print(f\"🎯 Correct mappings (Top-1): {correct}\")\n",
        "    print(f\"📊 Evaluation (P / R / F1): {results}\")\n",
        "\n",
        "    return output_file_top1, results, correct\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVyzng3Pe_v0"
      },
      "source": [
        "# **Precision@k, Recall@k, F1@k**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "FstoSsHPe_v0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "def evaluate_topk(topk_file, train_file, test_file, k=1, threshold=0.0):\n",
        "    \"\"\"\n",
        "    Evaluate Top-K predictions using Precision, Recall, and F1-score,\n",
        "    after filtering out training-only URIs, keeping only test sources, and applying 1-1 constraint.\n",
        "\n",
        "    Args:\n",
        "        topk_file (str): Path to the top-k prediction file (TSV with SrcEntity, TgtEntity, Score)\n",
        "        train_file (str): Path to the training mappings file (TSV)\n",
        "        test_file (str): Path to the test mappings file (TSV)\n",
        "        k (int): Value of K for top-k evaluation\n",
        "        threshold (float): Minimum score to consider a prediction valid\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing Precision@K, Recall@K, and F1@K\n",
        "    \"\"\"\n",
        "\n",
        "    # === Step 1: Load input files ===\n",
        "    df = pd.read_csv(topk_file, sep='\\t', dtype=str)\n",
        "    train_df = pd.read_csv(train_file, sep='\\t', dtype=str)\n",
        "    test_df = pd.read_csv(test_file, sep='\\t', dtype=str)\n",
        "\n",
        "    # === Step 2: Remove URIs only present in the training set ===\n",
        "    train_uris = set(train_df['SrcEntity']) | set(train_df['TgtEntity'])\n",
        "    test_uris = set(test_df['SrcEntity']) | set(test_df['TgtEntity'])\n",
        "    uris_to_exclude = train_uris - test_uris\n",
        "    df = df[~(df['SrcEntity'].isin(uris_to_exclude) | df['TgtEntity'].isin(uris_to_exclude))].reset_index(drop=True)\n",
        "\n",
        "    # === Step 3: Keep only source entities from the test set ===\n",
        "    src_entities_test = set(test_df['SrcEntity'])\n",
        "    df = df[df['SrcEntity'].isin(src_entities_test)].reset_index(drop=True)\n",
        "\n",
        "    # === Step 4: Convert score column to float and sort ===\n",
        "    df['Score'] = df['Score'].apply(lambda x: float(x.strip(\"[]\")) if isinstance(x, str) else float(x))\n",
        "    df_sorted = df.sort_values(by='Score', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    # === Step 5: Apply 1-to-1 constraint (greedy strategy with optional threshold)\n",
        "    matched_sources = set()\n",
        "    matched_targets = set()\n",
        "    result = []\n",
        "\n",
        "    for _, row in df_sorted.iterrows():\n",
        "        src, tgt, score = row['SrcEntity'], row['TgtEntity'], row['Score']\n",
        "        if src not in matched_sources and tgt not in matched_targets and score >= threshold:\n",
        "            result.append((src, tgt, score))\n",
        "            matched_sources.add(src)\n",
        "            matched_targets.add(tgt)\n",
        "\n",
        "    # === Step 6: Create and save Top-K prediction dataframe\n",
        "    matching_results_df = pd.DataFrame(result, columns=['SrcEntity', 'TgtEntity', 'Score'])\n",
        "    output_file = topk_file.replace(\".tsv\", \"_predictions.tsv\")\n",
        "    matching_results_df.to_csv(output_file, sep='\\t', index=False)\n",
        "\n",
        "    # === Step 7: Build reference dictionary from test set\n",
        "    ref_dict = defaultdict(set)\n",
        "    for _, row in test_df.iterrows():\n",
        "        ref_dict[row['SrcEntity']].add(row['TgtEntity'])\n",
        "\n",
        "    # === Step 8: Select Top-K predictions for each source entity\n",
        "    matching_results_df['Score'] = matching_results_df['Score'].astype(float)\n",
        "    topk_df = matching_results_df.sort_values(by='Score', ascending=False).groupby('SrcEntity').head(k)\n",
        "\n",
        "    # === Step 9: Compute Precision@K, Recall@K, F1@K\n",
        "    total_tp = total_pred = total_ref = 0\n",
        "\n",
        "    for src, group in topk_df.groupby('SrcEntity'):\n",
        "        predicted = set(group['TgtEntity'])\n",
        "        true = ref_dict.get(src, set())\n",
        "        tp = len(predicted & true)\n",
        "        total_tp += tp\n",
        "        total_pred += len(predicted)\n",
        "        total_ref += len(true)\n",
        "\n",
        "    precision = total_tp / total_pred if total_pred else 0.0\n",
        "    recall = total_tp / total_ref if total_ref else 0.0\n",
        "    f1 = 2 * precision * recall / (precision + recall + 1e-8) if precision + recall > 0 else 0.0\n",
        "\n",
        "    # === Step 10: Print metrics\n",
        "\n",
        "    print(f\"📊 Precision@{k}:            {precision:.3f}\")\n",
        "    print(f\"📊 Recall@{k}:               {recall:.3f}\")\n",
        "    print(f\"📊 F1@{k}:                   {f1:.3f}\\n\")\n",
        "\n",
        "    return {\n",
        "        f'Precision@{k}': round(precision, 3),\n",
        "        f'Recall@{k}': round(recall, 3),\n",
        "        f'F1@{k}': round(f1, 3)\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HyWMsw1MVhz"
      },
      "source": [
        "# **Main Code**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC37FlwGDqGM"
      },
      "source": [
        "\n",
        "\n",
        "# Reading semantic node embeddings provided by the ENE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "FuEfSnw5mod0"
      },
      "outputs": [],
      "source": [
        "# Read the source embeddings from a CSV file into a pandas DataFrame\n",
        "df_embbedings_src = pd.read_csv(src_Emb, index_col=0)\n",
        "\n",
        "# Convert the DataFrame to a NumPy array, which will remove the index and store the data as a raw matrix\n",
        "numpy_array = df_embbedings_src.to_numpy()\n",
        "\n",
        "# Convert the NumPy array into a PyTorch FloatTensor, which is the format required for PyTorch operations\n",
        "x_src = torch.FloatTensor(numpy_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "STUwqMUXmlG2"
      },
      "outputs": [],
      "source": [
        "# Read the target embeddings from a CSV file into a pandas DataFrame\n",
        "df_embbedings_tgt = pd.read_csv(tgt_Emb, index_col=0)\n",
        "\n",
        "# Convert the DataFrame to a NumPy array, which removes the index and converts the data to a raw matrix\n",
        "numpy_array = df_embbedings_tgt.to_numpy()\n",
        "\n",
        "# Convert the NumPy array into a PyTorch FloatTensor, which is required for PyTorch operations\n",
        "x_tgt = torch.FloatTensor(numpy_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZIu9P08DqGN"
      },
      "source": [
        "# Reading adjacency Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "pH69Up40mycz"
      },
      "outputs": [],
      "source": [
        "# Read the source adjacency matrix from a CSV file into a pandas DataFrame\n",
        "df_ma1 = pd.read_csv(src_Adjacence, index_col=0)\n",
        "\n",
        "# Convert the DataFrame to a list of lists (Python native list format)\n",
        "ma1 = df_ma1.values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "hYCmAO5Ymzpl"
      },
      "outputs": [],
      "source": [
        "# Read the target adjacency matrix from a CSV file into a pandas DataFrame\n",
        "df_ma2 = pd.read_csv(tgt_Adjacence, index_col=0)\n",
        "\n",
        "# Convert the DataFrame to a list of lists (Python native list format)\n",
        "ma2 = df_ma2.values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSyksqh3TrU-"
      },
      "source": [
        "# Convert Adjacency matrix (in list format) to an undirected edge index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "uVt-Pce5m5ll"
      },
      "outputs": [],
      "source": [
        "# Convert the source adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n",
        "edge_src = adjacency_matrix_to_undirected_edge_index(ma1)\n",
        "\n",
        "# Convert the target adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n",
        "edge_tgt = adjacency_matrix_to_undirected_edge_index(ma2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9wMTRdqT4aY"
      },
      "source": [
        "# GIT Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "eqiEKCLSMVh3"
      },
      "outputs": [],
      "source": [
        "def train_model_gnn(model, x_src, edge_src, x_tgt, edge_tgt,\n",
        "                    tensor_term1, tensor_term2, tensor_score,\n",
        "                    learning_rate, weight_decay_value, num_epochs, print_interval=10):\n",
        "    \"\"\"\n",
        "    Trains a graph neural network (GNN) model using source and target embeddings and contrastive loss.\n",
        "\n",
        "    Args:\n",
        "        model: The GNN model to be trained.\n",
        "        x_src (torch.Tensor): Source node embeddings.\n",
        "        edge_src (torch.Tensor): Source graph edges.\n",
        "        x_tgt (torch.Tensor): Target node embeddings.\n",
        "        edge_tgt (torch.Tensor): Target graph edges.\n",
        "        tensor_term1 (torch.Tensor): Indices of the source nodes to be compared.\n",
        "        tensor_term2 (torch.Tensor): Indices of the target nodes to be compared.\n",
        "        tensor_score (torch.Tensor): Labels indicating if the pairs are matched (1) or not (0).\n",
        "        learning_rate (float): Learning rate for the optimizer.\n",
        "        weight_decay_value (float): Weight decay (L2 regularization) value for the optimizer.\n",
        "        num_epochs (int): Number of epochs for training.\n",
        "        print_interval (int): Interval at which training progress is printed (every `print_interval` epochs).\n",
        "\n",
        "    Returns:\n",
        "        model: The trained GNN model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 1: Set device (GPU or CPU) for computation\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Step 2: Move the model and all inputs to the selected device\n",
        "    model.to(device)\n",
        "    x_tgt = x_tgt.to(device)               # Target node embeddings\n",
        "    edge_tgt = edge_tgt.to(device)         # Target graph edges\n",
        "    x_src = x_src.to(device)               # Source node embeddings\n",
        "    edge_src = edge_src.to(device)         # Source graph edges\n",
        "    tensor_term1 = tensor_term1.to(device) # Indices for source nodes\n",
        "    tensor_term2 = tensor_term2.to(device) # Indices for target nodes\n",
        "    tensor_score = tensor_score.to(device) # Ground truth labels\n",
        "\n",
        "    # Step 3: Define optimizer with learning rate and regularization\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay_value)\n",
        "\n",
        "    # Step 4: Initialize list to store training losses\n",
        "    train_losses = []\n",
        "\n",
        "    # Record the start time of training\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Step 5: Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        # Zero out gradients from the previous iteration\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass: Compute embeddings for source and target graphs\n",
        "        out1 = model(x_src, edge_src)  # Updated source embeddings\n",
        "        out2 = model(x_tgt, edge_tgt)  # Updated target embeddings\n",
        "\n",
        "        # Extract specific rows of embeddings for terms being compared\n",
        "        src_embeddings = select_rows_by_index(out1, tensor_term1)\n",
        "        tgt_embeddings = select_rows_by_index(out2, tensor_term2)\n",
        "\n",
        "        # Compute contrastive loss based on the embeddings and ground truth labels\n",
        "        loss = contrastive_loss(src_embeddings, tgt_embeddings, tensor_score)\n",
        "\n",
        "        # Backward pass: Compute gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the model's parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Append the loss for this iteration to the list\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        # Print loss every `print_interval` epochs\n",
        "        if (epoch + 1) % print_interval == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item()}\")\n",
        "\n",
        "    # Step 6: Record end time of training\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Step 7: Plot the training loss over time\n",
        "    plt.semilogy(range(1, num_epochs + 1), train_losses, label=\"Training Loss\", marker='o')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Print the total training time\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training complete! Total training time: {training_time:.2f} seconds\")\n",
        "\n",
        "    # Step 8: Return the trained model\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "6_tzUG_emtBg"
      },
      "outputs": [],
      "source": [
        "# Initialize the GIT_mod model with the dimensionality of the target embeddings\n",
        "# The first argument is the dimensionality of the target node embeddings (x_tgt.shape[1])\n",
        "# The second argument (1) represents the number of RGIT layers in the model\n",
        "GIT_model = RGIT_mod(x_tgt.shape[1], 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "wVo-s7UQssSp"
      },
      "outputs": [],
      "source": [
        "# Reading the training pairs from a CSV file into a pandas DataFrame\n",
        "df_embbedings = pd.read_csv(train_file, index_col=0)\n",
        "\n",
        "# Extract the 'SrcEntity' and 'TgtEntity' columns as NumPy arrays and convert them to integers\n",
        "tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)  # Source entity indices\n",
        "tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)  # Target entity indices\n",
        "\n",
        "# Extract the 'Score' column as a NumPy array and convert it to floats\n",
        "tensor_score = df_embbedings['Score'].values.astype(float)  # Scores (labels) indicating if pairs match (1) or not (0)\n",
        "\n",
        "# Convert the NumPy arrays to PyTorch LongTensors (for indices) and FloatTensors (for scores)\n",
        "tensor_term1_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)  # Source entity tensor\n",
        "tensor_term2_o = torch.from_numpy(tensor_term2).type(torch.LongTensor)  # Target entity tensor\n",
        "tensor_score_o = torch.from_numpy(tensor_score).type(torch.FloatTensor)  # Score tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "agHlFNesMVh3",
        "outputId": "7692e9b3-568f-4c52-dfc9-b8d809ae6231"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/1000], Training Loss: 0.0016867590602487326\n",
            "Epoch [20/1000], Training Loss: 0.0014249199302867055\n",
            "Epoch [30/1000], Training Loss: 0.001271699438802898\n",
            "Epoch [40/1000], Training Loss: 0.0011652997927740216\n",
            "Epoch [50/1000], Training Loss: 0.001082856673747301\n",
            "Epoch [60/1000], Training Loss: 0.00101495033595711\n",
            "Epoch [70/1000], Training Loss: 0.0009573315619491041\n",
            "Epoch [80/1000], Training Loss: 0.0009078149450942874\n",
            "Epoch [90/1000], Training Loss: 0.0008644377230666578\n",
            "Epoch [100/1000], Training Loss: 0.0008266025688499212\n",
            "Epoch [110/1000], Training Loss: 0.000793218205217272\n",
            "Epoch [120/1000], Training Loss: 0.0007636856753379107\n",
            "Epoch [130/1000], Training Loss: 0.0007372652180492878\n",
            "Epoch [140/1000], Training Loss: 0.0007136408821679652\n",
            "Epoch [150/1000], Training Loss: 0.0006922135944478214\n",
            "Epoch [160/1000], Training Loss: 0.000673093250952661\n",
            "Epoch [170/1000], Training Loss: 0.0006558924214914441\n",
            "Epoch [180/1000], Training Loss: 0.0006405109888873994\n",
            "Epoch [190/1000], Training Loss: 0.0006267466815188527\n",
            "Epoch [200/1000], Training Loss: 0.0006144504877738655\n",
            "Epoch [210/1000], Training Loss: 0.0006034258985891938\n",
            "Epoch [220/1000], Training Loss: 0.0005934827495366335\n",
            "Epoch [230/1000], Training Loss: 0.0005844515399076045\n",
            "Epoch [240/1000], Training Loss: 0.0005762512446381152\n",
            "Epoch [250/1000], Training Loss: 0.0005687515367753804\n",
            "Epoch [260/1000], Training Loss: 0.0005618234281428158\n",
            "Epoch [270/1000], Training Loss: 0.000555451144464314\n",
            "Epoch [280/1000], Training Loss: 0.0005494101205840707\n",
            "Epoch [290/1000], Training Loss: 0.0005437158397398889\n",
            "Epoch [300/1000], Training Loss: 0.0005383645184338093\n",
            "Epoch [310/1000], Training Loss: 0.0005333204753696918\n",
            "Epoch [320/1000], Training Loss: 0.0005284098442643881\n",
            "Epoch [330/1000], Training Loss: 0.0005237188888713717\n",
            "Epoch [340/1000], Training Loss: 0.0005192182725295424\n",
            "Epoch [350/1000], Training Loss: 0.0005148718482814729\n",
            "Epoch [360/1000], Training Loss: 0.0005106652388349175\n",
            "Epoch [370/1000], Training Loss: 0.0005065706791356206\n",
            "Epoch [380/1000], Training Loss: 0.00050260842544958\n",
            "Epoch [390/1000], Training Loss: 0.0004987625870853662\n",
            "Epoch [400/1000], Training Loss: 0.0004950081929564476\n",
            "Epoch [410/1000], Training Loss: 0.0004913680604659021\n",
            "Epoch [420/1000], Training Loss: 0.0004877504543401301\n",
            "Epoch [430/1000], Training Loss: 0.00048417854122817516\n",
            "Epoch [440/1000], Training Loss: 0.0004807094519492239\n",
            "Epoch [450/1000], Training Loss: 0.00047730165533721447\n",
            "Epoch [460/1000], Training Loss: 0.0004739688301924616\n",
            "Epoch [470/1000], Training Loss: 0.00047072613961063325\n",
            "Epoch [480/1000], Training Loss: 0.00046749060857109725\n",
            "Epoch [490/1000], Training Loss: 0.0004642901767510921\n",
            "Epoch [500/1000], Training Loss: 0.0004611597687471658\n",
            "Epoch [510/1000], Training Loss: 0.0004580702807288617\n",
            "Epoch [520/1000], Training Loss: 0.0004550460434984416\n",
            "Epoch [530/1000], Training Loss: 0.0004520622605923563\n",
            "Epoch [540/1000], Training Loss: 0.000449119572294876\n",
            "Epoch [550/1000], Training Loss: 0.0004461861390154809\n",
            "Epoch [560/1000], Training Loss: 0.0004433352150954306\n",
            "Epoch [570/1000], Training Loss: 0.00044045731192454696\n",
            "Epoch [580/1000], Training Loss: 0.00043766223825514317\n",
            "Epoch [590/1000], Training Loss: 0.00043488055234774947\n",
            "Epoch [600/1000], Training Loss: 0.000432205677498132\n",
            "Epoch [610/1000], Training Loss: 0.000429572508437559\n",
            "Epoch [620/1000], Training Loss: 0.00042710360139608383\n",
            "Epoch [630/1000], Training Loss: 0.0004246557073201984\n",
            "Epoch [640/1000], Training Loss: 0.0004222612187732011\n",
            "Epoch [650/1000], Training Loss: 0.0004198883252684027\n",
            "Epoch [660/1000], Training Loss: 0.00041762684122659266\n",
            "Epoch [670/1000], Training Loss: 0.0004153707413934171\n",
            "Epoch [680/1000], Training Loss: 0.00041325268102809787\n",
            "Epoch [690/1000], Training Loss: 0.0004111297312192619\n",
            "Epoch [700/1000], Training Loss: 0.000409047759603709\n",
            "Epoch [710/1000], Training Loss: 0.000406976934755221\n",
            "Epoch [720/1000], Training Loss: 0.00040496038855053484\n",
            "Epoch [730/1000], Training Loss: 0.00040298537351191044\n",
            "Epoch [740/1000], Training Loss: 0.0004009926924481988\n",
            "Epoch [750/1000], Training Loss: 0.0003991019038949162\n",
            "Epoch [760/1000], Training Loss: 0.0003971070400439203\n",
            "Epoch [770/1000], Training Loss: 0.00039525795727968216\n",
            "Epoch [780/1000], Training Loss: 0.00039323436794802547\n",
            "Epoch [790/1000], Training Loss: 0.00039133086102083325\n",
            "Epoch [800/1000], Training Loss: 0.00038921379018574953\n",
            "Epoch [810/1000], Training Loss: 0.0003871962835546583\n",
            "Epoch [820/1000], Training Loss: 0.0003850343346130103\n",
            "Epoch [830/1000], Training Loss: 0.0003829471243079752\n",
            "Epoch [840/1000], Training Loss: 0.00038084283005446196\n",
            "Epoch [850/1000], Training Loss: 0.00037916417932137847\n",
            "Epoch [860/1000], Training Loss: 0.0003770686744246632\n",
            "Epoch [870/1000], Training Loss: 0.000375332630937919\n",
            "Epoch [880/1000], Training Loss: 0.00037370389327406883\n",
            "Epoch [890/1000], Training Loss: 0.00037200917722657323\n",
            "Epoch [900/1000], Training Loss: 0.0003705682174768299\n",
            "Epoch [910/1000], Training Loss: 0.0003688119468279183\n",
            "Epoch [920/1000], Training Loss: 0.0003672716848086566\n",
            "Epoch [930/1000], Training Loss: 0.0003656319750007242\n",
            "Epoch [940/1000], Training Loss: 0.0003639917995315045\n",
            "Epoch [950/1000], Training Loss: 0.0003624535456765443\n",
            "Epoch [960/1000], Training Loss: 0.00036104413447901607\n",
            "Epoch [970/1000], Training Loss: 0.00035962811671197414\n",
            "Epoch [980/1000], Training Loss: 0.0003582517383620143\n",
            "Epoch [990/1000], Training Loss: 0.0003569535620044917\n",
            "Epoch [1000/1000], Training Loss: 0.00035570719046518207\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAloAAAGwCAYAAABxbMuTAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAARcdJREFUeJzt3XtclGX+//H3zHBGDiIKouIpT6jhmczUUkutKLW235a16O43N1PLzMq2TTus2m5tWcpqtZW7ZWntplnZwbQ0XQtTMUlFK1ILwUwRARWYuX9/uMyKogww53k9Hw8eD7nnmns+c4vM2+u67usyGYZhCAAAAE5n9nQBAAAA/oqgBQAA4CIELQAAABchaAEAALgIQQsAAMBFCFoAAAAuQtACAABwkSBPFxDIbDab8vPzFRUVJZPJ5OlyAACAAwzD0PHjx5WUlCSz+cJ9VgQtD8rPz1erVq08XQYAAKiHAwcOqGXLlhdsQ9DyoKioKEmn/6Kio6M9XA0AAHBEcXGxWrVqZf8cvxCClgdVDRdGR0cTtAAA8DGOTPthMjwAAICLELQAAABchKAFAADgIszRAgAEJKvVqoqKCk+XAS8VEhJS69INjiBoAQACimEYKigoUFFRkadLgRczm81q27atQkJCGnQeghYAIKBUhaxmzZopIiKCBaNxjqoFxQ8ePKjk5OQG/YwQtAAAAcNqtdpDVpMmTTxdDrxY06ZNlZ+fr8rKSgUHB9f7PEyGBwAEjKo5WRERER6uBN6uasjQarU26DwELQBAwGG4ELVx1s8IQ4d+yGozlJV3RIeOn1SzqDD1axsni5lfKgAAuBtBy898mHNQj767UwePnbQfax4TplnpKRrRrbkHKwMAIPAwdOhHPsw5qImvba0WsiSp4NhJTXxtqz7MOeihygDAv1hthjZ994veyf5Jm777RVab4emS6qxNmzaaN2+ew+0/++wzmUwmlsWoI3q0/ITVZujRd3eqpn/qhiSTpEff3akrUxIZRgSABnD3yEFtc4VmzZqlRx55pM7n3bx5syIjIx1uf+mll+rgwYOKiYmp82vVxWeffaYrrrhCR48eVWxsrEtfyx0IWn4iK+/IOT1ZZzIkHTx2Ull5R9S/Pbc0A0B9VI0cnP2f2qqRg4W39nJ62Dp48H+jEcuWLdPMmTOVm5trP9aoUSP7nw3DkNVqVVBQ7R/vTZs2rVMdISEhSkxMrNNzwNCh3zh0/Pwhqz7tACAQGIahsvJKh76On6zQrJXfnHfkQJIeWblTx09WOHQ+w3BsuDExMdH+FRMTI5PJZP9+9+7dioqK0gcffKDevXsrNDRUGzZs0Hfffafrr79eCQkJatSokfr27atPPvmk2nnPHjo0mUz6+9//rtGjRysiIkIdOnTQypUr7Y+fPXS4ePFixcbG6qOPPlKXLl3UqFEjjRgxolowrKys1F133aXY2Fg1adJEDzzwgDIyMjRq1CiH3ntNjh49qt/85jdq3LixIiIiNHLkSO3du9f++L59+5Senq7GjRsrMjJSXbt21apVq+zPHTt2rJo2barw8HB16NBBr7zySr1rcQQ9Wn6iWVSYU9sBQCA4UWFVysyPnHIuQ1JB8Ul1f+Rjh9rvfGy4IkKc8zE8Y8YMPfXUU2rXrp0aN26sAwcO6Oqrr9bs2bMVGhqqf/7zn0pPT1dubq6Sk5PPe55HH31Uf/nLX/Tkk09q/vz5Gjt2rPbt26e4uLga25eVlempp57Sq6++KrPZrFtvvVXTp0/XkiVLJEl//vOftWTJEr3yyivq0qWLnn32Wa1YsUJXXHFFvd/ruHHjtHfvXq1cuVLR0dF64IEHdPXVV2vnzp0KDg7WpEmTVF5ervXr1ysyMlI7d+609/o9/PDD2rlzpz744APFx8fr22+/1YkTJ+pdiyMIWn6iX9s4NY8JU8GxkzX+b8skKTHm9FIPAAD/8thjj+nKK6+0fx8XF6fU1FT7948//riWL1+ulStXavLkyec9z7hx43TzzTdLkubMmaPnnntOWVlZGjFiRI3tKyoqtGjRIrVv316SNHnyZD322GP2x+fPn68HH3xQo0ePliQtWLDA3rtUH1UBa+PGjbr00kslSUuWLFGrVq20YsUK/epXv9L+/ft1ww03qHv37pKkdu3a2Z+/f/9+9ezZU3369JF0ulfP1QhafsJiNmlWeoomvrZVJqla2KqaRjkrPYWJ8ABwhvBgi3Y+Ntyhtll5RzTulc21tls8vq9D/6kND7Y49LqOqAoOVUpKSvTII4/o/fff18GDB1VZWakTJ05o//79FzzPxRdfbP9zZGSkoqOjdejQofO2j4iIsIcsSWrevLm9/bFjx1RYWKh+/frZH7dYLOrdu7dsNlud3l+VXbt2KSgoSGlpafZjTZo0UadOnbRr1y5J0l133aWJEyfq448/1rBhw3TDDTfY39fEiRN1ww03aOvWrbrqqqs0atQoe2BzFeZo+ZER3Zpr4a29lBhTfXgwMSbMJRM0AcDXmUwmRYQEOfQ1sENTNY8J0/n+u2rS6bsPB3Zo6tD5nLk6/dl3D06fPl3Lly/XnDlz9Pnnnys7O1vdu3dXeXn5Bc9z9p5+JpPpgqGopvaOzj1zlf/7v//T999/r9tuu007duxQnz59NH/+fEnSyJEjtW/fPt1zzz3Kz8/X0KFDNX36dJfWQ9DyMyO6NdeGB4YoLPj0X+0zN6VqwwNDCFkA0EBVIweSzglb3jZysHHjRo0bN06jR49W9+7dlZiYqB9++MGtNcTExCghIUGbN/+vF9BqtWrr1q31PmeXLl1UWVmpL7/80n7sl19+UW5urlJSUuzHWrVqpTvuuENvv/227r33Xr344ov2x5o2baqMjAy99tprmjdvnl544YV61+MIhg79kMV8+n9oJyvK1bVFjFf8owcAf1A1cnD2OlqJXrYDR4cOHfT2228rPT1dJpNJDz/8cL2H6xpiypQpmjt3ri666CJ17txZ8+fP19GjRx3qzduxY4eioqLs35tMJqWmpur666/X7bffrueff15RUVGaMWOGWrRooeuvv16SNHXqVI0cOVIdO3bU0aNH9emnn6pLly6SpJkzZ6p3797q2rWrTp06pffee8/+mKsQtPxUsOX0D3F5pfv/YQGAPxvRrbmuTEn06j1ln376af32t7/VpZdeqvj4eD3wwAMqLi52ex0PPPCACgoK9Jvf/EYWi0UTJkzQ8OHDZbHUPj9t0KBB1b63WCyqrKzUK6+8orvvvlvXXnutysvLNWjQIK1atco+jGm1WjVp0iT9+OOPio6O1ogRI/TMM89IOr0W2IMPPqgffvhB4eHhGjhwoJYuXer8N34Gk+HpwdQAVlxcrJiYGB07dkzR0dFOPffAv6zVgSMn9Padl6pXcmOnnhsAfNXJkyeVl5entm3bKiyM5W7czWazqUuXLrrpppv0+OOPe7qcC7rQz0pdPr/p0fJTwZbTc7Qq6NECAHjIvn379PHHH2vw4ME6deqUFixYoLy8PN1yyy2eLs1tmAzvp0L+G7TKrQQtAIBnmM1mLV68WH379tWAAQO0Y8cOffLJJy6fF+VN6NHyUyFB/+3RImgBADykVatW2rhxo6fL8Ch6tPyUvUeLoUMAOAfTk1EbZ/2MELT8kNVmqKzcKkn6Jr9YVhu/UABA+t8Cm2VlZR6uBN6uanFXR+6QvBCGDv3MhzkHq63vMn/tt/rXlh+9an0XAPAUi8Wi2NhY+zYxERERTl2hHf7BZrPp559/VkREhIKCGhaVCFp+5MOcg5r42tZzNpUuOHZSE1/byjY8ACApMTFRki64hx9gNpuVnJzc4CBO0PITVpuhR9/deU7Ikk5vMG2S9Oi7O3VlSqJXLaoHAO5mMpnUvHlzNWvWTBUVFZ4uB14qJCREZnPDZ1gRtPxEVt6RattBnM2QdPDYSWXlHVH/9k3cVxgAeCmLxdLg+TdAbZgM7ycOHT9/yKpPOwAA0HAELT/RLMqxrSQcbQcAABqOoOUn+rWNU/OYMJ1v9pVJUvOY0xufAgAA9yBo+QmL2aRZ6SmSdE7Yqvp+VnoKE+EBAHAjgpYfGdGtuRbe2kuJMdWHBxNjwljaAQAAD+CuQz8zoltzXZmSqLmrdunvG/LUu3Vjvfn7/vRkAQDgAfRo+SGL2aQuzaMkSSWnKpWVd4RteAAA8ACClh/6MOegHn9/lyQpt+C4bn7xC13257X6MOeghysDACCwELT8TNU2PEVl1Vc7rtqGh7AFAID7ELT8SG3b8Eint+FhGBEAAPcgaPmRumzDAwAAXI+g5UfYhgcAAO9C0PIjbMMDAIB3IWj5EbbhAQDAuxC0/Ajb8AAA4F0IWn6mahuehGi24QEAwNMIWk5SVFSkPn36qEePHurWrZtefPFFj9UyoltzbZwxRCGW03+9z/26hzY8MISQBQCAm7HXoZNERUVp/fr1ioiIUGlpqbp166YxY8aoSZMmHqspNNiscqtNpyptHqsBAIBARo+Wk1gsFkVEREiSTp06JcMwZBieWRj0w5yDuuzPa3X8ZKUk6b5/fc0WPAAAeIDHg9bcuXPVt29fRUVFqVmzZho1apRyc3Od+hrr169Xenq6kpKSZDKZtGLFihrbZWZmqk2bNgoLC1NaWpqysrLq9DpFRUVKTU1Vy5Ytdd999yk+Pt4J1ddN1RY8Zy9cyhY8AAC4n8eD1rp16zRp0iR98cUXWr16tSoqKnTVVVeptLS0xvYbN25URUXFOcd37typwsLCGp9TWlqq1NRUZWZmnreOZcuWadq0aZo1a5a2bt2q1NRUDR8+XIcOHbK3qZp/dfZXfn6+JCk2Nlbbt29XXl6eXn/99fPW4ypswQMAgHcxGZ4a3zqPn3/+Wc2aNdO6des0aNCgao/ZbDb16tVLHTp00NKlS2WxWCRJubm5Gjx4sKZNm6b777//guc3mUxavny5Ro0aVe14Wlqa+vbtqwULFthfq1WrVpoyZYpmzJhR5/dx5513asiQIbrxxhvPeSwzM1OZmZmyWq3as2ePjh07pujo6Dq/xtk2ffeLbn7xi1rbvXH7Jerf3nNzxwAA8GXFxcWKiYlx6PPb4z1aZzt27JgkKS7u3EU1zWazVq1apW3btuk3v/mNbDabvvvuOw0ZMkSjRo2qNWSdT3l5ubZs2aJhw4ZVe61hw4Zp06ZNDp2jsLBQx48ft7+H9evXq1OnTjW2nTRpknbu3KnNmzfXq97zYQseAAC8i1fddWiz2TR16lQNGDBA3bp1q7FNUlKS1q5dq4EDB+qWW27Rpk2bNGzYMC1cuLDer3v48GFZrVYlJCRUO56QkKDdu3c7dI59+/ZpwoQJ9knwU6ZMUffu3etdU32wBQ8AAN7Fq4LWpEmTlJOTow0bNlywXXJysl599VUNHjxY7dq100svvSSTybOrnffr10/Z2dmereG/W/AUHDtZ4zwtiS14AABwJ68ZOpw8ebLee+89ffrpp2rZsuUF2xYWFmrChAlKT09XWVmZ7rnnnga9dnx8vCwWyzmT1wsLC5WYmNigc7vTmVvwnM91qc3ZggcAADfxeNAyDEOTJ0/W8uXLtXbtWrVt2/aC7Q8fPqyhQ4eqS5cuevvtt7VmzRotW7ZM06dPr3cNISEh6t27t9asWWM/ZrPZtGbNGvXv37/e5/WEEd2aa8Kg81/DF9bnscQDAABu4vGhw0mTJun111/XO++8o6ioKBUUFEiSYmJiFB4eXq2tzWbTyJEj1bp1ay1btkxBQUFKSUnR6tWrNWTIELVo0aLG3q2SkhJ9++239u/z8vKUnZ2tuLg4JScnS5KmTZumjIwM9enTR/369dO8efNUWlqq8ePHu/DdO5/VZmjl9gsHqUff3akrUxLp2QIAwMU8vrzD+eZWvfLKKxo3btw5x1evXq2BAwcqLKz6hO5t27apadOmNQ47fvbZZ7riiivOOZ6RkaHFixfbv1+wYIGefPJJFRQUqEePHnruueeUlpZWtzdUB3W5PdRRLPEAAIBr1eXz2+NBK5C5Imi9k/2T7l6aXWu7Z3/dQ9f3aOGU1wQAIJD49DpaaBiWeAAAwHsQtPxMv7Zxio0IvmCb2IhglngAAMANCFoBiCnwAAC4B0HLz2TlHVFR2bmbbp/paFmFsvKOuKkiAAACF0HLz7DfIQAA3oOg5WeYDA8AgPcgaPmZqv0Oa3O0tNwN1QAAENgIWn7GYjbp4Wu61Nru8fd3ympjCTUAAFyJoOWHGkeG1trm4LGTTIgHAMDFCFp+iAnxAAB4B4KWH2JCPAAA3oGg5Yd6t24scy2rkppNp9sBAADXIWj5oS37jqq2ee4243Q7AADgOgQtP8QcLQAAvANByw85Ovfqh8NlLq4EAIDARtDyQ/3axikxuvYlHpZu3s9aWgAAuBBByw9ZzCbd3C+51naspQUAgGsRtPxUm/hIh9oxTwsAANchaPkp1tICAMDzCFp+irW0AADwPIKWn2ItLQAAPI+g5adYSwsAAM8jaPmp+Mjal3eoSzsAAFB3BC1/Vcv8rDq3AwAAdUbQ8lOHS0451G7NrkIXVwIAQOAiaPkpR5dteCc7n9XhAQBwEYKWn+rXNk5xkcG1tvultJzV4QEAcBGClp+ymE0a3aOFQ2258xAAANcgaPmxYSmJDrVjdXgAAFyDoOXHWB0eAADPImj5MVaHBwDAswhafszRuVerdxa4uBIAAAITQcuPscQDAACeRdDyYyzxAACAZxG0/BhLPAAA4FkELT83pHOCQ+3YXBoAAOcjaPk7NpcGAMBjCFp+js2lAQDwHIKWn+POQwAAPIeg5ee48xAAAM8haPk5i9mk61OTHGpbcOyEi6sBACCwELQCQMvGEQ61O1Ja7uJKAAAILAStABDXyLGlG34sokcLAABnImgFgMRoxybEr2RCPAAATkXQCgBMiAcAwDMIWgGACfEAAHgGQStAMCEeAAD3I2gFCCbEAwDgfgStAMGEeAAA3I+gFSCYEA8AgPsRtAIEE+IBAHA/glYAYUI8AADuRdAKILERIU5tBwAALoygFUCKyhzrqdr03WEXVwIAQGAgaAUQR5d4+GTXIe48BADACQhaAcTRJR6KTlRw5yEAAE5A0Aog/drGKSYsyKG23HkIAEDDEbQCiMVs0pUpCQ613fgt87QAAGgoglaAGdChqUPtmKcFAEDDEbQCDPO0AABwH4JWgGGeFgAA7kPQCjDM0wIAwH0IWgGIeVoAALgHQSsAMU8LAAD3IGgFoLrM0/r4m4MurgYAAP9F0ApAdZmn9e+tPzF8CABAPRG0ApSj87SKT1YyfAgAQD0RtAKUo/O0JJZ5AACgvghaAapf2zhFhVkcanuktNzF1QAA4J8IWgHKYjZpTM8WDrXdf6TMxdUAAOCfCFoBLDku0qF2y7cxIR4AgPogaAWwuEahDrVjQjwAAPVD0ApgdZkQz3paAADUHUErgNVlQjzraQEAUHcErQBmMZt0Y6+WDrVl+BAAgLojaAW4q7o2d7gtw4cAANQNQSvAMXwIAIDrELQCHMOHAAC4DkELDB8CAOAiBC0wfAgAgIsQtMDwIQAALkLQgiSGDwEAcAWCFiTVbfhw6eYDDB8CAOAAghYk1W348ESFTV9894uLKwIAwPcRtGBXl+HDTd8fdmElAAD4B4IW7Pq1jVNEiGM/EnsPlbi4GgAAfB9BC3YWs0kjuyU61Hb9np+ZpwUAQC0IWqjmsg7NHGrHPC0AAGpH0EI1idFhDrd97csfXFcIAAB+gKCFavq1jVNkqGPLPHyy8xDDhwAAXABBC9VYzCbdfllbh9pW2AzNX7PXxRUBAOC7CFo4x5ShHRXs4E/GonXf0asFAMB5ELRwDovZpGEpjt19eLKSSfEAAJwPQQs1uvWS1g63ZVI8AAA1I2ihRpe0a6LQIJNDbZkUDwBAzQhaqJHFbNLEwe0dasukeAAAakbQwnkxKR4AgIYhaOG8mBQPAEDDELRwQXWZFP/PL35wXSEAAPggghYu6JJ2TRwePlyzq5DhQwAAzkDQwgVZzCYN7ZLgUNtKm5gUDwDAGQhaqNVt/ds43PbvG76nVwsAgP8iaKFWdVlTq+SUVVl5R1xcEQAAvoGghVrVZU0tSfr4m4MurAYAAN9B0IJDTq+p5Viv1pIv9zN8CACACFoNUlRUpD59+qhHjx7q1q2bXnzxRU+X5DIWs0m3XpLsUNtyKyvFAwAgEbQaJCoqSuvXr1d2dra+/PJLzZkzR7/84r+Ldl7VtbnDbVkpHgAAglaDWCwWRURESJJOnTolwzBkGP4bLvq1jVNkqMWhtqwUDwCAnwet9evXKz09XUlJSTKZTFqxYsU5bTIzM9WmTRuFhYUpLS1NWVlZdXqNoqIipaamqmXLlrrvvvsUHx/vpOq9j8Vs0u2XtXW4PSvFAwACXb2C1oEDB/Tjjz/av8/KytLUqVP1wgsvOK0wZygtLVVqaqoyMzNrfHzZsmWaNm2aZs2apa1btyo1NVXDhw/XoUOH7G2q5l+d/ZWfny9Jio2N1fbt25WXl6fXX39dhYWF563n1KlTKi4urvbla6YM7SiLY3PiWSkeABDw6hW0brnlFn366aeSpIKCAl155ZXKysrSQw89pMcee8ypBTbEyJEj9ac//UmjR4+u8fGnn35at99+u8aPH6+UlBQtWrRIERERevnll+1tsrOzlZOTc85XUlJStXMlJCQoNTVVn3/++XnrmTt3rmJiYuxfrVq1cs4bdSOL2aQrU1gpHgAAR9QraOXk5Khfv36SpDfffFPdunXTf/7zHy1ZskSLFy92Zn0uU15eri1btmjYsGH2Y2azWcOGDdOmTZscOkdhYaGOHz8uSTp27JjWr1+vTp06nbf9gw8+qGPHjtm/Dhw40LA34SF1WSk+89Nv6dUCAASsoPo8qaKiQqGhoZKkTz75RNddd50kqXPnzjp40DcWqzx8+LCsVqsSEqr3ziQkJGj37t0OnWPfvn2aMGGCfRL8lClT1L179/O2Dw0NtV83X1a1UvypytoDVIXt9FIPU6/s6IbKAADwLvXq0eratasWLVqkzz//XKtXr9aIESMkSfn5+WrSpIlTC/Rm/fr1U3Z2trZv366vv/5av//97z1dklvUdaV4erUAAIGqXkHrz3/+s55//nldfvnluvnmm5WamipJWrlypX1I0dvFx8fLYrGcM3m9sLBQiYmJHqrKd9RlpfiqXi0AAAJNvYLW5ZdfrsOHD+vw4cPVJo5PmDBBixYtclpxrhQSEqLevXtrzZo19mM2m01r1qxR//79PViZb7CYTZp0Bb1aAABcSL2C1okTJ3Tq1Ck1btxY0um5SvPmzVNubq6aNWvm1AIboqSkRNnZ2crOzpYk5eXlKTs7W/v375ckTZs2TS+++KL+8Y9/aNeuXZo4caJKS0s1fvx4D1btO+jVAgDgwuoVtK6//nr985//lHR6wc60tDT99a9/1ahRo7Rw4UKnFtgQX331lXr27KmePXtKOh2sevbsqZkzZ0qS/t//+3966qmnNHPmTPXo0UPZ2dn68MMPz5kgj5rVtVeLbXkAAIHGZNRjz5j4+HitW7dOXbt21d///nfNnz9f27Zt07///W/NnDlTu3btckWtfqe4uFgxMTE6duyYoqOjPV1OvVhthjr/8QNVOBiglvwuTQM6+O/q+QAA/1eXz+969WiVlZUpKipKkvTxxx9rzJgxMpvNuuSSS7Rv3776nBI+qq69Wk9+7NjSGQAA+IN6Ba2LLrpIK1as0IEDB/TRRx/pqquukiQdOnTIZ3tmUH912ZYn+8AxrfraN9ZaAwCgoeoVtGbOnKnp06erTZs26tevn/0uvY8//tg+HwqBoy7b8kjStDezmasFAAgI9QpaN954o/bv36+vvvpKH330kf340KFD9cwzzzitOPiOumzLc7LSxh2IAICAUK+gJUmJiYnq2bOn8vPz9eOPP0o6vVJ6586dnVYcfEfVtjyOYl0tAEAgqFfQstlseuyxxxQTE6PWrVurdevWio2N1eOPPy6bzebsGuED6rotD+tqAQACQb2C1kMPPaQFCxboiSee0LZt27Rt2zbNmTNH8+fP18MPP+zsGuEjpgztqFBHZ8WLXi0AgP+r1zpaSUlJWrRoka677rpqx9955x3deeed+umnn5xWoD/zh3W0zrbq63zd+fo2h9tPHdpBU6/s6MKKAABwLpevo3XkyJEa52J17txZR44cqc8p4SeuvjhJ13R3/A7E+Wv30qsFAPBb9QpaqampWrBgwTnHFyxYoIsvvrjBRfm7zMxMpaSkqG/fvp4uxSWeu7m3w3sgWg3p2dV7XFwRAACeUa+hw3Xr1umaa65RcnKyfQ2tTZs26cCBA1q1apUGDhzo9EL9kT8OHVaZtzpX89Z861DbILOU+6erZXEwnAEA4EkuHzocPHiw9uzZo9GjR6uoqEhFRUUaM2aMvvnmG7366qv1Khr+pS6rxVfaxB2IAAC/VK8erfPZvn27evXqJavV6qxT+jV/7tGSpHvf3KZ/b813qK1Z0t459GoBALyfy3u0AEfMHZPqcFubpJsW/cd1xQAA4AEELbhMSJC5TncgbtlfpHe3O9YDBgCALyBowaWeu7m3w3O1JOn+f21nuQcAgN8IqkvjMWPGXPDxoqKihtQCP2QxmzRlyEUO34F4osKmL777RQM6xLu4MgAAXK9OPVoxMTEX/GrdurV+85vfuKpW+KgpQzs6vK6WJD20YocLqwEAwH2cetch6sbf7zo803vZP2ny0myH28+/uafSU5NcVxAAAPXEXYfwOtf2aKE2TcIdbj916TbmagEAfB5BC24ze7Tj2zNZDZZ7AAD4PoIW3OaSdk0UFuz4jxzLPQAAfB1BC25jMZv01A1123T8nmUMIQIAfBdBC251bY8W6pUc43D7Spt09xvbXFgRAACuQ9CC2711x4A6LWL63o6DKq+0ua4gAABchKAFt7OYTXr2//Wo03OueXa9a4oBAMCFCFrwiLoOIe79uVSPv7fThRUBAOB8BC14zFt3DFAdRhD10oY8rfr6oMvqAQDA2Qha8BiL2aQpV7Sv03O4CxEA4EsIWvCou6/sVKeJ8aesBnchAgB8BkHLAzIzM5WSkqK+fft6uhSPq8/E+Pd2HGQIEQDgE9hU2oMCaVPp2oz52wZt3X/M4fahFpN2Pj5SFnNdZnkBANBwbCoNn/PWHQMUVIefRoYQAQC+gKAFr2Axm/Tcr3vW6TkMIQIAvB1BC17j6ouTdE33hDo95643tnIXIgDAaxG04FWeu7m3guow7arSkG5a9B/XFQQAQAMQtOBVLGaTJg+5qE7P2bK/SO9uz3dRRQAA1B9BC15nytCOCq3L4lqS7nqDhUwBAN6HoAWvYzGb9Ewd19YyJN34t40uqQcAgPoiaMErXX1xkm4f2KZOz9n24zE9+u43rikIAIB6IGjBaz10TVeNH9C6Ts95ZeMPevw9whYAwDsQtODVZqV3U4emkXV6zksbftDs93e6qCIAABxH0ILXe//uQXV+zouf57GYKQDA4wha8HohQWb97rK6DSFK0j3LuBMRAOBZBC34hIev7aa28eF1es4pq6G7Xt/qoooAAKgdQQs+45NpV9Rp42lJej+ngMnxAACPIWjBZ9Rn42np9OR4whYAwBMIWvAp9VlfS+JORACAZxC04HMeuqarru6WUOfncSciAMDdCFrwSfNv6V3n/RAl7kQEALgXQQs+qT77IUrciQgAcC+CFnxWfedrcSciAMBdCFrwaQ9d01W/u6xNnZ/H5HgAgDsQtDwgMzNTKSkp6tu3r6dL8QsPX1u/sPXi53l6Lzvf+QUBAPBfJsMwmBnsIcXFxYqJidGxY8cUHR3t6XJ83p2vfaVVOYV1ft6CX/fUtT2SXFARAMAf1eXzmx4t+I363ok4eek2zX6fOVsAAOcjaMFv1PdOREl68XNWjwcAOB9BC36lvnciSkyQBwA4H0ELfqe+dyJKTJAHADgXQQt+6eFru2r8gNb1eu7kpdsIWwAApyBowW/NSu+mIZ3i6/XcyUu36fH3cpxcEQAg0BC04NdeHp+m7klR9XruSxv26XeLs5xcEQAgkBC04PfevWuQhnRqWq/nrtn9M2ELAFBvBC0EhJfH99P4AW3q9dw1u3/WrJUMIwIA6o6ghYAxK73+E+T/8Z99Gp35uaw2NlIAADiOoIWA0pAJ8tsOFKvjH1bpw5yDTq4KAOCvCFoIOA2ZIG+VdMdrW7Xqa5Z/AADUjqCFgNSQCfKSdOfr27Ry609OrAgA4I8IWghYDZkgL0l3vZmtMczbAgBcAEELAW1Wev2365GkrQeK1eEPqxhKBADUiKCFgPfwtQ0LWzadHkpkJXkAwNkIWoBOh63bB7Zt0Dle2sASEACA6ghawH89dE2K/nZLL5kacI5tDCUCAM5A0ALOcPXFzfXtnKvVunFYvc9RNZR452tf0bsFAAGOoOVkZWVlat26taZPn+7pUlBPFrNJ6x4Yqm71XGuryqqcQnV4aJXey2YZCAAIVAQtJ5s9e7YuueQST5cBJ3jvrkEa2rlZg85hM6TJS7OZuwUAAYqg5UR79+7V7t27NXLkSE+XAid5aVxfzb+5Z4PPs+1Asdr/gd4tAAg0XhG0fvrpJ916661q0qSJwsPD1b17d3311VdOO//69euVnp6upKQkmUwmrVixosZ2mZmZatOmjcLCwpSWlqasrKw6vc706dM1d+5cJ1QMb5KemqTv5lytNnHhDT7X5KXZuvKvn6q80uaEygAA3s7jQevo0aMaMGCAgoOD9cEHH2jnzp3661//qsaNG9fYfuPGjaqoqDjn+M6dO1VYWFjjc0pLS5WamqrMzMzz1rFs2TJNmzZNs2bN0tatW5Wamqrhw4fr0KFD9jY9evRQt27dzvnKz8/XO++8o44dO6pjx451vALwBRazSZ/dP6TBQ4mStPfnMnX84we647XNDCcCgJ8zGYbh0d/0M2bM0MaNG/X555/X2tZms6lXr17q0KGDli5dKovFIknKzc3V4MGDNW3aNN1///0XPIfJZNLy5cs1atSoasfT0tLUt29fLViwwP5arVq10pQpUzRjxoxaa3vwwQf12muvyWKxqKSkRBUVFbr33ns1c+bMc9pmZmYqMzNTVqtVe/bs0bFjxxQdHV3ra8A7vLs9X1Pe2Oa08911RXvdfWUnWcwNWVgCAOAuxcXFiomJcejz2+NBKyUlRcOHD9ePP/6odevWqUWLFrrzzjt1++2319g+Pz9fgwYNUlpaml599VXl5eVp0KBBSk9P16JFi2p9vZqCVnl5uSIiIvSvf/2r2vGMjAwVFRXpnXfeqdN7Wrx4sXJycvTUU09dsF1d/qLgXaw2Q0Of+lQ/HDnhlPOZJD17U6qu69XSKecDALhOXT6/PT50+P3332vhwoXq0KGDPvroI02cOFF33XWX/vGPf9TYPikpSWvXrtWGDRt0yy23aMiQIRo2bJgWLlxY7xoOHz4sq9WqhISEascTEhJUUFBQ7/PCfzlzKFGSDEl3vbldaXM+Zv4WAPiRIE8XYLPZ1KdPH82ZM0eS1LNnT+Xk5GjRokXKyMio8TnJycl69dVXNXjwYLVr104vvfSSTCbvGXYZN26cp0uAm7w0rq/e3Z6vqcu2yeqEfFRYXKGOf/xA7eMj9ch1XXXpRfEMKQKAD/N4j1bz5s2VkpJS7ViXLl20f//+8z6nsLBQEyZMUHp6usrKynTPPfc0qIb4+HhZLJZzJtMXFhYqMTGxQeeG/0tPTdKeP12tu664yGnn/O5wqW57OUudWPAUAHyax4PWgAEDlJubW+3Ynj171Lp16xrbHz58WEOHDlWXLl309ttva82aNVq2bFmDVmIPCQlR7969tWbNGvsxm82mNWvWqH///vU+LwKHxWzStOGd9N2cq9W2SYTTzlv53wVPL5m9Wp/v+Zm7FAHAx3h86PCee+7RpZdeqjlz5uimm25SVlaWXnjhBb3wwgvntLXZbBo5cqRat26tZcuWKSgoSCkpKVq9erWGDBmiFi1a1Ni7VVJSom+//db+fV5enrKzsxUXF6fk5GRJ0rRp05SRkaE+ffqoX79+mjdvnkpLSzV+/HjXvXn4HYvZpE/vu0LvZP+kqUuz5axYVHC8XLe9nCWTpMmXt9fUq7hLEQB8gcfvOpSk9957Tw8++KD27t2rtm3batq0aee963D16tUaOHCgwsKqb/q7bds2NW3aVC1bnnvX1meffaYrrrjinOMZGRlavHix/fsFCxboySefVEFBgXr06KHnnntOaWlpDXtzF8Bdh/7NajM05fWtWpXjmhsqxvRI0hM3piokyOMd0wAQUHxqeYdARtAKDOWVNg3+y1odLD7lkvP3bROrJf/Xn8AFAG5C0PIRBK3A8k72T7pnWbZcNc2KOxUBwD0IWj6CoBV4rDZDz67eo+c+/bb2xg0wOjVJf/4Vw4oA4AoELR9B0ApcVpuhyUu26INvat6f01no5QIA5yNo+QiCFsorbbrtpS/0Zd5Rl76OSdJoJs8DgFMQtHwEQQtV3BW4JKlZVKj+77K2GjegLaELAOqBoOUjCFo4mzsDl8TQIgDUB0HLRxC0cD7llTbN+Pd2vb0t322vObB9E72Q0VfhIRa3vSYA+CKClo8gaKE2VpuheR/nKnPddy5bFuJskcFmDUtJ1I29W9LTBQA1IGj5CIIWHGW1GfrP3sOa/u9sFRaXu+11mUQPAOciaPkIghbq40S5VaP/tkG7C0rc+rrRYUFKv7i5/nhtV4YXAQQ0gpaPIGihIarmcS3flu+0zasdFRNm0aQrOnDnIoCARNDyEQQtOIPVZmhD7s+asfxrl+2neCGx4UG6Y3B7/faydoQuAAGBoOUjCFpwNncvD3E2hhcBBAKClo8gaMFVyittemXj93rp8zwdKnHf5PkzcfciAH9F0PIRBC24Q9VcrhXZ+W5bIqImfZJjdfewjoQuAD6PoOUjCFpwp6olIp5du0db9hW5fQL9mZpFhejKLgkMMQLwSQQtH0HQgqdUha5H3s3Rd4fLPFoLQ4wAfA1By0cQtOANvGE+15naxUfo132TWToCgNciaPkIgha8jbeFLpaOAOCNCFo+gqAFb+ZtoSsyxKLOiVEa3jWR3i4AHkXQ8hEELfgKbwtdkhQbHqzBHZsytwuA2xG0fARBC76ovNKmlzZ8p+fXfa+iE5WeLseOuV0A3IWg5eUyMzOVmZkpq9WqPXv2ELTgs7yxp0uSIkPMGto5Qb/q04reLgBOR9DyEfRowZ9Uha6lWQeU94tnl4w4W/PoUGVc2oZJ9QCcgqDlIwha8FdVG13P/mCn9hwq9XQ51TCpHkBDEbR8BEELgaBqcdS3tuzXuj2Hdeyk98zrkphUD6DuCFo+gqCFQOSt87qqtG0SoZv7MakewPkRtHwEQQuBrip0fZRToNzC4yott3m6pGrCgkxKaR6jEd0YZgTwPwQtH0HQAqrz1qUjqkQEm9UzOVYTBrXXZR2aMswIBCiClo8gaAHn5813MVaJiwhW2/hIJtYDAYag5SMIWoBjzpxQv37vYa/s7ZKYWA8ECoKWjyBoAfXj7XO7qjSPDlW/tk0IXoCfIWj5CIIW4BxVc7v+8Z8fVFDsfXcyVkmMDlUawQvweQQtH0HQApyvapjxza/2aW3uz17b2yWxYj3gqwhaPoKgBbieL0yql6RQi0mtm0RoTK+WBC/AyxG0fARBC3CvMyfVZ/1wxKuHGcOCzGoeE6ZL2zfRH6/tqvAQi6dLAvBfBC0fQdACPKtqT8ZF679V9o/HdKLCe4cZg81Sy8YRBC/ACxC0fARBC/AuVZPq/73lR+0/ckLlVu/99RhqllrHR6pL8xgm1wNuRtDyEQQtwLv9b37XfuX9csLT5dSK5SQA9yBo+QiCFuA7fGl+VxWWkwBcg6DlIwhagO/yldXqz0TwApyDoOUjCFqA/zhztfq8X0p1tMz7g1dcRLAuuyhev+rTiuAF1AFBy0cQtAD/deYdjd8cLFbxSaunS6pVZIhZLWLDWcsLqAVBy0cQtIDA4Usr1ldhEVWgZgQtH0HQAgJX1VDjhzsOalfBcZ2s9P5fxaEWkxpHhqh900hNGNRel3VoynAjAhJBy0cQtABUOXOO1+7C4yrzgR4vSWoUYlajsGDCFwIKQctHELQAnI+vBi+JuV7wfwQtH0HQAuCoM4NXbuFxn5jjVYUhR/gbgpaPIGgBqC9fXE7iTAw5wpcRtHwEQQuAs/jichJniwg2KS4yVL2SG7O2F7waQctHELQAuIo/BC9JCg+SIkODlRwXqRHdEjVuQFvmfMHjCFo+gqAFwF3OXMdrw3e/+NxQ45lCzFLTqDAlxoRpeFfCF9yPoOUjCFoAPOXMvRq/yT+mn4pO+sRaXucTYpbiG4WqUViQujSPYT9HuBRBy0cQtAB4E19cRLU2seFBahYVSviCUxG0fARBC4A3O/POxu8Pl6johG/O8zpbbJhFjcKClRDN0CPqh6DlQWVlZerSpYt+9atf6amnnrpgW4IWAF9y5nDjzoPFOlxyym/CV3iQSU0ahRK+4JC6fH4HuammgDF79mxdcsklni4DAJzOYjZpYKemGtipqf2Yv8z1OlFp6Meik/qx6KS27C/SnA92K8QsRYYFq2mjEFa5R70RtJxo79692r17t9LT05WTk+PpcgDA5WoKX/4y5Fhuk8rLKnS0rEJPfJirJz7MVYhZiggNUqPQINb7gkO8Kpo/8cQTMplMmjp1qlPPu379eqWnpyspKUkmk0krVqyosV1mZqbatGmjsLAwpaWlKSsrq06vM336dM2dO9cJFQOA7woJMuv3gy/S25MuU/asEfpuztV6dXw/XXdxoi5qGqHYcIunS6y3cptUdKJSPxad1MqvD+q2l7PU/g+r1OWP76vP4x9rTOZGvbDuO5VX+s4WSXAtr+nR2rx5s55//nldfPHFF2y3ceNG9evXT8HBwdWO79y5U02aNFFCQsI5zyktLVVqaqp++9vfasyYMTWed9myZZo2bZoWLVqktLQ0zZs3T8OHD1dubq6aNWsmSerRo4cqK89de+bjjz/W5s2b1bFjR3Xs2FH/+c9/HH3bAOD3HBlyLCw+pRIf2r/xbCcqpROVFTpcWqStB/439MiSE/CKyfAlJSXq1auX/va3v+lPf/qTevTooXnz5p3TzmazqVevXurQoYOWLl0qi+X0/4pyc3M1ePBgTZs2Tffff/8FX8tkMmn58uUaNWpUteNpaWnq27evFixYYH+tVq1aacqUKZoxY0at7+HBBx/Ua6+9JovFopKSElVUVOjee+/VzJkzz/scJsMDwP+cHb6OlpWr5JRN5VaPf0w5FUtO+D6fu+swIyNDcXFxeuaZZ3T55ZefN2hJUn5+vgYNGqS0tDS9+uqrysvL06BBg5Senq5FixbV+lo1Ba3y8nJFREToX//6V7XjGRkZKioq0jvvvFOn97N48WLl5OSc967DzMxMZWZmymq1as+ePQQtALiA8kqbXtrwnf695Uf9fPyUTlXafHLC/YWw5IRv8am7DpcuXaqtW7dq8+bNDrVPSkrS2rVrNXDgQN1yyy3atGmThg0bpoULF9a7hsOHD8tqtZ4z7JiQkKDdu3fX+7znM2nSJE2aNMn+FwUAOL+QILMmXt5BEy/vYD92dviy2gyfHnosOmlV0UlrtbseWXLCP3g0aB04cEB33323Vq9erbCwMIefl5ycrFdffVWDBw9Wu3bt9NJLL8lk8p5u13Hjxnm6BADwazWFrzM30v7u5xIVn6z06Z6vmpacCAsyq3lMmC5t30R/vLarwkN898aCQOHRoLVlyxYdOnRIvXr1sh+zWq1av369FixYoFOnTtnnYZ2psLBQEyZMUHp6ujZv3qx77rlH8+fPr3cd8fHxslgsKiwsPOd1EhMT631eAID7WMwmDe7STIO7NLMfO3OpiYLiEzpRbtPRE767ofbJSpvyfilT3i9lWpJ1QCEmqVlMGL1eXsyjQWvo0KHasWNHtWPjx49X586d9cADD9QYsg4fPqyhQ4eqS5cueuutt7Rnzx5dfvnlCg0NrXUl9vMJCQlR7969tWbNGvscLZvNpjVr1mjy5Mn1OicAwPOqlpr4/eCL7MfOXuH+l9JyHS3zzfBVbujcXi+LFBkapOAgi9o3jdSEQe11WYemTLj3EI8GraioKHXr1q3ascjISDVp0uSc49Lp8DNy5Ei1bt1ay5YtU1BQkFJSUrR69WoNGTJELVq00D333HPO80pKSvTtt9/av8/Ly1N2drbi4uKUnJwsSZo2bZoyMjLUp08f9evXT/PmzVNpaanGjx/v5HcNAPCk2pab2HmwWKWnKnS0zDeHHk9apZNllZIqVVB8Shu/OyJJCg+SIkODlRwXqRHd6P1yF6+46/BMtd11uHr1ag0cOPCcOV3btm1T06ZN1bJly3Oe89lnn+mKK64453hGRoYWL15s/37BggV68sknVVBQoB49eui5555TWlpag97PhbC8AwB4tzOHHg8eK9Pxk1afnnR/tmCTFB0epLjIUKUksdyEo3xueYdARdACAN8TCOt9RQabFBsRqsQY5n7VhKDlIwhaAOA//G3JibOFB0mNI0JkNpsDfvI9QctHELQAwL/525ITNQmzSBEhFlkNKchsCohhSIKWjyBoAUDg8bclJ2oTE2ZRlJ+tek/Q8hEELQCA5F9LTjjC15egIGj5CIIWAOB8zg5f+cdOqsyP5nzVJDLYpCCLWRaTFBpkkcXinfPBCFo+gqAFAKiLM4cd834p9eter5p4S08YQctHELQAAA1xdq9XWXmlyk6d3qA6kFT1hAVbzG5ZkJWg5SMIWgAAVwiEtb4cERFsVs/kWKf3fBG0fARBCwDgTlVDjx/uOKh9R0p1ssJQWYV/z/uqEhpk1rO/7qER3Zo3+FwELR9B0AIAeFpV79ebX+3Tlv1HVXrKqrJyq/w1fy26tVeDw1ZdPr89uqk0AADwrJo22ZakE+VWPfZejv7z7WGVnKyQ1WZS0Unfn3z/yMqdujIl0W0T6AlaAADgHOEhFs0dk1rtWE2T7w2boVOVNp2s9I1hyILik8rKO6L+7Zu45fUIWgAAwCHn6/2qcvaWQ5VWm0rKvW8S/qHjJ932WgQtAADgFBazSYO7NNPgLs2qHT93GFIeXYKiWVSY216LoAUAAFzKkWHI0lMVOlVhk9WQLCa5rCcsMTpM/drGOf2850PQAgAAblfbMKTkmp6wR65LcetK8gQtAADglerSE1ZbD5gz19GqC4IWAADwGRfqCTtzQdb9R8sUbPHsnogSC5Z6FAuWAgDge+ry+e2a3RYBAABA0AIAAHAVghYAAICLELQAAABchKAFAADgIgQtAAAAFyFoAQAAuAhBCwAAwEUIWgAAAC7CFjweVLUof3FxsYcrAQAAjqr63HZkcx2ClgcdP35cktSqVSsPVwIAAOrq+PHjiomJuWAb9jr0IJvNpvz8fEVFRclkcu5Gl8XFxWrVqpUOHDjAPoouxHV2D66ze3Cd3Ydr7R6uus6GYej48eNKSkqS2XzhWVj0aHmQ2WxWy5YtXfoa0dHR/CN2A66ze3Cd3YPr7D5ca/dwxXWurSerCpPhAQAAXISgBQAA4CIELT8VGhqqWbNmKTQ01NOl+DWus3twnd2D6+w+XGv38IbrzGR4AAAAF6FHCwAAwEUIWgAAAC5C0AIAAHARghYAAICLELT8UGZmptq0aaOwsDClpaUpKyvL0yX5lLlz56pv376KiopSs2bNNGrUKOXm5lZrc/LkSU2aNElNmjRRo0aNdMMNN6iwsLBam/379+uaa65RRESEmjVrpvvuu0+VlZXufCs+5YknnpDJZNLUqVPtx7jOzvHTTz/p1ltvVZMmTRQeHq7u3bvrq6++sj9uGIZmzpyp5s2bKzw8XMOGDdPevXurnePIkSMaO3asoqOjFRsbq9/97ncqKSlx91vxWlarVQ8//LDatm2r8PBwtW/fXo8//ni1vfC4zvWzfv16paenKykpSSaTSStWrKj2uLOu69dff62BAwcqLCxMrVq10l/+8hfnvAEDfmXp0qVGSEiI8fLLLxvffPONcfvttxuxsbFGYWGhp0vzGcOHDzdeeeUVIycnx8jOzjauvvpqIzk52SgpKbG3ueOOO4xWrVoZa9asMb766ivjkksuMS699FL745WVlUa3bt2MYcOGGdu2bTNWrVplxMfHGw8++KAn3pLXy8rKMtq0aWNcfPHFxt13320/znVuuCNHjhitW7c2xo0bZ3z55ZfG999/b3z00UfGt99+a2/zxBNPGDExMcaKFSuM7du3G9ddd53Rtm1b48SJE/Y2I0aMMFJTU40vvvjC+Pzzz42LLrrIuPnmmz3xlrzS7NmzjSZNmhjvvfeekZeXZ7z11ltGo0aNjGeffdbehutcP6tWrTIeeugh4+233zYkGcuXL6/2uDOu67Fjx4yEhARj7NixRk5OjvHGG28Y4eHhxvPPP9/g+glafqZfv37GpEmT7N9brVYjKSnJmDt3rger8m2HDh0yJBnr1q0zDMMwioqKjODgYOOtt96yt9m1a5chydi0aZNhGKd/MZjNZqOgoMDeZuHChUZ0dLRx6tQp974BL3f8+HGjQ4cOxurVq43BgwfbgxbX2TkeeOAB47LLLjvv4zabzUhMTDSefPJJ+7GioiIjNDTUeOONNwzDMIydO3cakozNmzfb23zwwQeGyWQyfvrpJ9cV70OuueYa47e//W21Y2PGjDHGjh1rGAbX2VnODlrOuq5/+9vfjMaNG1f7vfHAAw8YnTp1anDNDB36kfLycm3ZskXDhg2zHzObzRo2bJg2bdrkwcp827FjxyRJcXFxkqQtW7aooqKi2nXu3LmzkpOT7dd506ZN6t69uxISEuxthg8fruLiYn3zzTdurN77TZo0Sddcc0216ylxnZ1l5cqV6tOnj371q1+pWbNm6tmzp1588UX743l5eSooKKh2nWNiYpSWllbtOsfGxqpPnz72NsOGDZPZbNaXX37pvjfjxS699FKtWbNGe/bskSRt375dGzZs0MiRIyVxnV3FWdd106ZNGjRokEJCQuxthg8frtzcXB09erRBNbKptB85fPiwrFZrtQ8dSUpISNDu3bs9VJVvs9lsmjp1qgYMGKBu3bpJkgoKChQSEqLY2NhqbRMSElRQUGBvU9PfQ9VjOG3p0qXaunWrNm/efM5jXGfn+P7777Vw4UJNmzZNf/jDH7R582bdddddCgkJUUZGhv061XQdz7zOzZo1q/Z4UFCQ4uLiuM7/NWPGDBUXF6tz586yWCyyWq2aPXu2xo4dK0lcZxdx1nUtKChQ27ZtzzlH1WONGzeud40ELeACJk2apJycHG3YsMHTpfidAwcO6O6779bq1asVFhbm6XL8ls1mU58+fTRnzhxJUs+ePZWTk6NFixYpIyPDw9X5jzfffFNLlizR66+/rq5duyo7O1tTp05VUlIS1znAMXToR+Lj42WxWM65K6uwsFCJiYkeqsp3TZ48We+9954+/fRTtWzZ0n48MTFR5eXlKioqqtb+zOucmJhY499D1WM4PTR46NAh9erVS0FBQQoKCtK6dev03HPPKSgoSAkJCVxnJ2jevLlSUlKqHevSpYv2798v6X/X6UK/NxITE3Xo0KFqj1dWVurIkSNc5/+67777NGPGDP36179W9+7dddttt+mee+7R3LlzJXGdXcVZ19WVv0sIWn4kJCREvXv31po1a+zHbDab1qxZo/79+3uwMt9iGIYmT56s5cuXa+3ated0J/fu3VvBwcHVrnNubq72799vv879+/fXjh07qv3jXr16taKjo8/50AtUQ4cO1Y4dO5SdnW3/6tOnj8aOHWv/M9e54QYMGHDO8iR79uxR69atJUlt27ZVYmJitetcXFysL7/8stp1Lioq0pYtW+xt1q5dK5vNprS0NDe8C+9XVlYms7n6R6rFYpHNZpPEdXYVZ13X/v37a/369aqoqLC3Wb16tTp16tSgYUNJLO/gb5YuXWqEhoYaixcvNnbu3GlMmDDBiI2NrXZXFi5s4sSJRkxMjPHZZ58ZBw8etH+VlZXZ29xxxx1GcnKysXbtWuOrr74y+vfvb/Tv39/+eNWyA1dddZWRnZ1tfPjhh0bTpk1ZdqAWZ951aBhcZ2fIysoygoKCjNmzZxt79+41lixZYkRERBivvfaavc0TTzxhxMbGGu+8847x9ddfG9dff32Nt8f37NnT+PLLL40NGzYYHTp0CPhlB86UkZFhtGjRwr68w9tvv23Ex8cb999/v70N17l+jh8/bmzbts3Ytm2bIcl4+umnjW3bthn79u0zDMM517WoqMhISEgwbrvtNiMnJ8dYunSpERERwfIOqNn8+fON5ORkIyQkxOjXr5/xxRdfeLoknyKpxq9XXnnF3ubEiRPGnXfeaTRu3NiIiIgwRo8ebRw8eLDaeX744Qdj5MiRRnh4uBEfH2/ce++9RkVFhZvfjW85O2hxnZ3j3XffNbp162aEhoYanTt3Nl544YVqj9tsNuPhhx82EhISjNDQUGPo0KFGbm5utTa//PKLcfPNNxuNGjUyoqOjjfHjxxvHjx9359vwasXFxcbdd99tJCcnG2FhYUa7du2Mhx56qNpyAVzn+vn0009r/J2ckZFhGIbzruv27duNyy67zAgNDTVatGhhPPHEE06p32QYZyxbCwAAAKdhjhYAAICLELQAAABchKAFAADgIgQtAAAAFyFoAQAAuAhBCwAAwEUIWgAAAC5C0AIAAHARghYAeBmTyaQVK1Z4ugwATkDQAoAzjBs3TiaT6ZyvESNGeLo0AD4oyNMFAIC3GTFihF555ZVqx0JDQz1UDQBfRo8WAJwlNDRUiYmJ1b4aN24s6fSw3sKFCzVy5EiFh4erXbt2+te//lXt+Tt27NCQIUMUHh6uJk2aaMKECSopKanW5uWXX1bXrl0VGhqq5s2ba/LkydUeP3z4sEaPHq2IiAh16NBBK1eudO2bBuASBC0AqKOHH35YN9xwg7Zv366xY8fq17/+tXbt2iVJKi0t1fDhw9W4cWNt3rxZb731lj755JNqQWrhwoWaNGmSJkyYoB07dmjlypW66KKLqr3Go48+qptuuklff/21rr76ao0dO1ZHjhxx6/sE4AQGAMAuIyPDsFgsRmRkZLWv2bNnG4ZhGJKMO+64o9pz0tLSjIkTJxqGYRgvvPCC0bhxY6OkpMT++Pvvv2+YzWajoKDAMAzDSEpKMh566KHz1iDJ+OMf/2j/vqSkxJBkfPDBB057nwDcgzlaAHCWK664QgsXLqx2LC4uzv7n/v37V3usf//+ys7OliTt2rVLqampioyMtD8+YMAA2Ww25ebmymQyKT8/X0OHDr1gDRdffLH9z5GRkYqOjtahQ4fq+5YAeAhBCwDOEhkZec5QnrOEh4c71C44OLja9yaTSTabzRUlAXAh5mgBQB198cUX53zfpUsXSVKXLl20fft2lZaW2h/fuHGjzGazOnXqpKioKLVp00Zr1qxxa80APIMeLQA4y6lTp1RQUFDtWFBQkOLj4yVJb731lvr06aPLLrtMS5YsUVZWll566SVJ0tixYzVr1ixlZGTokUce0c8//6wpU6botttuU0JCgiTpkUce0R133KFmzZpp5MiROn78uDZu3KgpU6a4940CcDmCFgCc5cMPP1Tz5s2rHevUqZN2794t6fQdgUuXLtWdd96p5s2b64033lBKSookKSIiQh999JHuvvtu9e3bVxEREbrhhhv09NNP28+VkZGhkydP6plnntH06dMVHx+vG2+80X1vEIDbmAzDMDxdBAD4CpPJpOXLl2vUqFGeLgWAD2COFgAAgIsQtAAAAFyEOVoAUAfMtgBQF/RoAQAAuAhBCwAAwEUIWgAAAC5C0AIAAHARghYAAICLELQAAABchKAFAADgIgQtAAAAF/n/iJp+fAdTKV0AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete! Total training time: 1451.77 seconds\n"
          ]
        }
      ],
      "source": [
        "# Train the GNN model using the provided source and target graph embeddings, edges, and training data\n",
        "trained_model = train_model_gnn(\n",
        "    model=GIT_model,                # The GNN model to be trained (initialized earlier)\n",
        "    x_src=x_src,                    # Source node embeddings (tensor for source graph)\n",
        "    edge_src=edge_src,              # Source graph edges (undirected edge index for source graph)\n",
        "    x_tgt=x_tgt,                    # Target node embeddings (tensor for target graph)\n",
        "    edge_tgt=edge_tgt,              # Target graph edges (undirected edge index for target graph)\n",
        "    tensor_term1=tensor_term1_o,    # Indices of source entities for training\n",
        "    tensor_term2=tensor_term2_o,    # Indices of target entities for training\n",
        "    tensor_score=tensor_score_o,    # Scores (labels) indicating if pairs match (1) or not (0)\n",
        "    learning_rate=0.0001,            # Learning rate for the Adam optimizer\n",
        "    weight_decay_value=1e-4,        # Weight decay for L2 regularization to prevent overfitting\n",
        "    num_epochs=1000,                # Number of training epochs\n",
        "    print_interval=10               # Interval at which to print training progress (every 10 epochs)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYyhvjcTUaae"
      },
      "source": [
        "# GIT Application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "BZ_VqP6tq6iD"
      },
      "outputs": [],
      "source": [
        "# Determine if a GPU is available and move the computations to it; otherwise, use the CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Assuming the model has been trained and hyperparameters (x_src, edge_src, x_tgt, edge_tgt) are set\n",
        "\n",
        "# Move the trained GIT_model to the device (GPU or CPU)\n",
        "GIT_model.to(device)\n",
        "\n",
        "# Move the data tensors to the same device (GPU or CPU)\n",
        "x_tgt = x_tgt.to(device)         # Target node embeddings\n",
        "edge_tgt = edge_tgt.to(device)   # Target graph edges\n",
        "x_src = x_src.to(device)         # Source node embeddings\n",
        "edge_src = edge_src.to(device)   # Source graph edges\n",
        "\n",
        "# Set the model to evaluation mode; this disables dropout and batch normalization\n",
        "GIT_model.eval()\n",
        "\n",
        "# Pass the source and target embeddings through the trained GNN model to update the embeddings\n",
        "with torch.no_grad():  # Disable gradient computation (inference mode)\n",
        "    embeddings_tgt = GIT_model(x_tgt, edge_tgt)  # Get updated embeddings for the target graph\n",
        "    embeddings_src = GIT_model(x_src, edge_src)  # Get updated embeddings for the source graph\n",
        "\n",
        "# Detach the embeddings from the computation graph and move them back to the CPU\n",
        "# This step is useful if you need to use the embeddings for tasks outside PyTorch (e.g., saving to disk)\n",
        "embeddings_tgt = embeddings_tgt.detach().cpu()  # Target graph embeddings\n",
        "embeddings_src = embeddings_src.detach().cpu()  # Source graph embeddings\n",
        "\n",
        "# At this point, embeddings_tgt and embeddings_src contain the updated embeddings, ready for downstream tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og5fdoGJrTCG"
      },
      "source": [
        "# Selecting embedding pairs to train the Gated Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "J0nTwc-dnjLn"
      },
      "outputs": [],
      "source": [
        "# Read the training pairs from a CSV file into a pandas DataFrame\n",
        "df_embeddings = pd.read_csv(train_file, index_col=0)\n",
        "\n",
        "# Extract columns and convert to NumPy arrays\n",
        "tensor_term1 = df_embeddings['SrcEntity'].values.astype(int)  # Source entity indices\n",
        "tensor_term2 = df_embeddings['TgtEntity'].values.astype(int)  # Target entity indices\n",
        "tensor_score = df_embeddings['Score'].values.astype(float)  # Matching scores\n",
        "\n",
        "# Split data into training and validation sets\n",
        "tensor_term1_train, tensor_term1_val, tensor_term2_train, tensor_term2_val, tensor_score_train, tensor_score_val = train_test_split(\n",
        "    tensor_term1, tensor_term2, tensor_score, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Convert split data to PyTorch tensors\n",
        "tensor_term1_train = torch.from_numpy(tensor_term1_train).type(torch.LongTensor)\n",
        "tensor_term2_train = torch.from_numpy(tensor_term2_train).type(torch.LongTensor)\n",
        "tensor_score_train = torch.from_numpy(tensor_score_train).type(torch.FloatTensor)\n",
        "\n",
        "tensor_term1_val = torch.from_numpy(tensor_term1_val).type(torch.LongTensor)\n",
        "tensor_term2_val = torch.from_numpy(tensor_term2_val).type(torch.LongTensor)\n",
        "tensor_score_val = torch.from_numpy(tensor_score_val).type(torch.FloatTensor)\n",
        "\n",
        "# Move the embeddings back to the CPU if not already there\n",
        "x_tgt = x_tgt.cpu()  # Target node embeddings\n",
        "x_src = x_src.cpu()  # Source node embeddings\n",
        "\n",
        "# Select embeddings for the training set\n",
        "X1_train = select_rows_by_index(embeddings_src, tensor_term1_train)\n",
        "X2_train = select_rows_by_index(x_src, tensor_term1_train)\n",
        "X3_train = select_rows_by_index(embeddings_tgt, tensor_term2_train)\n",
        "X4_train = select_rows_by_index(x_tgt, tensor_term2_train)\n",
        "\n",
        "# Select embeddings for the validation set\n",
        "X1_val = select_rows_by_index(embeddings_src, tensor_term1_val)\n",
        "X2_val = select_rows_by_index(x_src, tensor_term1_val)\n",
        "X3_val = select_rows_by_index(embeddings_tgt, tensor_term2_val)\n",
        "X4_val = select_rows_by_index(x_tgt, tensor_term2_val)\n",
        "\n",
        "# Now you have:\n",
        "# - Training tensors: X1_train, X2_train, X3_train, X4_train, tensor_score_train\n",
        "# - Validation tensors: X1_val, X2_val, X3_val, X4_val, tensor_score_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNdCgaTMExPK"
      },
      "source": [
        "# Gated Network Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Gof1eIPIWSVU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def train_gated_combination_model(X1_t, X2_t, X3_t, X4_t, tensor_score_o,\n",
        "                                  X1_val, X2_val, X3_val, X4_val, tensor_score_val,\n",
        "                                  epochs=120, batch_size=32, learning_rate=0.001, weight_decay=1e-5):\n",
        "    \"\"\"\n",
        "    Trains the GatedCombination model with training and validation data, using ReduceLROnPlateau scheduler.\n",
        "    Also calculates and displays F1-score during training and validation.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create datasets and DataLoaders\n",
        "    train_dataset = TensorDataset(X1_t, X2_t, X3_t, X4_t, tensor_score_o)\n",
        "    val_dataset = TensorDataset(X1_val, X2_val, X3_val, X4_val, tensor_score_val)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = GatedCombination(X1_t.shape[1]).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # Use ReduceLROnPlateau scheduler\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_train_loss = 0.0\n",
        "        y_true_train, y_pred_train = [], []\n",
        "\n",
        "        for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in train_loader:\n",
        "            batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (\n",
        "                batch_X1.to(device),\n",
        "                batch_X2.to(device),\n",
        "                batch_X3.to(device),\n",
        "                batch_X4.to(device),\n",
        "                batch_y.to(device),\n",
        "            )\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = F.binary_cross_entropy(outputs, batch_y.unsqueeze(1).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # Store true labels and predictions for F1-score\n",
        "            y_true_train.extend(batch_y.cpu().numpy())\n",
        "            y_pred_train.extend((outputs > 0.5).float().cpu().numpy())\n",
        "\n",
        "        train_loss = total_train_loss / len(train_loader)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # Calculate F1-score for training\n",
        "        train_f1 = f1_score(y_true_train, y_pred_train)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        total_val_loss = 0.0\n",
        "        y_true_val, y_pred_val = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in val_loader:\n",
        "                batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (\n",
        "                    batch_X1.to(device),\n",
        "                    batch_X2.to(device),\n",
        "                    batch_X3.to(device),\n",
        "                    batch_X4.to(device),\n",
        "                    batch_y.to(device),\n",
        "                )\n",
        "                outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n",
        "\n",
        "                # Compute loss\n",
        "                val_loss = F.binary_cross_entropy(outputs, batch_y.unsqueeze(1).float())\n",
        "                total_val_loss += val_loss.item()\n",
        "\n",
        "                # Store true labels and predictions for F1-score\n",
        "                y_true_val.extend(batch_y.cpu().numpy())\n",
        "                y_pred_val.extend((outputs > 0.5).float().cpu().numpy())\n",
        "\n",
        "        avg_val_loss = total_val_loss / len(val_loader)\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        # Calculate F1-score for validation\n",
        "        val_f1 = f1_score(y_true_val, y_pred_val)\n",
        "\n",
        "        # Step the scheduler with validation loss\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        # Print training and validation metrics\n",
        "        print(f\"Epoch [{epoch + 1}/{epochs}] Training Loss: {train_loss:.4f}, F1 Score: {train_f1:.4f} | \"\n",
        "              f\"Validation Loss: {avg_val_loss:.4f}, F1 Score: {val_f1:.4f}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Plotting training and validation loss\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label=\"Training Loss\", marker='o')\n",
        "    plt.plot(val_losses, label=\"Validation Loss\", marker='x')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Training complete! Total time: {end_time - start_time:.2f} seconds\")\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QrpFp6aDbtSW",
        "outputId": "7e1e7e10-de77-4d88-899b-366b8b6705af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100] Training Loss: 0.0339, F1 Score: 0.0000 | Validation Loss: 0.0342, F1 Score: 0.0000\n",
            "Epoch [2/100] Training Loss: 0.0315, F1 Score: 0.0000 | Validation Loss: 0.0316, F1 Score: 0.0000\n",
            "Epoch [3/100] Training Loss: 0.0293, F1 Score: 0.0000 | Validation Loss: 0.0298, F1 Score: 0.0000\n",
            "Epoch [4/100] Training Loss: 0.0273, F1 Score: 0.0051 | Validation Loss: 0.0282, F1 Score: 0.0056\n",
            "Epoch [5/100] Training Loss: 0.0256, F1 Score: 0.0447 | Validation Loss: 0.0257, F1 Score: 0.0334\n",
            "Epoch [6/100] Training Loss: 0.0241, F1 Score: 0.0827 | Validation Loss: 0.0246, F1 Score: 0.0815\n",
            "Epoch [7/100] Training Loss: 0.0227, F1 Score: 0.1672 | Validation Loss: 0.0231, F1 Score: 0.2696\n",
            "Epoch [8/100] Training Loss: 0.0214, F1 Score: 0.2349 | Validation Loss: 0.0231, F1 Score: 0.3844\n",
            "Epoch [9/100] Training Loss: 0.0203, F1 Score: 0.3177 | Validation Loss: 0.0205, F1 Score: 0.3070\n",
            "Epoch [10/100] Training Loss: 0.0194, F1 Score: 0.3715 | Validation Loss: 0.0198, F1 Score: 0.3955\n",
            "Epoch [11/100] Training Loss: 0.0186, F1 Score: 0.4469 | Validation Loss: 0.0191, F1 Score: 0.4817\n",
            "Epoch [12/100] Training Loss: 0.0179, F1 Score: 0.4798 | Validation Loss: 0.0182, F1 Score: 0.5126\n",
            "Epoch [13/100] Training Loss: 0.0172, F1 Score: 0.5197 | Validation Loss: 0.0175, F1 Score: 0.4979\n",
            "Epoch [14/100] Training Loss: 0.0167, F1 Score: 0.5470 | Validation Loss: 0.0173, F1 Score: 0.4817\n",
            "Epoch [15/100] Training Loss: 0.0162, F1 Score: 0.5766 | Validation Loss: 0.0163, F1 Score: 0.5726\n",
            "Epoch [16/100] Training Loss: 0.0158, F1 Score: 0.5957 | Validation Loss: 0.0159, F1 Score: 0.5610\n",
            "Epoch [17/100] Training Loss: 0.0154, F1 Score: 0.6142 | Validation Loss: 0.0160, F1 Score: 0.6629\n",
            "Epoch [18/100] Training Loss: 0.0151, F1 Score: 0.6269 | Validation Loss: 0.0154, F1 Score: 0.6450\n",
            "Epoch [19/100] Training Loss: 0.0147, F1 Score: 0.6352 | Validation Loss: 0.0154, F1 Score: 0.6827\n",
            "Epoch [20/100] Training Loss: 0.0146, F1 Score: 0.6503 | Validation Loss: 0.0150, F1 Score: 0.7055\n",
            "Epoch [21/100] Training Loss: 0.0142, F1 Score: 0.6616 | Validation Loss: 0.0144, F1 Score: 0.6827\n",
            "Epoch [22/100] Training Loss: 0.0141, F1 Score: 0.6605 | Validation Loss: 0.0144, F1 Score: 0.6996\n",
            "Epoch [23/100] Training Loss: 0.0138, F1 Score: 0.6700 | Validation Loss: 0.0143, F1 Score: 0.6778\n",
            "Epoch [24/100] Training Loss: 0.0137, F1 Score: 0.6793 | Validation Loss: 0.0141, F1 Score: 0.6996\n",
            "Epoch [25/100] Training Loss: 0.0136, F1 Score: 0.6902 | Validation Loss: 0.0145, F1 Score: 0.7171\n",
            "Epoch [26/100] Training Loss: 0.0133, F1 Score: 0.6923 | Validation Loss: 0.0142, F1 Score: 0.6642\n",
            "Epoch [27/100] Training Loss: 0.0131, F1 Score: 0.7055 | Validation Loss: 0.0143, F1 Score: 0.6900\n",
            "Epoch [28/100] Training Loss: 0.0133, F1 Score: 0.6944 | Validation Loss: 0.0133, F1 Score: 0.7217\n",
            "Epoch [29/100] Training Loss: 0.0130, F1 Score: 0.7129 | Validation Loss: 0.0135, F1 Score: 0.7020\n",
            "Epoch [30/100] Training Loss: 0.0130, F1 Score: 0.7065 | Validation Loss: 0.0134, F1 Score: 0.7340\n",
            "Epoch [31/100] Training Loss: 0.0129, F1 Score: 0.7188 | Validation Loss: 0.0132, F1 Score: 0.7308\n",
            "Epoch [32/100] Training Loss: 0.0128, F1 Score: 0.7226 | Validation Loss: 0.0130, F1 Score: 0.7091\n",
            "Epoch [33/100] Training Loss: 0.0127, F1 Score: 0.7277 | Validation Loss: 0.0130, F1 Score: 0.7161\n",
            "Epoch [34/100] Training Loss: 0.0126, F1 Score: 0.7226 | Validation Loss: 0.0128, F1 Score: 0.7276\n",
            "Epoch [35/100] Training Loss: 0.0127, F1 Score: 0.7255 | Validation Loss: 0.0131, F1 Score: 0.7091\n",
            "Epoch [36/100] Training Loss: 0.0126, F1 Score: 0.7229 | Validation Loss: 0.0131, F1 Score: 0.7101\n",
            "Epoch [37/100] Training Loss: 0.0126, F1 Score: 0.7248 | Validation Loss: 0.0141, F1 Score: 0.6424\n",
            "Epoch [38/100] Training Loss: 0.0124, F1 Score: 0.7304 | Validation Loss: 0.0137, F1 Score: 0.6876\n",
            "Epoch [39/100] Training Loss: 0.0124, F1 Score: 0.7356 | Validation Loss: 0.0127, F1 Score: 0.7299\n",
            "Epoch [40/100] Training Loss: 0.0123, F1 Score: 0.7350 | Validation Loss: 0.0132, F1 Score: 0.7020\n",
            "Epoch [41/100] Training Loss: 0.0123, F1 Score: 0.7441 | Validation Loss: 0.0125, F1 Score: 0.7500\n",
            "Epoch [42/100] Training Loss: 0.0122, F1 Score: 0.7432 | Validation Loss: 0.0133, F1 Score: 0.6924\n",
            "Epoch [43/100] Training Loss: 0.0123, F1 Score: 0.7425 | Validation Loss: 0.0125, F1 Score: 0.7566\n",
            "Epoch [44/100] Training Loss: 0.0122, F1 Score: 0.7408 | Validation Loss: 0.0132, F1 Score: 0.7705\n",
            "Epoch [45/100] Training Loss: 0.0122, F1 Score: 0.7404 | Validation Loss: 0.0127, F1 Score: 0.7230\n",
            "Epoch [46/100] Training Loss: 0.0122, F1 Score: 0.7482 | Validation Loss: 0.0125, F1 Score: 0.7420\n",
            "Epoch [47/100] Training Loss: 0.0121, F1 Score: 0.7477 | Validation Loss: 0.0134, F1 Score: 0.7065\n",
            "Epoch [48/100] Training Loss: 0.0121, F1 Score: 0.7329 | Validation Loss: 0.0126, F1 Score: 0.7703\n",
            "Epoch [49/100] Training Loss: 0.0121, F1 Score: 0.7334 | Validation Loss: 0.0125, F1 Score: 0.7522\n",
            "Epoch [50/100] Training Loss: 0.0120, F1 Score: 0.7451 | Validation Loss: 0.0128, F1 Score: 0.7321\n",
            "Epoch [51/100] Training Loss: 0.0121, F1 Score: 0.7471 | Validation Loss: 0.0124, F1 Score: 0.7474\n",
            "Epoch [52/100] Training Loss: 0.0120, F1 Score: 0.7554 | Validation Loss: 0.0147, F1 Score: 0.6024\n",
            "Epoch [53/100] Training Loss: 0.0121, F1 Score: 0.7506 | Validation Loss: 0.0127, F1 Score: 0.7161\n",
            "Epoch [54/100] Training Loss: 0.0120, F1 Score: 0.7408 | Validation Loss: 0.0123, F1 Score: 0.7655\n",
            "Epoch [55/100] Training Loss: 0.0121, F1 Score: 0.7518 | Validation Loss: 0.0121, F1 Score: 0.7732\n",
            "Epoch [56/100] Training Loss: 0.0120, F1 Score: 0.7461 | Validation Loss: 0.0124, F1 Score: 0.7660\n",
            "Epoch [57/100] Training Loss: 0.0120, F1 Score: 0.7571 | Validation Loss: 0.0124, F1 Score: 0.7299\n",
            "Epoch [58/100] Training Loss: 0.0120, F1 Score: 0.7496 | Validation Loss: 0.0121, F1 Score: 0.7617\n",
            "Epoch [59/100] Training Loss: 0.0120, F1 Score: 0.7488 | Validation Loss: 0.0128, F1 Score: 0.7161\n",
            "Epoch [60/100] Training Loss: 0.0120, F1 Score: 0.7445 | Validation Loss: 0.0126, F1 Score: 0.8033\n",
            "Epoch [61/100] Training Loss: 0.0120, F1 Score: 0.7484 | Validation Loss: 0.0121, F1 Score: 0.7668\n",
            "Epoch [62/100] Training Loss: 0.0120, F1 Score: 0.7550 | Validation Loss: 0.0121, F1 Score: 0.7823\n",
            "Epoch [63/100] Training Loss: 0.0120, F1 Score: 0.7496 | Validation Loss: 0.0123, F1 Score: 0.7430\n",
            "Epoch [64/100] Training Loss: 0.0119, F1 Score: 0.7516 | Validation Loss: 0.0134, F1 Score: 0.6654\n",
            "Epoch [65/100] Training Loss: 0.0120, F1 Score: 0.7525 | Validation Loss: 0.0122, F1 Score: 0.7474\n",
            "Epoch [66/100] Training Loss: 0.0119, F1 Score: 0.7500 | Validation Loss: 0.0124, F1 Score: 0.7552\n",
            "Epoch [67/100] Training Loss: 0.0120, F1 Score: 0.7508 | Validation Loss: 0.0117, F1 Score: 0.7808\n",
            "Epoch [68/100] Training Loss: 0.0119, F1 Score: 0.7492 | Validation Loss: 0.0122, F1 Score: 0.7411\n",
            "Epoch [69/100] Training Loss: 0.0119, F1 Score: 0.7479 | Validation Loss: 0.0121, F1 Score: 0.7939\n",
            "Epoch [70/100] Training Loss: 0.0119, F1 Score: 0.7610 | Validation Loss: 0.0130, F1 Score: 0.7091\n",
            "Epoch [71/100] Training Loss: 0.0119, F1 Score: 0.7492 | Validation Loss: 0.0122, F1 Score: 0.7703\n",
            "Epoch [72/100] Training Loss: 0.0119, F1 Score: 0.7529 | Validation Loss: 0.0122, F1 Score: 0.7626\n",
            "Epoch [73/100] Training Loss: 0.0119, F1 Score: 0.7556 | Validation Loss: 0.0124, F1 Score: 0.7574\n",
            "Epoch [74/100] Training Loss: 0.0120, F1 Score: 0.7539 | Validation Loss: 0.0120, F1 Score: 0.7857\n",
            "Epoch [75/100] Training Loss: 0.0119, F1 Score: 0.7577 | Validation Loss: 0.0122, F1 Score: 0.7690\n",
            "Epoch [76/100] Training Loss: 0.0119, F1 Score: 0.7471 | Validation Loss: 0.0121, F1 Score: 0.7753\n",
            "Epoch [77/100] Training Loss: 0.0120, F1 Score: 0.7527 | Validation Loss: 0.0125, F1 Score: 0.7933\n",
            "Epoch [78/100] Training Loss: 0.0119, F1 Score: 0.7519 | Validation Loss: 0.0121, F1 Score: 0.7587\n",
            "Epoch [79/100] Training Loss: 0.0111, F1 Score: 0.7773 | Validation Loss: 0.0116, F1 Score: 0.7919\n",
            "Epoch [80/100] Training Loss: 0.0111, F1 Score: 0.7837 | Validation Loss: 0.0116, F1 Score: 0.7829\n",
            "Epoch [81/100] Training Loss: 0.0111, F1 Score: 0.7779 | Validation Loss: 0.0116, F1 Score: 0.7724\n",
            "Epoch [82/100] Training Loss: 0.0111, F1 Score: 0.7822 | Validation Loss: 0.0117, F1 Score: 0.7724\n",
            "Epoch [83/100] Training Loss: 0.0111, F1 Score: 0.7810 | Validation Loss: 0.0116, F1 Score: 0.7829\n",
            "Epoch [84/100] Training Loss: 0.0111, F1 Score: 0.7806 | Validation Loss: 0.0116, F1 Score: 0.7891\n",
            "Epoch [85/100] Training Loss: 0.0111, F1 Score: 0.7785 | Validation Loss: 0.0117, F1 Score: 0.7766\n",
            "Epoch [86/100] Training Loss: 0.0111, F1 Score: 0.7776 | Validation Loss: 0.0116, F1 Score: 0.7926\n",
            "Epoch [87/100] Training Loss: 0.0111, F1 Score: 0.7837 | Validation Loss: 0.0116, F1 Score: 0.7808\n",
            "Epoch [88/100] Training Loss: 0.0111, F1 Score: 0.7760 | Validation Loss: 0.0117, F1 Score: 0.7761\n",
            "Epoch [89/100] Training Loss: 0.0112, F1 Score: 0.7810 | Validation Loss: 0.0116, F1 Score: 0.7823\n",
            "Epoch [90/100] Training Loss: 0.0111, F1 Score: 0.7807 | Validation Loss: 0.0116, F1 Score: 0.7823\n",
            "Epoch [91/100] Training Loss: 0.0110, F1 Score: 0.7846 | Validation Loss: 0.0116, F1 Score: 0.7836\n",
            "Epoch [92/100] Training Loss: 0.0110, F1 Score: 0.7861 | Validation Loss: 0.0116, F1 Score: 0.7836\n",
            "Epoch [93/100] Training Loss: 0.0110, F1 Score: 0.7825 | Validation Loss: 0.0116, F1 Score: 0.7836\n",
            "Epoch [94/100] Training Loss: 0.0110, F1 Score: 0.7834 | Validation Loss: 0.0116, F1 Score: 0.7823\n",
            "Epoch [95/100] Training Loss: 0.0110, F1 Score: 0.7816 | Validation Loss: 0.0116, F1 Score: 0.7823\n",
            "Epoch [96/100] Training Loss: 0.0110, F1 Score: 0.7852 | Validation Loss: 0.0116, F1 Score: 0.7823\n",
            "Epoch [97/100] Training Loss: 0.0110, F1 Score: 0.7852 | Validation Loss: 0.0116, F1 Score: 0.7816\n",
            "Epoch [98/100] Training Loss: 0.0110, F1 Score: 0.7797 | Validation Loss: 0.0116, F1 Score: 0.7823\n",
            "Epoch [99/100] Training Loss: 0.0110, F1 Score: 0.7843 | Validation Loss: 0.0116, F1 Score: 0.7823\n",
            "Epoch [100/100] Training Loss: 0.0110, F1 Score: 0.7834 | Validation Loss: 0.0116, F1 Score: 0.7836\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete! Total time: 1305.52 seconds\n"
          ]
        }
      ],
      "source": [
        "# Train the GatedCombination model using training and validation data\n",
        "trained_model = train_gated_combination_model(\n",
        "    X1_train,          # Updated source embeddings (after applying the GNN model)\n",
        "    X2_train,          # Original source embeddings (before applying the GNN model)\n",
        "    X3_train,          # Updated target embeddings (after applying the GNN model)\n",
        "    X4_train,          # Original target embeddings (before applying the GNN model)\n",
        "    tensor_score_train, # Ground truth labels for the training set (1 for matched pairs, 0 for unmatched pairs)\n",
        "\n",
        "    X1_val,            # Updated source embeddings for the validation set\n",
        "    X2_val,            # Original source embeddings for the validation set\n",
        "    X3_val,            # Updated target embeddings for the validation set\n",
        "    X4_val,            # Original target embeddings for the validation set\n",
        "    tensor_score_val,  # Ground truth labels for the validation set (1 for matched pairs, 0 for unmatched pairs)\n",
        "\n",
        "    epochs=100,        # Number of epochs (iterations over the entire training dataset)\n",
        "    batch_size=32,     # Number of training samples processed in one forward/backward pass\n",
        "    learning_rate=0.001, # Learning rate for the optimizer (controls step size during optimization)\n",
        "    weight_decay=1e-4 # Weight decay (L2 regularization) to prevent overfitting\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAmLuMtGW9c2"
      },
      "source": [
        "# **Second Round Modifications**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVDqN5AxFu9m"
      },
      "source": [
        "# **Generate Embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ITZZcElm8qRN"
      },
      "outputs": [],
      "source": [
        "# Build an indexed dictionary for the source ontology classes\n",
        "# src_class is the file path to the JSON file containing the source ontology classes\n",
        "indexed_dict_src = build_indexed_dict(src_class)\n",
        "\n",
        "# Build an indexed dictionary for the target ontology classes\n",
        "# tgt_class is the file path to the JSON file containing the target ontology classes\n",
        "indexed_dict_tgt = build_indexed_dict(tgt_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbSbmPlRDOs3",
        "outputId": "ff50586d-4af9-420f-f1ec-4e09d27c02fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Gated embeddings saved:\n",
            "- Source: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_SapBERT.tsv\n",
            "- Target: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_SapBERT.tsv\n",
            "⏱️ Execution time: 40.53 seconds\n"
          ]
        }
      ],
      "source": [
        "# Define output file paths for final embeddings of source and target ontologies\n",
        "output_file_src = f\"{data_dir}/{src_ent}_final_embeddings_SapBERT.tsv\"\n",
        "output_file_tgt = f\"{data_dir}/{tgt_ent}_final_embeddings_SapBERT.tsv\"\n",
        "\n",
        "# Save the final gated embeddings for all concepts in source and target ontologies\n",
        "save_gated_embeddings(\n",
        "    gated_model=trained_model,          # The trained GatedCombination model\n",
        "    embeddings_src=embeddings_src,      # GNN-transformed embeddings for source entities\n",
        "    x_src=x_src,                        # Initial semantic embeddings for source entities\n",
        "    embeddings_tgt=embeddings_tgt,      # GNN-transformed embeddings for target entities\n",
        "    x_tgt=x_tgt,                        # Initial semantic embeddings for target entities\n",
        "    indexed_dict_src=indexed_dict_src,  # Index-to-URI mapping for source ontology\n",
        "    indexed_dict_tgt=indexed_dict_tgt,  # Index-to-URI mapping for target ontology\n",
        "    output_file_src=output_file_src,    # Destination file path for source embeddings\n",
        "    output_file_tgt=output_file_tgt     # Destination file path for target embeddings\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIDvbZj2GIGo"
      },
      "source": [
        "# **Filter No Used Concepts**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Gl_wUG9KADo",
        "outputId": "71b0ce8c-3856-4ff0-a15f-9c7458373158"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Initial source file: 23107 rows\n",
            "🔍 Initial target file: 20498 rows\n",
            "✅ Source after removing ignored classes: 11407 rows\n",
            "✅ Target after removing ignored classes: 14207 rows\n",
            "📁 Cleaned source file saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_SapBERT_cleaned.tsv\n",
            "📁 Cleaned target file saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_SapBERT_cleaned.tsv\n"
          ]
        }
      ],
      "source": [
        "# Call the function to filter out ignored concepts (e.g., owl:Thing, deprecated, etc.)\n",
        "# from the source and target ontology embeddings.\n",
        "\n",
        "# Input:\n",
        "# - src_emb_path: Path to the TSV file containing embeddings for the source ontology\n",
        "# - tgt_emb_path: Path to the TSV file containing embeddings for the target ontology\n",
        "# - src_onto / tgt_onto: DeepOnto ontology objects used to identify ignored concepts\n",
        "\n",
        "# Output:\n",
        "# - src_file: Path to the cleaned source embeddings (with ignored concepts removed)\n",
        "# - tgt_file: Path to the cleaned target embeddings (with ignored concepts removed)\n",
        "\n",
        "src_file, tgt_file = filter_ignored_class(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_SapBERT.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_SapBERT.tsv\",\n",
        "    src_onto=src_onto,\n",
        "    tgt_onto=tgt_onto\n",
        "\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpUklR4xnVMH"
      },
      "source": [
        "# **Mappings Generation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP5o60scKn2e"
      },
      "source": [
        "# **Using faiss l2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOSRYREwerBi",
        "outputId": "62b7dacf-cf48-442a-b93f-b34871fed01d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-10 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_SapBERT.tsv\n",
            "⏱️ Execution time: 13.54 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using l2 distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the l2 distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_l2(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_SapBERT_cleaned.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_SapBERT_cleaned.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2_SapBERT.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD-mvVjaerBh"
      },
      "source": [
        "# **Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Global Metrics: Precision, Recall and F1 score**"
      ],
      "metadata": {
        "id": "r8GRfT_pR1kD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WZKJM46erBi",
        "outputId": "fe5e5d2e-dea8-4aa1-ad17-a887d3ffa966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 94192 rows\n",
            "✅ After keeping only test SrcEntities: 22267 rows\n",
            "✅ After applying threshold ≥ 0.0: 22267 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_SapBERT_filtered.tsv\n",
            "🏆 Selected candidates within 99.2% of best score per SrcEntity: 2564 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_SapBERT_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1683\n",
            "📊 Evaluation (P / R / F1): {'P': 0.656, 'R': 0.632, 'F1': 0.644}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = evaluate_predictions(\n",
        "    pred_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2_SapBERT.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}