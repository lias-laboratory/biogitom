{"cells":[{"cell_type":"markdown","metadata":{"id":"MkAX88H3RNRW"},"source":["# **Package Installation**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SlL2v0xgmFJ-","outputId":"55d285c4-3b25-4abe-b48e-fc1a93ba80be","executionInfo":{"status":"ok","timestamp":1735215050329,"user_tz":-60,"elapsed":204400,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==2.0.0\n","  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.16.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n","  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n","  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n","  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n","  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n","  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n","  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.0.0 (from torch==2.0.0)\n","  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (75.1.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.45.1)\n","Collecting cmake (from triton==2.0.0->torch==2.0.0)\n","  Downloading cmake-3.31.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n","Collecting lit (from triton==2.0.0->torch==2.0.0)\n","  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n","Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m614.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cmake-3.31.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.8/27.8 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, cmake, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.1+cpu\n","    Uninstalling torch-2.5.1+cpu:\n","      Successfully uninstalled torch-2.5.1+cpu\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.5.1+cpu requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\n","torchvision 0.20.1+cpu requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed cmake-3.31.2 lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 triton-2.0.0\n","Collecting torch-geometric==2.4.0\n","  Downloading torch_geometric-2.4.0-py3-none-any.whl.metadata (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (4.67.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (3.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (2.32.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (3.2.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.6.0)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric==2.4.0) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (2024.12.14)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.4.0) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.4.0) (3.5.0)\n","Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-geometric\n","Successfully installed torch-geometric-2.4.0\n","Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_scatter-2.1.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (494 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_sparse-0.6.18%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-cluster\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_cluster-1.6.3%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (751 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.3/751.3 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-spline-conv\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (208 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n","Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n","Installing collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster\n","Successfully installed torch-cluster-1.6.3+pt20cpu torch-scatter-2.1.2+pt20cpu torch-sparse-0.6.18+pt20cpu torch-spline-conv-1.2.2+pt20cpu\n","Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.67.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.6.0)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.12.14)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting deeponto\n","  Downloading deeponto-0.9.2-py3-none-any.whl.metadata (15 kB)\n","Collecting JPype1 (from deeponto)\n","  Downloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting yacs (from deeponto)\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deeponto) (2.0.0)\n","Collecting anytree (from deeponto)\n","  Downloading anytree-2.12.1-py3-none-any.whl.metadata (8.1 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from deeponto) (8.1.7)\n","Collecting dill (from deeponto)\n","  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from deeponto) (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deeponto) (1.26.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deeponto) (1.6.0)\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (from deeponto) (4.47.1)\n","Collecting datasets (from deeponto)\n","  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.7.5)\n","Collecting pprintpp (from deeponto)\n","  Downloading pprintpp-0.4.0-py2.py3-none-any.whl.metadata (7.9 kB)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.4.2)\n","Collecting lxml (from deeponto)\n","  Downloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n","Collecting textdistance (from deeponto)\n","  Downloading textdistance-4.6.3-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from deeponto) (7.7.1)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from deeponto) (5.5.6)\n","Collecting enlighten (from deeponto)\n","  Downloading enlighten-1.13.0-py2.py3-none-any.whl.metadata (18 kB)\n","Collecting rdflib (from deeponto)\n","  Downloading rdflib-7.1.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.9.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anytree->deeponto) (1.17.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (18.1.0)\n","Collecting dill (from deeponto)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (4.67.1)\n","Collecting xxhash (from datasets->deeponto)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets->deeponto)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->deeponto)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (3.11.11)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (0.27.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (6.0.2)\n","Collecting blessed>=1.17.7 (from enlighten->deeponto)\n","  Downloading blessed-1.20.0-py2.py3-none-any.whl.metadata (13 kB)\n","Collecting prefixed>=0.3.2 (from enlighten->deeponto)\n","  Downloading prefixed-0.9.0-py2.py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (0.2.0)\n","Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (7.34.0)\n","Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (5.7.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (6.1.12)\n","Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (6.3.3)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->deeponto) (3.6.10)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->deeponto) (3.0.13)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->deeponto) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->deeponto) (2024.11.6)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2024.2)\n","Collecting isodate<1.0.0,>=0.7.2 (from rdflib->deeponto)\n","  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib->deeponto) (3.2.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deeponto) (1.13.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deeponto) (3.5.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.0.11)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.0.10)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.5.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (0.15.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.10.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.1.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (75.1.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.5.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (1.13.1)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (2.0.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->deeponto) (0.45.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deeponto) (3.31.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deeponto) (18.1.8)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (0.4.5)\n","Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (1.2.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->transformers[torch]->deeponto) (5.9.5)\n","Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.7->enlighten->deeponto) (0.2.13)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.3.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (5.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (24.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.18.3)\n","Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->deeponto)\n","  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (5.1.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (3.0.48)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (2.18.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (4.9.0)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (2.27.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (2024.12.14)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->deeponto) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->deeponto) (0.1.5)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (0.20.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (7.1.0)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.5.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy->deeponto) (3.0.2)\n","Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->deeponto) (5.7.2)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->deeponto) (24.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deeponto) (1.3.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->deeponto) (0.8.4)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel->deeponto) (4.3.6)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.2.1)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (23.1.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (5.10.4)\n","Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (7.16.4)\n","Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.6.0)\n","Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.3)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.18.1)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.21.1)\n","Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.1.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel->deeponto) (0.7.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (3.0.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->deeponto) (1.14.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (0.1.2)\n","Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.2.4)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.12.3)\n","Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.2.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.7.1)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.3.0)\n","Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.0.2)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.10.1)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.5.1)\n","Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.4.0)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.21.1)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.23.0)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (21.2.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.5.1)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.22.3)\n","Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.24.0)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.17.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.6)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.22)\n","Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.7.1)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.2.2)\n","Downloading deeponto-0.9.2-py3-none-any.whl (89.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading anytree-2.12.1-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading enlighten-1.13.0-py2.py3-none-any.whl (42 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.8/493.8 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n","Downloading rdflib-7.1.1-py3-none-any.whl (562 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m562.4/562.4 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading textdistance-4.6.3-py3-none-any.whl (31 kB)\n","Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n","Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading prefixed-0.9.0-py2.py3-none-any.whl (13 kB)\n","Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: prefixed, pprintpp, yacs, xxhash, textdistance, lxml, JPype1, jedi, isodate, fsspec, dill, blessed, anytree, rdflib, multiprocess, enlighten, datasets, deeponto\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","Successfully installed JPype1-1.5.1 anytree-2.12.1 blessed-1.20.0 datasets-3.2.0 deeponto-0.9.2 dill-0.3.8 enlighten-1.13.0 fsspec-2024.9.0 isodate-0.7.2 jedi-0.19.2 lxml-5.3.0 multiprocess-0.70.16 pprintpp-0.4.0 prefixed-0.9.0 rdflib-7.1.1 textdistance-4.6.3 xxhash-3.5.0 yacs-0.1.8\n","/bin/bash: line 1: username: No such file or directory\n"]}],"source":["# We assume that PyTorch is already installed in the environment.\n","# If not, this command installs it.\n","!pip install torch==2.0.0\n","\n","# Install PyTorch Geometric, a library for creating graph neural networks using PyTorch.\n","!pip install torch-geometric==2.4.0\n","\n","# Import PyTorch to access its functionalities.\n","import torch\n","\n","# Install additional PyTorch Geometric dependencies for graph processing (scatter, sparse, cluster, spline-conv).\n","# These packages enable operations like sparse tensors and convolutions on graphs.\n","!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","\n","# Reinstall PyTorch Geometric to ensure all dependencies are correctly loaded.\n","!pip install torch-geometric\n","\n","# Retrieve the installed version of PyTorch to ensure compatibility with other packages.\n","torchversion = torch.__version__\n","\n","# Install the latest version of PyTorch Geometric directly from the GitHub repository.\n","# This allows access to the most recent updates and features for graph-based neural networks.\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","\n","# Install DeepOnto, a package specifically designed for ontology matching, particularly useful in biomedical applications.\n","!pip install deeponto\n","\n","# Install a custom version of DeepOnto from a GitHub repository.\n","# The '<username>' part should be replaced with the actual GitHub username of the repository maintainer.\n","!pip install git+https://github.com/<username>/deeponto.git\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"HPAlAgjLMVhw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735215068459,"user_tz":-60,"elapsed":18148,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"ee34ccb6-a89f-4be6-917e-4d4076eef894"},"outputs":[{"output_type":"stream","name":"stdout","text":["Please enter the maximum memory located to JVM [8g]: 8g\n","\n"]}],"source":["# Import pandas for data manipulation and analysis, such as loading, processing, and saving tabular data.\n","import pandas as pd\n","\n","# Import pickle for saving and loading serialized objects (e.g., trained models or preprocessed data).\n","import pickle\n","\n","# Import function to convert a directed graph to an undirected one, useful for certain graph algorithms.\n","from torch_geometric.utils import to_undirected\n","\n","# Import optimizer module from PyTorch for training models using gradient-based optimization techniques.\n","import torch.optim as optim\n","\n","# Import PyTorch's modules for defining neural network architectures and operations:\n","from torch.nn import (\n","    Linear,       # For linear transformations (dense layers).\n","    Sequential,   # For stacking layers sequentially.\n","    BatchNorm1d,  # For normalizing input within mini-batches.\n","    PReLU,        # Parametric ReLU activation function.\n","    Dropout       # For regularization by randomly dropping connections during training.\n",")\n","\n","# Import functional API from PyTorch for operations like activations and loss functions.\n","import torch.nn.functional as F\n","\n","# Import Matplotlib for visualizations, such as plotting training loss curves.\n","import matplotlib.pyplot as plt\n","\n","# Import PyTorch Geometric's graph convolutional layers:\n","from torch_geometric.nn import GCNConv, GINConv\n","\n","# Import pooling operations for aggregating node embeddings to graph-level representations:\n","from torch_geometric.nn import global_mean_pool, global_add_pool\n","\n","# Import NumPy for numerical operations, such as working with arrays and matrices.\n","import numpy as np\n","\n","# Import time module for measuring execution time of code blocks.\n","import time\n","\n","# Import typing module for specifying types in function arguments and return values.\n","from typing import Optional, Tuple, Union, Callable\n","\n","# Import PyTorch's DataLoader and TensorDataset for handling data batching and loading during training.\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","# Import PyTorch's Parameter class for defining learnable parameters in custom models.\n","from torch.nn import Parameter\n","\n","# Import math module for performing mathematical computations.\n","import math\n","\n","# Import Tensor type from PyTorch for defining and manipulating tensors.\n","from torch import Tensor\n","\n","# Import PyTorch's nn module for defining and building neural network architectures.\n","import torch.nn as nn\n","\n","# Import initialization utilities from PyTorch Geometric for resetting weights and biases in layers.\n","from torch_geometric.nn.inits import reset\n","\n","# Import the base class for defining message-passing layers in graph neural networks (GNNs).\n","from torch_geometric.nn.conv import MessagePassing\n","\n","# Import linear transformation utilities for creating dense representations in graph models.\n","from torch_geometric.nn.dense.linear import Linear\n","\n","# Import typing utilities for defining adjacency matrices and tensor types specific to PyTorch Geometric.\n","from torch_geometric.typing import Adj, OptTensor, PairTensor, SparseTensor\n","\n","# Import softmax function for normalizing attention scores in GNNs.\n","from torch_geometric.utils import softmax\n","\n","# Import initialization utilities for weight initialization (e.g., Glorot initialization).\n","from torch_geometric.nn.inits import glorot, zeros\n","\n","# Import F1 score metric from scikit-learn for evaluating model performance in binary/multi-class tasks.\n","from sklearn.metrics import f1_score\n","\n","# Import JSON module for reading and writing JSON files, useful for storing configuration or ontology data.\n","import json\n","\n","# Import Ontology class from DeepOnto for representing and manipulating ontologies in the pipeline.\n","from deeponto.onto import Ontology\n","\n","# Import tools from DeepOnto for handling Ontology Alignment Evaluation Initiative (OAEI) tasks.\n","from deeponto.align.oaei import *\n","\n","# Import evaluation tools from DeepOnto for assessing alignment results using metrics like precision, recall, and F1.\n","from deeponto.align.evaluation import AlignmentEvaluator\n","\n","# Import mapping utilities from DeepOnto for working with reference mappings and entity pairs.\n","from deeponto.align.mapping import ReferenceMapping, EntityMapping\n","\n","# Import utility function for reading tables (e.g., TSV, CSV) from DeepOnto.\n","from deeponto.utils import read_table\n","\n","# Importing the train_test_split function from sklearn's model_selection module.\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"-abbBHOoRdWl"},"source":["# **Paths Definition**"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AVgl_Bb42naS","outputId":"4f9748ae-f3da-45bf-e691-7e6d054235c7","executionInfo":{"status":"ok","timestamp":1735215088666,"user_tz":-60,"elapsed":20213,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# Importing the 'drive' module from Google Colab to interact with Google Drive\n","from google.colab import drive\n","\n","# Mount the user's Google Drive to the Colab environment\n","# After running this, a link will appear to authorize access, and Google Drive will be mounted at '/content/gdrive'\n","drive.mount('/content/gdrive')\n"]},{"cell_type":"code","source":["import random\n","\n","# Set the seed for PyTorch's random number generator to ensure reproducibility\n","torch.manual_seed(42)\n","\n","# Set the seed for NumPy's random number generator to ensure reproducibility\n","np.random.seed(42)\n","\n","# Set the seed for Python's built-in random module to ensure reproducibility\n","random.seed(42)"],"metadata":{"id":"n5j8x2HqWs4_","executionInfo":{"status":"ok","timestamp":1735215088667,"user_tz":-60,"elapsed":7,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eQxSrJP7WoIj"},"source":["# **Paths Definition**"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2db4d54d-fd5b-4ec1-dd93-68cfcbbad811","executionInfo":{"status":"ok","timestamp":1735215090564,"user_tz":-60,"elapsed":1903,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"id":"detugQhiWoIk"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["# Importing the 'drive' module from Google Colab to interact with Google Drive\n","from google.colab import drive\n","\n","# Mount the user's Google Drive to the Colab environment\n","# After running this, a link will appear to authorize access, and Google Drive will be mounted at '/content/gdrive'\n","drive.mount('/content/gdrive')\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"36ttssQ3W7cx","executionInfo":{"status":"ok","timestamp":1735215090565,"user_tz":-60,"elapsed":7,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Define the source ontology name\n","src_ent = \"snomed.neoplas\"\n","\n","# Define the target ontology name\n","tgt_ent = \"ncit.neoplas\"\n","\n","# Define the task name for this ontology matching process\n","task = \"neoplas\"\n","\n","# Define the similarity threshold for validating matches\n","thres = 0.20"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"SJpvkdwVSQye","executionInfo":{"status":"ok","timestamp":1735215090565,"user_tz":-60,"elapsed":6,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["dir = \"/content/gdrive/My Drive/BioGITOM-VLDB/\"\n","\n","# Define the directory for the dataset containing source and target ontologies\n","dataset_dir = f\"{dir}/Datasets/{task}\"\n","\n","# Define the data directory for storing embeddings, adjacency matrices, and related files\n","data_dir = f\"{dir}/{task}/Data\"\n","\n","# Define the directory for storing the results\n","results_dir = f\"{dir}/{task}/Results\""]},{"cell_type":"code","execution_count":8,"metadata":{"id":"eFDNSFef23er","executionInfo":{"status":"ok","timestamp":1735215113977,"user_tz":-60,"elapsed":23417,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Load the Source ontology using the Ontology class from DeepOnto\n","# This initializes the source ontology by loading its .owl file.\n","src_onto = Ontology(f\"{dataset_dir}/{src_ent}.owl\")\n","\n","# Load the Target ontology using the Ontology class from DeepOnto\n","# This initializes the target ontology by loading its .owl file.\n","tgt_onto = Ontology(f\"{dataset_dir}/{tgt_ent}.owl\")\n","\n","# Define the file path for the Source embeddings CSV file\n","# Embeddings for the source ontology entities are stored in this file.\n","src_Emb = f\"{data_dir}/{src_ent}_bert-base-nli-mean-tokens_emb.csv\"\n","\n","# Define the file path for the Target embeddings CSV file\n","# Embeddings for the target ontology entities are stored in this file.\n","tgt_Emb = f\"{data_dir}/{tgt_ent}_bert-base-nli-mean-tokens_emb.csv\"\n","\n","# Define the file path for the Source adjacency matrix\n","# This file represents the relationships (edges) between entities in the source ontology.\n","src_Adjacence = f\"{data_dir}/{src_ent}_adjacence.csv\"\n","\n","# Define the file path for the Target adjacency matrix\n","# This file represents the relationships (edges) between entities in the target ontology.\n","tgt_Adjacence = f\"{data_dir}/{tgt_ent}_adjacence.csv\"\n","\n","# Define the file path for the JSON file containing the Source ontology class labels\n","# This file maps the source ontology entities to their labels or names.\n","src_class = f\"{data_dir}/{src_ent}_classes.json\"\n","\n","# Define the file path for the JSON file containing the Target ontology class labels\n","# This file maps the target ontology entities to their labels or names.\n","tgt_class = f\"{data_dir}/{tgt_ent}_classes.json\"\n","\n","# Define the file path for the train data\n","train_file = f\"{data_dir}/{task}_train.csv\"\n","\n","# Define the file path for the test data\n","# The test file contains reference mappings (ground truth) between the source and target ontologies.\n","test_file = f\"{dataset_dir}/refs_equiv/test.tsv\"\n","\n","# Define the file path for the candidate mappings used during testing\n","# This file includes the candidate pairs (source and target entities) for ranking and evaluation.\n","test_cands = f\"{dataset_dir}/refs_equiv/test.cands.tsv\"\n","\n","# Define the file path for the candidate mappings between Source to Target entities\n","# This file contains cleaned, combined, and encoded candidates used for predictions.\n","candidates_Prediction = f\"{data_dir}/{task}_candidates_prediction.csv\"\n","\n","# Define the file path for the candidate mappings between Source to Target entities for ranking-based metrics\n","# This file is used to compute ranking-based metrics like MRR and Hits@k.\n","candidates_Rank = f\"{data_dir}/{task}_candidates.csv\"\n","\n","# Define the path where the prediction results will be saved in TSV format\n","# This file will store the final predictions (mappings) between source and target entities.\n","prediction_path = f\"{results_dir}/{task}_matching_results.tsv\"\n","\n","# Define the path where all prediction results will be saved in TSV format\n","# This file will store detailed prediction results, including all candidate scores.\n","all_predictions_path = f\"{results_dir}/{task}_all_predictions.tsv\"\n","\n","# Define the path where all ranking prediction results will be saved in TSV format\n","# This file will store predictions sorted by rank based on their scores.\n","all_predictions_path_ranked = f\"{results_dir}/{task}_all_predictions_ranked.tsv\"\n","\n","# Define the path where formatted ranking predictions will be saved in TSV format\n","# This file will contain predictions formatted for evaluation using ranking-based metrics.\n","formatted_predictions_path = f\"{results_dir}/{task}_formatted_predictions.tsv\""]},{"cell_type":"markdown","metadata":{"id":"zqEXsgPGMVhw"},"source":["# **GIT Architecture**\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"A_d6XCsUMVhx","executionInfo":{"status":"ok","timestamp":1735215113978,"user_tz":-60,"elapsed":10,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# RGIT class definition which inherits from PyTorch Geometric's MessagePassing class\n","class RGIT(MessagePassing):\n","\n","    _alpha: OptTensor  # Define _alpha as an optional tensor for storing attention weights\n","\n","    def __init__(\n","        self,\n","        nn: Callable,  # Neural network to be used in the final layer of the GNN\n","        in_channels: Union[int, Tuple[int, int]],  # Input dimension, can be a single or pair of integers\n","        out_channels: int,  # Output dimension of the GNN\n","        eps: float = 0.,  # GIN parameter: epsilon for GIN aggregation\n","        train_eps: bool = False,  # GIN parameter: whether epsilon should be learnable\n","        heads: int = 1,  # Transformer parameter: number of attention heads\n","        dropout: float = 0.,  # Dropout rate for attention weights\n","        edge_dim: Optional[int] = None,  # Dimension for edge attributes (optional)\n","        bias: bool = True,  # Whether to use bias in linear layers\n","        root_weight: bool = True,  # GIN parameter: whether to apply root weight in aggregation\n","        **kwargs,  # Additional arguments passed to the parent class\n","    ):\n","        # Set the aggregation type to 'add' and initialize the parent class with node_dim=0\n","        kwargs.setdefault('aggr', 'add')\n","        super().__init__(node_dim=0, **kwargs)\n","\n","        # Initialize input/output dimensions, neural network, and GIN/transformer parameters\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.nn = nn  # Neural network used by the GNN\n","        self.initial_eps = eps  # Initial value of epsilon for GIN\n","\n","        # Set epsilon to be learnable or fixed\n","        if train_eps:\n","            self.eps = torch.nn.Parameter(torch.empty(1))  # Learnable epsilon\n","        else:\n","            self.register_buffer('eps', torch.empty(1))  # Non-learnable epsilon (fixed)\n","\n","        # Initialize transformer-related parameters\n","        self.heads = heads\n","        self.dropout = dropout\n","        self.edge_dim = edge_dim\n","        self._alpha = None  # Placeholder for attention weights\n","\n","        # Handle case where in_channels is a single integer or a tuple\n","        if isinstance(in_channels, int):\n","            in_channels = (in_channels, in_channels)\n","\n","        # Define the linear layers for key, query, and value for the transformer mechanism\n","        self.lin_key = Linear(in_channels[0], heads * out_channels)\n","        self.lin_query = Linear(in_channels[1], heads * out_channels)\n","        self.lin_value = Linear(in_channels[0], heads * out_channels)\n","\n","        # Define linear transformation for edge embeddings if provided\n","        if edge_dim is not None:\n","            self.lin_edge = Linear(edge_dim, heads * out_channels, bias=False)\n","        else:\n","            self.lin_edge = self.register_parameter('lin_edge', None)\n","\n","        # Reset all parameters to their initial values\n","        self.reset_parameters()\n","\n","    # Function to reset model parameters\n","    def reset_parameters(self):\n","        super().reset_parameters()  # Call parent class reset method\n","        self.lin_key.reset_parameters()  # Reset key linear layer\n","        self.lin_query.reset_parameters()  # Reset query linear layer\n","        self.lin_value.reset_parameters()  # Reset value linear layer\n","        if self.edge_dim:\n","            self.lin_edge.reset_parameters()  # Reset edge linear layer if used\n","        reset(self.nn)  # Reset the neural network provided\n","        self.eps.data.fill_(self.initial_eps)  # Initialize epsilon with the starting value\n","\n","    # Forward function defining how the input data flows through the model\n","    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj,\n","                edge_attr: OptTensor = None, return_attention_weights=None):\n","        # Unpack number of heads and output channels\n","        H, C = self.heads, self.out_channels\n","\n","        # If x is a tensor, treat it as a pair of tensors (source and target embeddings)\n","        if isinstance(x, Tensor):\n","            x: PairTensor = (x, x)\n","\n","        # Extract source node embeddings\n","        x_t = x[0]\n","\n","        # Apply linear transformations and reshape query, key, and value for multi-head attention\n","        query = self.lin_query(x[1]).view(-1, H, C)\n","        key = self.lin_key(x[0]).view(-1, H, C)\n","        value = self.lin_value(x[0]).view(-1, H, C)\n","\n","        # Propagate messages through the graph using the propagate function\n","        out = self.propagate(edge_index, query=query, key=key, value=value,\n","                             edge_attr=edge_attr, size=None)\n","\n","        # Retrieve attention weights and reset them\n","        alpha = self._alpha\n","        self._alpha = None  # Reset _alpha after use\n","        out = out.mean(dim=1)  # Take the mean over all attention heads\n","\n","        # Apply GIN aggregation by adding epsilon-scaled original node embeddings\n","        out = out + (1 + self.eps) * x_t\n","        return self.nn(out)  # Pass through the neural network\n","\n","    # Message passing function which calculates attention and combines messages\n","    def message(self, query_i: Tensor, key_j: Tensor, value_j: Tensor,\n","                edge_attr: OptTensor, index: Tensor, ptr: OptTensor,\n","                size_i: Optional[int]) -> Tensor:\n","        # If edge attributes are used, apply linear transformation and add them to the key\n","        if self.lin_edge is not None:\n","            assert edge_attr is not None\n","            edge_attr = self.lin_edge(edge_attr).view(-1, self.heads, self.out_channels)\n","            key_j = key_j + edge_attr\n","\n","        # Calculate attention (alpha) using the dot product between query and key\n","        alpha = (query_i * key_j).sum(dim=-1) / math.sqrt(self.out_channels)\n","        alpha = softmax(alpha, index, ptr, size_i)  # Apply softmax to normalize attention\n","        self._alpha = alpha  # Store attention weights\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)  # Apply dropout\n","\n","        # Calculate the output message by applying attention to the value\n","        out = value_j\n","        if edge_attr is not None:\n","            out = out + edge_attr  # Add edge embeddings to the output if present\n","        out = out * alpha.view(-1, self.heads, 1)  # Scale by attention weights\n","        return out\n","\n","    # String representation function for debugging or printing\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}({self.in_channels}, '\n","                f'{self.out_channels}, heads={self.heads})')"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"qwFv6RgHmGCf","executionInfo":{"status":"ok","timestamp":1735215113978,"user_tz":-60,"elapsed":9,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Define the RGIT_mod class, a multi-layer GNN that uses both RGIT and linear layers\n","class RGIT_mod(torch.nn.Module):\n","    \"\"\"Multi-layer RGIT with optional linear layers\"\"\"\n","\n","    # Initialize the model with hidden dimension, number of RGIT layers, and number of linear layers\n","    def __init__(self, dim_h, num_layers, num_linear_layers=1):\n","        super(RGIT_mod, self).__init__()\n","        self.num_layers = num_layers  # Number of RGIT layers\n","        self.num_linear_layers = num_linear_layers  # Number of linear layers\n","        self.linears = torch.nn.ModuleList()  # List to store linear layers\n","        self.rgit_layers = torch.nn.ModuleList()  # List to store RGIT layers\n","\n","        # Create a list of Linear and PReLU layers (for encoding entity names)\n","        for _ in range(num_linear_layers):\n","            self.linears.append(Linear(dim_h, dim_h))  # Linear transformation layer\n","            self.linears.append(PReLU(num_parameters=dim_h))  # Parametric ReLU activation function\n","\n","        # Create a list of RGIT layers\n","        for _ in range(num_layers):\n","            self.rgit_layers.append(RGIT(  # Each RGIT layer contains a small MLP with Linear and PReLU\n","                Sequential(Linear(dim_h, dim_h), PReLU(num_parameters=dim_h),\n","                           Linear(dim_h, dim_h), PReLU(num_parameters=dim_h)), dim_h, dim_h))\n","\n","    # Forward pass through the model\n","    def forward(self, x, edge_index):\n","        # Apply the linear layers first to the input\n","        for layer in self.linears:\n","            x = layer(x)\n","\n","        # Then apply the RGIT layers for message passing\n","        for layer in self.rgit_layers:\n","            x = layer(x, edge_index)\n","\n","        return x  # Return the final node embeddings after all layers\n"]},{"cell_type":"markdown","metadata":{"id":"zxCn5ztKVztw"},"source":["# **Gated Network Architecture**"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"7MKQUv7o7zay","executionInfo":{"status":"ok","timestamp":1735215113978,"user_tz":-60,"elapsed":8,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["class GatedCombination(nn.Module):\n","    \"\"\"\n","    A neural network module for combining embeddings using a gating mechanism\n","    and evaluating their similarity. This class is particularly useful for\n","    ontology matching tasks.\n","\n","    Args:\n","        input_dim (int): Dimensionality of the input embeddings.\n","    \"\"\"\n","    def __init__(self, input_dim):\n","        super(GatedCombination, self).__init__()\n","\n","        # Fully connected layer for gating mechanism on the first embedding pair (x1, x2)\n","        self.gate_A_fc = nn.Linear(input_dim, input_dim)\n","\n","        # Fully connected layer for gating mechanism on the second embedding pair (x3, x4)\n","        self.gate_B_fc = nn.Linear(input_dim, input_dim)\n","\n","        # Fully connected layer for final similarity classification\n","        self.fc = nn.Linear(1, 1)\n","\n","    def forward(self, x1, x2, x3, x4, return_embeddings=False):\n","        \"\"\"\n","        Forward pass through the GatedCombination model.\n","\n","        Args:\n","            x1 (torch.Tensor): First set of embeddings (e.g., updated source embeddings).\n","            x2 (torch.Tensor): Second set of embeddings (e.g., original source embeddings).\n","            x3 (torch.Tensor): Third set of embeddings (e.g., updated target embeddings).\n","            x4 (torch.Tensor): Fourth set of embeddings (e.g., original target embeddings).\n","            return_embeddings (bool): Whether to return the intermediate combined embeddings (a, b).\n","\n","        Returns:\n","            torch.Tensor: Probability score for binary classification if return_embeddings is False.\n","            Tuple[torch.Tensor, torch.Tensor]: Intermediate embeddings (a, b) if return_embeddings is True.\n","        \"\"\"\n","        # Compute gating weights for the first pair of embeddings (x1, x2)\n","        gate_values1 = torch.sigmoid(self.gate_A_fc(x1))\n","\n","        # Blend x1 and x2 using the computed gating weights\n","        a = x1 * gate_values1 + x2 * (1 - gate_values1)\n","\n","        # Compute gating weights for the second pair of embeddings (x3, x4)\n","        gate_values2 = torch.sigmoid(self.gate_B_fc(x3))\n","\n","        # Blend x3 and x4 using the computed gating weights\n","        b = x3 * gate_values2 + x4 * (1 - gate_values2)\n","\n","        # If return_embeddings is True, return the intermediate blended embeddings\n","        if return_embeddings:\n","            return a, b\n","\n","        # Compute cosine similarity between the blended embeddings a and b\n","        x = torch.cosine_similarity(a, b, dim=1)\n","\n","        # Apply a fully connected layer and sigmoid activation for classification\n","        out = torch.sigmoid(self.fc(x.unsqueeze(1)))\n","        return out\n","\n"]},{"cell_type":"markdown","metadata":{"id":"aLJ5j9FNMVhy"},"source":["# **Utility functions**"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"k0L86DgUQjMU","executionInfo":{"status":"ok","timestamp":1735215113978,"user_tz":-60,"elapsed":8,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def adjacency_matrix_to_undirected_edge_index(adjacency_matrix):\n","    \"\"\"\n","    Converts an adjacency matrix into an undirected edge index for use in graph-based neural networks.\n","\n","    Args:\n","        adjacency_matrix: A 2D list or array representing the adjacency matrix of a graph.\n","\n","    Returns:\n","        edge_index_undirected: A PyTorch tensor representing the undirected edges.\n","    \"\"\"\n","    # Convert each element in the adjacency matrix to an integer (from boolean or float)\n","    adjacency_matrix = [[int(element) for element in sublist] for sublist in adjacency_matrix]\n","\n","    # Convert the adjacency matrix into a PyTorch LongTensor (used for indexing)\n","    edge_index = torch.tensor(adjacency_matrix, dtype=torch.long)\n","\n","    # Transpose the edge_index tensor so that rows represent edges in the form [source, target]\n","    edge_index = edge_index.t().contiguous()\n","\n","    # Convert the directed edge_index into an undirected edge_index, meaning both directions are added (i.e., (i, j) and (j, i))\n","    edge_index_undirected = to_undirected(edge_index)\n","\n","    return edge_index_undirected  # Return the undirected edge index"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"YvmOxkLcpf9w","executionInfo":{"status":"ok","timestamp":1735215113979,"user_tz":-60,"elapsed":8,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def build_indexed_dict(file_path):\n","    \"\"\"\n","    Builds a dictionary with numeric indexes for each key from a JSON file.\n","\n","    Args:\n","        file_path (str): The path to the JSON file.\n","\n","    Returns:\n","        indexed_dict (dict): A new dictionary where each key from the JSON file is assigned a numeric index.\n","    \"\"\"\n","    # Load the JSON file into a Python dictionary\n","    with open(file_path, 'r') as file:\n","        data = json.load(file)\n","\n","    # Create a new dictionary with numeric indexes as keys and the original JSON keys as values\n","    indexed_dict = {index: key for index, key in enumerate(data.keys())}\n","\n","    return indexed_dict  # Return the newly created dictionary"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"QgFINoPGl9Wg","executionInfo":{"status":"ok","timestamp":1735215113979,"user_tz":-60,"elapsed":7,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def select_rows_by_index(embedding_vector, index_vector):\n","    \"\"\"\n","    Select rows from an embedding vector using an index vector.\n","\n","    Args:\n","        embedding_vector (torch.Tensor): 2D tensor representing the embedding vector with shape [num_rows, embedding_size].\n","        index_vector (torch.Tensor): 1D tensor representing the index vector.\n","\n","    Returns:\n","        torch.Tensor: New tensor with selected rows from the embedding vector.\n","    \"\"\"\n","    # Use torch.index_select to select the desired rows\n","    new_tensor = torch.index_select(embedding_vector, 0, index_vector)\n","\n","    return new_tensor"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"a12L7vEmmCJq","executionInfo":{"status":"ok","timestamp":1735215113979,"user_tz":-60,"elapsed":7,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def contrastive_loss(source_embeddings, target_embeddings, labels, margin=1.0):\n","    \"\"\"\n","    Computes the contrastive loss, a type of loss function used to train models in tasks like matching or similarity learning.\n","\n","    Args:\n","        source_embeddings (torch.Tensor): Embeddings of the source graphs, shape [batch_size, embedding_size].\n","        target_embeddings (torch.Tensor): Embeddings of the target graphs, shape [batch_size, embedding_size].\n","        labels (torch.Tensor): Binary labels indicating if the pairs are matched (1) or not (0), shape [batch_size].\n","        margin (float): Margin value for the contrastive loss. Defaults to 1.0.\n","\n","    Returns:\n","        torch.Tensor: The contrastive loss value.\n","    \"\"\"\n","    # Calculate the pairwise Euclidean distance between source and target embeddings\n","    distances = F.pairwise_distance(source_embeddings, target_embeddings)\n","\n","    # Compute the contrastive loss:\n","    # - For matched pairs (label == 1), the loss is the squared distance between embeddings.\n","    # - For non-matched pairs (label == 0), the loss is based on how far apart the embeddings are,\n","    #   but penalizes them only if the distance is less than the margin.\n","    loss = torch.mean(\n","        labels * 0.4 * distances.pow(2) +  # For positive pairs, minimize the distance (squared)\n","        (1 - labels) * 0.4 * torch.max(torch.zeros_like(distances), margin - distances).pow(2)  # For negative pairs, maximize the distance (up to the margin)\n","    )\n","\n","    return loss  # Return the computed contrastive loss\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"ZhCizXEb7D4N","executionInfo":{"status":"ok","timestamp":1735215113979,"user_tz":-60,"elapsed":6,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def Prediction_with_candidates(model, X1_tt, X2_tt, X3_tt, X4_tt, src_entity_tensor_o, tgt_entity_tensor_o,\n","                                   indexed_dict_src, indexed_dict_tgt, all_predictions_path):\n","    \"\"\"\n","    Evaluates the GatedCombination model using the given embeddings and candidate entity pairs.\n","    Saves the predictions and evaluation results to a file.\n","\n","    Args:\n","        model: Trained GatedCombination model.\n","        X1_tt, X2_tt, X3_tt, X4_tt (torch.Tensor): Tensors of source and target entity embeddings (updated and original).\n","        src_entity_tensor_o, tgt_entity_tensor_o (torch.Tensor): Tensors of source and target entity indices.\n","        indexed_dict_src, indexed_dict_tgt (dict): Dictionaries mapping entity indices to URIs for source and target.\n","        output_file (str): Path to save the predictions and results.\n","        hits_at_k_values (list): List of k-values for which hits@k is evaluated.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    # Move the model to CPU and set it to evaluation mode\n","    model = model.to(\"cpu\")\n","    model.eval()\n","\n","    # Set batch size for evaluation\n","    batch_size_test = 32\n","\n","    # Create a DataLoader for the evaluation data\n","    test_dataset = TensorDataset(X1_tt, X2_tt, X3_tt, X4_tt)\n","    test_dataloader = DataLoader(test_dataset, batch_size=batch_size_test)\n","\n","    # Prepare for collecting predictions and results\n","    predictions = []\n","    results = []\n","    count_predictions = 0  # Counter for predictions above threshold (0.5)\n","\n","    # Measure prediction time\n","    start_time = time.time()\n","\n","    # Disable gradient computation for evaluation\n","    with torch.no_grad():\n","        # Iterate over batches and compute model predictions\n","        for batch_X1, batch_X2, batch_X3, batch_X4 in test_dataloader:\n","            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","            predictions.extend(outputs.cpu().numpy())  # Collect predictions in CPU memory\n","\n","    end_time = time.time()\n","    predicting_time = end_time - start_time\n","    print(f\"Predicting time: {predicting_time:.2f} seconds\")\n","\n","    # Convert tensors to lists for easier iteration\n","    src_indices = src_entity_tensor_o.tolist()\n","    tgt_indices = tgt_entity_tensor_o.tolist()\n","\n","    # Prepare results\n","    for i in range(len(predictions)):\n","        if predictions[i] >= 0.00:  # Consider only predictions greater than 0.5\n","            count_predictions += 1  # Increment the counter\n","\n","            # Map the source and target entity indices to their URIs\n","            src_code = src_indices[i]\n","            tgt_code = tgt_indices[i]\n","\n","            src_uri = indexed_dict_src.get(int(src_code), \"Unknown URI\")\n","            tgt_uri = indexed_dict_tgt.get(int(tgt_code), \"Unknown URI\")\n","\n","            # Get the model's predicted score for the current pair\n","            score = predictions[i]\n","\n","            # Append the results (with URIs instead of entity indices)\n","            results.append({\n","                'SrcEntity': src_uri,\n","                'TgtEntity': tgt_uri,\n","                'Score': score\n","            })\n","\n","    # Convert the results into a pandas DataFrame\n","    df_results = pd.DataFrame(results)\n","\n","    # Save the results to a TSV file\n","    df_results.to_csv(all_predictions_path, sep='\\t', index=False)\n","\n","    print(f\"Predictions saved to {all_predictions_path}\")"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"TslUdYHBcGVj","executionInfo":{"status":"ok","timestamp":1735215113979,"user_tz":-60,"elapsed":6,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def filter_highest_predictions(input_file_path, output_file_path, threshold=thres):\n","    # Load the all predictions file\n","    df = pd.read_csv(input_file_path, sep='\\t')\n","\n","    # Extract the similarity score from the list in the 'Score' column\n","    df['Score'] = df['Score'].apply(lambda x: float(x.strip('[]')))\n","\n","    # Sorting the dataframe by similarity score in descending order\n","    df_sorted = df.sort_values(by='Score', ascending=False).reset_index(drop=True)\n","\n","    # Initialize variables with threshold value\n","    source_concepts = set(df_sorted['SrcEntity'])\n","    target_concepts = set(df_sorted['TgtEntity'])\n","    matched_sources = set()\n","    matched_targets = set()\n","    result = []\n","\n","    # Iterate through the sorted dataframe and find highest correspondences\n","    for _, row in df_sorted.iterrows():\n","        source, target, similarity = row['SrcEntity'], row['TgtEntity'], row['Score']\n","\n","        # Check if the source or target has already been matched and if the similarity is above the threshold\n","        if source not in matched_sources and target not in matched_targets and similarity >= threshold:\n","            # Add the match to the result list\n","            result.append((source, target, similarity))\n","            # Mark the source and target as matched\n","            matched_sources.add(source)\n","            matched_targets.add(target)\n","\n","    # Create a dataframe for the matching results with threshold applied\n","    matching_results_df_threshold = pd.DataFrame(result, columns=['SrcEntity', 'TgtEntity', 'Score'])\n","\n","    # Save the matching results with the updated column names to a new TSV file\n","    matching_results_df_threshold.to_csv(output_file_path, sep='\\t', index=False)\n","\n","    # Print the number of predictions saved\n","    print(f\"Number of Positive Predictions : {len(matching_results_df_threshold)}\")\n","\n","    return matching_results_df_threshold, len(matching_results_df_threshold)"]},{"cell_type":"code","source":["def compute_mrr_and_hits(reference_file, predicted_file, output_file, k_values=[1, 5, 10]):\n","    \"\"\"\n","    Compute MRR and Hits@k for ontology matching predictions based on a reference file.\n","\n","    Args:\n","        reference_file (str): Path to the reference file (test.cands.tsv format).\n","        predicted_file (str): Path to the predictions file with scores.\n","        output_file (str): Path to save the scored results.\n","        k_values (list): List of k values for Hits@k.\n","\n","    Returns:\n","        dict: A dictionary containing MRR and Hits@k metrics.\n","    \"\"\"\n","    # Read the reference mappings\n","    test_candidate_mappings = read_table(reference_file).values.tolist()\n","    ranking_results = []\n","\n","    # Read the predicted scores\n","    predicted_data = pd.read_csv(predicted_file, sep=\"\\t\")\n","    predicted_data[\"Score\"] = predicted_data[\"Score\"].apply(lambda x: float(x.strip(\"[]\")))\n","\n","    # Create a lookup dictionary for predicted scores\n","    score_lookup = {}\n","    for _, row in predicted_data.iterrows():\n","        score_lookup[(row[\"SrcEntity\"], row[\"TgtEntity\"])] = row[\"Score\"]\n","\n","    for src_ref_class, tgt_ref_class, tgt_cands in test_candidate_mappings:\n","        tgt_cands = eval(tgt_cands)  # Convert string to list of candidates\n","        scored_cands = []\n","        for tgt_cand in tgt_cands:\n","            # Retrieve score for each candidate, defaulting to a very low score if not found\n","            matching_score = score_lookup.get((src_ref_class, tgt_cand), -1e9)\n","            scored_cands.append((tgt_cand, matching_score))\n","\n","        # Sort candidates by score in descending order\n","        scored_cands = sorted(scored_cands, key=lambda x: x[1], reverse=True)\n","        ranking_results.append((src_ref_class, tgt_ref_class, scored_cands))\n","\n","    # Save the ranked results to a file\n","    pd.DataFrame(ranking_results, columns=[\"SrcEntity\", \"TgtEntity\", \"TgtCandidates\"]).to_csv(output_file, sep=\"\\t\", index=False)\n","\n","    # Compute MRR and Hits@k\n","    total_entities = len(ranking_results)\n","    reciprocal_ranks = []\n","    hits_at_k = {k: 0 for k in k_values}\n","\n","    for src_entity, tgt_ref_class, tgt_cands in ranking_results:\n","        ranked_candidates = [candidate[0] for candidate in tgt_cands]\n","        if tgt_ref_class in ranked_candidates:\n","            rank = ranked_candidates.index(tgt_ref_class) + 1\n","            reciprocal_ranks.append(1 / rank)\n","            for k in k_values:\n","                if rank <= k:\n","                    hits_at_k[k] += 1\n","        else:\n","            reciprocal_ranks.append(0)\n","\n","    mrr = sum(reciprocal_ranks) / total_entities\n","    hits_at_k = {k: hits / total_entities for k, hits in hits_at_k.items()}\n","\n","    return {\"MRR\": mrr, \"Hits@k\": hits_at_k}"],"metadata":{"id":"_ggVYlTiO_WA","executionInfo":{"status":"ok","timestamp":1735215113979,"user_tz":-60,"elapsed":6,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1HyWMsw1MVhz"},"source":["# **Main Code**\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"IC37FlwGDqGM"},"source":["\n","\n","# Reading semantic node embeddings provided by the ENE"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"FuEfSnw5mod0","executionInfo":{"status":"ok","timestamp":1735215120172,"user_tz":-60,"elapsed":6198,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the source embeddings from a CSV file into a pandas DataFrame\n","df_embbedings_src = pd.read_csv(src_Emb, index_col=0)\n","\n","# Convert the DataFrame to a NumPy array, which will remove the index and store the data as a raw matrix\n","numpy_array = df_embbedings_src.to_numpy()\n","\n","# Convert the NumPy array into a PyTorch FloatTensor, which is the format required for PyTorch operations\n","x_src = torch.FloatTensor(numpy_array)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"STUwqMUXmlG2","executionInfo":{"status":"ok","timestamp":1735215127541,"user_tz":-60,"elapsed":7372,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the target embeddings from a CSV file into a pandas DataFrame\n","df_embbedings_tgt = pd.read_csv(tgt_Emb, index_col=0)\n","\n","# Convert the DataFrame to a NumPy array, which removes the index and converts the data to a raw matrix\n","numpy_array = df_embbedings_tgt.to_numpy()\n","\n","# Convert the NumPy array into a PyTorch FloatTensor, which is required for PyTorch operations\n","x_tgt = torch.FloatTensor(numpy_array)"]},{"cell_type":"markdown","metadata":{"id":"jZIu9P08DqGN"},"source":["# Reading adjacency Matrix"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"pH69Up40mycz","executionInfo":{"status":"ok","timestamp":1735215127767,"user_tz":-60,"elapsed":229,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the source adjacency matrix from a CSV file into a pandas DataFrame\n","df_ma1 = pd.read_csv(src_Adjacence, index_col=0)\n","\n","# Convert the DataFrame to a list of lists (Python native list format)\n","ma1 = df_ma1.values.tolist()"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"hYCmAO5Ymzpl","executionInfo":{"status":"ok","timestamp":1735215127966,"user_tz":-60,"elapsed":203,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the target adjacency matrix from a CSV file into a pandas DataFrame\n","df_ma2 = pd.read_csv(tgt_Adjacence, index_col=0)\n","\n","# Convert the DataFrame to a list of lists (Python native list format)\n","ma2 = df_ma2.values.tolist()"]},{"cell_type":"markdown","metadata":{"id":"PSyksqh3TrU-"},"source":["# Convert Adjacency matrix (in list format) to an undirected edge index"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"uVt-Pce5m5ll","executionInfo":{"status":"ok","timestamp":1735215127967,"user_tz":-60,"elapsed":4,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Convert the source adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n","edge_src = adjacency_matrix_to_undirected_edge_index(ma1)\n","\n","# Convert the target adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n","edge_tgt = adjacency_matrix_to_undirected_edge_index(ma2)"]},{"cell_type":"markdown","metadata":{"id":"H9wMTRdqT4aY"},"source":["# GIT Training"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"eqiEKCLSMVh3","executionInfo":{"status":"ok","timestamp":1735215127967,"user_tz":-60,"elapsed":4,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def train_model_gnn(model, x_src, edge_src, x_tgt, edge_tgt,\n","                    tensor_term1, tensor_term2, tensor_score,\n","                    learning_rate, weight_decay_value, num_epochs, print_interval=10):\n","    \"\"\"\n","    Trains a graph neural network (GNN) model using source and target embeddings and contrastive loss.\n","\n","    Args:\n","        model: The GNN model to be trained.\n","        x_src (torch.Tensor): Source node embeddings.\n","        edge_src (torch.Tensor): Source graph edges.\n","        x_tgt (torch.Tensor): Target node embeddings.\n","        edge_tgt (torch.Tensor): Target graph edges.\n","        tensor_term1 (torch.Tensor): Indices of the source nodes to be compared.\n","        tensor_term2 (torch.Tensor): Indices of the target nodes to be compared.\n","        tensor_score (torch.Tensor): Labels indicating if the pairs are matched (1) or not (0).\n","        learning_rate (float): Learning rate for the optimizer.\n","        weight_decay_value (float): Weight decay (L2 regularization) value for the optimizer.\n","        num_epochs (int): Number of epochs for training.\n","        print_interval (int): Interval at which training progress is printed (every `print_interval` epochs).\n","\n","    Returns:\n","        model: The trained GNN model.\n","    \"\"\"\n","\n","    # Step 1: Set device (GPU or CPU) for computation\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    # Step 2: Move the model and all inputs to the selected device\n","    model.to(device)\n","    x_tgt = x_tgt.to(device)               # Target node embeddings\n","    edge_tgt = edge_tgt.to(device)         # Target graph edges\n","    x_src = x_src.to(device)               # Source node embeddings\n","    edge_src = edge_src.to(device)         # Source graph edges\n","    tensor_term1 = tensor_term1.to(device) # Indices for source nodes\n","    tensor_term2 = tensor_term2.to(device) # Indices for target nodes\n","    tensor_score = tensor_score.to(device) # Ground truth labels\n","\n","    # Step 3: Define optimizer with learning rate and regularization\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay_value)\n","\n","    # Step 4: Initialize list to store training losses\n","    train_losses = []\n","\n","    # Record the start time of training\n","    start_time = time.time()\n","\n","    # Step 5: Training loop\n","    for epoch in range(num_epochs):\n","        # Zero out gradients from the previous iteration\n","        optimizer.zero_grad()\n","\n","        # Forward pass: Compute embeddings for source and target graphs\n","        out1 = model(x_src, edge_src)  # Updated source embeddings\n","        out2 = model(x_tgt, edge_tgt)  # Updated target embeddings\n","\n","        # Extract specific rows of embeddings for terms being compared\n","        src_embeddings = select_rows_by_index(out1, tensor_term1)\n","        tgt_embeddings = select_rows_by_index(out2, tensor_term2)\n","\n","        # Compute contrastive loss based on the embeddings and ground truth labels\n","        loss = contrastive_loss(src_embeddings, tgt_embeddings, tensor_score)\n","\n","        # Backward pass: Compute gradients\n","        loss.backward()\n","\n","        # Update the model's parameters\n","        optimizer.step()\n","\n","        # Append the loss for this iteration to the list\n","        train_losses.append(loss.item())\n","\n","        # Print loss every `print_interval` epochs\n","        if (epoch + 1) % print_interval == 0:\n","            print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item()}\")\n","\n","    # Step 6: Record end time of training\n","    end_time = time.time()\n","\n","    # Step 7: Plot the training loss over time\n","    plt.semilogy(range(1, num_epochs + 1), train_losses, label=\"Training Loss\", marker='o')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    # Print the total training time\n","    training_time = end_time - start_time\n","    print(f\"Training complete! Total training time: {training_time:.2f} seconds\")\n","\n","    # Step 8: Return the trained model\n","    return model"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"6_tzUG_emtBg","executionInfo":{"status":"ok","timestamp":1735215127967,"user_tz":-60,"elapsed":3,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Initialize the GIT_mod model with the dimensionality of the target embeddings\n","# The first argument is the dimensionality of the target node embeddings (x_tgt.shape[1])\n","# The second argument (1) represents the number of RGIT layers in the model\n","GIT_model = RGIT_mod(x_tgt.shape[1], 1)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"wVo-s7UQssSp","executionInfo":{"status":"ok","timestamp":1735215128548,"user_tz":-60,"elapsed":584,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Reading the training pairs from a CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(train_file, index_col=0)\n","\n","# Extract the 'SrcEntity' and 'TgtEntity' columns as NumPy arrays and convert them to integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)  # Source entity indices\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)  # Target entity indices\n","\n","# Extract the 'Score' column as a NumPy array and convert it to floats\n","tensor_score = df_embbedings['Score'].values.astype(float)  # Scores (labels) indicating if pairs match (1) or not (0)\n","\n","# Convert the NumPy arrays to PyTorch LongTensors (for indices) and FloatTensors (for scores)\n","tensor_term1_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)  # Source entity tensor\n","tensor_term2_o = torch.from_numpy(tensor_term2).type(torch.LongTensor)  # Target entity tensor\n","tensor_score_o = torch.from_numpy(tensor_score).type(torch.FloatTensor)  # Score tensor"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"agHlFNesMVh3","outputId":"a94a568f-22d8-4129-9fa1-8228d41e347e","executionInfo":{"status":"ok","timestamp":1735216851567,"user_tz":-60,"elapsed":1723021,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [10/1000], Training Loss: 0.00256549846380949\n","Epoch [20/1000], Training Loss: 0.002105807652696967\n","Epoch [30/1000], Training Loss: 0.0018768584122881293\n","Epoch [40/1000], Training Loss: 0.0017342569772154093\n","Epoch [50/1000], Training Loss: 0.0016312204534187913\n","Epoch [60/1000], Training Loss: 0.0015500365989282727\n","Epoch [70/1000], Training Loss: 0.0014837071066722274\n","Epoch [80/1000], Training Loss: 0.001427219482138753\n","Epoch [90/1000], Training Loss: 0.0013774153776466846\n","Epoch [100/1000], Training Loss: 0.001333890133537352\n","Epoch [110/1000], Training Loss: 0.001295732450671494\n","Epoch [120/1000], Training Loss: 0.001262017758563161\n","Epoch [130/1000], Training Loss: 0.0012313824845477939\n","Epoch [140/1000], Training Loss: 0.0012039452558383346\n","Epoch [150/1000], Training Loss: 0.0011793046724051237\n","Epoch [160/1000], Training Loss: 0.001157363411039114\n","Epoch [170/1000], Training Loss: 0.0011369700077921152\n","Epoch [180/1000], Training Loss: 0.001118185231462121\n","Epoch [190/1000], Training Loss: 0.0011007144348695874\n","Epoch [200/1000], Training Loss: 0.0010846751974895597\n","Epoch [210/1000], Training Loss: 0.0010698263067752123\n","Epoch [220/1000], Training Loss: 0.0010559805668890476\n","Epoch [230/1000], Training Loss: 0.0010429647518321872\n","Epoch [240/1000], Training Loss: 0.0010305900359526277\n","Epoch [250/1000], Training Loss: 0.0010190331377089024\n","Epoch [260/1000], Training Loss: 0.0010080953361466527\n","Epoch [270/1000], Training Loss: 0.0009974995627999306\n","Epoch [280/1000], Training Loss: 0.0009873479139059782\n","Epoch [290/1000], Training Loss: 0.0009775323560461402\n","Epoch [300/1000], Training Loss: 0.0009680556249804795\n","Epoch [310/1000], Training Loss: 0.0009589255205355585\n","Epoch [320/1000], Training Loss: 0.0009500898304395378\n","Epoch [330/1000], Training Loss: 0.0009415401727892458\n","Epoch [340/1000], Training Loss: 0.0009333196212537587\n","Epoch [360/1000], Training Loss: 0.0009176075109280646\n","Epoch [370/1000], Training Loss: 0.0009100330644287169\n","Epoch [380/1000], Training Loss: 0.0009026748593896627\n","Epoch [390/1000], Training Loss: 0.0008955104858614504\n","Epoch [400/1000], Training Loss: 0.0008885933202691376\n","Epoch [410/1000], Training Loss: 0.0008818518836051226\n","Epoch [420/1000], Training Loss: 0.0008753659785725176\n","Epoch [430/1000], Training Loss: 0.0008689939277246594\n","Epoch [440/1000], Training Loss: 0.000862885091919452\n","Epoch [450/1000], Training Loss: 0.000856943370308727\n","Epoch [460/1000], Training Loss: 0.0008511383202858269\n","Epoch [470/1000], Training Loss: 0.0008453985210508108\n","Epoch [480/1000], Training Loss: 0.0008398136124014854\n","Epoch [490/1000], Training Loss: 0.000834405655041337\n","Epoch [500/1000], Training Loss: 0.0008290871046483517\n","Epoch [510/1000], Training Loss: 0.000823897949885577\n","Epoch [520/1000], Training Loss: 0.0008188420906662941\n","Epoch [530/1000], Training Loss: 0.0008139002602547407\n","Epoch [540/1000], Training Loss: 0.000809017161373049\n","Epoch [550/1000], Training Loss: 0.0008042258559726179\n","Epoch [560/1000], Training Loss: 0.0007995229098014534\n","Epoch [570/1000], Training Loss: 0.0007949181599542499\n","Epoch [580/1000], Training Loss: 0.0007903646910563111\n","Epoch [590/1000], Training Loss: 0.0007858977187424898\n","Epoch [600/1000], Training Loss: 0.0007814496639184654\n","Epoch [610/1000], Training Loss: 0.000777091714553535\n","Epoch [620/1000], Training Loss: 0.0007728005293756723\n","Epoch [630/1000], Training Loss: 0.0007686124299652874\n","Epoch [640/1000], Training Loss: 0.0007644316065125167\n","Epoch [650/1000], Training Loss: 0.000760318711400032\n","Epoch [660/1000], Training Loss: 0.00075621745781973\n","Epoch [670/1000], Training Loss: 0.0007521901279687881\n","Epoch [680/1000], Training Loss: 0.0007481705979444087\n","Epoch [690/1000], Training Loss: 0.0007442167261615396\n","Epoch [700/1000], Training Loss: 0.0007403147174045444\n","Epoch [710/1000], Training Loss: 0.0007364830817095935\n","Epoch [720/1000], Training Loss: 0.0007326962659135461\n","Epoch [730/1000], Training Loss: 0.0007289333152584732\n","Epoch [740/1000], Training Loss: 0.000725241145119071\n","Epoch [750/1000], Training Loss: 0.0007216242956928909\n","Epoch [760/1000], Training Loss: 0.0007180311949923635\n","Epoch [770/1000], Training Loss: 0.0007144494447857141\n","Epoch [780/1000], Training Loss: 0.0007110049482434988\n","Epoch [790/1000], Training Loss: 0.0007075658650137484\n","Epoch [800/1000], Training Loss: 0.0007041635108180344\n","Epoch [810/1000], Training Loss: 0.0007007794338278472\n","Epoch [820/1000], Training Loss: 0.0006974944844841957\n","Epoch [830/1000], Training Loss: 0.0006941563333384693\n","Epoch [840/1000], Training Loss: 0.0006910435622557998\n","Epoch [850/1000], Training Loss: 0.0006877469131723046\n","Epoch [860/1000], Training Loss: 0.0006845687166787684\n","Epoch [870/1000], Training Loss: 0.0006812189240008593\n","Epoch [880/1000], Training Loss: 0.0006780567346140742\n","Epoch [890/1000], Training Loss: 0.0006748528685420752\n","Epoch [900/1000], Training Loss: 0.0006718100048601627\n","Epoch [910/1000], Training Loss: 0.000668652355670929\n","Epoch [920/1000], Training Loss: 0.0006654920871369541\n","Epoch [930/1000], Training Loss: 0.0006624034722335637\n","Epoch [940/1000], Training Loss: 0.0006592210265807807\n","Epoch [950/1000], Training Loss: 0.000656247022561729\n","Epoch [960/1000], Training Loss: 0.0006537468289025128\n","Epoch [970/1000], Training Loss: 0.0006509235827252269\n","Epoch [980/1000], Training Loss: 0.0006478537688963115\n","Epoch [990/1000], Training Loss: 0.000644728890620172\n","Epoch [1000/1000], Training Loss: 0.0006421227590180933\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training complete! Total training time: 1721.74 seconds\n"]}],"source":["# Train the GNN model using the provided source and target graph embeddings, edges, and training data\n","trained_model = train_model_gnn(\n","    model=GIT_model,                # The GNN model to be trained (initialized earlier)\n","    x_src=x_src,                    # Source node embeddings (tensor for source graph)\n","    edge_src=edge_src,              # Source graph edges (undirected edge index for source graph)\n","    x_tgt=x_tgt,                    # Target node embeddings (tensor for target graph)\n","    edge_tgt=edge_tgt,              # Target graph edges (undirected edge index for target graph)\n","    tensor_term1=tensor_term1_o,    # Indices of source entities for training\n","    tensor_term2=tensor_term2_o,    # Indices of target entities for training\n","    tensor_score=tensor_score_o,    # Scores (labels) indicating if pairs match (1) or not (0)\n","    learning_rate=0.0001,            # Learning rate for the Adam optimizer\n","    weight_decay_value=1e-4,        # Weight decay for L2 regularization to prevent overfitting\n","    num_epochs=1000,                # Number of training epochs\n","    print_interval=10               # Interval at which to print training progress (every 10 epochs)\n",")"]},{"cell_type":"markdown","metadata":{"id":"MYyhvjcTUaae"},"source":["# GIT Application"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"BZ_VqP6tq6iD","executionInfo":{"status":"ok","timestamp":1735216851897,"user_tz":-60,"elapsed":332,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Determine if a GPU is available and move the computations to it; otherwise, use the CPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Assuming the model has been trained and hyperparameters (x_src, edge_src, x_tgt, edge_tgt) are set\n","\n","# Move the trained GIT_model to the device (GPU or CPU)\n","GIT_model.to(device)\n","\n","# Move the data tensors to the same device (GPU or CPU)\n","x_tgt = x_tgt.to(device)         # Target node embeddings\n","edge_tgt = edge_tgt.to(device)   # Target graph edges\n","x_src = x_src.to(device)         # Source node embeddings\n","edge_src = edge_src.to(device)   # Source graph edges\n","\n","# Set the model to evaluation mode; this disables dropout and batch normalization\n","GIT_model.eval()\n","\n","# Pass the source and target embeddings through the trained GNN model to update the embeddings\n","with torch.no_grad():  # Disable gradient computation (inference mode)\n","    embeddings_tgt = GIT_model(x_tgt, edge_tgt)  # Get updated embeddings for the target graph\n","    embeddings_src = GIT_model(x_src, edge_src)  # Get updated embeddings for the source graph\n","\n","# Detach the embeddings from the computation graph and move them back to the CPU\n","# This step is useful if you need to use the embeddings for tasks outside PyTorch (e.g., saving to disk)\n","embeddings_tgt = embeddings_tgt.detach().cpu()  # Target graph embeddings\n","embeddings_src = embeddings_src.detach().cpu()  # Source graph embeddings\n","\n","# At this point, embeddings_tgt and embeddings_src contain the updated embeddings, ready for downstream tasks"]},{"cell_type":"markdown","metadata":{"id":"Og5fdoGJrTCG"},"source":["# Selecting embedding pairs to train the Gated Network"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"J0nTwc-dnjLn","executionInfo":{"status":"ok","timestamp":1735216852288,"user_tz":-60,"elapsed":392,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the training pairs from a CSV file into a pandas DataFrame\n","df_embeddings = pd.read_csv(train_file, index_col=0)\n","\n","# Extract columns and convert to NumPy arrays\n","tensor_term1 = df_embeddings['SrcEntity'].values.astype(int)  # Source entity indices\n","tensor_term2 = df_embeddings['TgtEntity'].values.astype(int)  # Target entity indices\n","tensor_score = df_embeddings['Score'].values.astype(float)  # Matching scores\n","\n","# Split data into training and validation sets\n","tensor_term1_train, tensor_term1_val, tensor_term2_train, tensor_term2_val, tensor_score_train, tensor_score_val = train_test_split(\n","    tensor_term1, tensor_term2, tensor_score, test_size=0.3, random_state=42\n",")\n","\n","# Convert split data to PyTorch tensors\n","tensor_term1_train = torch.from_numpy(tensor_term1_train).type(torch.LongTensor)\n","tensor_term2_train = torch.from_numpy(tensor_term2_train).type(torch.LongTensor)\n","tensor_score_train = torch.from_numpy(tensor_score_train).type(torch.FloatTensor)\n","\n","tensor_term1_val = torch.from_numpy(tensor_term1_val).type(torch.LongTensor)\n","tensor_term2_val = torch.from_numpy(tensor_term2_val).type(torch.LongTensor)\n","tensor_score_val = torch.from_numpy(tensor_score_val).type(torch.FloatTensor)\n","\n","# Move the embeddings back to the CPU if not already there\n","x_tgt = x_tgt.cpu()  # Target node embeddings\n","x_src = x_src.cpu()  # Source node embeddings\n","\n","# Select embeddings for the training set\n","X1_train = select_rows_by_index(embeddings_src, tensor_term1_train)\n","X2_train = select_rows_by_index(x_src, tensor_term1_train)\n","X3_train = select_rows_by_index(embeddings_tgt, tensor_term2_train)\n","X4_train = select_rows_by_index(x_tgt, tensor_term2_train)\n","\n","# Select embeddings for the validation set\n","X1_val = select_rows_by_index(embeddings_src, tensor_term1_val)\n","X2_val = select_rows_by_index(x_src, tensor_term1_val)\n","X3_val = select_rows_by_index(embeddings_tgt, tensor_term2_val)\n","X4_val = select_rows_by_index(x_tgt, tensor_term2_val)\n","\n","# Now you have:\n","# - Training tensors: X1_train, X2_train, X3_train, X4_train, tensor_score_train\n","# - Validation tensors: X1_val, X2_val, X3_val, X4_val, tensor_score_val"]},{"cell_type":"markdown","metadata":{"id":"fNdCgaTMExPK"},"source":["# Gated Network Training"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"Gof1eIPIWSVU","executionInfo":{"status":"ok","timestamp":1735216852288,"user_tz":-60,"elapsed":3,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["from sklearn.metrics import f1_score\n","\n","def train_gated_combination_model(X1_t, X2_t, X3_t, X4_t, tensor_score_o,\n","                                  X1_val, X2_val, X3_val, X4_val, tensor_score_val,\n","                                  epochs=120, batch_size=32, learning_rate=0.001, weight_decay=1e-5):\n","    \"\"\"\n","    Trains the GatedCombination model with training and validation data, using ReduceLROnPlateau scheduler.\n","    Also calculates and displays F1-score during training and validation.\n","    \"\"\"\n","\n","    # Create datasets and DataLoaders\n","    train_dataset = TensorDataset(X1_t, X2_t, X3_t, X4_t, tensor_score_o)\n","    val_dataset = TensorDataset(X1_val, X2_val, X3_val, X4_val, tensor_score_val)\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = GatedCombination(X1_t.shape[1]).to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","\n","    # Use ReduceLROnPlateau scheduler\n","    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n","\n","    train_losses, val_losses = [], []\n","\n","    start_time = time.time()\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        total_train_loss = 0.0\n","        y_true_train, y_pred_train = [], []\n","\n","        for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in train_loader:\n","            batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (\n","                batch_X1.to(device),\n","                batch_X2.to(device),\n","                batch_X3.to(device),\n","                batch_X4.to(device),\n","                batch_y.to(device),\n","            )\n","            optimizer.zero_grad()\n","\n","            # Forward pass\n","            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","\n","            # Compute loss\n","            loss = F.binary_cross_entropy(outputs, batch_y.unsqueeze(1).float())\n","            loss.backward()\n","            optimizer.step()\n","            total_train_loss += loss.item()\n","\n","            # Store true labels and predictions for F1-score\n","            y_true_train.extend(batch_y.cpu().numpy())\n","            y_pred_train.extend((outputs > 0.5).float().cpu().numpy())\n","\n","        train_loss = total_train_loss / len(train_loader)\n","        train_losses.append(train_loss)\n","\n","        # Calculate F1-score for training\n","        train_f1 = f1_score(y_true_train, y_pred_train)\n","\n","        # Validation phase\n","        model.eval()\n","        total_val_loss = 0.0\n","        y_true_val, y_pred_val = [], []\n","\n","        with torch.no_grad():\n","            for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in val_loader:\n","                batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (\n","                    batch_X1.to(device),\n","                    batch_X2.to(device),\n","                    batch_X3.to(device),\n","                    batch_X4.to(device),\n","                    batch_y.to(device),\n","                )\n","                outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","\n","                # Compute loss\n","                val_loss = F.binary_cross_entropy(outputs, batch_y.unsqueeze(1).float())\n","                total_val_loss += val_loss.item()\n","\n","                # Store true labels and predictions for F1-score\n","                y_true_val.extend(batch_y.cpu().numpy())\n","                y_pred_val.extend((outputs > 0.5).float().cpu().numpy())\n","\n","        avg_val_loss = total_val_loss / len(val_loader)\n","        val_losses.append(avg_val_loss)\n","\n","        # Calculate F1-score for validation\n","        val_f1 = f1_score(y_true_val, y_pred_val)\n","\n","        # Step the scheduler with validation loss\n","        scheduler.step(avg_val_loss)\n","\n","        # Print training and validation metrics\n","        print(f\"Epoch [{epoch + 1}/{epochs}] Training Loss: {train_loss:.4f}, F1 Score: {train_f1:.4f} | \"\n","              f\"Validation Loss: {avg_val_loss:.4f}, F1 Score: {val_f1:.4f}\")\n","\n","    end_time = time.time()\n","\n","    # Plotting training and validation loss\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(train_losses, label=\"Training Loss\", marker='o')\n","    plt.plot(val_losses, label=\"Validation Loss\", marker='x')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    print(f\"Training complete! Total time: {end_time - start_time:.2f} seconds\")\n","    return model\n","\n"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"l11dgb8ei69T","outputId":"0f688844-5cf1-471d-99bf-6604b6bea5a8","executionInfo":{"status":"ok","timestamp":1735218190092,"user_tz":-60,"elapsed":1337806,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/100] Training Loss: 0.1661, F1 Score: 0.0000 | Validation Loss: 0.0816, F1 Score: 0.0000\n","Epoch [2/100] Training Loss: 0.0680, F1 Score: 0.0000 | Validation Loss: 0.0645, F1 Score: 0.0000\n","Epoch [3/100] Training Loss: 0.0614, F1 Score: 0.0000 | Validation Loss: 0.0629, F1 Score: 0.0000\n","Epoch [4/100] Training Loss: 0.0605, F1 Score: 0.0000 | Validation Loss: 0.0624, F1 Score: 0.0000\n","Epoch [5/100] Training Loss: 0.0599, F1 Score: 0.0000 | Validation Loss: 0.0615, F1 Score: 0.0000\n","Epoch [6/100] Training Loss: 0.0592, F1 Score: 0.0000 | Validation Loss: 0.0609, F1 Score: 0.0000\n","Epoch [7/100] Training Loss: 0.0585, F1 Score: 0.0000 | Validation Loss: 0.0601, F1 Score: 0.0000\n","Epoch [8/100] Training Loss: 0.0578, F1 Score: 0.0000 | Validation Loss: 0.0594, F1 Score: 0.0000\n","Epoch [9/100] Training Loss: 0.0571, F1 Score: 0.0000 | Validation Loss: 0.0588, F1 Score: 0.0000\n","Epoch [10/100] Training Loss: 0.0564, F1 Score: 0.0000 | Validation Loss: 0.0580, F1 Score: 0.0000\n","Epoch [11/100] Training Loss: 0.0557, F1 Score: 0.0000 | Validation Loss: 0.0573, F1 Score: 0.0000\n","Epoch [12/100] Training Loss: 0.0550, F1 Score: 0.0000 | Validation Loss: 0.0565, F1 Score: 0.0000\n","Epoch [13/100] Training Loss: 0.0542, F1 Score: 0.0000 | Validation Loss: 0.0557, F1 Score: 0.0000\n","Epoch [14/100] Training Loss: 0.0534, F1 Score: 0.0000 | Validation Loss: 0.0549, F1 Score: 0.0000\n","Epoch [15/100] Training Loss: 0.0526, F1 Score: 0.0000 | Validation Loss: 0.0541, F1 Score: 0.0000\n","Epoch [16/100] Training Loss: 0.0518, F1 Score: 0.0000 | Validation Loss: 0.0532, F1 Score: 0.0000\n","Epoch [17/100] Training Loss: 0.0510, F1 Score: 0.0000 | Validation Loss: 0.0525, F1 Score: 0.0000\n","Epoch [18/100] Training Loss: 0.0502, F1 Score: 0.0000 | Validation Loss: 0.0516, F1 Score: 0.0000\n","Epoch [19/100] Training Loss: 0.0494, F1 Score: 0.0000 | Validation Loss: 0.0508, F1 Score: 0.0000\n","Epoch [20/100] Training Loss: 0.0486, F1 Score: 0.0000 | Validation Loss: 0.0500, F1 Score: 0.0000\n","Epoch [21/100] Training Loss: 0.0478, F1 Score: 0.0000 | Validation Loss: 0.0491, F1 Score: 0.0000\n","Epoch [22/100] Training Loss: 0.0470, F1 Score: 0.0000 | Validation Loss: 0.0487, F1 Score: 0.0000\n","Epoch [23/100] Training Loss: 0.0462, F1 Score: 0.0000 | Validation Loss: 0.0474, F1 Score: 0.0000\n","Epoch [24/100] Training Loss: 0.0454, F1 Score: 0.0000 | Validation Loss: 0.0468, F1 Score: 0.0000\n","Epoch [25/100] Training Loss: 0.0446, F1 Score: 0.0000 | Validation Loss: 0.0461, F1 Score: 0.0000\n","Epoch [26/100] Training Loss: 0.0439, F1 Score: 0.0000 | Validation Loss: 0.0454, F1 Score: 0.0000\n","Epoch [27/100] Training Loss: 0.0431, F1 Score: 0.0000 | Validation Loss: 0.0444, F1 Score: 0.0000\n","Epoch [29/100] Training Loss: 0.0418, F1 Score: 0.0000 | Validation Loss: 0.0428, F1 Score: 0.0000\n","Epoch [30/100] Training Loss: 0.0411, F1 Score: 0.0000 | Validation Loss: 0.0429, F1 Score: 0.0000\n","Epoch [31/100] Training Loss: 0.0405, F1 Score: 0.0000 | Validation Loss: 0.0416, F1 Score: 0.0000\n","Epoch [32/100] Training Loss: 0.0399, F1 Score: 0.0000 | Validation Loss: 0.0411, F1 Score: 0.0000\n","Epoch [33/100] Training Loss: 0.0393, F1 Score: 0.0000 | Validation Loss: 0.0404, F1 Score: 0.0000\n","Epoch [34/100] Training Loss: 0.0388, F1 Score: 0.0000 | Validation Loss: 0.0400, F1 Score: 0.0000\n","Epoch [35/100] Training Loss: 0.0383, F1 Score: 0.0000 | Validation Loss: 0.0392, F1 Score: 0.0000\n","Epoch [36/100] Training Loss: 0.0377, F1 Score: 0.0000 | Validation Loss: 0.0387, F1 Score: 0.0000\n","Epoch [37/100] Training Loss: 0.0373, F1 Score: 0.0000 | Validation Loss: 0.0382, F1 Score: 0.0000\n","Epoch [38/100] Training Loss: 0.0368, F1 Score: 0.0000 | Validation Loss: 0.0376, F1 Score: 0.0000\n","Epoch [39/100] Training Loss: 0.0363, F1 Score: 0.0000 | Validation Loss: 0.0371, F1 Score: 0.0000\n","Epoch [40/100] Training Loss: 0.0360, F1 Score: 0.0000 | Validation Loss: 0.0370, F1 Score: 0.0000\n","Epoch [41/100] Training Loss: 0.0356, F1 Score: 0.0000 | Validation Loss: 0.0365, F1 Score: 0.0000\n","Epoch [42/100] Training Loss: 0.0352, F1 Score: 0.0000 | Validation Loss: 0.0365, F1 Score: 0.0000\n","Epoch [43/100] Training Loss: 0.0349, F1 Score: 0.0000 | Validation Loss: 0.0366, F1 Score: 0.0000\n","Epoch [44/100] Training Loss: 0.0346, F1 Score: 0.0000 | Validation Loss: 0.0373, F1 Score: 0.0000\n","Epoch [45/100] Training Loss: 0.0342, F1 Score: 0.0000 | Validation Loss: 0.0355, F1 Score: 0.0000\n","Epoch [46/100] Training Loss: 0.0340, F1 Score: 0.0000 | Validation Loss: 0.0350, F1 Score: 0.0000\n","Epoch [47/100] Training Loss: 0.0337, F1 Score: 0.0000 | Validation Loss: 0.0346, F1 Score: 0.0000\n","Epoch [48/100] Training Loss: 0.0335, F1 Score: 0.0000 | Validation Loss: 0.0349, F1 Score: 0.0000\n","Epoch [49/100] Training Loss: 0.0332, F1 Score: 0.0000 | Validation Loss: 0.0349, F1 Score: 0.0000\n","Epoch [50/100] Training Loss: 0.0330, F1 Score: 0.0000 | Validation Loss: 0.0348, F1 Score: 0.0000\n","Epoch [51/100] Training Loss: 0.0328, F1 Score: 0.0000 | Validation Loss: 0.0340, F1 Score: 0.0000\n","Epoch [52/100] Training Loss: 0.0325, F1 Score: 0.0000 | Validation Loss: 0.0340, F1 Score: 0.0000\n","Epoch [53/100] Training Loss: 0.0324, F1 Score: 0.0000 | Validation Loss: 0.0335, F1 Score: 0.0000\n","Epoch [54/100] Training Loss: 0.0322, F1 Score: 0.0000 | Validation Loss: 0.0334, F1 Score: 0.0000\n","Epoch [55/100] Training Loss: 0.0321, F1 Score: 0.0000 | Validation Loss: 0.0337, F1 Score: 0.0000\n","Epoch [56/100] Training Loss: 0.0320, F1 Score: 0.0000 | Validation Loss: 0.0332, F1 Score: 0.0000\n","Epoch [57/100] Training Loss: 0.0318, F1 Score: 0.0000 | Validation Loss: 0.0331, F1 Score: 0.0000\n","Epoch [58/100] Training Loss: 0.0317, F1 Score: 0.0000 | Validation Loss: 0.0325, F1 Score: 0.0000\n","Epoch [59/100] Training Loss: 0.0315, F1 Score: 0.0000 | Validation Loss: 0.0337, F1 Score: 0.0000\n","Epoch [60/100] Training Loss: 0.0314, F1 Score: 0.0000 | Validation Loss: 0.0334, F1 Score: 0.0000\n","Epoch [61/100] Training Loss: 0.0313, F1 Score: 0.0000 | Validation Loss: 0.0324, F1 Score: 0.0000\n","Epoch [62/100] Training Loss: 0.0312, F1 Score: 0.0000 | Validation Loss: 0.0326, F1 Score: 0.0000\n","Epoch [63/100] Training Loss: 0.0310, F1 Score: 0.0000 | Validation Loss: 0.0322, F1 Score: 0.0000\n","Epoch [64/100] Training Loss: 0.0309, F1 Score: 0.0000 | Validation Loss: 0.0318, F1 Score: 0.0000\n","Epoch [65/100] Training Loss: 0.0308, F1 Score: 0.0000 | Validation Loss: 0.0320, F1 Score: 0.0000\n","Epoch [66/100] Training Loss: 0.0307, F1 Score: 0.0000 | Validation Loss: 0.0323, F1 Score: 0.0000\n","Epoch [67/100] Training Loss: 0.0308, F1 Score: 0.0000 | Validation Loss: 0.0312, F1 Score: 0.0000\n","Epoch [68/100] Training Loss: 0.0306, F1 Score: 0.0000 | Validation Loss: 0.0314, F1 Score: 0.0000\n","Epoch [69/100] Training Loss: 0.0305, F1 Score: 0.0000 | Validation Loss: 0.0322, F1 Score: 0.0000\n","Epoch [70/100] Training Loss: 0.0304, F1 Score: 0.0000 | Validation Loss: 0.0315, F1 Score: 0.0000\n","Epoch [71/100] Training Loss: 0.0304, F1 Score: 0.0000 | Validation Loss: 0.0311, F1 Score: 0.0000\n","Epoch [72/100] Training Loss: 0.0302, F1 Score: 0.0000 | Validation Loss: 0.0313, F1 Score: 0.0000\n","Epoch [73/100] Training Loss: 0.0302, F1 Score: 0.0000 | Validation Loss: 0.0317, F1 Score: 0.0000\n","Epoch [74/100] Training Loss: 0.0302, F1 Score: 0.0000 | Validation Loss: 0.0315, F1 Score: 0.0000\n","Epoch [75/100] Training Loss: 0.0300, F1 Score: 0.0000 | Validation Loss: 0.0327, F1 Score: 0.0000\n","Epoch [76/100] Training Loss: 0.0301, F1 Score: 0.0000 | Validation Loss: 0.0319, F1 Score: 0.0000\n","Epoch [77/100] Training Loss: 0.0300, F1 Score: 0.0000 | Validation Loss: 0.0327, F1 Score: 0.0000\n","Epoch [78/100] Training Loss: 0.0300, F1 Score: 0.0000 | Validation Loss: 0.0309, F1 Score: 0.0000\n","Epoch [79/100] Training Loss: 0.0300, F1 Score: 0.0000 | Validation Loss: 0.0317, F1 Score: 0.0000\n","Epoch [80/100] Training Loss: 0.0299, F1 Score: 0.0000 | Validation Loss: 0.0305, F1 Score: 0.0000\n","Epoch [81/100] Training Loss: 0.0297, F1 Score: 0.0000 | Validation Loss: 0.0311, F1 Score: 0.0000\n","Epoch [82/100] Training Loss: 0.0298, F1 Score: 0.0000 | Validation Loss: 0.0314, F1 Score: 0.0000\n","Epoch [83/100] Training Loss: 0.0298, F1 Score: 0.0000 | Validation Loss: 0.0305, F1 Score: 0.0000\n","Epoch [84/100] Training Loss: 0.0297, F1 Score: 0.0000 | Validation Loss: 0.0311, F1 Score: 0.0000\n","Epoch [85/100] Training Loss: 0.0297, F1 Score: 0.0000 | Validation Loss: 0.0310, F1 Score: 0.0000\n","Epoch [86/100] Training Loss: 0.0297, F1 Score: 0.0000 | Validation Loss: 0.0313, F1 Score: 0.0000\n","Epoch [87/100] Training Loss: 0.0296, F1 Score: 0.0000 | Validation Loss: 0.0309, F1 Score: 0.0000\n","Epoch [88/100] Training Loss: 0.0295, F1 Score: 0.0000 | Validation Loss: 0.0308, F1 Score: 0.0000\n","Epoch [89/100] Training Loss: 0.0296, F1 Score: 0.0000 | Validation Loss: 0.0304, F1 Score: 0.0000\n","Epoch [90/100] Training Loss: 0.0296, F1 Score: 0.0000 | Validation Loss: 0.0308, F1 Score: 0.0000\n","Epoch [91/100] Training Loss: 0.0295, F1 Score: 0.0025 | Validation Loss: 0.0311, F1 Score: 0.0000\n","Epoch [92/100] Training Loss: 0.0295, F1 Score: 0.0000 | Validation Loss: 0.0304, F1 Score: 0.0000\n","Epoch [93/100] Training Loss: 0.0295, F1 Score: 0.0000 | Validation Loss: 0.0304, F1 Score: 0.0000\n","Epoch [94/100] Training Loss: 0.0295, F1 Score: 0.0000 | Validation Loss: 0.0310, F1 Score: 0.0000\n","Epoch [95/100] Training Loss: 0.0295, F1 Score: 0.0000 | Validation Loss: 0.0319, F1 Score: 0.0000\n","Epoch [96/100] Training Loss: 0.0294, F1 Score: 0.0025 | Validation Loss: 0.0304, F1 Score: 0.0000\n","Epoch [97/100] Training Loss: 0.0294, F1 Score: 0.0000 | Validation Loss: 0.0305, F1 Score: 0.0000\n","Epoch [98/100] Training Loss: 0.0293, F1 Score: 0.0025 | Validation Loss: 0.0304, F1 Score: 0.0000\n","Epoch [99/100] Training Loss: 0.0294, F1 Score: 0.0000 | Validation Loss: 0.0312, F1 Score: 0.0000\n","Epoch [100/100] Training Loss: 0.0293, F1 Score: 0.0025 | Validation Loss: 0.0304, F1 Score: 0.0000\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x500 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training complete! Total time: 1337.48 seconds\n"]}],"source":["# Train the GatedCombination model using training and validation data\n","trained_model = train_gated_combination_model(\n","    X1_train,          # Updated source embeddings (after applying the GNN model)\n","    X2_train,          # Original source embeddings (before applying the GNN model)\n","    X3_train,          # Updated target embeddings (after applying the GNN model)\n","    X4_train,          # Original target embeddings (before applying the GNN model)\n","    tensor_score_train, # Ground truth labels for the training set (1 for matched pairs, 0 for unmatched pairs)\n","\n","    X1_val,            # Updated source embeddings for the validation set\n","    X2_val,            # Original source embeddings for the validation set\n","    X3_val,            # Updated target embeddings for the validation set\n","    X4_val,            # Original target embeddings for the validation set\n","    tensor_score_val,  # Ground truth labels for the validation set (1 for matched pairs, 0 for unmatched pairs)\n","\n","    epochs=100,        # Number of epochs (iterations over the entire training dataset)\n","    batch_size=32,     # Number of training samples processed in one forward/backward pass\n","    learning_rate=0.001, # Learning rate for the optimizer (controls step size during optimization)\n","    weight_decay=1e-4 # Weight decay (L2 regularization) to prevent overfitting\n",")"]},{"cell_type":"markdown","metadata":{"id":"uAmLuMtGW9c2"},"source":["# **Mappings Selector**"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"lnFtpUAfJQHl","executionInfo":{"status":"ok","timestamp":1735218190887,"user_tz":-60,"elapsed":797,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Build an indexed dictionary for the source ontology classes\n","# src_class is the file path to the JSON file containing the source ontology classes\n","indexed_dict_src = build_indexed_dict(src_class)\n","\n","# Build an indexed dictionary for the target ontology classes\n","# tgt_class is the file path to the JSON file containing the target ontology classes\n","indexed_dict_tgt = build_indexed_dict(tgt_class)"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"beipwavuJQHl","executionInfo":{"status":"ok","timestamp":1735218191108,"user_tz":-60,"elapsed":223,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the candidate pairs from a Candidates CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(candidates_Prediction, index_col=0)\n","\n","# Extract the 'SrcEntity' column (source entity indices) and convert it to a NumPy array of integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)\n","\n","# Extract the 'TgtEntity' column (target entity indices) and convert it to a NumPy array of integers\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)\n","\n","# Convert the source entity indices to a PyTorch LongTensor\n","src_entity_tensor_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)\n","\n","# Convert the target entity indices to a PyTorch LongTensor\n","tgt_entity_tenso_or = torch.from_numpy(tensor_term2).type(torch.LongTensor)"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"ECLhmxyKJQHl","executionInfo":{"status":"ok","timestamp":1735218191365,"user_tz":-60,"elapsed":259,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Select rows from the updated source embeddings based on the indices in src_entity_tensor_o\n","X1_tt = select_rows_by_index(embeddings_src, src_entity_tensor_o)\n","\n","# Select rows from the original source embeddings based on the indices in src_entity_tensor_o\n","X2_tt = select_rows_by_index(x_src, src_entity_tensor_o)\n","\n","# Select rows from the updated target embeddings based on the indices in tgt_entity_tenso_or\n","X3_tt = select_rows_by_index(embeddings_tgt, tgt_entity_tenso_or)\n","\n","# Select rows from the original target embeddings based on the indices in tgt_entity_tenso_or\n","X4_tt = select_rows_by_index(x_tgt, tgt_entity_tenso_or)"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0d17cfdb-2631-4b52-c81f-22ad2c513b4e","id":"UFP6OQR-7D4N","executionInfo":{"status":"ok","timestamp":1735218222714,"user_tz":-60,"elapsed":31351,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting time: 12.17 seconds\n","Predictions saved to /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_all_predictions.tsv\n"]}],"source":["# Generate predictions for candidate mappings using the trained GatedCombination model\n","Prediction_with_candidates(\n","    model=trained_model,             # The trained GatedCombination model used to evaluate similarity\n","    X1_tt=X1_tt,                     # Updated source embeddings (after applying the GIT model)\n","    X2_tt=X2_tt,                     # Original source embeddings (before applying the GIT model)\n","    X3_tt=X3_tt,                     # Updated target embeddings (after applying the GIT model)\n","    X4_tt=X4_tt,                     # Original target embeddings (before applying the GIT model)\n","    src_entity_tensor_o=src_entity_tensor_o,  # Tensor of source entity indices used for evaluation\n","    tgt_entity_tensor_o=tgt_entity_tenso_or,  # Tensor of target entity indices used for evaluation\n","    indexed_dict_src=indexed_dict_src,        # Dictionary mapping source entity indices to their URIs\n","    indexed_dict_tgt=indexed_dict_tgt,        # Dictionary mapping target entity indices to their URIs\n","    all_predictions_path=all_predictions_path # Path to save all predictions with similarity scores in TSV format\n",")"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"mEc12J-B7D4N","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0741d5ab-c5c3-4b4d-9ff4-1b4711c9aff8","executionInfo":{"status":"ok","timestamp":1735218235116,"user_tz":-60,"elapsed":12405,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Positive Predictions : 1294\n"]}],"source":["# Filter the highest scoring predictions from the predictions file and save the results to a new file\n","matching_results_df = filter_highest_predictions(\n","    all_predictions_path,  # Path to the file containing all predictions with scores for all candidate pairs\n","    prediction_path        # Path where the filtered predictions with highest scores will be saved\n",")"]},{"cell_type":"markdown","metadata":{"id":"BIx74lNV7D4O"},"source":["# **Evaluation**"]},{"cell_type":"markdown","source":["# Global metrics calculation"],"metadata":{"id":"Pp3IpBBfWn9m"}},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bkOewzXr7D4O","outputId":"a2b71ed9-6b0a-4801-8491-5f1580382ae8","executionInfo":{"status":"ok","timestamp":1735218236671,"user_tz":-60,"elapsed":1562,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Correct Predictions: 1021\n","{'P': 0.789, 'R': 0.383, 'F1': 0.516}\n"]}],"source":["# Retrieve the indices of the ignored classes (from source and target ontologies)\n","ignored_class_index = get_ignored_class_index(src_onto)  # Get ignored class indices from source ontology\n","ignored_class_index.update(get_ignored_class_index(tgt_onto))  # Update with ignored class indices from target ontology\n","\n","# Read the predicted mappings from the prediction results file\n","preds = EntityMapping.read_table_mappings(prediction_path)\n","\n","# Read the reference mappings from the ground truth test file\n","refs = ReferenceMapping.read_table_mappings(f\"{dataset_dir}/refs_equiv/test.tsv\")\n","\n","# Filter the predicted mappings to remove any mappings that involve ignored classes\n","preds = remove_ignored_mappings(preds, ignored_class_index)\n","\n","# Compute the precision, recall, and F1-score by comparing predictions with the reference mappings\n","results = AlignmentEvaluator.f1(preds, refs)\n","\n","preds2 = [p.to_tuple() for p in preds]\n","refs2 = [r.to_tuple() for r in refs]\n","\n","correct= len(set(preds2).intersection(set(refs2)))\n","\n","print(f\"Number of Correct Predictions: {correct}\")\n","\n","# Print the computed precision, recall, and F1-score metrics\n","print(results)"]},{"cell_type":"markdown","source":["# Ranked-based metrics calculation"],"metadata":{"id":"aECB6igZW04C"}},{"cell_type":"code","execution_count":38,"metadata":{"id":"-AK-jADkSbTa","executionInfo":{"status":"ok","timestamp":1735218237271,"user_tz":-60,"elapsed":602,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the candidate pairs from a Candidates CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(candidates_Rank, index_col=0)\n","\n","# Extract the 'SrcEntity' column (source entity indices) and convert it to a NumPy array of integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)\n","\n","# Extract the 'TgtEntity' column (target entity indices) and convert it to a NumPy array of integers\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)\n","\n","# Convert the source entity indices to a PyTorch LongTensor\n","src_entity_tensor_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)\n","\n","# Convert the target entity indices to a PyTorch LongTensor\n","tgt_entity_tenso_or = torch.from_numpy(tensor_term2).type(torch.LongTensor)"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"oyOzcLv-SbTb","executionInfo":{"status":"ok","timestamp":1735218237651,"user_tz":-60,"elapsed":382,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Select rows from the updated source embeddings based on the indices in src_entity_tensor_o\n","X1_tt = select_rows_by_index(embeddings_src, src_entity_tensor_o)\n","\n","# Select rows from the original source embeddings based on the indices in src_entity_tensor_o\n","X2_tt = select_rows_by_index(x_src, src_entity_tensor_o)\n","\n","# Select rows from the updated target embeddings based on the indices in tgt_entity_tenso_or\n","X3_tt = select_rows_by_index(embeddings_tgt, tgt_entity_tenso_or)\n","\n","# Select rows from the original target embeddings based on the indices in tgt_entity_tenso_or\n","X4_tt = select_rows_by_index(x_tgt, tgt_entity_tenso_or)"]},{"cell_type":"code","source":["# Perform ranking-based predictions using the trained GatedCombination model\n","# Generate predictions for candidate mappings using the trained GatedCombination model\n","Prediction_with_candidates(\n","    model=trained_model,             # The trained GatedCombination model used to evaluate similarity\n","    X1_tt=X1_tt,                     # Updated source embeddings (after applying the GIT model)\n","    X2_tt=X2_tt,                     # Original source embeddings (before applying the GIT model)\n","    X3_tt=X3_tt,                     # Updated target embeddings (after applying the GIT model)\n","    X4_tt=X4_tt,                     # Original target embeddings (before applying the GIT model)\n","    src_entity_tensor_o=src_entity_tensor_o,  # Tensor of source entity indices used for evaluation\n","    tgt_entity_tensor_o=tgt_entity_tenso_or,  # Tensor of target entity indices used for evaluation\n","    indexed_dict_src=indexed_dict_src,        # Dictionary mapping source entity indices to their URIs\n","    indexed_dict_tgt=indexed_dict_tgt,        # Dictionary mapping target entity indices to their URIs\n","    all_predictions_path=all_predictions_path_ranked, # Path where the ranked predictions will be saved in TSV format\n",")"],"metadata":{"id":"-O2f7X6cSb-m","executionInfo":{"status":"ok","timestamp":1735218266325,"user_tz":-60,"elapsed":28675,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"004a704d-15f6-4a1a-b101-d0803c40b1dc"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting time: 11.37 seconds\n","Predictions saved to /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_all_predictions_ranked.tsv\n"]}]},{"cell_type":"code","execution_count":41,"metadata":{"id":"_402seVv7D4O","executionInfo":{"status":"ok","timestamp":1735218281479,"user_tz":-60,"elapsed":15164,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b8636b00-e7db-41cb-d95d-728edfe39c2f"},"outputs":[{"output_type":"stream","name":"stdout","text":["MRR and Hits@k Results:\n","{'MRR': 0.7227624922623681, 'Hits@k': {1: 0.6222305670296658, 5: 0.8516710476905746, 10: 0.9038678182500939}}\n"]}],"source":["# Compute MRR and Hits@k metrics\n","# This function evaluates the predicted rankings against the reference mappings\n","results = compute_mrr_and_hits(\n","    reference_file=test_cands,             # Reference file with true ranks\n","    predicted_file=all_predictions_path_ranked,             # File containing predicted rankings\n","    output_file=formatted_predictions_path,    # File path to save formatted predictions\n","    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",")\n","\n","# Display the computed metrics\n","print(\"MRR and Hits@k Results:\")\n","print(results)  # Output the Mean Reciprocal Rank (MRR) and Hits@k metrics"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"wStfa4eZ7D4O","executionInfo":{"status":"ok","timestamp":1735218284400,"user_tz":-60,"elapsed":2923,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"720ece05-d8b5-4e03-8094-8b9d50bd621d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ranking Evaluation Results at K=1, 5, and 10:\n","{'MRR': 0.7227624922623681, 'Hits@1': 0.6222305670296658, 'Hits@5': 0.8516710476905746, 'Hits@10': 0.9038678182500939}\n"]}],"source":["# Call the ranking evaluation function, passing the path to the formatted predictions file.\n","# Ks specifies the evaluation levels, checking if the correct target is within the top K candidates.\n","results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n","print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n","print(results)"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}