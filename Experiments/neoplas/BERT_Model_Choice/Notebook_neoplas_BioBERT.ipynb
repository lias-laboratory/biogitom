{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkAX88H3RNRW"
      },
      "source": [
        "# **Package Installation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bSuJvX5_qNhr",
        "outputId": "6864f298-0ae8-4b37-d725-447f75887e6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.6.0\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchvision==0.21.0\n",
            "  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting filelock (from torch==2.6.0)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch==2.6.0)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting networkx (from torch==2.6.0)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch==2.6.0)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch==2.6.0)\n",
            "  Downloading fsspec-2025.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.6.0)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch==2.6.0)\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting sympy==1.13.1 (from torch==2.6.0)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting numpy (from torchvision==0.21.0)\n",
            "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.21.0)\n",
            "  Downloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch==2.6.0)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.6.0)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m554.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m116.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m113.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2025.5.0-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.13.2\n",
            "    Uninstalling typing_extensions-4.13.2:\n",
            "      Successfully uninstalled typing_extensions-4.13.2\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.2.1\n",
            "    Uninstalling pillow-11.2.1:\n",
            "      Successfully uninstalled pillow-11.2.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.18.0\n",
            "    Uninstalling filelock-3.18.0:\n",
            "      Successfully uninstalled filelock-3.18.0\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cpu\n",
            "    Uninstalling torch-2.6.0+cpu:\n",
            "      Successfully uninstalled torch-2.6.0+cpu\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cpu\n",
            "    Uninstalling torchvision-0.21.0+cpu:\n",
            "      Successfully uninstalled torchvision-0.21.0+cpu\n",
            "Successfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.5.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 pillow-11.2.1 sympy-1.13.1 torch-2.6.0 torchvision-0.21.0 triton-3.2.0 typing-extensions-4.13.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "191d861531b642c6b0e941855cf2f637"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Reinstall a specific version of PyTorch (v2.6.0) and torchvision (v0.21.0)\n",
        "# The \"--force-reinstall\" flag ensures that the packages are reinstalled even if the correct version is already present.\n",
        "# This is useful to resolve environment issues or when dependencies need to be reset.\n",
        "!pip install torch==2.6.0 torchvision==0.21.0 --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ItSvFeEAfLBF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05c2e235-8e1c-4399-987c-2b4420a7559e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.2.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.2.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.2.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\n",
            "Collecting torch-geometric==2.4.0\n",
            "  Using cached torch_geometric-2.4.0-py3-none-any.whl.metadata (63 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (2.2.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (1.15.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (3.1.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (3.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (1.6.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric==2.4.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.4.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.4.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.4.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.4.0) (2025.4.26)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->torch-geometric==2.4.0) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->torch-geometric==2.4.0) (3.6.0)\n",
            "Using cached torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "Installing collected packages: torch-geometric\n",
            "  Attempting uninstall: torch-geometric\n",
            "    Found existing installation: torch-geometric 2.7.0\n",
            "    Uninstalling torch-geometric-2.7.0:\n",
            "      Successfully uninstalled torch-geometric-2.7.0\n",
            "Successfully installed torch-geometric-2.4.0\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.11/dist-packages (2.1.2+pt20cpu)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.11/dist-packages (0.6.18+pt20cpu)\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.11/dist-packages (1.6.3+pt20cpu)\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.11/dist-packages (1.2.2+pt20cpu)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (2.2.6)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: deeponto in /usr/local/lib/python3.11/dist-packages (0.9.3)\n",
            "Requirement already satisfied: JPype1 in /usr/local/lib/python3.11/dist-packages (from deeponto) (1.5.2)\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.11/dist-packages (from deeponto) (0.1.8)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from deeponto) (2.6.0)\n",
            "Requirement already satisfied: anytree in /usr/local/lib/python3.11/dist-packages (from deeponto) (2.13.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from deeponto) (8.2.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from deeponto) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from deeponto) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deeponto) (2.2.6)\n",
            "Requirement already satisfied: scikit_learn in /usr/local/lib/python3.11/dist-packages (from deeponto) (1.6.1)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.11/dist-packages (from deeponto) (4.51.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from deeponto) (3.6.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (from deeponto) (3.8.5)\n",
            "Requirement already satisfied: pprintpp in /usr/local/lib/python3.11/dist-packages (from deeponto) (0.4.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from deeponto) (3.4.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from deeponto) (5.4.0)\n",
            "Requirement already satisfied: textdistance in /usr/local/lib/python3.11/dist-packages (from deeponto) (4.6.3)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from deeponto) (7.7.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from deeponto) (6.17.1)\n",
            "Requirement already satisfied: enlighten in /usr/local/lib/python3.11/dist-packages (from deeponto) (1.14.1)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.11/dist-packages (from deeponto) (7.1.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from deeponto) (3.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (20.0.0)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (0.31.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (6.0.2)\n",
            "Requirement already satisfied: blessed>=1.17.7 in /usr/local/lib/python3.11/dist-packages (from enlighten->deeponto) (1.21.0)\n",
            "Requirement already satisfied: prefixed>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from enlighten->deeponto) (0.9.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (6.4.2)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (5.7.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->deeponto) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->deeponto) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->deeponto) (3.0.15)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->deeponto) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->deeponto) (2024.11.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->deeponto) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->deeponto) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->deeponto) (2025.2)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from rdflib->deeponto) (3.2.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn->deeponto) (1.15.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn->deeponto) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (0.15.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (2.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (4.13.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->deeponto) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->deeponto) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->deeponto) (0.5.3)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->deeponto) (1.6.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.11/dist-packages (from blessed>=1.17.7->enlighten->deeponto) (0.2.13)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (3.11.15)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (5.2.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (4.9.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel->deeponto) (5.7.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->deeponto) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->deeponto) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->deeponto) (2025.4.26)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->deeponto) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->deeponto) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (14.0.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (7.1.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.5.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy->deeponto) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (1.20.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->deeponto) (0.8.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel->deeponto) (4.3.8)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.3.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->deeponto) (0.7.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (3.0.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->deeponto) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (0.1.2)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.23.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.24.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "# === Base Libraries ===\n",
        "!pip install numpy --upgrade\n",
        "!pip install pandas\n",
        "!pip install optuna\n",
        "\n",
        "# === FAISS (for Approximate Nearest Neighbor Search) ===\n",
        "!pip install faiss-cpu        # CPU version (recommended unless using GPU)\n",
        "# !pip install faiss-gpu      # Uncomment if running on CUDA-enabled GPU\n",
        "\n",
        "# === PyTorch Geometric and dependencies ===\n",
        "!pip install torch-geometric==2.4.0\n",
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
        "# Optional: latest dev version from GitHub\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "# === DeepOnto (Ontology Matching Toolkit) ===\n",
        "!pip install deeponto\n",
        "# Optionally install custom version from a GitHub repository\n",
        "# !pip install git+https://github.com/<username>/deeponto.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nFonRjT5fMCv"
      },
      "outputs": [],
      "source": [
        "# Import pandas for working with tabular data (e.g., CSV, TSV files)\n",
        "import pandas as pd\n",
        "\n",
        "# Import numpy for numerical operations and efficient array handling\n",
        "import numpy as np\n",
        "\n",
        "# Import json for reading and writing JSON-formatted files (useful for config or ontology structures)\n",
        "import json\n",
        "\n",
        "# Import pickle for serializing and deserializing Python objects (e.g., saving models or processed data)\n",
        "import pickle\n",
        "\n",
        "# Import warnings to control or suppress warning messages during runtime\n",
        "import warnings\n",
        "\n",
        "# Import gc (garbage collector) for managing memory manually when dealing with large datasets\n",
        "import gc\n",
        "\n",
        "# Ignore all warning messages to keep the output clean\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uchfZJP2fZwe"
      },
      "outputs": [],
      "source": [
        "# Import PyTorch core library for tensor operations and model definition\n",
        "import torch\n",
        "\n",
        "# Import commonly used PyTorch components\n",
        "from torch import Tensor, optim  # Tensor type and optimization algorithms (e.g., SGD, Adam)\n",
        "\n",
        "# Import PyTorch's neural network module (base class for defining models)\n",
        "import torch.nn as nn\n",
        "\n",
        "# Import PyTorch's functional API for operations like activations and loss functions\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Import DataLoader utilities for batching and loading datasets during training\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# === PyTorch Geometric (PyG) modules for graph-based learning ===\n",
        "\n",
        "# Basic graph data structure from PyG\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# PyG-specific DataLoader for batching graphs\n",
        "from torch_geometric.loader import DataLoader as GeoDataLoader\n",
        "\n",
        "# Import graph convolution layers and pooling functions from PyG\n",
        "from torch_geometric.nn import (\n",
        "    GCNConv,             # Graph Convolutional Network layer\n",
        "    GINConv,             # Graph Isomorphism Network convolution\n",
        "    global_mean_pool,    # Global mean pooling over node embeddings\n",
        "    global_add_pool,     # Global sum pooling over node embeddings\n",
        "    MessagePassing       # Base class for defining custom GNN layers\n",
        ")\n",
        "\n",
        "# Explicitly re-import MessagePassing (optional if already above)\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "\n",
        "# Graph utility functions from PyG\n",
        "from torch_geometric.utils import (\n",
        "    to_undirected,       # Converts a directed graph to undirected\n",
        "    softmax              # Softmax over edges (e.g., for attention)\n",
        ")\n",
        "\n",
        "# Initialization utilities for GNN layers\n",
        "from torch_geometric.nn.inits import (\n",
        "    reset,               # Reset parameters\n",
        "    glorot,              # Glorot (Xavier) weight initialization\n",
        "    zeros                # Zero initialization\n",
        ")\n",
        "\n",
        "# Typing utilities from PyG for adjacency and tensor specifications\n",
        "from torch_geometric.typing import (\n",
        "    Adj, OptTensor, PairTensor, SparseTensor\n",
        ")\n",
        "\n",
        "# Dense linear transformation layer from PyG (alternative to torch.nn.Linear)\n",
        "from torch_geometric.nn.dense.linear import Linear\n",
        "\n",
        "# Additional PyTorch neural network components\n",
        "from torch.nn import (\n",
        "    Linear,             # Fully connected (dense) layer\n",
        "    PReLU,              # Parametric ReLU activation\n",
        "    Sequential,         # Layer container for building sequential models\n",
        "    BatchNorm1d,        # Batch normalization for 1D inputs\n",
        "    Dropout             # Dropout regularization\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ziMBSWE8ff1N"
      },
      "outputs": [],
      "source": [
        "# Import matplotlib for creating visualizations (e.g., loss curves, evaluation metrics, embedding projections)\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JeAvp6PNfiLh"
      },
      "outputs": [],
      "source": [
        "# Import function to split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import encoder to convert categorical labels into integer values (useful for classification tasks)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Import evaluation metrics for classification and regression tasks\n",
        "from sklearn.metrics import (\n",
        "    f1_score,            # Harmonic mean of precision and recall; useful for imbalanced classification\n",
        "    precision_score,     # Measures the proportion of true positives among all predicted positives\n",
        "    accuracy_score,      # Measures overall correctness of predictions (classification)\n",
        "    mean_squared_error,  # Measures average squared difference between predicted and actual values (regression)\n",
        "    mean_absolute_error  # Measures average absolute difference between predicted and actual values (regression)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jm1rMZvmfl2M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b93c701c-0906-4cf1-dfa0-a4bc1a7d42b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enter the maximum memory located to JVM [8g]: 8g\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import the Ontology class for loading and manipulating OWL ontologies\n",
        "from deeponto.onto import Ontology\n",
        "\n",
        "# Import all components related to OAEI (Ontology Alignment Evaluation Initiative) benchmarking\n",
        "from deeponto.align.oaei import *\n",
        "\n",
        "# Import data structures for representing mappings between ontology entities\n",
        "from deeponto.align.mapping import EntityMapping, ReferenceMapping\n",
        "# - EntityMapping: represents a predicted alignment (one or more mappings)\n",
        "# - ReferenceMapping: represents the gold standard/reference alignments\n",
        "\n",
        "# Import the evaluator to compute Precision, Recall, and F1-score for alignments\n",
        "from deeponto.align.evaluation import AlignmentEvaluator\n",
        "\n",
        "# Utility function to read TSV/CSV tables as mapping or data frames\n",
        "from deeponto.utils import read_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JYhwr3Q_ft2N"
      },
      "outputs": [],
      "source": [
        "# Import Optuna, a hyperparameter optimization framework for automating model tuning using strategies like Bayesian optimization\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UmSCo5Olfzuz"
      },
      "outputs": [],
      "source": [
        "# Import the math module for mathematical functions (e.g., sqrt, log, exp)\n",
        "import math\n",
        "\n",
        "# Import the time module for measuring execution time of code blocks or functions\n",
        "import time\n",
        "\n",
        "# Import typing annotations for function signatures and code clarity\n",
        "from typing import Optional, Tuple, Union, Callable\n",
        "# - Optional[T]: denotes a value that could be of type T or None\n",
        "# - Tuple: fixed-size ordered collection of elements\n",
        "# - Union: allows multiple possible types (e.g., Union[int, str])\n",
        "# - Callable: represents a function or method type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9WNn0OMQW2CS"
      },
      "outputs": [],
      "source": [
        "# Import Python's built-in random module for generating pseudo-random numbers\n",
        "import random\n",
        "\n",
        "# Set the seed for PyTorch's random number generator to ensure reproducibility\n",
        "import torch\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Set the seed for NumPy's random number generator to ensure reproducibility\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "\n",
        "# Set the seed for Python's built-in random module to ensure reproducibility\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-abbBHOoRdWl"
      },
      "source": [
        "# **Paths Definition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AVgl_Bb42naS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d0f4ced-25ec-48a4-c403-0cb9b316d650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Importing the 'drive' module from Google Colab to interact with Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount the user's Google Drive to the Colab environment\n",
        "# After running this, a link will appear to authorize access, and Google Drive will be mounted at '/content/gdrive'\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "36ttssQ3W7cx"
      },
      "outputs": [],
      "source": [
        "# Define the source ontology name\n",
        "src_ent = \"snomed.neoplas\"\n",
        "\n",
        "# Define the target ontology name\n",
        "tgt_ent = \"ncit.neoplas\"\n",
        "\n",
        "# Define the task name for this ontology matching process\n",
        "task = \"neoplas\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SJpvkdwVSQye"
      },
      "outputs": [],
      "source": [
        "dir = \"/content/gdrive/My Drive/BioGITOM-VLDB/\"\n",
        "\n",
        "# Define the directory for the dataset containing source and target ontologies\n",
        "dataset_dir = f\"{dir}/Datasets/{task}\"\n",
        "\n",
        "# Define the data directory for storing embeddings, adjacency matrices, and related files\n",
        "data_dir = f\"{dir}/{task}/Data\"\n",
        "\n",
        "# Define the directory for storing the results\n",
        "results_dir = f\"{dir}/{task}/Results\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "eFDNSFef23er"
      },
      "outputs": [],
      "source": [
        "# Load the Source ontology using the Ontology class from DeepOnto\n",
        "# This initializes the source ontology by loading its .owl file.\n",
        "src_onto = Ontology(f\"{dataset_dir}/{src_ent}.owl\")\n",
        "\n",
        "# Load the Target ontology using the Ontology class from DeepOnto\n",
        "# This initializes the target ontology by loading its .owl file.\n",
        "tgt_onto = Ontology(f\"{dataset_dir}/{tgt_ent}.owl\")\n",
        "\n",
        "# Define the file path for the Source embeddings CSV file\n",
        "# Embeddings for the source ontology entities are stored in this file.\n",
        "src_Emb = f\"{data_dir}/{src_ent}_BioBERT_emb.csv\"\n",
        "\n",
        "# Define the file path for the Target embeddings CSV file\n",
        "# Embeddings for the target ontology entities are stored in this file.\n",
        "tgt_Emb = f\"{data_dir}/{tgt_ent}_BioBERT_emb.csv\"\n",
        "\n",
        "# Define the file path for the Source adjacency matrix\n",
        "# This file represents the relationships (edges) between entities in the source ontology.\n",
        "src_Adjacence = f\"{data_dir}/{src_ent}_adjacence.csv\"\n",
        "\n",
        "# Define the file path for the Target adjacency matrix\n",
        "# This file represents the relationships (edges) between entities in the target ontology.\n",
        "tgt_Adjacence = f\"{data_dir}/{tgt_ent}_adjacence.csv\"\n",
        "\n",
        "# Define the file path for the JSON file containing the Source ontology class labels\n",
        "# This file maps the source ontology entities to their labels or names.\n",
        "src_class = f\"{data_dir}/{src_ent}_classes.json\"\n",
        "\n",
        "# Define the file path for the JSON file containing the Target ontology class labels\n",
        "# This file maps the target ontology entities to their labels or names.\n",
        "tgt_class = f\"{data_dir}/{tgt_ent}_classes.json\"\n",
        "\n",
        "# Define the file path for the train data\n",
        "train_file = f\"{data_dir}/{task}_train.csv\"\n",
        "\n",
        "# Define the file path for the test data\n",
        "# The test file contains reference mappings (ground truth) between the source and target ontologies.\n",
        "test_file = f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "\n",
        "# Define the file path for the candidate mappings used during testing\n",
        "# This file includes the candidate pairs (source and target entities) for ranking based metrics.\n",
        "test_cands = f\"{dataset_dir}/refs_equiv/test.cands.tsv\"\n",
        "cands_path = f\"{data_dir}/{task}_cands.csv\"\n",
        "\n",
        "# Define the path where the prediction results will be saved in TSV format\n",
        "# This file will store the final predictions (mappings) between source and target entities.\n",
        "prediction_path = f\"{results_dir}/{task}_matching_results.tsv\"\n",
        "\n",
        "# Define the path where all prediction results will be saved in TSV format\n",
        "# This file will store detailed prediction results, including all candidate scores.\n",
        "all_predictions_path = f\"{results_dir}/{task}_all_predictions.tsv\"\n",
        "\n",
        "# Define the path where formatted ranking predictions will be saved in TSV format\n",
        "# This file will contain predictions formatted for evaluation using ranking-based metrics.\n",
        "formatted_predictions_path = f\"{results_dir}/{task}_formatted_predictions.tsv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqEXsgPGMVhw"
      },
      "source": [
        "# **GIT Architecture**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "A_d6XCsUMVhx"
      },
      "outputs": [],
      "source": [
        "# RGIT class definition which inherits from PyTorch Geometric's MessagePassing class\n",
        "class RGIT(MessagePassing):\n",
        "\n",
        "    _alpha: OptTensor  # Define _alpha as an optional tensor for storing attention weights\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        nn: Callable,  # Neural network to be used in the final layer of the GNN\n",
        "        in_channels: Union[int, Tuple[int, int]],  # Input dimension, can be a single or pair of integers\n",
        "        out_channels: int,  # Output dimension of the GNN\n",
        "        eps: float = 0.,  # GIN parameter: epsilon for GIN aggregation\n",
        "        train_eps: bool = False,  # GIN parameter: whether epsilon should be learnable\n",
        "        heads: int = 1,  # Transformer parameter: number of attention heads\n",
        "        dropout: float = 0.,  # Dropout rate for attention weights\n",
        "        edge_dim: Optional[int] = None,  # Dimension for edge attributes (optional)\n",
        "        bias: bool = True,  # Whether to use bias in linear layers\n",
        "        root_weight: bool = True,  # GIN parameter: whether to apply root weight in aggregation\n",
        "        **kwargs,  # Additional arguments passed to the parent class\n",
        "    ):\n",
        "        # Set the aggregation type to 'add' and initialize the parent class with node_dim=0\n",
        "        kwargs.setdefault('aggr', 'add')\n",
        "        super().__init__(node_dim=0, **kwargs)\n",
        "\n",
        "        # Initialize input/output dimensions, neural network, and GIN/transformer parameters\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.nn = nn  # Neural network used by the GNN\n",
        "        self.initial_eps = eps  # Initial value of epsilon for GIN\n",
        "\n",
        "        # Set epsilon to be learnable or fixed\n",
        "        if train_eps:\n",
        "            self.eps = torch.nn.Parameter(torch.empty(1))  # Learnable epsilon\n",
        "        else:\n",
        "            self.register_buffer('eps', torch.empty(1))  # Non-learnable epsilon (fixed)\n",
        "\n",
        "        # Initialize transformer-related parameters\n",
        "        self.heads = heads\n",
        "        self.dropout = dropout\n",
        "        self.edge_dim = edge_dim\n",
        "        self._alpha = None  # Placeholder for attention weights\n",
        "\n",
        "        # Handle case where in_channels is a single integer or a tuple\n",
        "        if isinstance(in_channels, int):\n",
        "            in_channels = (in_channels, in_channels)\n",
        "\n",
        "        # Define the linear layers for key, query, and value for the transformer mechanism\n",
        "        self.lin_key = Linear(in_channels[0], heads * out_channels)\n",
        "        self.lin_query = Linear(in_channels[1], heads * out_channels)\n",
        "        self.lin_value = Linear(in_channels[0], heads * out_channels)\n",
        "\n",
        "        # Define linear transformation for edge embeddings if provided\n",
        "        if edge_dim is not None:\n",
        "            self.lin_edge = Linear(edge_dim, heads * out_channels, bias=False)\n",
        "        else:\n",
        "            self.lin_edge = self.register_parameter('lin_edge', None)\n",
        "\n",
        "        # Reset all parameters to their initial values\n",
        "        self.reset_parameters()\n",
        "\n",
        "    # Function to reset model parameters\n",
        "    def reset_parameters(self):\n",
        "        super().reset_parameters()  # Call parent class reset method\n",
        "        self.lin_key.reset_parameters()  # Reset key linear layer\n",
        "        self.lin_query.reset_parameters()  # Reset query linear layer\n",
        "        self.lin_value.reset_parameters()  # Reset value linear layer\n",
        "        if self.edge_dim:\n",
        "            self.lin_edge.reset_parameters()  # Reset edge linear layer if used\n",
        "        reset(self.nn)  # Reset the neural network provided\n",
        "        self.eps.data.fill_(self.initial_eps)  # Initialize epsilon with the starting value\n",
        "\n",
        "    # Forward function defining how the input data flows through the model\n",
        "    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj,\n",
        "                edge_attr: OptTensor = None, return_attention_weights=None):\n",
        "        # Unpack number of heads and output channels\n",
        "        H, C = self.heads, self.out_channels\n",
        "\n",
        "        # If x is a tensor, treat it as a pair of tensors (source and target embeddings)\n",
        "        if isinstance(x, Tensor):\n",
        "            x: PairTensor = (x, x)\n",
        "\n",
        "        # Extract source node embeddings\n",
        "        x_t = x[0]\n",
        "\n",
        "        # Apply linear transformations and reshape query, key, and value for multi-head attention\n",
        "        query = self.lin_query(x[1]).view(-1, H, C)\n",
        "        key = self.lin_key(x[0]).view(-1, H, C)\n",
        "        value = self.lin_value(x[0]).view(-1, H, C)\n",
        "\n",
        "        # Propagate messages through the graph using the propagate function\n",
        "        out = self.propagate(edge_index, query=query, key=key, value=value,\n",
        "                             edge_attr=edge_attr, size=None)\n",
        "\n",
        "        # Retrieve attention weights and reset them\n",
        "        alpha = self._alpha\n",
        "        self._alpha = None  # Reset _alpha after use\n",
        "        out = out.mean(dim=1)  # Take the mean over all attention heads\n",
        "\n",
        "        # Apply GIN aggregation by adding epsilon-scaled original node embeddings\n",
        "        out = out + (1 + self.eps) * x_t\n",
        "        return self.nn(out)  # Pass through the neural network\n",
        "\n",
        "    # Message passing function which calculates attention and combines messages\n",
        "    def message(self, query_i: Tensor, key_j: Tensor, value_j: Tensor,\n",
        "                edge_attr: OptTensor, index: Tensor, ptr: OptTensor,\n",
        "                size_i: Optional[int]) -> Tensor:\n",
        "        # If edge attributes are used, apply linear transformation and add them to the key\n",
        "        if self.lin_edge is not None:\n",
        "            assert edge_attr is not None\n",
        "            edge_attr = self.lin_edge(edge_attr).view(-1, self.heads, self.out_channels)\n",
        "            key_j = key_j + edge_attr\n",
        "\n",
        "        # Calculate attention (alpha) using the dot product between query and key\n",
        "        alpha = (query_i * key_j).sum(dim=-1) / math.sqrt(self.out_channels)\n",
        "        alpha = softmax(alpha, index, ptr, size_i)  # Apply softmax to normalize attention\n",
        "        self._alpha = alpha  # Store attention weights\n",
        "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)  # Apply dropout\n",
        "\n",
        "        # Calculate the output message by applying attention to the value\n",
        "        out = value_j\n",
        "        if edge_attr is not None:\n",
        "            out = out + edge_attr  # Add edge embeddings to the output if present\n",
        "        out = out * alpha.view(-1, self.heads, 1)  # Scale by attention weights\n",
        "        return out\n",
        "\n",
        "    # String representation function for debugging or printing\n",
        "    def __repr__(self) -> str:\n",
        "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
        "                f'{self.out_channels}, heads={self.heads})')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qwFv6RgHmGCf"
      },
      "outputs": [],
      "source": [
        "# Define the RGIT_mod class, a multi-layer GNN that uses both RGIT and linear layers\n",
        "class RGIT_mod(torch.nn.Module):\n",
        "    \"\"\"Multi-layer RGIT with optional linear layers\"\"\"\n",
        "\n",
        "    # Initialize the model with hidden dimension, number of RGIT layers, and number of linear layers\n",
        "    def __init__(self, dim_h, num_layers, num_linear_layers=1):\n",
        "        super(RGIT_mod, self).__init__()\n",
        "        self.num_layers = num_layers  # Number of RGIT layers\n",
        "        self.num_linear_layers = num_linear_layers  # Number of linear layers\n",
        "        self.linears = torch.nn.ModuleList()  # List to store linear layers\n",
        "        self.rgit_layers = torch.nn.ModuleList()  # List to store RGIT layers\n",
        "\n",
        "        # Create a list of Linear and PReLU layers (for encoding entity names)\n",
        "        for _ in range(num_linear_layers):\n",
        "            self.linears.append(Linear(dim_h, dim_h))  # Linear transformation layer\n",
        "            self.linears.append(PReLU(num_parameters=dim_h))  # Parametric ReLU activation function\n",
        "\n",
        "        # Create a list of RGIT layers\n",
        "        for _ in range(num_layers):\n",
        "            self.rgit_layers.append(RGIT(  # Each RGIT layer contains a small MLP with Linear and PReLU\n",
        "                Sequential(Linear(dim_h, dim_h), PReLU(num_parameters=dim_h),\n",
        "                           Linear(dim_h, dim_h), PReLU(num_parameters=dim_h)), dim_h, dim_h))\n",
        "\n",
        "    # Forward pass through the model\n",
        "    def forward(self, x, edge_index):\n",
        "        # Apply the linear layers first to the input\n",
        "        for layer in self.linears:\n",
        "            x = layer(x)\n",
        "\n",
        "        # Then apply the RGIT layers for message passing\n",
        "        for layer in self.rgit_layers:\n",
        "            x = layer(x, edge_index)\n",
        "\n",
        "        return x  # Return the final node embeddings after all layers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxCn5ztKVztw"
      },
      "source": [
        "# **Gated Network Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7MKQUv7o7zay"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GatedCombination(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(GatedCombination, self).__init__()\n",
        "        self.gate_A_fc = nn.Linear(input_dim, input_dim)\n",
        "        self.gate_B_fc = nn.Linear(input_dim, input_dim)\n",
        "        self.fc = nn.Linear(1, 1)\n",
        "\n",
        "    def euclidean_distance(self, a, b):\n",
        "        \"\"\"\n",
        "        Compute the Euclidean distance between two tensors.\n",
        "        Args:\n",
        "            a: Tensor of shape [batch, dim]\n",
        "            b: Tensor of shape [batch, dim]\n",
        "        Returns:\n",
        "            Tensor of shape [batch] representing the L2 distance.\n",
        "        \"\"\"\n",
        "        return torch.norm(a - b, p=2, dim=1)\n",
        "\n",
        "    def forward(self, x1, x2, x3, x4, return_embeddings=False):\n",
        "        gate_values1 = torch.sigmoid(self.gate_A_fc(x1))\n",
        "        a = x1 * gate_values1 + x2 * (1 - gate_values1)\n",
        "\n",
        "        gate_values2 = torch.sigmoid(self.gate_B_fc(x3))\n",
        "        b = x3 * gate_values2 + x4 * (1 - gate_values2)\n",
        "\n",
        "        if return_embeddings:\n",
        "            return a, b\n",
        "\n",
        "        # Utilisation de la distance Euclidienne\n",
        "        distance = self.euclidean_distance(a, b)\n",
        "\n",
        "        # Passage dans couche de classification\n",
        "        out = torch.sigmoid(self.fc(distance.unsqueeze(1)))\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-niEvlkie_vx"
      },
      "source": [
        "\n",
        "\n",
        "# **Encoder Definition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8GHQKz8Re_vx"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# === Simple Linear Encoder ===\n",
        "class LinearEncoder(nn.Module):\n",
        "    def __init__(self, embedding_dim):\n",
        "        super(LinearEncoder, self).__init__()\n",
        "        # A single linear transformation layer: y = Wx + b\n",
        "        self.linear = nn.Linear(embedding_dim, embedding_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass: apply the linear transformation\n",
        "        return self.linear(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLJ5j9FNMVhy"
      },
      "source": [
        "# **Utility functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "k0L86DgUQjMU"
      },
      "outputs": [],
      "source": [
        "def adjacency_matrix_to_undirected_edge_index(adjacency_matrix):\n",
        "    \"\"\"\n",
        "    Converts an adjacency matrix into an undirected edge index for use in graph-based neural networks.\n",
        "\n",
        "    Args:\n",
        "        adjacency_matrix: A 2D list or array representing the adjacency matrix of a graph.\n",
        "\n",
        "    Returns:\n",
        "        edge_index_undirected: A PyTorch tensor representing the undirected edges.\n",
        "    \"\"\"\n",
        "    # Convert each element in the adjacency matrix to an integer (from boolean or float)\n",
        "    adjacency_matrix = [[int(element) for element in sublist] for sublist in adjacency_matrix]\n",
        "\n",
        "    # Convert the adjacency matrix into a PyTorch LongTensor (used for indexing)\n",
        "    edge_index = torch.tensor(adjacency_matrix, dtype=torch.long)\n",
        "\n",
        "    # Transpose the edge_index tensor so that rows represent edges in the form [source, target]\n",
        "    edge_index = edge_index.t().contiguous()\n",
        "\n",
        "    # Convert the directed edge_index into an undirected edge_index, meaning both directions are added (i.e., (i, j) and (j, i))\n",
        "    edge_index_undirected = to_undirected(edge_index)\n",
        "\n",
        "    return edge_index_undirected  # Return the undirected edge index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YvmOxkLcpf9w"
      },
      "outputs": [],
      "source": [
        "def build_indexed_dict(file_path):\n",
        "    \"\"\"\n",
        "    Builds a dictionary with numeric indexes for each key from a JSON file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): The path to the JSON file.\n",
        "\n",
        "    Returns:\n",
        "        indexed_dict (dict): A new dictionary where each key from the JSON file is assigned a numeric index.\n",
        "    \"\"\"\n",
        "    # Load the JSON file into a Python dictionary\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    # Create a new dictionary with numeric indexes as keys and the original JSON keys as values\n",
        "    indexed_dict = {index: key for index, key in enumerate(data.keys())}\n",
        "\n",
        "    return indexed_dict  # Return the newly created dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QgFINoPGl9Wg"
      },
      "outputs": [],
      "source": [
        "def select_rows_by_index(embedding_vector, index_vector):\n",
        "    \"\"\"\n",
        "    Select rows from an embedding vector using an index vector.\n",
        "\n",
        "    Args:\n",
        "        embedding_vector (torch.Tensor): 2D tensor representing the embedding vector with shape [num_rows, embedding_size].\n",
        "        index_vector (torch.Tensor): 1D tensor representing the index vector.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: New tensor with selected rows from the embedding vector.\n",
        "    \"\"\"\n",
        "    # Use torch.index_select to select the desired rows\n",
        "    new_tensor = torch.index_select(embedding_vector, 0, index_vector)\n",
        "\n",
        "    return new_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "a12L7vEmmCJq"
      },
      "outputs": [],
      "source": [
        "def contrastive_loss(source_embeddings, target_embeddings, labels, margin=1.0):\n",
        "    \"\"\"\n",
        "    Computes the contrastive loss, a type of loss function used to train models in tasks like matching or similarity learning.\n",
        "\n",
        "    Args:\n",
        "        source_embeddings (torch.Tensor): Embeddings of the source graphs, shape [batch_size, embedding_size].\n",
        "        target_embeddings (torch.Tensor): Embeddings of the target graphs, shape [batch_size, embedding_size].\n",
        "        labels (torch.Tensor): Binary labels indicating if the pairs are matched (1) or not (0), shape [batch_size].\n",
        "        margin (float): Margin value for the contrastive loss. Defaults to 1.0.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The contrastive loss value.\n",
        "    \"\"\"\n",
        "    # Calculate the pairwise Euclidean distance between source and target embeddings\n",
        "    distances = F.pairwise_distance(source_embeddings, target_embeddings)\n",
        "\n",
        "    # Compute the contrastive loss:\n",
        "    # - For matched pairs (label == 1), the loss is the squared distance between embeddings.\n",
        "    # - For non-matched pairs (label == 0), the loss is based on how far apart the embeddings are,\n",
        "    #   but penalizes them only if the distance is less than the margin.\n",
        "    loss = torch.mean(\n",
        "        labels * 0.4 * distances.pow(2) +  # For positive pairs, minimize the distance (squared)\n",
        "        (1 - labels) * 0.4 * torch.max(torch.zeros_like(distances), margin - distances).pow(2)  # For negative pairs, maximize the distance (up to the margin)\n",
        "    )\n",
        "\n",
        "    return loss  # Return the computed contrastive loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_ggVYlTiO_WA"
      },
      "outputs": [],
      "source": [
        "def compute_mrr_and_hits(reference_file, predicted_file, output_file, k_values=[1, 5, 10]):\n",
        "    \"\"\"\n",
        "    Compute Mean Reciprocal Rank (MRR) and Hits@k metrics for ontology matching results.\n",
        "\n",
        "    Args:\n",
        "        reference_file (str): Path to the reference test candidate file (usually 'test.cands.tsv').\n",
        "        predicted_file (str): Path to the prediction results (with columns: SrcEntity, TgtEntity, Score).\n",
        "        output_file (str): Path to save ranked candidate predictions with scores.\n",
        "        k_values (list): List of integers specifying which Hits@k metrics to compute.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary with MRR and Hits@k scores.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load reference candidate mappings: each row = (SrcEntity, CorrectTgtEntity, [CandidateTgtEntities])\n",
        "    test_candidate_mappings = read_table(reference_file).values.tolist()\n",
        "\n",
        "    # Load predictions and ensure Score is float\n",
        "    predicted_data = pd.read_csv(predicted_file, sep=\"\\t\")\n",
        "    predicted_data[\"Score\"] = predicted_data[\"Score\"].apply(\n",
        "        lambda x: float(x.strip(\"[]\")) if isinstance(x, str) else float(x)\n",
        "    )\n",
        "\n",
        "    # Create a dictionary mapping (SrcEntity, TgtEntity) -> predicted score\n",
        "    score_lookup = {\n",
        "        (row[\"SrcEntity\"], row[\"TgtEntity\"]): row[\"Score\"]\n",
        "        for _, row in predicted_data.iterrows()\n",
        "    }\n",
        "\n",
        "    ranking_results = []\n",
        "\n",
        "    # Rank the candidates for each source entity\n",
        "    for src_ref_class, tgt_ref_class, tgt_cands in test_candidate_mappings:\n",
        "        # Safely parse the candidate list (tgt_cands is a stringified list)\n",
        "        try:\n",
        "            tgt_cands = eval(tgt_cands)\n",
        "        except Exception:\n",
        "            tgt_cands = []\n",
        "\n",
        "        # Score each candidate (use a large negative default if not found)\n",
        "        scored_cands = [\n",
        "            (tgt_cand, score_lookup.get((src_ref_class, tgt_cand), -1e9))\n",
        "            for tgt_cand in tgt_cands\n",
        "        ]\n",
        "\n",
        "        # Sort candidates by score descending\n",
        "        scored_cands = sorted(scored_cands, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Store the ranking result\n",
        "        ranking_results.append((src_ref_class, tgt_ref_class, scored_cands))\n",
        "\n",
        "    # Save ranked predictions for inspection/debugging\n",
        "    pd.DataFrame(ranking_results, columns=[\"SrcEntity\", \"TgtEntity\", \"TgtCandidates\"]).to_csv(\n",
        "        output_file, sep=\"\\t\", index=False\n",
        "    )\n",
        "\n",
        "    # === Evaluation: compute MRR and Hits@k ===\n",
        "    total_entities = len(ranking_results)\n",
        "    reciprocal_ranks = []\n",
        "    hits_at_k = {k: 0 for k in k_values}\n",
        "\n",
        "    for src_entity, tgt_ref_class, tgt_cands in ranking_results:\n",
        "        ranked_candidates = [cand[0] for cand in tgt_cands]  # candidate URIs only\n",
        "        if tgt_ref_class in ranked_candidates:\n",
        "            rank = ranked_candidates.index(tgt_ref_class) + 1\n",
        "            reciprocal_ranks.append(1 / rank)\n",
        "            for k in k_values:\n",
        "                if rank <= k:\n",
        "                    hits_at_k[k] += 1\n",
        "        else:\n",
        "            reciprocal_ranks.append(0)  # No correct match in candidate list\n",
        "\n",
        "    # Compute final metrics\n",
        "    mrr = sum(reciprocal_ranks) / total_entities\n",
        "    hits_at_k = {k: hits / total_entities for k, hits in hits_at_k.items()}\n",
        "\n",
        "    return {\"MRR\": mrr, \"Hits@k\": hits_at_k}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "kh1zdPJQe_vy"
      },
      "outputs": [],
      "source": [
        "def save_gated_embeddings(gated_model, embeddings_src, x_src, embeddings_tgt, x_tgt,\n",
        "                          indexed_dict_src, indexed_dict_tgt,\n",
        "                          output_file_src, output_file_tgt):\n",
        "    \"\"\"\n",
        "    Compute and save the final entity embeddings generated by the GatedCombination model\n",
        "    for both source and target ontologies. Outputs include entity URIs and their final vectors.\n",
        "    Measures and prints the execution time of the entire operation.\n",
        "\n",
        "    Args:\n",
        "        gated_model (nn.Module): The trained GatedCombination model.\n",
        "        embeddings_src (Tensor): Structural embeddings for the source ontology.\n",
        "        x_src (Tensor): Semantic embeddings for the source ontology.\n",
        "        embeddings_tgt (Tensor): Structural embeddings for the target ontology.\n",
        "        x_tgt (Tensor): Semantic embeddings for the target ontology.\n",
        "        indexed_dict_src (dict): Index-to-URI mapping for the source ontology.\n",
        "        indexed_dict_tgt (dict): Index-to-URI mapping for the target ontology.\n",
        "        output_file_src (str): Path to save source embeddings (TSV).\n",
        "        output_file_tgt (str): Path to save target embeddings (TSV).\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "    import torch\n",
        "    import time\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Use GPU if available\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    gated_model = gated_model.to(device)\n",
        "    gated_model.eval()\n",
        "\n",
        "    # Move inputs to the same device\n",
        "    embeddings_src = embeddings_src.to(device)\n",
        "    x_src = x_src.to(device)\n",
        "    embeddings_tgt = embeddings_tgt.to(device)\n",
        "    x_tgt = x_tgt.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # === Source ontology ===\n",
        "        gate_src = torch.sigmoid(gated_model.gate_A_fc(embeddings_src))\n",
        "        final_src = embeddings_src * gate_src + x_src * (1 - gate_src)\n",
        "        final_src = final_src.cpu().numpy()\n",
        "\n",
        "        # === Target ontology ===\n",
        "        gate_tgt = torch.sigmoid(gated_model.gate_B_fc(embeddings_tgt))\n",
        "        final_tgt = embeddings_tgt * gate_tgt + x_tgt * (1 - gate_tgt)\n",
        "        final_tgt = final_tgt.cpu().numpy()\n",
        "\n",
        "    # Create DataFrames with Concept URI and embedding values\n",
        "    df_src = pd.DataFrame(final_src)\n",
        "    df_src.insert(0, \"Concept\", [indexed_dict_src[i] for i in range(len(df_src))])\n",
        "\n",
        "    df_tgt = pd.DataFrame(final_tgt)\n",
        "    df_tgt.insert(0, \"Concept\", [indexed_dict_tgt[i] for i in range(len(df_tgt))])\n",
        "\n",
        "    # Save embeddings to file\n",
        "    df_src.to_csv(output_file_src, sep='\\t', index=False)\n",
        "    df_tgt.to_csv(output_file_tgt, sep='\\t', index=False)\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"✅ Gated embeddings saved:\\n- Source: {output_file_src}\\n- Target: {output_file_tgt}\")\n",
        "    print(f\"⏱️ Execution time: {elapsed_time:.2f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "LXvbHTVfe_vz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def filter_ignored_class(src_emb_path, tgt_emb_path, src_onto, tgt_onto):\n",
        "    \"\"\"\n",
        "    Filters the source and target embedding files by removing concepts considered \"ignored classes\"\n",
        "    (e.g., owl:Thing, deprecated entities, etc.) based on both source and target ontologies.\n",
        "\n",
        "    Args:\n",
        "        src_emb_path (str): Path to the TSV file containing source embeddings with 'Concept' column.\n",
        "        tgt_emb_path (str): Path to the TSV file containing target embeddings with 'Concept' column.\n",
        "        src_onto (Ontology): Source ontology object loaded with DeepOnto.\n",
        "        tgt_onto (Ontology): Target ontology object loaded with DeepOnto.\n",
        "\n",
        "    Returns:\n",
        "        (str, str): Paths to the cleaned source and target embedding files.\n",
        "    \"\"\"\n",
        "\n",
        "    # === Load the embedding files ===\n",
        "    df_src = pd.read_csv(src_emb_path, sep='\\t', dtype=str)\n",
        "    print(f\"🔍 Initial source file: {len(df_src)} rows\")\n",
        "\n",
        "    df_tgt = pd.read_csv(tgt_emb_path, sep='\\t', dtype=str)\n",
        "    print(f\"🔍 Initial target file: {len(df_tgt)} rows\")\n",
        "\n",
        "    # === Step 1: Retrieve ignored classes from both ontologies ===\n",
        "    ignored_class_index = get_ignored_class_index(src_onto)  # e.g., owl:Thing, non-usable classes\n",
        "    ignored_class_index.update(get_ignored_class_index(tgt_onto))  # Merge with target ontology's ignored classes\n",
        "    ignored_uris = set(str(uri).strip() for uri in ignored_class_index)\n",
        "\n",
        "    # === Step 2: Remove rows where the 'Concept' column matches ignored URIs ===\n",
        "    df_src_cleaned = df_src[~df_src['Concept'].isin(ignored_uris)].reset_index(drop=True)\n",
        "    df_tgt_cleaned = df_tgt[~df_tgt['Concept'].isin(ignored_uris)].reset_index(drop=True)\n",
        "\n",
        "    print(f\"✅ Source after removing ignored classes: {len(df_src_cleaned)} rows\")\n",
        "    print(f\"✅ Target after removing ignored classes: {len(df_tgt_cleaned)} rows\")\n",
        "\n",
        "    # === Step 3: Save the cleaned embedding files ===\n",
        "    output_file_src = src_emb_path.replace(\".tsv\", \"_cleaned.tsv\")\n",
        "    output_file_tgt = tgt_emb_path.replace(\".tsv\", \"_cleaned.tsv\")\n",
        "\n",
        "    df_src_cleaned.to_csv(output_file_src, sep='\\t', index=False)\n",
        "    df_tgt_cleaned.to_csv(output_file_tgt, sep='\\t', index=False)\n",
        "\n",
        "    print(f\"📁 Cleaned source file saved to: {output_file_src}\")\n",
        "    print(f\"📁 Cleaned target file saved to: {output_file_tgt}\")\n",
        "\n",
        "    return output_file_src, output_file_tgt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "_9YDcnTbKaHk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "def encode_embeddings_with_concept_column(encoder_model, input_file, output_file):\n",
        "    \"\"\"\n",
        "    Applies an encoder model to a set of embeddings (while preserving the 'Concept' column),\n",
        "    and saves the encoded results in the same tabular format.\n",
        "\n",
        "    Args:\n",
        "        encoder_model: A PyTorch model (e.g., LinearEncoder, MLPEncoder, etc.)\n",
        "        input_file (str): Path to the input TSV file containing 'Concept' and embedding vectors.\n",
        "        output_file (str): Path to save the encoded embeddings.\n",
        "    \"\"\"\n",
        "\n",
        "    # Select device (GPU if available, else CPU)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Move the encoder model to the selected device and set it to evaluation mode\n",
        "    encoder_model = encoder_model.to(device)\n",
        "    encoder_model.eval()\n",
        "\n",
        "    # Load the input TSV file containing concept URIs and embeddings\n",
        "    df = pd.read_csv(input_file, sep='\\t')\n",
        "\n",
        "    # Extract the 'Concept' column to preserve URIs\n",
        "    concepts = df['Concept'].tolist()\n",
        "\n",
        "    # Extract the numerical embedding values (excluding the 'Concept' column)\n",
        "    embedding_values = df.drop(columns=['Concept']).values\n",
        "\n",
        "    # Convert the embedding matrix into a PyTorch tensor and move to the device\n",
        "    embeddings = torch.FloatTensor(embedding_values).to(device)\n",
        "\n",
        "    # Pass the embeddings through the encoder model without computing gradients\n",
        "    with torch.no_grad():\n",
        "        encoded = encoder_model(embeddings).cpu().numpy()\n",
        "\n",
        "    # Reconstruct a new DataFrame with the encoded vectors and corresponding URIs\n",
        "    df_encoded = pd.DataFrame(encoded, columns=[f'dim_{i}' for i in range(encoded.shape[1])])\n",
        "    df_encoded.insert(0, \"Concept\", concepts)  # Re-insert the 'Concept' column at the first position\n",
        "\n",
        "    # Save the encoded embeddings to a TSV file\n",
        "    df_encoded.to_csv(output_file, sep='\\t', index=False)\n",
        "    print(f\"✅ Encoded embeddings saved to: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBAlDrOpe_vz"
      },
      "source": [
        "# **FAISS Similarity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "CyG7ztCne_vz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import faiss\n",
        "import time\n",
        "\n",
        "def load_embeddings(src_emb_path, tgt_emb_path):\n",
        "    \"\"\"\n",
        "    Load the embeddings for the source and target ontologies from TSV files.\n",
        "\n",
        "    Args:\n",
        "        src_emb_path (str): Path to the source embeddings file.\n",
        "        tgt_emb_path (str): Path to the target embeddings file.\n",
        "\n",
        "    Returns:\n",
        "        uris_src (np.ndarray): URIs of source entities.\n",
        "        uris_tgt (np.ndarray): URIs of target entities.\n",
        "        src_vecs (np.ndarray): Embedding vectors for source entities.\n",
        "        tgt_vecs (np.ndarray): Embedding vectors for target entities.\n",
        "    \"\"\"\n",
        "    df_src = pd.read_csv(src_emb_path, sep='\\t')  # Read source embeddings\n",
        "    df_tgt = pd.read_csv(tgt_emb_path, sep='\\t')  # Read target embeddings\n",
        "    uris_src = df_src[\"Concept\"].values           # Extract source URIs\n",
        "    uris_tgt = df_tgt[\"Concept\"].values           # Extract target URIs\n",
        "    src_vecs = df_src.drop(columns=[\"Concept\"]).values.astype('float32')  # Extract and convert source vectors\n",
        "    tgt_vecs = df_tgt.drop(columns=[\"Concept\"]).values.astype('float32')  # Extract and convert target vectors\n",
        "    return uris_src, uris_tgt, src_vecs, tgt_vecs\n",
        "\n",
        "def save_results(uris_src, uris_tgt, indices, scores, output_file, top_k):\n",
        "    \"\"\"\n",
        "    Save the top-k mapping results to a TSV file.\n",
        "\n",
        "    Args:\n",
        "        uris_src (np.ndarray): URIs of source entities.\n",
        "        uris_tgt (np.ndarray): URIs of target entities.\n",
        "        indices (np.ndarray): Indices of top-k matched target entities.\n",
        "        scores (np.ndarray): Corresponding similarity scores.\n",
        "        output_file (str): Output TSV file path.\n",
        "        top_k (int): Number of top matches per source entity.\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for i, (ind_row, score_row) in enumerate(zip(indices, scores)):\n",
        "        src_uri = uris_src[i]\n",
        "        for j, tgt_idx in enumerate(ind_row):\n",
        "            tgt_uri = uris_tgt[tgt_idx]\n",
        "            score = score_row[j]\n",
        "            rows.append((src_uri, tgt_uri, score))  # Store each top-k match\n",
        "    df_result = pd.DataFrame(rows, columns=[\"SrcEntity\", \"TgtEntity\", \"Score\"])\n",
        "    df_result.to_csv(output_file, sep='\\t', index=False)  # Save to file\n",
        "    print(f\"Top-{top_k} FAISS similarity results saved to: {output_file}\")\n",
        "\n",
        "def topk_faiss_l2(src_emb_path, tgt_emb_path, top_k=15, output_file=\"topk_l2.tsv\"):\n",
        "    \"\"\"\n",
        "    Compute the top-k most similar target entities for each source entity using FAISS with L2 distance.\n",
        "\n",
        "    Args:\n",
        "        src_emb_path (str): Path to the source embeddings file.\n",
        "        tgt_emb_path (str): Path to the target embeddings file.\n",
        "        top_k (int): Number of top matches to retrieve.\n",
        "        output_file (str): Path to save the top-k results.\n",
        "    \"\"\"\n",
        "    print(\"🔹 Using L2 (Euclidean) distance with FAISS\")\n",
        "    start = time.time()  # Start timing\n",
        "\n",
        "    # Load embeddings\n",
        "    uris_src, uris_tgt, src_vecs, tgt_vecs = load_embeddings(src_emb_path, tgt_emb_path)\n",
        "\n",
        "    # Build FAISS index using L2 distance\n",
        "    dim = src_vecs.shape[1]\n",
        "    index = faiss.IndexFlatL2(dim)  # Create FAISS index for L2 distance\n",
        "    index.add(tgt_vecs)             # Add target vectors to index\n",
        "\n",
        "    # Perform nearest neighbor search\n",
        "    distances, indices = index.search(src_vecs, top_k)\n",
        "\n",
        "    # Convert distances to similarity scores (optional: inverse of distance)\n",
        "    similarity_scores = 1 / (1 + distances)\n",
        "\n",
        "    # Save the results\n",
        "    save_results(uris_src, uris_tgt, indices, similarity_scores, output_file, top_k)\n",
        "\n",
        "    # Display execution time\n",
        "    print(f\"⏱️ Execution time: {time.time() - start:.2f} seconds\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zq0p_64e_vz"
      },
      "source": [
        "# **Mappings Evaluation Functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "repA9zGMe_vz"
      },
      "source": [
        "# **Precision, Recall, F1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GW0Am-TmVMR"
      },
      "source": [
        "### Evaluation Strategy and Filtering Justification\n",
        "\n",
        "### Filtering Justification\n",
        "\n",
        "In the `evaluate_predictions` function, two important filtering steps are applied to ensure that the evaluation metrics (such as Precision, Recall, and F1-score) accurately reflect the model's performance:\n",
        "\n",
        "\n",
        "#### 1. Filtering Out Training-Only Entities\n",
        "\n",
        "We remove all predicted mappings involving source or target entities that are present **only in the training set** and not in the test set.\n",
        "\n",
        "This step is critical because:\n",
        "\n",
        "- In some datasets like **Bio-ML**, the same entity can appear in both training and test sets, although with **different correspondences**.\n",
        "- If we don't remove training-only entities, it can lead to **label leakage** and **metric distortion**.\n",
        "\n",
        "#### 2. Filtering on `SrcEntity` present in the test set\n",
        "\n",
        "The second step keeps only the predictions where the `SrcEntity` is included in the test reference set.\n",
        "\n",
        "- This eliminates **non-evaluable false positives**, i.e., predicted mappings for source entities that do not appear in the test set and therefore have no ground-truth correspondences. Including such predictions **unfairly penalizes precision and F1-score**, even though they are technically not verifiable errors.\n",
        "\n",
        "- It focuses the evaluation on entities with defined ground-truth mappings, which is critical for computing metrics such as :\n",
        "\n",
        "$P_{\\text{test}} = \\frac{|\\mathcal{M}_{\\text{out}} \\cap \\mathcal{M}_{\\text{test}}|}{|\\mathcal{M}_{\\text{out}} \\setminus (\\mathcal{M}_{\\text{ref}} \\setminus \\mathcal{M}_{\\text{test}})|}$.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "eOQkhXEVOQDT"
      },
      "outputs": [],
      "source": [
        "def select_best_candidates_per_src_with_margin(df, score_margin=0.01):\n",
        "    \"\"\"\n",
        "    For each SrcEntity, retain all candidate mappings whose similarity score is\n",
        "    within 99% of the best score (default margin = 0.01).\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing columns ['SrcEntity', 'TgtEntity', 'Score'].\n",
        "        score_margin (float): Score margin. 0.01 means keep scores ≥ 99% of best score.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Filtered DataFrame with multiple high-quality candidates per SrcEntity.\n",
        "    \"\"\"\n",
        "    selected_rows = []\n",
        "\n",
        "    for src, group in df.groupby(\"SrcEntity\"):\n",
        "        group_sorted = group.sort_values(by=\"Score\", ascending=False)\n",
        "        best_score = group_sorted.iloc[0][\"Score\"]\n",
        "        threshold = best_score * (1 - score_margin)\n",
        "\n",
        "        # Keep all target entities with score >= threshold\n",
        "        close_matches = group_sorted[group_sorted[\"Score\"] >= threshold]\n",
        "        selected_rows.append(close_matches)\n",
        "\n",
        "    result_df = pd.concat(selected_rows).reset_index(drop=True)\n",
        "    print(f\"🏆 Selected candidates within {(1 - score_margin) * 100:.1f}% of best score per SrcEntity: {len(result_df)} rows\")\n",
        "    return result_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "-4deIPBfOQDU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "def evaluate_predictions(\n",
        "    pred_file, train_file, test_file,\n",
        "    threshold=0.0, margin_ratio=0.997\n",
        "):\n",
        "    \"\"\"\n",
        "    Evaluate predicted mappings by applying filtering, thresholding, top-1 selection with margin,\n",
        "    and computing precision, recall, and F1-score against the test set.\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 1: Load prediction, train, and test data\n",
        "    df = pd.read_csv(pred_file, sep='\\t')\n",
        "    train_df = pd.read_csv(train_file, sep='\\t')\n",
        "    test_df = pd.read_csv(test_file, sep='\\t')\n",
        "    print(f\"🔍 Initial file: {len(df)} rows\")\n",
        "\n",
        "    # Step 2: Remove entities that appear only in the training set\n",
        "    train_uris = set(train_df['SrcEntity']) | set(train_df['TgtEntity'])\n",
        "    test_uris = set(test_df['SrcEntity']) | set(test_df['TgtEntity'])\n",
        "    uris_to_exclude = train_uris - test_uris\n",
        "    df = df[~df['SrcEntity'].isin(uris_to_exclude) & ~df['TgtEntity'].isin(uris_to_exclude)]\n",
        "    print(f\"✅ After removing train-only URIs: {len(df)} rows\")\n",
        "\n",
        "    # Step 3: Keep only predictions where SrcEntity is part of the test set\n",
        "    test_src_entities = set(test_df['SrcEntity'])\n",
        "    df = df[df['SrcEntity'].isin(test_src_entities)]\n",
        "    print(f\"✅ After keeping only test SrcEntities: {len(df)} rows\")\n",
        "\n",
        "    # Step 4: Apply a minimum score threshold\n",
        "    df = df[df[\"Score\"] >= threshold]\n",
        "    print(f\"✅ After applying threshold ≥ {threshold}: {len(df)} rows\")\n",
        "\n",
        "    # Step 5: Save filtered predictions to file\n",
        "    output_file_all = pred_file.replace(\".tsv\", f\"_filtered.tsv\")\n",
        "    df.to_csv(output_file_all, sep='\\t', index=False)\n",
        "    print(f\"📁 Filtered predictions saved: {output_file_all}\")\n",
        "\n",
        "    # Step 6: Select best predictions per SrcEntity using a relaxed top-1 margin\n",
        "    df_top1 = select_best_candidates_per_src_with_margin(df, score_margin=0.0075)\n",
        "\n",
        "    # Step 7: Save the top-1 filtered predictions\n",
        "    output_file_top1 = pred_file.replace(\".tsv\", f\"_filtered_top1_th{threshold}.tsv\")\n",
        "    df_top1.to_csv(output_file_top1, sep='\\t', index=False)\n",
        "    print(f\"📁 Filtered Top-1 file saved: {output_file_top1}\")\n",
        "\n",
        "    # Step 8: Evaluate using gold standard test mappings\n",
        "    preds = EntityMapping.read_table_mappings(output_file_top1)   # Read predicted mappings\n",
        "    refs = ReferenceMapping.read_table_mappings(test_file)        # Read reference (gold standard) mappings\n",
        "\n",
        "    results = AlignmentEvaluator.f1(preds, refs)  # Compute precision, recall, and F1\n",
        "\n",
        "    # Optional: Count correct predictions (intersection)\n",
        "    preds2 = [p.to_tuple() for p in preds]\n",
        "    refs2 = [r.to_tuple() for r in refs]\n",
        "    correct = len(set(preds2).intersection(set(refs2)))\n",
        "\n",
        "    print(f\"🎯 Correct mappings (Top-1): {correct}\")\n",
        "    print(f\"📊 Evaluation (P / R / F1): {results}\")\n",
        "\n",
        "    return output_file_top1, results, correct\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVyzng3Pe_v0"
      },
      "source": [
        "# **Precision@k, Recall@k, F1@k**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "FstoSsHPe_v0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "def evaluate_topk(topk_file, train_file, test_file, k=1, threshold=0.0):\n",
        "    \"\"\"\n",
        "    Evaluate Top-K predictions using Precision, Recall, and F1-score,\n",
        "    after filtering out training-only URIs, keeping only test sources, and applying 1-1 constraint.\n",
        "\n",
        "    Args:\n",
        "        topk_file (str): Path to the top-k prediction file (TSV with SrcEntity, TgtEntity, Score)\n",
        "        train_file (str): Path to the training mappings file (TSV)\n",
        "        test_file (str): Path to the test mappings file (TSV)\n",
        "        k (int): Value of K for top-k evaluation\n",
        "        threshold (float): Minimum score to consider a prediction valid\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing Precision@K, Recall@K, and F1@K\n",
        "    \"\"\"\n",
        "\n",
        "    # === Step 1: Load input files ===\n",
        "    df = pd.read_csv(topk_file, sep='\\t', dtype=str)\n",
        "    train_df = pd.read_csv(train_file, sep='\\t', dtype=str)\n",
        "    test_df = pd.read_csv(test_file, sep='\\t', dtype=str)\n",
        "\n",
        "    # === Step 2: Remove URIs only present in the training set ===\n",
        "    train_uris = set(train_df['SrcEntity']) | set(train_df['TgtEntity'])\n",
        "    test_uris = set(test_df['SrcEntity']) | set(test_df['TgtEntity'])\n",
        "    uris_to_exclude = train_uris - test_uris\n",
        "    df = df[~(df['SrcEntity'].isin(uris_to_exclude) | df['TgtEntity'].isin(uris_to_exclude))].reset_index(drop=True)\n",
        "\n",
        "    # === Step 3: Keep only source entities from the test set ===\n",
        "    src_entities_test = set(test_df['SrcEntity'])\n",
        "    df = df[df['SrcEntity'].isin(src_entities_test)].reset_index(drop=True)\n",
        "\n",
        "    # === Step 4: Convert score column to float and sort ===\n",
        "    df['Score'] = df['Score'].apply(lambda x: float(x.strip(\"[]\")) if isinstance(x, str) else float(x))\n",
        "    df_sorted = df.sort_values(by='Score', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    # === Step 5: Apply 1-to-1 constraint (greedy strategy with optional threshold)\n",
        "    matched_sources = set()\n",
        "    matched_targets = set()\n",
        "    result = []\n",
        "\n",
        "    for _, row in df_sorted.iterrows():\n",
        "        src, tgt, score = row['SrcEntity'], row['TgtEntity'], row['Score']\n",
        "        if src not in matched_sources and tgt not in matched_targets and score >= threshold:\n",
        "            result.append((src, tgt, score))\n",
        "            matched_sources.add(src)\n",
        "            matched_targets.add(tgt)\n",
        "\n",
        "    # === Step 6: Create and save Top-K prediction dataframe\n",
        "    matching_results_df = pd.DataFrame(result, columns=['SrcEntity', 'TgtEntity', 'Score'])\n",
        "    output_file = topk_file.replace(\".tsv\", \"_predictions.tsv\")\n",
        "    matching_results_df.to_csv(output_file, sep='\\t', index=False)\n",
        "\n",
        "    # === Step 7: Build reference dictionary from test set\n",
        "    ref_dict = defaultdict(set)\n",
        "    for _, row in test_df.iterrows():\n",
        "        ref_dict[row['SrcEntity']].add(row['TgtEntity'])\n",
        "\n",
        "    # === Step 8: Select Top-K predictions for each source entity\n",
        "    matching_results_df['Score'] = matching_results_df['Score'].astype(float)\n",
        "    topk_df = matching_results_df.sort_values(by='Score', ascending=False).groupby('SrcEntity').head(k)\n",
        "\n",
        "    # === Step 9: Compute Precision@K, Recall@K, F1@K\n",
        "    total_tp = total_pred = total_ref = 0\n",
        "\n",
        "    for src, group in topk_df.groupby('SrcEntity'):\n",
        "        predicted = set(group['TgtEntity'])\n",
        "        true = ref_dict.get(src, set())\n",
        "        tp = len(predicted & true)\n",
        "        total_tp += tp\n",
        "        total_pred += len(predicted)\n",
        "        total_ref += len(true)\n",
        "\n",
        "    precision = total_tp / total_pred if total_pred else 0.0\n",
        "    recall = total_tp / total_ref if total_ref else 0.0\n",
        "    f1 = 2 * precision * recall / (precision + recall + 1e-8) if precision + recall > 0 else 0.0\n",
        "\n",
        "    # === Step 10: Print metrics\n",
        "\n",
        "    print(f\"📊 Precision@{k}:            {precision:.3f}\")\n",
        "    print(f\"📊 Recall@{k}:               {recall:.3f}\")\n",
        "    print(f\"📊 F1@{k}:                   {f1:.3f}\\n\")\n",
        "\n",
        "    return {\n",
        "        f'Precision@{k}': round(precision, 3),\n",
        "        f'Recall@{k}': round(recall, 3),\n",
        "        f'F1@{k}': round(f1, 3)\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HyWMsw1MVhz"
      },
      "source": [
        "# **Main Code**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC37FlwGDqGM"
      },
      "source": [
        "\n",
        "\n",
        "# Reading semantic node embeddings provided by the ENE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "FuEfSnw5mod0"
      },
      "outputs": [],
      "source": [
        "# Read the source embeddings from a CSV file into a pandas DataFrame\n",
        "df_embbedings_src = pd.read_csv(src_Emb, index_col=0)\n",
        "\n",
        "# Convert the DataFrame to a NumPy array, which will remove the index and store the data as a raw matrix\n",
        "numpy_array = df_embbedings_src.to_numpy()\n",
        "\n",
        "# Convert the NumPy array into a PyTorch FloatTensor, which is the format required for PyTorch operations\n",
        "x_src = torch.FloatTensor(numpy_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "STUwqMUXmlG2"
      },
      "outputs": [],
      "source": [
        "# Read the target embeddings from a CSV file into a pandas DataFrame\n",
        "df_embbedings_tgt = pd.read_csv(tgt_Emb, index_col=0)\n",
        "\n",
        "# Convert the DataFrame to a NumPy array, which removes the index and converts the data to a raw matrix\n",
        "numpy_array = df_embbedings_tgt.to_numpy()\n",
        "\n",
        "# Convert the NumPy array into a PyTorch FloatTensor, which is required for PyTorch operations\n",
        "x_tgt = torch.FloatTensor(numpy_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZIu9P08DqGN"
      },
      "source": [
        "# Reading adjacency Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "pH69Up40mycz"
      },
      "outputs": [],
      "source": [
        "# Read the source adjacency matrix from a CSV file into a pandas DataFrame\n",
        "df_ma1 = pd.read_csv(src_Adjacence, index_col=0)\n",
        "\n",
        "# Convert the DataFrame to a list of lists (Python native list format)\n",
        "ma1 = df_ma1.values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "hYCmAO5Ymzpl"
      },
      "outputs": [],
      "source": [
        "# Read the target adjacency matrix from a CSV file into a pandas DataFrame\n",
        "df_ma2 = pd.read_csv(tgt_Adjacence, index_col=0)\n",
        "\n",
        "# Convert the DataFrame to a list of lists (Python native list format)\n",
        "ma2 = df_ma2.values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSyksqh3TrU-"
      },
      "source": [
        "# Convert Adjacency matrix (in list format) to an undirected edge index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "uVt-Pce5m5ll"
      },
      "outputs": [],
      "source": [
        "# Convert the source adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n",
        "edge_src = adjacency_matrix_to_undirected_edge_index(ma1)\n",
        "\n",
        "# Convert the target adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n",
        "edge_tgt = adjacency_matrix_to_undirected_edge_index(ma2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9wMTRdqT4aY"
      },
      "source": [
        "# GIT Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "eqiEKCLSMVh3"
      },
      "outputs": [],
      "source": [
        "def train_model_gnn(model, x_src, edge_src, x_tgt, edge_tgt,\n",
        "                    tensor_term1, tensor_term2, tensor_score,\n",
        "                    learning_rate, weight_decay_value, num_epochs, print_interval=10):\n",
        "    \"\"\"\n",
        "    Trains a graph neural network (GNN) model using source and target embeddings and contrastive loss.\n",
        "\n",
        "    Args:\n",
        "        model: The GNN model to be trained.\n",
        "        x_src (torch.Tensor): Source node embeddings.\n",
        "        edge_src (torch.Tensor): Source graph edges.\n",
        "        x_tgt (torch.Tensor): Target node embeddings.\n",
        "        edge_tgt (torch.Tensor): Target graph edges.\n",
        "        tensor_term1 (torch.Tensor): Indices of the source nodes to be compared.\n",
        "        tensor_term2 (torch.Tensor): Indices of the target nodes to be compared.\n",
        "        tensor_score (torch.Tensor): Labels indicating if the pairs are matched (1) or not (0).\n",
        "        learning_rate (float): Learning rate for the optimizer.\n",
        "        weight_decay_value (float): Weight decay (L2 regularization) value for the optimizer.\n",
        "        num_epochs (int): Number of epochs for training.\n",
        "        print_interval (int): Interval at which training progress is printed (every `print_interval` epochs).\n",
        "\n",
        "    Returns:\n",
        "        model: The trained GNN model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 1: Set device (GPU or CPU) for computation\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Step 2: Move the model and all inputs to the selected device\n",
        "    model.to(device)\n",
        "    x_tgt = x_tgt.to(device)               # Target node embeddings\n",
        "    edge_tgt = edge_tgt.to(device)         # Target graph edges\n",
        "    x_src = x_src.to(device)               # Source node embeddings\n",
        "    edge_src = edge_src.to(device)         # Source graph edges\n",
        "    tensor_term1 = tensor_term1.to(device) # Indices for source nodes\n",
        "    tensor_term2 = tensor_term2.to(device) # Indices for target nodes\n",
        "    tensor_score = tensor_score.to(device) # Ground truth labels\n",
        "\n",
        "    # Step 3: Define optimizer with learning rate and regularization\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay_value)\n",
        "\n",
        "    # Step 4: Initialize list to store training losses\n",
        "    train_losses = []\n",
        "\n",
        "    # Record the start time of training\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Step 5: Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        # Zero out gradients from the previous iteration\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass: Compute embeddings for source and target graphs\n",
        "        out1 = model(x_src, edge_src)  # Updated source embeddings\n",
        "        out2 = model(x_tgt, edge_tgt)  # Updated target embeddings\n",
        "\n",
        "        # Extract specific rows of embeddings for terms being compared\n",
        "        src_embeddings = select_rows_by_index(out1, tensor_term1)\n",
        "        tgt_embeddings = select_rows_by_index(out2, tensor_term2)\n",
        "\n",
        "        # Compute contrastive loss based on the embeddings and ground truth labels\n",
        "        loss = contrastive_loss(src_embeddings, tgt_embeddings, tensor_score)\n",
        "\n",
        "        # Backward pass: Compute gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the model's parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Append the loss for this iteration to the list\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        # Print loss every `print_interval` epochs\n",
        "        if (epoch + 1) % print_interval == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item()}\")\n",
        "\n",
        "    # Step 6: Record end time of training\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Step 7: Plot the training loss over time\n",
        "    plt.semilogy(range(1, num_epochs + 1), train_losses, label=\"Training Loss\", marker='o')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Print the total training time\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training complete! Total training time: {training_time:.2f} seconds\")\n",
        "\n",
        "    # Step 8: Return the trained model\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "6_tzUG_emtBg"
      },
      "outputs": [],
      "source": [
        "# Initialize the GIT_mod model with the dimensionality of the target embeddings\n",
        "# The first argument is the dimensionality of the target node embeddings (x_tgt.shape[1])\n",
        "# The second argument (1) represents the number of RGIT layers in the model\n",
        "GIT_model = RGIT_mod(x_tgt.shape[1], 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "wVo-s7UQssSp"
      },
      "outputs": [],
      "source": [
        "# Reading the training pairs from a CSV file into a pandas DataFrame\n",
        "df_embbedings = pd.read_csv(train_file, index_col=0)\n",
        "\n",
        "# Extract the 'SrcEntity' and 'TgtEntity' columns as NumPy arrays and convert them to integers\n",
        "tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)  # Source entity indices\n",
        "tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)  # Target entity indices\n",
        "\n",
        "# Extract the 'Score' column as a NumPy array and convert it to floats\n",
        "tensor_score = df_embbedings['Score'].values.astype(float)  # Scores (labels) indicating if pairs match (1) or not (0)\n",
        "\n",
        "# Convert the NumPy arrays to PyTorch LongTensors (for indices) and FloatTensors (for scores)\n",
        "tensor_term1_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)  # Source entity tensor\n",
        "tensor_term2_o = torch.from_numpy(tensor_term2).type(torch.LongTensor)  # Target entity tensor\n",
        "tensor_score_o = torch.from_numpy(tensor_score).type(torch.FloatTensor)  # Score tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "agHlFNesMVh3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b6a91427-0354-4ed4-f2b4-c87bfbd13725"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/1000], Training Loss: 0.0021779483649879694\n",
            "Epoch [20/1000], Training Loss: 0.0015377459349110723\n",
            "Epoch [30/1000], Training Loss: 0.001387910102494061\n",
            "Epoch [40/1000], Training Loss: 0.0012420862913131714\n",
            "Epoch [50/1000], Training Loss: 0.0011588926427066326\n",
            "Epoch [60/1000], Training Loss: 0.0010933290468528867\n",
            "Epoch [70/1000], Training Loss: 0.0010340104345232248\n",
            "Epoch [80/1000], Training Loss: 0.0009862493025138974\n",
            "Epoch [90/1000], Training Loss: 0.0009424245799891651\n",
            "Epoch [100/1000], Training Loss: 0.0009045129991136491\n",
            "Epoch [110/1000], Training Loss: 0.0008708186214789748\n",
            "Epoch [120/1000], Training Loss: 0.0008403518586419523\n",
            "Epoch [130/1000], Training Loss: 0.0008131646318361163\n",
            "Epoch [140/1000], Training Loss: 0.0007885092636570334\n",
            "Epoch [150/1000], Training Loss: 0.0007662921561859548\n",
            "Epoch [160/1000], Training Loss: 0.0007462045177817345\n",
            "Epoch [170/1000], Training Loss: 0.000728106708265841\n",
            "Epoch [180/1000], Training Loss: 0.000711174972821027\n",
            "Epoch [190/1000], Training Loss: 0.0006957427831366658\n",
            "Epoch [200/1000], Training Loss: 0.0006816152017563581\n",
            "Epoch [210/1000], Training Loss: 0.0006686307024210691\n",
            "Epoch [220/1000], Training Loss: 0.0006565302610397339\n",
            "Epoch [230/1000], Training Loss: 0.0006454581161960959\n",
            "Epoch [240/1000], Training Loss: 0.0006351742777042091\n",
            "Epoch [250/1000], Training Loss: 0.000625570653937757\n",
            "Epoch [260/1000], Training Loss: 0.0006166317034512758\n",
            "Epoch [270/1000], Training Loss: 0.0006082014879211783\n",
            "Epoch [280/1000], Training Loss: 0.0006003589951433241\n",
            "Epoch [290/1000], Training Loss: 0.0005929607432335615\n",
            "Epoch [300/1000], Training Loss: 0.0005860388628207147\n",
            "Epoch [310/1000], Training Loss: 0.0005794864264316857\n",
            "Epoch [320/1000], Training Loss: 0.000573299708776176\n",
            "Epoch [330/1000], Training Loss: 0.0005675120046362281\n",
            "Epoch [340/1000], Training Loss: 0.0005620152223855257\n",
            "Epoch [350/1000], Training Loss: 0.0005568115157075226\n",
            "Epoch [360/1000], Training Loss: 0.0005519411060959101\n",
            "Epoch [370/1000], Training Loss: 0.0005472111515700817\n",
            "Epoch [380/1000], Training Loss: 0.000542700756341219\n",
            "Epoch [390/1000], Training Loss: 0.0005383659736253321\n",
            "Epoch [400/1000], Training Loss: 0.0005342027288861573\n",
            "Epoch [410/1000], Training Loss: 0.000530154153238982\n",
            "Epoch [420/1000], Training Loss: 0.0005262584309093654\n",
            "Epoch [430/1000], Training Loss: 0.0005224593915045261\n",
            "Epoch [440/1000], Training Loss: 0.0005187282804399729\n",
            "Epoch [450/1000], Training Loss: 0.0005150983924977481\n",
            "Epoch [460/1000], Training Loss: 0.0005115238018333912\n",
            "Epoch [470/1000], Training Loss: 0.0005080981645733118\n",
            "Epoch [480/1000], Training Loss: 0.0005047645536251366\n",
            "Epoch [490/1000], Training Loss: 0.0005015124916099012\n",
            "Epoch [500/1000], Training Loss: 0.0004983928520232439\n",
            "Epoch [510/1000], Training Loss: 0.0004953547031618655\n",
            "Epoch [520/1000], Training Loss: 0.000492385879624635\n",
            "Epoch [530/1000], Training Loss: 0.0004894951707683504\n",
            "Epoch [540/1000], Training Loss: 0.0004866814997512847\n",
            "Epoch [550/1000], Training Loss: 0.00048393543693237007\n",
            "Epoch [560/1000], Training Loss: 0.0004812964762095362\n",
            "Epoch [570/1000], Training Loss: 0.0004787706711795181\n",
            "Epoch [580/1000], Training Loss: 0.00047631649067625403\n",
            "Epoch [590/1000], Training Loss: 0.00047392011038027704\n",
            "Epoch [600/1000], Training Loss: 0.00047162623377516866\n",
            "Epoch [610/1000], Training Loss: 0.0004694033705163747\n",
            "Epoch [620/1000], Training Loss: 0.00046727521112188697\n",
            "Epoch [630/1000], Training Loss: 0.0004651677154470235\n",
            "Epoch [640/1000], Training Loss: 0.00046313097118400037\n",
            "Epoch [650/1000], Training Loss: 0.00046114189899526536\n",
            "Epoch [660/1000], Training Loss: 0.00045921094715595245\n",
            "Epoch [670/1000], Training Loss: 0.0004573650367092341\n",
            "Epoch [680/1000], Training Loss: 0.00045555265387520194\n",
            "Epoch [690/1000], Training Loss: 0.00045384225086309016\n",
            "Epoch [700/1000], Training Loss: 0.0004521961964201182\n",
            "Epoch [710/1000], Training Loss: 0.00045060348929837346\n",
            "Epoch [720/1000], Training Loss: 0.00044902515946887434\n",
            "Epoch [730/1000], Training Loss: 0.00044749240623787045\n",
            "Epoch [740/1000], Training Loss: 0.0004459489427972585\n",
            "Epoch [750/1000], Training Loss: 0.0004444322839844972\n",
            "Epoch [760/1000], Training Loss: 0.0004429259861353785\n",
            "Epoch [770/1000], Training Loss: 0.0004414439608808607\n",
            "Epoch [780/1000], Training Loss: 0.0004399626632221043\n",
            "Epoch [790/1000], Training Loss: 0.0004384923668112606\n",
            "Epoch [800/1000], Training Loss: 0.0004370029491838068\n",
            "Epoch [810/1000], Training Loss: 0.0004355275887064636\n",
            "Epoch [820/1000], Training Loss: 0.00043402836308814585\n",
            "Epoch [830/1000], Training Loss: 0.0004325290210545063\n",
            "Epoch [840/1000], Training Loss: 0.00043103500502184033\n",
            "Epoch [850/1000], Training Loss: 0.00042955021490342915\n",
            "Epoch [860/1000], Training Loss: 0.00042808454600162804\n",
            "Epoch [870/1000], Training Loss: 0.0004266178875695914\n",
            "Epoch [880/1000], Training Loss: 0.0004251800128258765\n",
            "Epoch [890/1000], Training Loss: 0.00042381251114420593\n",
            "Epoch [900/1000], Training Loss: 0.0004224535950925201\n",
            "Epoch [910/1000], Training Loss: 0.00042111697257496417\n",
            "Epoch [920/1000], Training Loss: 0.0004197923408355564\n",
            "Epoch [930/1000], Training Loss: 0.0004184542631264776\n",
            "Epoch [940/1000], Training Loss: 0.00041713283280842006\n",
            "Epoch [950/1000], Training Loss: 0.0004158326191827655\n",
            "Epoch [960/1000], Training Loss: 0.000414532667491585\n",
            "Epoch [970/1000], Training Loss: 0.0004132186295464635\n",
            "Epoch [980/1000], Training Loss: 0.0004119078803341836\n",
            "Epoch [990/1000], Training Loss: 0.00041058185161091387\n",
            "Epoch [1000/1000], Training Loss: 0.0004092734889127314\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete! Total training time: 1539.93 seconds\n"
          ]
        }
      ],
      "source": [
        "# Train the GNN model using the provided source and target graph embeddings, edges, and training data\n",
        "trained_model = train_model_gnn(\n",
        "    model=GIT_model,                # The GNN model to be trained (initialized earlier)\n",
        "    x_src=x_src,                    # Source node embeddings (tensor for source graph)\n",
        "    edge_src=edge_src,              # Source graph edges (undirected edge index for source graph)\n",
        "    x_tgt=x_tgt,                    # Target node embeddings (tensor for target graph)\n",
        "    edge_tgt=edge_tgt,              # Target graph edges (undirected edge index for target graph)\n",
        "    tensor_term1=tensor_term1_o,    # Indices of source entities for training\n",
        "    tensor_term2=tensor_term2_o,    # Indices of target entities for training\n",
        "    tensor_score=tensor_score_o,    # Scores (labels) indicating if pairs match (1) or not (0)\n",
        "    learning_rate=0.0001,            # Learning rate for the Adam optimizer\n",
        "    weight_decay_value=1e-4,        # Weight decay for L2 regularization to prevent overfitting\n",
        "    num_epochs=1000,                # Number of training epochs\n",
        "    print_interval=10               # Interval at which to print training progress (every 10 epochs)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYyhvjcTUaae"
      },
      "source": [
        "# GIT Application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "BZ_VqP6tq6iD"
      },
      "outputs": [],
      "source": [
        "# Determine if a GPU is available and move the computations to it; otherwise, use the CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Assuming the model has been trained and hyperparameters (x_src, edge_src, x_tgt, edge_tgt) are set\n",
        "\n",
        "# Move the trained GIT_model to the device (GPU or CPU)\n",
        "GIT_model.to(device)\n",
        "\n",
        "# Move the data tensors to the same device (GPU or CPU)\n",
        "x_tgt = x_tgt.to(device)         # Target node embeddings\n",
        "edge_tgt = edge_tgt.to(device)   # Target graph edges\n",
        "x_src = x_src.to(device)         # Source node embeddings\n",
        "edge_src = edge_src.to(device)   # Source graph edges\n",
        "\n",
        "# Set the model to evaluation mode; this disables dropout and batch normalization\n",
        "GIT_model.eval()\n",
        "\n",
        "# Pass the source and target embeddings through the trained GNN model to update the embeddings\n",
        "with torch.no_grad():  # Disable gradient computation (inference mode)\n",
        "    embeddings_tgt = GIT_model(x_tgt, edge_tgt)  # Get updated embeddings for the target graph\n",
        "    embeddings_src = GIT_model(x_src, edge_src)  # Get updated embeddings for the source graph\n",
        "\n",
        "# Detach the embeddings from the computation graph and move them back to the CPU\n",
        "# This step is useful if you need to use the embeddings for tasks outside PyTorch (e.g., saving to disk)\n",
        "embeddings_tgt = embeddings_tgt.detach().cpu()  # Target graph embeddings\n",
        "embeddings_src = embeddings_src.detach().cpu()  # Source graph embeddings\n",
        "\n",
        "# At this point, embeddings_tgt and embeddings_src contain the updated embeddings, ready for downstream tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og5fdoGJrTCG"
      },
      "source": [
        "# Selecting embedding pairs to train the Gated Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "J0nTwc-dnjLn"
      },
      "outputs": [],
      "source": [
        "# Read the training pairs from a CSV file into a pandas DataFrame\n",
        "df_embeddings = pd.read_csv(train_file, index_col=0)\n",
        "\n",
        "# Extract columns and convert to NumPy arrays\n",
        "tensor_term1 = df_embeddings['SrcEntity'].values.astype(int)  # Source entity indices\n",
        "tensor_term2 = df_embeddings['TgtEntity'].values.astype(int)  # Target entity indices\n",
        "tensor_score = df_embeddings['Score'].values.astype(float)  # Matching scores\n",
        "\n",
        "# Split data into training and validation sets\n",
        "tensor_term1_train, tensor_term1_val, tensor_term2_train, tensor_term2_val, tensor_score_train, tensor_score_val = train_test_split(\n",
        "    tensor_term1, tensor_term2, tensor_score, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Convert split data to PyTorch tensors\n",
        "tensor_term1_train = torch.from_numpy(tensor_term1_train).type(torch.LongTensor)\n",
        "tensor_term2_train = torch.from_numpy(tensor_term2_train).type(torch.LongTensor)\n",
        "tensor_score_train = torch.from_numpy(tensor_score_train).type(torch.FloatTensor)\n",
        "\n",
        "tensor_term1_val = torch.from_numpy(tensor_term1_val).type(torch.LongTensor)\n",
        "tensor_term2_val = torch.from_numpy(tensor_term2_val).type(torch.LongTensor)\n",
        "tensor_score_val = torch.from_numpy(tensor_score_val).type(torch.FloatTensor)\n",
        "\n",
        "# Move the embeddings back to the CPU if not already there\n",
        "x_tgt = x_tgt.cpu()  # Target node embeddings\n",
        "x_src = x_src.cpu()  # Source node embeddings\n",
        "\n",
        "# Select embeddings for the training set\n",
        "X1_train = select_rows_by_index(embeddings_src, tensor_term1_train)\n",
        "X2_train = select_rows_by_index(x_src, tensor_term1_train)\n",
        "X3_train = select_rows_by_index(embeddings_tgt, tensor_term2_train)\n",
        "X4_train = select_rows_by_index(x_tgt, tensor_term2_train)\n",
        "\n",
        "# Select embeddings for the validation set\n",
        "X1_val = select_rows_by_index(embeddings_src, tensor_term1_val)\n",
        "X2_val = select_rows_by_index(x_src, tensor_term1_val)\n",
        "X3_val = select_rows_by_index(embeddings_tgt, tensor_term2_val)\n",
        "X4_val = select_rows_by_index(x_tgt, tensor_term2_val)\n",
        "\n",
        "# Now you have:\n",
        "# - Training tensors: X1_train, X2_train, X3_train, X4_train, tensor_score_train\n",
        "# - Validation tensors: X1_val, X2_val, X3_val, X4_val, tensor_score_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNdCgaTMExPK"
      },
      "source": [
        "# Gated Network Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Gof1eIPIWSVU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def train_gated_combination_model(X1_t, X2_t, X3_t, X4_t, tensor_score_o,\n",
        "                                  X1_val, X2_val, X3_val, X4_val, tensor_score_val,\n",
        "                                  epochs=120, batch_size=32, learning_rate=0.001, weight_decay=1e-5):\n",
        "    \"\"\"\n",
        "    Trains the GatedCombination model with training and validation data, using ReduceLROnPlateau scheduler.\n",
        "    Also calculates and displays F1-score during training and validation.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create datasets and DataLoaders\n",
        "    train_dataset = TensorDataset(X1_t, X2_t, X3_t, X4_t, tensor_score_o)\n",
        "    val_dataset = TensorDataset(X1_val, X2_val, X3_val, X4_val, tensor_score_val)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = GatedCombination(X1_t.shape[1]).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # Use ReduceLROnPlateau scheduler\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_train_loss = 0.0\n",
        "        y_true_train, y_pred_train = [], []\n",
        "\n",
        "        for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in train_loader:\n",
        "            batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (\n",
        "                batch_X1.to(device),\n",
        "                batch_X2.to(device),\n",
        "                batch_X3.to(device),\n",
        "                batch_X4.to(device),\n",
        "                batch_y.to(device),\n",
        "            )\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = F.binary_cross_entropy(outputs, batch_y.unsqueeze(1).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # Store true labels and predictions for F1-score\n",
        "            y_true_train.extend(batch_y.cpu().numpy())\n",
        "            y_pred_train.extend((outputs > 0.5).float().cpu().numpy())\n",
        "\n",
        "        train_loss = total_train_loss / len(train_loader)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # Calculate F1-score for training\n",
        "        train_f1 = f1_score(y_true_train, y_pred_train)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        total_val_loss = 0.0\n",
        "        y_true_val, y_pred_val = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in val_loader:\n",
        "                batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (\n",
        "                    batch_X1.to(device),\n",
        "                    batch_X2.to(device),\n",
        "                    batch_X3.to(device),\n",
        "                    batch_X4.to(device),\n",
        "                    batch_y.to(device),\n",
        "                )\n",
        "                outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n",
        "\n",
        "                # Compute loss\n",
        "                val_loss = F.binary_cross_entropy(outputs, batch_y.unsqueeze(1).float())\n",
        "                total_val_loss += val_loss.item()\n",
        "\n",
        "                # Store true labels and predictions for F1-score\n",
        "                y_true_val.extend(batch_y.cpu().numpy())\n",
        "                y_pred_val.extend((outputs > 0.5).float().cpu().numpy())\n",
        "\n",
        "        avg_val_loss = total_val_loss / len(val_loader)\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        # Calculate F1-score for validation\n",
        "        val_f1 = f1_score(y_true_val, y_pred_val)\n",
        "\n",
        "        # Step the scheduler with validation loss\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        # Print training and validation metrics\n",
        "        print(f\"Epoch [{epoch + 1}/{epochs}] Training Loss: {train_loss:.4f}, F1 Score: {train_f1:.4f} | \"\n",
        "              f\"Validation Loss: {avg_val_loss:.4f}, F1 Score: {val_f1:.4f}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Plotting training and validation loss\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label=\"Training Loss\", marker='o')\n",
        "    plt.plot(val_losses, label=\"Validation Loss\", marker='x')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Training complete! Total time: {end_time - start_time:.2f} seconds\")\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "QrpFp6aDbtSW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "574abeb2-9cac-437c-9d29-8d9dcaeeafce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100] Training Loss: 0.4137, F1 Score: 0.0187 | Validation Loss: 0.0367, F1 Score: 0.0000\n",
            "Epoch [2/100] Training Loss: 0.0336, F1 Score: 0.0000 | Validation Loss: 0.0337, F1 Score: 0.0000\n",
            "Epoch [3/100] Training Loss: 0.0318, F1 Score: 0.0000 | Validation Loss: 0.0319, F1 Score: 0.0000\n",
            "Epoch [4/100] Training Loss: 0.0302, F1 Score: 0.0000 | Validation Loss: 0.0302, F1 Score: 0.0000\n",
            "Epoch [5/100] Training Loss: 0.0284, F1 Score: 0.0025 | Validation Loss: 0.0285, F1 Score: 0.0000\n",
            "Epoch [6/100] Training Loss: 0.0265, F1 Score: 0.0126 | Validation Loss: 0.0266, F1 Score: 0.0056\n",
            "Epoch [7/100] Training Loss: 0.0249, F1 Score: 0.0325 | Validation Loss: 0.0250, F1 Score: 0.0169\n",
            "Epoch [8/100] Training Loss: 0.0234, F1 Score: 0.0710 | Validation Loss: 0.0232, F1 Score: 0.1072\n",
            "Epoch [9/100] Training Loss: 0.0222, F1 Score: 0.1459 | Validation Loss: 0.0221, F1 Score: 0.1804\n",
            "Epoch [10/100] Training Loss: 0.0210, F1 Score: 0.2091 | Validation Loss: 0.0208, F1 Score: 0.2481\n",
            "Epoch [11/100] Training Loss: 0.0200, F1 Score: 0.2525 | Validation Loss: 0.0197, F1 Score: 0.3733\n",
            "Epoch [12/100] Training Loss: 0.0191, F1 Score: 0.3442 | Validation Loss: 0.0196, F1 Score: 0.2906\n",
            "Epoch [13/100] Training Loss: 0.0183, F1 Score: 0.3996 | Validation Loss: 0.0193, F1 Score: 0.4415\n",
            "Epoch [14/100] Training Loss: 0.0177, F1 Score: 0.4392 | Validation Loss: 0.0178, F1 Score: 0.5413\n",
            "Epoch [15/100] Training Loss: 0.0171, F1 Score: 0.4871 | Validation Loss: 0.0180, F1 Score: 0.4346\n",
            "Epoch [16/100] Training Loss: 0.0166, F1 Score: 0.5301 | Validation Loss: 0.0169, F1 Score: 0.5737\n",
            "Epoch [17/100] Training Loss: 0.0161, F1 Score: 0.5516 | Validation Loss: 0.0165, F1 Score: 0.5823\n",
            "Epoch [18/100] Training Loss: 0.0158, F1 Score: 0.5781 | Validation Loss: 0.0161, F1 Score: 0.6332\n",
            "Epoch [19/100] Training Loss: 0.0154, F1 Score: 0.5940 | Validation Loss: 0.0157, F1 Score: 0.5668\n",
            "Epoch [20/100] Training Loss: 0.0150, F1 Score: 0.6169 | Validation Loss: 0.0148, F1 Score: 0.6252\n",
            "Epoch [21/100] Training Loss: 0.0148, F1 Score: 0.6422 | Validation Loss: 0.0145, F1 Score: 0.6279\n",
            "Epoch [22/100] Training Loss: 0.0145, F1 Score: 0.6335 | Validation Loss: 0.0154, F1 Score: 0.5292\n",
            "Epoch [23/100] Training Loss: 0.0143, F1 Score: 0.6582 | Validation Loss: 0.0144, F1 Score: 0.7194\n",
            "Epoch [24/100] Training Loss: 0.0141, F1 Score: 0.6514 | Validation Loss: 0.0146, F1 Score: 0.6717\n",
            "Epoch [25/100] Training Loss: 0.0139, F1 Score: 0.6706 | Validation Loss: 0.0140, F1 Score: 0.6924\n",
            "Epoch [26/100] Training Loss: 0.0139, F1 Score: 0.6622 | Validation Loss: 0.0138, F1 Score: 0.7161\n",
            "Epoch [27/100] Training Loss: 0.0136, F1 Score: 0.6913 | Validation Loss: 0.0146, F1 Score: 0.7892\n",
            "Epoch [28/100] Training Loss: 0.0135, F1 Score: 0.6939 | Validation Loss: 0.0139, F1 Score: 0.7031\n",
            "Epoch [29/100] Training Loss: 0.0135, F1 Score: 0.6970 | Validation Loss: 0.0133, F1 Score: 0.7276\n",
            "Epoch [30/100] Training Loss: 0.0133, F1 Score: 0.6977 | Validation Loss: 0.0132, F1 Score: 0.6996\n",
            "Epoch [31/100] Training Loss: 0.0132, F1 Score: 0.7044 | Validation Loss: 0.0132, F1 Score: 0.6840\n",
            "Epoch [32/100] Training Loss: 0.0131, F1 Score: 0.7061 | Validation Loss: 0.0126, F1 Score: 0.7308\n",
            "Epoch [33/100] Training Loss: 0.0130, F1 Score: 0.7071 | Validation Loss: 0.0126, F1 Score: 0.7253\n",
            "Epoch [34/100] Training Loss: 0.0129, F1 Score: 0.7219 | Validation Loss: 0.0132, F1 Score: 0.7181\n",
            "Epoch [35/100] Training Loss: 0.0129, F1 Score: 0.7118 | Validation Loss: 0.0124, F1 Score: 0.7946\n",
            "Epoch [36/100] Training Loss: 0.0128, F1 Score: 0.7190 | Validation Loss: 0.0122, F1 Score: 0.7509\n",
            "Epoch [37/100] Training Loss: 0.0128, F1 Score: 0.7171 | Validation Loss: 0.0126, F1 Score: 0.7250\n",
            "Epoch [38/100] Training Loss: 0.0127, F1 Score: 0.7270 | Validation Loss: 0.0127, F1 Score: 0.7531\n",
            "Epoch [39/100] Training Loss: 0.0126, F1 Score: 0.7270 | Validation Loss: 0.0125, F1 Score: 0.7443\n",
            "Epoch [40/100] Training Loss: 0.0127, F1 Score: 0.7266 | Validation Loss: 0.0128, F1 Score: 0.7007\n",
            "Epoch [41/100] Training Loss: 0.0126, F1 Score: 0.7284 | Validation Loss: 0.0127, F1 Score: 0.7318\n",
            "Epoch [42/100] Training Loss: 0.0125, F1 Score: 0.7370 | Validation Loss: 0.0121, F1 Score: 0.7517\n",
            "Epoch [43/100] Training Loss: 0.0124, F1 Score: 0.7370 | Validation Loss: 0.0137, F1 Score: 0.6279\n",
            "Epoch [44/100] Training Loss: 0.0125, F1 Score: 0.7390 | Validation Loss: 0.0120, F1 Score: 0.7407\n",
            "Epoch [45/100] Training Loss: 0.0124, F1 Score: 0.7376 | Validation Loss: 0.0121, F1 Score: 0.7420\n",
            "Epoch [46/100] Training Loss: 0.0125, F1 Score: 0.7261 | Validation Loss: 0.0123, F1 Score: 0.7604\n",
            "Epoch [47/100] Training Loss: 0.0123, F1 Score: 0.7274 | Validation Loss: 0.0121, F1 Score: 0.7905\n",
            "Epoch [48/100] Training Loss: 0.0123, F1 Score: 0.7400 | Validation Loss: 0.0117, F1 Score: 0.7768\n",
            "Epoch [49/100] Training Loss: 0.0123, F1 Score: 0.7394 | Validation Loss: 0.0125, F1 Score: 0.7858\n",
            "Epoch [50/100] Training Loss: 0.0123, F1 Score: 0.7349 | Validation Loss: 0.0125, F1 Score: 0.7230\n",
            "Epoch [51/100] Training Loss: 0.0123, F1 Score: 0.7319 | Validation Loss: 0.0123, F1 Score: 0.7761\n",
            "Epoch [52/100] Training Loss: 0.0123, F1 Score: 0.7425 | Validation Loss: 0.0124, F1 Score: 0.7171\n",
            "Epoch [53/100] Training Loss: 0.0123, F1 Score: 0.7384 | Validation Loss: 0.0122, F1 Score: 0.7844\n",
            "Epoch [54/100] Training Loss: 0.0122, F1 Score: 0.7411 | Validation Loss: 0.0123, F1 Score: 0.7184\n",
            "Epoch [55/100] Training Loss: 0.0122, F1 Score: 0.7445 | Validation Loss: 0.0117, F1 Score: 0.7795\n",
            "Epoch [56/100] Training Loss: 0.0123, F1 Score: 0.7358 | Validation Loss: 0.0119, F1 Score: 0.7548\n",
            "Epoch [57/100] Training Loss: 0.0123, F1 Score: 0.7420 | Validation Loss: 0.0124, F1 Score: 0.7797\n",
            "Epoch [58/100] Training Loss: 0.0122, F1 Score: 0.7461 | Validation Loss: 0.0131, F1 Score: 0.8138\n",
            "Epoch [59/100] Training Loss: 0.0123, F1 Score: 0.7504 | Validation Loss: 0.0120, F1 Score: 0.7509\n",
            "Epoch [60/100] Training Loss: 0.0121, F1 Score: 0.7424 | Validation Loss: 0.0127, F1 Score: 0.6937\n",
            "Epoch [61/100] Training Loss: 0.0121, F1 Score: 0.7463 | Validation Loss: 0.0122, F1 Score: 0.7885\n",
            "Epoch [62/100] Training Loss: 0.0121, F1 Score: 0.7486 | Validation Loss: 0.0122, F1 Score: 0.7919\n",
            "Epoch [63/100] Training Loss: 0.0121, F1 Score: 0.7473 | Validation Loss: 0.0125, F1 Score: 0.7055\n",
            "Epoch [64/100] Training Loss: 0.0122, F1 Score: 0.7398 | Validation Loss: 0.0124, F1 Score: 0.7101\n",
            "Epoch [65/100] Training Loss: 0.0121, F1 Score: 0.7461 | Validation Loss: 0.0123, F1 Score: 0.7078\n",
            "Epoch [66/100] Training Loss: 0.0122, F1 Score: 0.7408 | Validation Loss: 0.0119, F1 Score: 0.7443\n",
            "Epoch [67/100] Training Loss: 0.0111, F1 Score: 0.7747 | Validation Loss: 0.0112, F1 Score: 0.7782\n",
            "Epoch [68/100] Training Loss: 0.0111, F1 Score: 0.7717 | Validation Loss: 0.0111, F1 Score: 0.7892\n",
            "Epoch [69/100] Training Loss: 0.0111, F1 Score: 0.7738 | Validation Loss: 0.0112, F1 Score: 0.7719\n",
            "Epoch [70/100] Training Loss: 0.0111, F1 Score: 0.7644 | Validation Loss: 0.0112, F1 Score: 0.7810\n",
            "Epoch [71/100] Training Loss: 0.0112, F1 Score: 0.7732 | Validation Loss: 0.0112, F1 Score: 0.7933\n",
            "Epoch [72/100] Training Loss: 0.0111, F1 Score: 0.7738 | Validation Loss: 0.0111, F1 Score: 0.7905\n",
            "Epoch [73/100] Training Loss: 0.0111, F1 Score: 0.7648 | Validation Loss: 0.0111, F1 Score: 0.7851\n",
            "Epoch [74/100] Training Loss: 0.0111, F1 Score: 0.7651 | Validation Loss: 0.0113, F1 Score: 0.7726\n",
            "Epoch [75/100] Training Loss: 0.0111, F1 Score: 0.7704 | Validation Loss: 0.0112, F1 Score: 0.7726\n",
            "Epoch [76/100] Training Loss: 0.0112, F1 Score: 0.7691 | Validation Loss: 0.0112, F1 Score: 0.7698\n",
            "Epoch [77/100] Training Loss: 0.0111, F1 Score: 0.7706 | Validation Loss: 0.0112, F1 Score: 0.7872\n",
            "Epoch [78/100] Training Loss: 0.0112, F1 Score: 0.7766 | Validation Loss: 0.0112, F1 Score: 0.7768\n",
            "Epoch [79/100] Training Loss: 0.0111, F1 Score: 0.7738 | Validation Loss: 0.0113, F1 Score: 0.7676\n",
            "Epoch [80/100] Training Loss: 0.0111, F1 Score: 0.7653 | Validation Loss: 0.0111, F1 Score: 0.7892\n",
            "Epoch [81/100] Training Loss: 0.0111, F1 Score: 0.7685 | Validation Loss: 0.0112, F1 Score: 0.7676\n",
            "Epoch [82/100] Training Loss: 0.0111, F1 Score: 0.7702 | Validation Loss: 0.0111, F1 Score: 0.7761\n",
            "Epoch [83/100] Training Loss: 0.0111, F1 Score: 0.7657 | Validation Loss: 0.0111, F1 Score: 0.7851\n",
            "Epoch [84/100] Training Loss: 0.0109, F1 Score: 0.7757 | Validation Loss: 0.0111, F1 Score: 0.7810\n",
            "Epoch [85/100] Training Loss: 0.0109, F1 Score: 0.7729 | Validation Loss: 0.0111, F1 Score: 0.7851\n",
            "Epoch [86/100] Training Loss: 0.0109, F1 Score: 0.7729 | Validation Loss: 0.0111, F1 Score: 0.7892\n",
            "Epoch [87/100] Training Loss: 0.0109, F1 Score: 0.7729 | Validation Loss: 0.0111, F1 Score: 0.7872\n",
            "Epoch [88/100] Training Loss: 0.0109, F1 Score: 0.7710 | Validation Loss: 0.0111, F1 Score: 0.7851\n",
            "Epoch [89/100] Training Loss: 0.0109, F1 Score: 0.7729 | Validation Loss: 0.0111, F1 Score: 0.7872\n",
            "Epoch [90/100] Training Loss: 0.0109, F1 Score: 0.7710 | Validation Loss: 0.0111, F1 Score: 0.7872\n",
            "Epoch [91/100] Training Loss: 0.0109, F1 Score: 0.7738 | Validation Loss: 0.0111, F1 Score: 0.7864\n",
            "Epoch [92/100] Training Loss: 0.0109, F1 Score: 0.7701 | Validation Loss: 0.0111, F1 Score: 0.7872\n",
            "Epoch [93/100] Training Loss: 0.0109, F1 Score: 0.7719 | Validation Loss: 0.0111, F1 Score: 0.7872\n",
            "Epoch [94/100] Training Loss: 0.0109, F1 Score: 0.7719 | Validation Loss: 0.0111, F1 Score: 0.7892\n",
            "Epoch [95/100] Training Loss: 0.0109, F1 Score: 0.7729 | Validation Loss: 0.0111, F1 Score: 0.7872\n",
            "Epoch [96/100] Training Loss: 0.0109, F1 Score: 0.7701 | Validation Loss: 0.0111, F1 Score: 0.7892\n",
            "Epoch [97/100] Training Loss: 0.0109, F1 Score: 0.7729 | Validation Loss: 0.0111, F1 Score: 0.7768\n",
            "Epoch [98/100] Training Loss: 0.0109, F1 Score: 0.7710 | Validation Loss: 0.0111, F1 Score: 0.7810\n",
            "Epoch [99/100] Training Loss: 0.0109, F1 Score: 0.7710 | Validation Loss: 0.0111, F1 Score: 0.7831\n",
            "Epoch [100/100] Training Loss: 0.0109, F1 Score: 0.7710 | Validation Loss: 0.0111, F1 Score: 0.7831\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete! Total time: 1355.81 seconds\n"
          ]
        }
      ],
      "source": [
        "# Train the GatedCombination model using training and validation data\n",
        "trained_model = train_gated_combination_model(\n",
        "    X1_train,          # Updated source embeddings (after applying the GNN model)\n",
        "    X2_train,          # Original source embeddings (before applying the GNN model)\n",
        "    X3_train,          # Updated target embeddings (after applying the GNN model)\n",
        "    X4_train,          # Original target embeddings (before applying the GNN model)\n",
        "    tensor_score_train, # Ground truth labels for the training set (1 for matched pairs, 0 for unmatched pairs)\n",
        "\n",
        "    X1_val,            # Updated source embeddings for the validation set\n",
        "    X2_val,            # Original source embeddings for the validation set\n",
        "    X3_val,            # Updated target embeddings for the validation set\n",
        "    X4_val,            # Original target embeddings for the validation set\n",
        "    tensor_score_val,  # Ground truth labels for the validation set (1 for matched pairs, 0 for unmatched pairs)\n",
        "\n",
        "    epochs=100,        # Number of epochs (iterations over the entire training dataset)\n",
        "    batch_size=32,     # Number of training samples processed in one forward/backward pass\n",
        "    learning_rate=0.001, # Learning rate for the optimizer (controls step size during optimization)\n",
        "    weight_decay=1e-4 # Weight decay (L2 regularization) to prevent overfitting\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAmLuMtGW9c2"
      },
      "source": [
        "# **Second Round Modifications**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVDqN5AxFu9m"
      },
      "source": [
        "# **Generate Embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ITZZcElm8qRN"
      },
      "outputs": [],
      "source": [
        "# Build an indexed dictionary for the source ontology classes\n",
        "# src_class is the file path to the JSON file containing the source ontology classes\n",
        "indexed_dict_src = build_indexed_dict(src_class)\n",
        "\n",
        "# Build an indexed dictionary for the target ontology classes\n",
        "# tgt_class is the file path to the JSON file containing the target ontology classes\n",
        "indexed_dict_tgt = build_indexed_dict(tgt_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "GbSbmPlRDOs3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb69631e-58ac-4557-ec41-0dd88d0585c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Gated embeddings saved:\n",
            "- Source: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_BioBERT.tsv\n",
            "- Target: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_BioBERT.tsv\n",
            "⏱️ Execution time: 38.04 seconds\n"
          ]
        }
      ],
      "source": [
        "# Define output file paths for final embeddings of source and target ontologies\n",
        "output_file_src = f\"{data_dir}/{src_ent}_final_embeddings_BioBERT.tsv\"\n",
        "output_file_tgt = f\"{data_dir}/{tgt_ent}_final_embeddings_BioBERT.tsv\"\n",
        "\n",
        "# Save the final gated embeddings for all concepts in source and target ontologies\n",
        "save_gated_embeddings(\n",
        "    gated_model=trained_model,          # The trained GatedCombination model\n",
        "    embeddings_src=embeddings_src,      # GNN-transformed embeddings for source entities\n",
        "    x_src=x_src,                        # Initial semantic embeddings for source entities\n",
        "    embeddings_tgt=embeddings_tgt,      # GNN-transformed embeddings for target entities\n",
        "    x_tgt=x_tgt,                        # Initial semantic embeddings for target entities\n",
        "    indexed_dict_src=indexed_dict_src,  # Index-to-URI mapping for source ontology\n",
        "    indexed_dict_tgt=indexed_dict_tgt,  # Index-to-URI mapping for target ontology\n",
        "    output_file_src=output_file_src,    # Destination file path for source embeddings\n",
        "    output_file_tgt=output_file_tgt     # Destination file path for target embeddings\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIDvbZj2GIGo"
      },
      "source": [
        "# **Filter No Used Concepts**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "6Gl_wUG9KADo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "729cc1b8-07ba-43d3-9ea3-bddd6cf3085f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Initial source file: 23107 rows\n",
            "🔍 Initial target file: 20498 rows\n",
            "✅ Source after removing ignored classes: 11407 rows\n",
            "✅ Target after removing ignored classes: 14207 rows\n",
            "📁 Cleaned source file saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_BioBERT_cleaned.tsv\n",
            "📁 Cleaned target file saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_BioBERT_cleaned.tsv\n"
          ]
        }
      ],
      "source": [
        "# Call the function to filter out ignored concepts (e.g., owl:Thing, deprecated, etc.)\n",
        "# from the source and target ontology embeddings.\n",
        "\n",
        "# Input:\n",
        "# - src_emb_path: Path to the TSV file containing embeddings for the source ontology\n",
        "# - tgt_emb_path: Path to the TSV file containing embeddings for the target ontology\n",
        "# - src_onto / tgt_onto: DeepOnto ontology objects used to identify ignored concepts\n",
        "\n",
        "# Output:\n",
        "# - src_file: Path to the cleaned source embeddings (with ignored concepts removed)\n",
        "# - tgt_file: Path to the cleaned target embeddings (with ignored concepts removed)\n",
        "\n",
        "src_file, tgt_file = filter_ignored_class(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_BioBERT.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_BioBERT.tsv\",\n",
        "    src_onto=src_onto,\n",
        "    tgt_onto=tgt_onto\n",
        "\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpUklR4xnVMH"
      },
      "source": [
        "# **Mappings Generation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP5o60scKn2e"
      },
      "source": [
        "# **Using faiss l2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "xOSRYREwerBi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9770e5d-3b66-446a-e1d4-ab52ec9427ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-10 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_BioBERT.tsv\n",
            "⏱️ Execution time: 13.71 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using l2 distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the l2 distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_l2(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_BioBERT_cleaned.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_BioBERT_cleaned.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2_BioBERT.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD-mvVjaerBh"
      },
      "source": [
        "# **Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Global Metrics: Precision, Recall and F1 score**"
      ],
      "metadata": {
        "id": "r8GRfT_pR1kD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "9WZKJM46erBi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70b2d74e-5c74-44ac-ab3b-57c017a914b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 93041 rows\n",
            "✅ After keeping only test SrcEntities: 22220 rows\n",
            "✅ After applying threshold ≥ 0.0: 22220 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_BioBERT_filtered.tsv\n",
            "🏆 Selected candidates within 99.2% of best score per SrcEntity: 2565 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_BioBERT_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1618\n",
            "📊 Evaluation (P / R / F1): {'P': 0.631, 'R': 0.608, 'F1': 0.619}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = evaluate_predictions(\n",
        "    pred_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2_BioBERT.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "KBAlDrOpe_vz"
      ],
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}