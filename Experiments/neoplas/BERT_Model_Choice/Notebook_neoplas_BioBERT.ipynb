{"cells":[{"cell_type":"markdown","metadata":{"id":"MkAX88H3RNRW"},"source":["# **Package Installation**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":213031,"status":"ok","timestamp":1732228041247,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"SlL2v0xgmFJ-","outputId":"1f35a75e-1633-4535-f21a-56577d1ebdf7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==2.0.0\n","  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.16.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n","  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n","  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n","  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n","  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n","  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n","  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.0.0 (from torch==2.0.0)\n","  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (75.1.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.45.0)\n","Collecting cmake (from triton==2.0.0->torch==2.0.0)\n","  Downloading cmake-3.31.0.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n","Collecting lit (from triton==2.0.0->torch==2.0.0)\n","  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n","Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m530.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m559.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cmake-3.31.0.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.8/27.8 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, cmake, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.1+cpu\n","    Uninstalling torch-2.5.1+cpu:\n","      Successfully uninstalled torch-2.5.1+cpu\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.5.1+cpu requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\n","torchvision 0.20.1+cpu requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed cmake-3.31.0.1 lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 triton-2.0.0\n","Collecting torch-geometric==2.4.0\n","  Downloading torch_geometric-2.4.0-py3-none-any.whl.metadata (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (4.66.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (3.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (2.32.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (3.2.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.5.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric==2.4.0) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (2024.8.30)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.4.0) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.4.0) (3.5.0)\n","Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-geometric\n","Successfully installed torch-geometric-2.4.0\n","Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_scatter-2.1.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (494 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_sparse-0.6.18%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-cluster\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_cluster-1.6.3%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (751 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.3/751.3 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-spline-conv\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (208 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n","Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n","Installing collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster\n","Successfully installed torch-cluster-1.6.3+pt20cpu torch-scatter-2.1.2+pt20cpu torch-sparse-0.6.18+pt20cpu torch-spline-conv-1.2.2+pt20cpu\n","Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.5.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.9/208.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.4/319.4 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting deeponto\n","  Downloading deeponto-0.9.2-py3-none-any.whl.metadata (15 kB)\n","Collecting JPype1 (from deeponto)\n","  Downloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting yacs (from deeponto)\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deeponto) (2.0.0)\n","Collecting anytree (from deeponto)\n","  Downloading anytree-2.12.1-py3-none-any.whl.metadata (8.1 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from deeponto) (8.1.7)\n","Collecting dill (from deeponto)\n","  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from deeponto) (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deeponto) (1.26.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deeponto) (1.5.2)\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (from deeponto) (4.46.2)\n","Collecting datasets (from deeponto)\n","  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.7.5)\n","Collecting pprintpp (from deeponto)\n","  Downloading pprintpp-0.4.0-py2.py3-none-any.whl.metadata (7.9 kB)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.4.2)\n","Collecting lxml (from deeponto)\n","  Downloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n","Collecting textdistance (from deeponto)\n","  Downloading textdistance-4.6.3-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from deeponto) (7.7.1)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from deeponto) (5.5.6)\n","Collecting enlighten (from deeponto)\n","  Downloading enlighten-1.12.4-py2.py3-none-any.whl.metadata (18 kB)\n","Collecting rdflib (from deeponto)\n","  Downloading rdflib-7.1.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.9.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anytree->deeponto) (1.16.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (18.0.0)\n","Collecting dill (from deeponto)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (4.66.6)\n","Collecting xxhash (from datasets->deeponto)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets->deeponto)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->deeponto)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (3.11.7)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (0.26.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (6.0.2)\n","Collecting blessed>=1.17.7 (from enlighten->deeponto)\n","  Downloading blessed-1.20.0-py2.py3-none-any.whl.metadata (13 kB)\n","Collecting prefixed>=0.3.2 (from enlighten->deeponto)\n","  Downloading prefixed-0.9.0-py2.py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (0.2.0)\n","Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (7.34.0)\n","Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (5.7.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (6.1.12)\n","Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (6.3.3)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->deeponto) (3.6.10)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->deeponto) (3.0.13)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->deeponto) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->deeponto) (2024.11.6)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2024.2)\n","Collecting isodate<1.0.0,>=0.7.2 (from rdflib->deeponto)\n","  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib->deeponto) (3.2.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deeponto) (1.13.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deeponto) (3.5.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (0.13.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.9.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.1.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (75.1.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.4.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (1.13.1)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (2.0.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->deeponto) (0.45.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deeponto) (3.31.0.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deeponto) (18.1.8)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (0.20.3)\n","Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (1.1.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->transformers[torch]->deeponto) (5.9.5)\n","Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.7->enlighten->deeponto) (0.2.13)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.3.1)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (5.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (0.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.18.0)\n","Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->deeponto)\n","  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (5.1.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (3.0.48)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (2.18.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (4.9.0)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.2.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (2024.8.30)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->deeponto) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->deeponto) (0.1.5)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (0.20.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (7.0.5)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.5.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy->deeponto) (3.0.2)\n","Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->deeponto) (5.7.2)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->deeponto) (24.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deeponto) (1.3.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->deeponto) (0.8.4)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel->deeponto) (4.3.6)\n","Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.2.1)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (23.1.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (5.10.4)\n","Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (7.16.4)\n","Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.6.0)\n","Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.3)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.18.1)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.21.0)\n","Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.1.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel->deeponto) (0.7.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (3.0.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->deeponto) (1.14.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (0.1.2)\n","Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.2.4)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.12.3)\n","Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.2.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.7.1)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.3.0)\n","Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.0.2)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.10.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.5.1)\n","Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.4.0)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.20.0)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.23.0)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (21.2.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.5.1)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.21.0)\n","Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.24.0)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.17.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.6)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.22)\n","Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.7.1)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.2.2)\n","Downloading deeponto-0.9.2-py3-none-any.whl (89.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading anytree-2.12.1-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading enlighten-1.12.4-py2.py3-none-any.whl (41 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.8/493.8 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n","Downloading rdflib-7.1.1-py3-none-any.whl (562 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m562.4/562.4 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading textdistance-4.6.3-py3-none-any.whl (31 kB)\n","Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n","Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading prefixed-0.9.0-py2.py3-none-any.whl (13 kB)\n","Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: prefixed, pprintpp, yacs, xxhash, textdistance, lxml, JPype1, jedi, isodate, fsspec, dill, blessed, anytree, rdflib, multiprocess, enlighten, datasets, deeponto\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","Successfully installed JPype1-1.5.1 anytree-2.12.1 blessed-1.20.0 datasets-3.1.0 deeponto-0.9.2 dill-0.3.8 enlighten-1.12.4 fsspec-2024.9.0 isodate-0.7.2 jedi-0.19.2 lxml-5.3.0 multiprocess-0.70.16 pprintpp-0.4.0 prefixed-0.9.0 rdflib-7.1.1 textdistance-4.6.3 xxhash-3.5.0 yacs-0.1.8\n","/bin/bash: line 1: username: No such file or directory\n"]}],"source":["# We assume that PyTorch is already installed in the environment.\n","# If not, this command installs it.\n","!pip install torch==2.0.0\n","\n","# Install PyTorch Geometric, a library for creating graph neural networks using PyTorch.\n","!pip install torch-geometric==2.4.0\n","\n","# Import PyTorch to access its functionalities.\n","import torch\n","\n","# Install additional PyTorch Geometric dependencies for graph processing (scatter, sparse, cluster, spline-conv).\n","# These packages enable operations like sparse tensors and convolutions on graphs.\n","!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","\n","# Reinstall PyTorch Geometric to ensure all dependencies are correctly loaded.\n","!pip install torch-geometric\n","\n","# Retrieve the installed version of PyTorch to ensure compatibility with other packages.\n","torchversion = torch.__version__\n","\n","# Install the latest version of PyTorch Geometric directly from the GitHub repository.\n","# This allows access to the most recent updates and features for graph-based neural networks.\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","\n","# Install DeepOnto, a package specifically designed for ontology matching, particularly useful in biomedical applications.\n","!pip install deeponto\n","\n","# Install a custom version of DeepOnto from a GitHub repository.\n","# The '<username>' part should be replaced with the actual GitHub username of the repository maintainer.\n","!pip install git+https://github.com/<username>/deeponto.git\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":66392,"status":"ok","timestamp":1732228107633,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"HPAlAgjLMVhw","outputId":"e9999e01-3ba3-44d5-b19a-f3bcf4f9c645"},"outputs":[{"output_type":"stream","name":"stdout","text":["Please enter the maximum memory located to JVM [8g]: 8g\n","\n"]}],"source":["# Import pandas for data manipulation and analysis, such as loading, processing, and saving tabular data.\n","import pandas as pd\n","\n","# Import pickle for saving and loading serialized objects (e.g., trained models or preprocessed data).\n","import pickle\n","\n","# Import function to convert a directed graph to an undirected one, useful for certain graph algorithms.\n","from torch_geometric.utils import to_undirected\n","\n","# Import optimizer module from PyTorch for training models using gradient-based optimization techniques.\n","import torch.optim as optim\n","\n","# Import PyTorch's modules for defining neural network architectures and operations:\n","from torch.nn import (\n","    Linear,       # For linear transformations (dense layers).\n","    Sequential,   # For stacking layers sequentially.\n","    BatchNorm1d,  # For normalizing input within mini-batches.\n","    PReLU,        # Parametric ReLU activation function.\n","    Dropout       # For regularization by randomly dropping connections during training.\n",")\n","\n","# Import functional API from PyTorch for operations like activations and loss functions.\n","import torch.nn.functional as F\n","\n","# Import Matplotlib for visualizations, such as plotting training loss curves.\n","import matplotlib.pyplot as plt\n","\n","# Import PyTorch Geometric's graph convolutional layers:\n","from torch_geometric.nn import GCNConv, GINConv\n","\n","# Import pooling operations for aggregating node embeddings to graph-level representations:\n","from torch_geometric.nn import global_mean_pool, global_add_pool\n","\n","# Import NumPy for numerical operations, such as working with arrays and matrices.\n","import numpy as np\n","\n","# Import time module for measuring execution time of code blocks.\n","import time\n","\n","# Import typing module for specifying types in function arguments and return values.\n","from typing import Optional, Tuple, Union, Callable\n","\n","# Import PyTorch's DataLoader and TensorDataset for handling data batching and loading during training.\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","# Import PyTorch's Parameter class for defining learnable parameters in custom models.\n","from torch.nn import Parameter\n","\n","# Import math module for performing mathematical computations.\n","import math\n","\n","# Import Tensor type from PyTorch for defining and manipulating tensors.\n","from torch import Tensor\n","\n","# Import PyTorch's nn module for defining and building neural network architectures.\n","import torch.nn as nn\n","\n","# Import initialization utilities from PyTorch Geometric for resetting weights and biases in layers.\n","from torch_geometric.nn.inits import reset\n","\n","# Import the base class for defining message-passing layers in graph neural networks (GNNs).\n","from torch_geometric.nn.conv import MessagePassing\n","\n","# Import linear transformation utilities for creating dense representations in graph models.\n","from torch_geometric.nn.dense.linear import Linear\n","\n","# Import typing utilities for defining adjacency matrices and tensor types specific to PyTorch Geometric.\n","from torch_geometric.typing import Adj, OptTensor, PairTensor, SparseTensor\n","\n","# Import softmax function for normalizing attention scores in GNNs.\n","from torch_geometric.utils import softmax\n","\n","# Import initialization utilities for weight initialization (e.g., Glorot initialization).\n","from torch_geometric.nn.inits import glorot, zeros\n","\n","# Import F1 score metric from scikit-learn for evaluating model performance in binary/multi-class tasks.\n","from sklearn.metrics import f1_score\n","\n","# Import JSON module for reading and writing JSON files, useful for storing configuration or ontology data.\n","import json\n","\n","# Import Ontology class from DeepOnto for representing and manipulating ontologies in the pipeline.\n","from deeponto.onto import Ontology\n","\n","# Import tools from DeepOnto for handling Ontology Alignment Evaluation Initiative (OAEI) tasks.\n","from deeponto.align.oaei import *\n","\n","# Import evaluation tools from DeepOnto for assessing alignment results using metrics like precision, recall, and F1.\n","from deeponto.align.evaluation import AlignmentEvaluator\n","\n","# Import mapping utilities from DeepOnto for working with reference mappings and entity pairs.\n","from deeponto.align.mapping import ReferenceMapping, EntityMapping\n","\n","# Import utility function for reading tables (e.g., TSV, CSV) from DeepOnto.\n","from deeponto.utils import read_table\n","\n","# Importing the train_test_split function from sklearn's model_selection module.\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"-abbBHOoRdWl"},"source":["# **Paths Definition**"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33471,"status":"ok","timestamp":1732228141096,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"AVgl_Bb42naS","outputId":"d3447fa9-1ee5-4fc7-e93d-413a211758f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# Importing the 'drive' module from Google Colab to interact with Google Drive\n","from google.colab import drive\n","\n","# Mount the user's Google Drive to the Colab environment\n","# After running this, a link will appear to authorize access, and Google Drive will be mounted at '/content/gdrive'\n","drive.mount('/content/gdrive')\n"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":271,"status":"ok","timestamp":1732230490673,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"36ttssQ3W7cx"},"outputs":[],"source":["# Define the source ontology name\n","src_ent = \"snomed.neoplas\"\n","\n","# Define the target ontology name\n","tgt_ent = \"ncit.neoplas\"\n","\n","# Define the task name for this ontology matching process\n","task = \"neoplas\"\n","\n","# Define the weight for the training data\n","# This weight is likely used to balance the training process, giving more emphasis to certain examples.\n","# For instance, a weight of 10.0 could be applied to penalize errors in certain types of predictions more heavily.\n","weight_train= 50.0\n","\n","# Define the similarity threshold for validating matches\n","thres = 0.50"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":847,"status":"ok","timestamp":1732232111251,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"SJpvkdwVSQye"},"outputs":[],"source":["dir = f\"/content/gdrive/My Drive/BioGITOM-VLDB/Experiments/{task}\"\n","\n","dataset=\"/content/gdrive/My Drive/BioGITOM-VLDB/\"\n","\n","# Define the directory for the dataset containing source and target ontologies\n","dataset_dir = f\"{dataset}/Datasets/{task}\"\n","\n","# Define the data directory for storing embeddings, adjacency matrices, and related files\n","data_dir = f\"{dir}/Data\"\n","\n","\n","# Define the directory for storing the results\n","results_dir = f\"{dir}/BERT_Model_Choice/Results\""]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":21164,"status":"ok","timestamp":1732232171727,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"eFDNSFef23er"},"outputs":[],"source":["# Load the Source ontology using the Ontology class from DeepOnto\n","# This initializes the source ontology by loading its .owl file.\n","src_onto = Ontology(f\"{dataset_dir}/{src_ent}.owl\")\n","\n","# Load the Target ontology using the Ontology class from DeepOnto\n","# This initializes the target ontology by loading its .owl file.\n","tgt_onto = Ontology(f\"{dataset_dir}/{tgt_ent}.owl\")\n","\n","# Define the file path for the Source embeddings CSV file\n","# Embeddings for the source ontology entities are stored in this file.\n","src_Emb = f\"{data_dir}/{src_ent}_BioBERT_emb.csv\"\n","\n","# Define the file path for the Target embeddings CSV file\n","# Embeddings for the target ontology entities are stored in this file.\n","tgt_Emb = f\"{data_dir}/{tgt_ent}_BioBERT_emb.csv\"\n","\n","# Define the file path for the Source adjacency matrix\n","# This file represents the relationships (edges) between entities in the source ontology.\n","src_Adjacence = f\"{data_dir}/{src_ent}_adjacence.csv\"\n","\n","# Define the file path for the Target adjacency matrix\n","# This file represents the relationships (edges) between entities in the target ontology.\n","tgt_Adjacence = f\"{data_dir}/{tgt_ent}_adjacence.csv\"\n","\n","# Define the file path for the JSON file containing the Source ontology class labels\n","# This file maps the source ontology entities to their labels or names.\n","src_class = f\"{data_dir}/{src_ent}_classes.json\"\n","\n","# Define the file path for the JSON file containing the Target ontology class labels\n","# This file maps the target ontology entities to their labels or names.\n","tgt_class = f\"{data_dir}/{tgt_ent}_classes.json\"\n","\n","# Define the file path for the train data\n","train_file = f\"{data_dir}/{task}_train_100.csv\"\n","\n","# Define the file path for the test data\n","# The test file contains reference mappings (ground truth) between the source and target ontologies.\n","test_file = f\"{dataset_dir}/refs_equiv/test.tsv\"\n","\n","# Define the file path for the candidate mappings used during testing\n","# This file includes the candidate pairs (source and target entities) for ranking and evaluation.\n","test_cands = f\"{dataset_dir}/refs_equiv/test.cands.tsv\"\n","\n","# Define the file path for the candidate mappings between Source to Target entities\n","# This file contains cleaned, combined, and encoded candidates used for predictions.\n","candidates_Prediction = f\"{data_dir}/{task}_candidates_prediction.csv\"\n","\n","# Define the file path for the candidate mappings between Source to Target entities for ranking-based metrics\n","# This file is used to compute ranking-based metrics like MRR and Hits@k.\n","candidates_Rank = f\"{data_dir}/{task}_candidates.csv\"\n","\n","# Define the path where the prediction results will be saved in TSV format\n","# This file will store the final predictions (mappings) between source and target entities.\n","prediction_path = f\"{results_dir}/{task}_matching_results_All_Mini.tsv\"\n","\n","# Define the path where all prediction results will be saved in TSV format\n","# This file will store detailed prediction results, including all candidate scores.\n","all_predictions_path = f\"{results_dir}/{task}_all_predictions_Mini.tsv\"\n","\n","# Define the path where all ranking prediction results will be saved in TSV format\n","# This file will store predictions sorted by rank based on their scores.\n","all_predictions_path_ranked = f\"{results_dir}/{task}_all_predictions_ranked_All_Mini.tsv\"\n","\n","# Define the path where formatted ranking predictions will be saved in TSV format\n","# This file will contain predictions formatted for evaluation using ranking-based metrics.\n","formatted_predictions_path = f\"{results_dir}/{task}_formatted_predictions_All_Mini.tsv\""]},{"cell_type":"markdown","metadata":{"id":"zqEXsgPGMVhw"},"source":["# **GIT Architecture**\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1732228164412,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"A_d6XCsUMVhx"},"outputs":[],"source":["# RGIT class definition which inherits from PyTorch Geometric's MessagePassing class\n","class RGIT(MessagePassing):\n","\n","    _alpha: OptTensor  # Define _alpha as an optional tensor for storing attention weights\n","\n","    def __init__(\n","        self,\n","        nn: Callable,  # Neural network to be used in the final layer of the GNN\n","        in_channels: Union[int, Tuple[int, int]],  # Input dimension, can be a single or pair of integers\n","        out_channels: int,  # Output dimension of the GNN\n","        eps: float = 0.,  # GIN parameter: epsilon for GIN aggregation\n","        train_eps: bool = False,  # GIN parameter: whether epsilon should be learnable\n","        heads: int = 1,  # Transformer parameter: number of attention heads\n","        dropout: float = 0.,  # Dropout rate for attention weights\n","        edge_dim: Optional[int] = None,  # Dimension for edge attributes (optional)\n","        bias: bool = True,  # Whether to use bias in linear layers\n","        root_weight: bool = True,  # GIN parameter: whether to apply root weight in aggregation\n","        **kwargs,  # Additional arguments passed to the parent class\n","    ):\n","        # Set the aggregation type to 'add' and initialize the parent class with node_dim=0\n","        kwargs.setdefault('aggr', 'add')\n","        super().__init__(node_dim=0, **kwargs)\n","\n","        # Initialize input/output dimensions, neural network, and GIN/transformer parameters\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.nn = nn  # Neural network used by the GNN\n","        self.initial_eps = eps  # Initial value of epsilon for GIN\n","\n","        # Set epsilon to be learnable or fixed\n","        if train_eps:\n","            self.eps = torch.nn.Parameter(torch.empty(1))  # Learnable epsilon\n","        else:\n","            self.register_buffer('eps', torch.empty(1))  # Non-learnable epsilon (fixed)\n","\n","        # Initialize transformer-related parameters\n","        self.heads = heads\n","        self.dropout = dropout\n","        self.edge_dim = edge_dim\n","        self._alpha = None  # Placeholder for attention weights\n","\n","        # Handle case where in_channels is a single integer or a tuple\n","        if isinstance(in_channels, int):\n","            in_channels = (in_channels, in_channels)\n","\n","        # Define the linear layers for key, query, and value for the transformer mechanism\n","        self.lin_key = Linear(in_channels[0], heads * out_channels)\n","        self.lin_query = Linear(in_channels[1], heads * out_channels)\n","        self.lin_value = Linear(in_channels[0], heads * out_channels)\n","\n","        # Define linear transformation for edge embeddings if provided\n","        if edge_dim is not None:\n","            self.lin_edge = Linear(edge_dim, heads * out_channels, bias=False)\n","        else:\n","            self.lin_edge = self.register_parameter('lin_edge', None)\n","\n","        # Reset all parameters to their initial values\n","        self.reset_parameters()\n","\n","    # Function to reset model parameters\n","    def reset_parameters(self):\n","        super().reset_parameters()  # Call parent class reset method\n","        self.lin_key.reset_parameters()  # Reset key linear layer\n","        self.lin_query.reset_parameters()  # Reset query linear layer\n","        self.lin_value.reset_parameters()  # Reset value linear layer\n","        if self.edge_dim:\n","            self.lin_edge.reset_parameters()  # Reset edge linear layer if used\n","        reset(self.nn)  # Reset the neural network provided\n","        self.eps.data.fill_(self.initial_eps)  # Initialize epsilon with the starting value\n","\n","    # Forward function defining how the input data flows through the model\n","    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj,\n","                edge_attr: OptTensor = None, return_attention_weights=None):\n","        # Unpack number of heads and output channels\n","        H, C = self.heads, self.out_channels\n","\n","        # If x is a tensor, treat it as a pair of tensors (source and target embeddings)\n","        if isinstance(x, Tensor):\n","            x: PairTensor = (x, x)\n","\n","        # Extract source node embeddings\n","        x_t = x[0]\n","\n","        # Apply linear transformations and reshape query, key, and value for multi-head attention\n","        query = self.lin_query(x[1]).view(-1, H, C)\n","        key = self.lin_key(x[0]).view(-1, H, C)\n","        value = self.lin_value(x[0]).view(-1, H, C)\n","\n","        # Propagate messages through the graph using the propagate function\n","        out = self.propagate(edge_index, query=query, key=key, value=value,\n","                             edge_attr=edge_attr, size=None)\n","\n","        # Retrieve attention weights and reset them\n","        alpha = self._alpha\n","        self._alpha = None  # Reset _alpha after use\n","        out = out.mean(dim=1)  # Take the mean over all attention heads\n","\n","        # Apply GIN aggregation by adding epsilon-scaled original node embeddings\n","        out = out + (1 + self.eps) * x_t\n","        return self.nn(out)  # Pass through the neural network\n","\n","    # Message passing function which calculates attention and combines messages\n","    def message(self, query_i: Tensor, key_j: Tensor, value_j: Tensor,\n","                edge_attr: OptTensor, index: Tensor, ptr: OptTensor,\n","                size_i: Optional[int]) -> Tensor:\n","        # If edge attributes are used, apply linear transformation and add them to the key\n","        if self.lin_edge is not None:\n","            assert edge_attr is not None\n","            edge_attr = self.lin_edge(edge_attr).view(-1, self.heads, self.out_channels)\n","            key_j = key_j + edge_attr\n","\n","        # Calculate attention (alpha) using the dot product between query and key\n","        alpha = (query_i * key_j).sum(dim=-1) / math.sqrt(self.out_channels)\n","        alpha = softmax(alpha, index, ptr, size_i)  # Apply softmax to normalize attention\n","        self._alpha = alpha  # Store attention weights\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)  # Apply dropout\n","\n","        # Calculate the output message by applying attention to the value\n","        out = value_j\n","        if edge_attr is not None:\n","            out = out + edge_attr  # Add edge embeddings to the output if present\n","        out = out * alpha.view(-1, self.heads, 1)  # Scale by attention weights\n","        return out\n","\n","    # String representation function for debugging or printing\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}({self.in_channels}, '\n","                f'{self.out_channels}, heads={self.heads})')"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1732228164412,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"qwFv6RgHmGCf"},"outputs":[],"source":["# Define the RGIT_mod class, a multi-layer GNN that uses both RGIT and linear layers\n","class RGIT_mod(torch.nn.Module):\n","    \"\"\"Multi-layer RGIT with optional linear layers\"\"\"\n","\n","    # Initialize the model with hidden dimension, number of RGIT layers, and number of linear layers\n","    def __init__(self, dim_h, num_layers, num_linear_layers=1):\n","        super(RGIT_mod, self).__init__()\n","        self.num_layers = num_layers  # Number of RGIT layers\n","        self.num_linear_layers = num_linear_layers  # Number of linear layers\n","        self.linears = torch.nn.ModuleList()  # List to store linear layers\n","        self.rgit_layers = torch.nn.ModuleList()  # List to store RGIT layers\n","\n","        # Create a list of Linear and PReLU layers (for encoding entity names)\n","        for _ in range(num_linear_layers):\n","            self.linears.append(Linear(dim_h, dim_h))  # Linear transformation layer\n","            self.linears.append(PReLU(num_parameters=dim_h))  # Parametric ReLU activation function\n","\n","        # Create a list of RGIT layers\n","        for _ in range(num_layers):\n","            self.rgit_layers.append(RGIT(  # Each RGIT layer contains a small MLP with Linear and PReLU\n","                Sequential(Linear(dim_h, dim_h), PReLU(num_parameters=dim_h),\n","                           Linear(dim_h, dim_h), PReLU(num_parameters=dim_h)), dim_h, dim_h))\n","\n","    # Forward pass through the model\n","    def forward(self, x, edge_index):\n","        # Apply the linear layers first to the input\n","        for layer in self.linears:\n","            x = layer(x)\n","\n","        # Then apply the RGIT layers for message passing\n","        for layer in self.rgit_layers:\n","            x = layer(x, edge_index)\n","\n","        return x  # Return the final node embeddings after all layers\n"]},{"cell_type":"markdown","metadata":{"id":"zxCn5ztKVztw"},"source":["# **Gated Network Architecture**"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1732228164413,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"7MKQUv7o7zay"},"outputs":[],"source":["# Define the GatedCombination class for combining two pairs of embeddings using a gating mechanism\n","class GatedCombination(nn.Module):\n","    def __init__(self, input_dim):\n","        \"\"\"\n","        Initialize the GatedCombination model.\n","\n","        Args:\n","            input_dim (int): The dimensionality of the input embeddings (x1, x2, x3, x4).\n","        \"\"\"\n","        super(GatedCombination, self).__init__()\n","\n","        # Define a linear layer (gate) for combining embeddings x1 and x2 (first pair)\n","        self.gate_A_fc = nn.Linear(input_dim, input_dim)\n","\n","        # Define a linear layer (gate) for combining embeddings x3 and x4 (second pair)\n","        self.gate_B_fc = nn.Linear(input_dim, input_dim)\n","\n","        # A final fully connected layer that outputs a single neuron (binary classification)\n","        self.fc = nn.Linear(1, 1)\n","\n","    def forward(self, x1, x2, x3, x4):\n","        \"\"\"\n","        Forward pass through the gating mechanism and cosine similarity.\n","\n","        Args:\n","            x1 (torch.Tensor): First set of embeddings (source embeddings after update).\n","            x2 (torch.Tensor): Second set of embeddings (original source embeddings).\n","            x3 (torch.Tensor): Third set of embeddings (target embeddings after update).\n","            x4 (torch.Tensor): Fourth set of embeddings (original target embeddings).\n","\n","        Returns:\n","            torch.Tensor: Output of the model (probability score for binary classification).\n","        \"\"\"\n","        # Compute gate values for the first pair (x1 and x2) using a sigmoid activation\n","        gate_values1 = torch.sigmoid(self.gate_A_fc(x1))\n","\n","        # Combine x1 and x2 using the gate values\n","        # The result is a weighted combination of x1 and x2\n","        a = x1 * gate_values1 + x2 * (1 - gate_values1)\n","\n","        # Compute gate values for the second pair (x3 and x4) using a sigmoid activation\n","        gate_values2 = torch.sigmoid(self.gate_B_fc(x3))\n","\n","        # Combine x3 and x4 using the gate values\n","        # The result is a weighted combination of x3 and x4\n","        b = x3 * gate_values2 + x4 * (1 - gate_values2)\n","\n","        # Compute cosine similarity between the combined vectors a and b\n","        x = torch.cosine_similarity(a, b, dim=1)\n","\n","        # Pass the cosine similarity result through a fully connected layer (fc) for classification\n","        # Use a sigmoid activation to output a probability for binary classification\n","        out = torch.sigmoid(self.fc(x.unsqueeze(1)))  # unsqueeze(1) to match the input shape for the fc layer\n","        return out\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1732228164413,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"PCzq6hHCD8vg"},"outputs":[],"source":["class WeightedBCELoss(nn.Module):\n","    def __init__(self, pos_weight):\n","        \"\"\"\n","        Weighted Binary Cross-Entropy Loss.\n","\n","        Args:\n","            pos_weight (float): Weight for the positive class.\n","        \"\"\"\n","        super(WeightedBCELoss, self).__init__()\n","        self.pos_weight = pos_weight\n","\n","    def forward(self, outputs, targets):\n","        \"\"\"\n","        Args:\n","            outputs (torch.Tensor): Predicted probabilities from the model (after sigmoid).\n","            targets (torch.Tensor): Ground truth labels (0 or 1).\n","\n","        Returns:\n","            torch.Tensor: Computed weighted binary cross-entropy loss.\n","        \"\"\"\n","        # Compute weighted BCE loss\n","        loss = - (self.pos_weight * targets * torch.log(outputs + 1e-8) +\n","                  (1 - targets) * torch.log(1 - outputs + 1e-8))\n","        return loss.mean()"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1732228164413,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"4kO42TTCqQZ8"},"outputs":[],"source":["class FocalLoss(nn.Module):\n","    def __init__(self, alpha=0.25, gamma=2):\n","        \"\"\"\n","        Focal Loss for binary classification.\n","\n","        Args:\n","            alpha (float): Balancing factor for positive/negative classes.\n","            gamma (float): Focusing parameter for hard examples.\n","        \"\"\"\n","        super(FocalLoss, self).__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","\n","    def forward(self, outputs, targets):\n","        \"\"\"\n","        Args:\n","            outputs (torch.Tensor): Predicted probabilities from the model (after sigmoid).\n","            targets (torch.Tensor): Ground truth labels (0 or 1).\n","\n","        Returns:\n","            torch.Tensor: Computed focal loss.\n","        \"\"\"\n","        # Compute binary cross-entropy loss\n","        bce_loss = F.binary_cross_entropy(outputs, targets, reduction='none')\n","\n","        # Compute modulating factor (1 - p_t)^gamma\n","        pt = torch.where(targets == 1, outputs, 1 - outputs)  # pt = p if y==1 else 1-p\n","        modulating_factor = (1 - pt) ** self.gamma\n","\n","        # Apply alpha and modulating factor\n","        focal_loss = self.alpha * modulating_factor * bce_loss\n","        return focal_loss.mean()"]},{"cell_type":"markdown","metadata":{"id":"aLJ5j9FNMVhy"},"source":["# **Utility functions**"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1732228164413,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"k0L86DgUQjMU"},"outputs":[],"source":["def adjacency_matrix_to_undirected_edge_index(adjacency_matrix):\n","    \"\"\"\n","    Converts an adjacency matrix into an undirected edge index for use in graph-based neural networks.\n","\n","    Args:\n","        adjacency_matrix: A 2D list or array representing the adjacency matrix of a graph.\n","\n","    Returns:\n","        edge_index_undirected: A PyTorch tensor representing the undirected edges.\n","    \"\"\"\n","    # Convert each element in the adjacency matrix to an integer (from boolean or float)\n","    adjacency_matrix = [[int(element) for element in sublist] for sublist in adjacency_matrix]\n","\n","    # Convert the adjacency matrix into a PyTorch LongTensor (used for indexing)\n","    edge_index = torch.tensor(adjacency_matrix, dtype=torch.long)\n","\n","    # Transpose the edge_index tensor so that rows represent edges in the form [source, target]\n","    edge_index = edge_index.t().contiguous()\n","\n","    # Convert the directed edge_index into an undirected edge_index, meaning both directions are added (i.e., (i, j) and (j, i))\n","    edge_index_undirected = to_undirected(edge_index)\n","\n","    return edge_index_undirected  # Return the undirected edge index"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1732228164413,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"YvmOxkLcpf9w"},"outputs":[],"source":["def build_indexed_dict(file_path):\n","    \"\"\"\n","    Builds a dictionary with numeric indexes for each key from a JSON file.\n","\n","    Args:\n","        file_path (str): The path to the JSON file.\n","\n","    Returns:\n","        indexed_dict (dict): A new dictionary where each key from the JSON file is assigned a numeric index.\n","    \"\"\"\n","    # Load the JSON file into a Python dictionary\n","    with open(file_path, 'r') as file:\n","        data = json.load(file)\n","\n","    # Create a new dictionary with numeric indexes as keys and the original JSON keys as values\n","    indexed_dict = {index: key for index, key in enumerate(data.keys())}\n","\n","    return indexed_dict  # Return the newly created dictionary"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1732228164413,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"QgFINoPGl9Wg"},"outputs":[],"source":["def select_rows_by_index(embedding_vector, index_vector):\n","    \"\"\"\n","    Select rows from an embedding vector using an index vector.\n","\n","    Args:\n","        embedding_vector (torch.Tensor): 2D tensor representing the embedding vector with shape [num_rows, embedding_size].\n","        index_vector (torch.Tensor): 1D tensor representing the index vector.\n","\n","    Returns:\n","        torch.Tensor: New tensor with selected rows from the embedding vector.\n","    \"\"\"\n","    # Use torch.index_select to select the desired rows\n","    new_tensor = torch.index_select(embedding_vector, 0, index_vector)\n","\n","    return new_tensor"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1732228164413,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"a12L7vEmmCJq"},"outputs":[],"source":["def contrastive_loss(source_embeddings, target_embeddings, labels, margin=1.0):\n","    \"\"\"\n","    Computes the contrastive loss, a type of loss function used to train models in tasks like matching or similarity learning.\n","\n","    Args:\n","        source_embeddings (torch.Tensor): Embeddings of the source graphs, shape [batch_size, embedding_size].\n","        target_embeddings (torch.Tensor): Embeddings of the target graphs, shape [batch_size, embedding_size].\n","        labels (torch.Tensor): Binary labels indicating if the pairs are matched (1) or not (0), shape [batch_size].\n","        margin (float): Margin value for the contrastive loss. Defaults to 1.0.\n","\n","    Returns:\n","        torch.Tensor: The contrastive loss value.\n","    \"\"\"\n","    # Calculate the pairwise Euclidean distance between source and target embeddings\n","    distances = F.pairwise_distance(source_embeddings, target_embeddings)\n","\n","    # Compute the contrastive loss:\n","    # - For matched pairs (label == 1), the loss is the squared distance between embeddings.\n","    # - For non-matched pairs (label == 0), the loss is based on how far apart the embeddings are,\n","    #   but penalizes them only if the distance is less than the margin.\n","    loss = torch.mean(\n","        labels * 0.4 * distances.pow(2) +  # For positive pairs, minimize the distance (squared)\n","        (1 - labels) * 0.4 * torch.max(torch.zeros_like(distances), margin - distances).pow(2)  # For negative pairs, maximize the distance (up to the margin)\n","    )\n","\n","    return loss  # Return the computed contrastive loss\n"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1732228164414,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"ZhCizXEb7D4N"},"outputs":[],"source":["def Prediction_with_candidates(model, X1_tt, X2_tt, X3_tt, X4_tt, src_entity_tensor_o, tgt_entity_tensor_o,\n","                                   indexed_dict_src, indexed_dict_tgt, all_predictions_path):\n","    \"\"\"\n","    Evaluates the GatedCombination model using the given embeddings and candidate entity pairs.\n","    Saves the predictions and evaluation results to a file.\n","\n","    Args:\n","        model: Trained GatedCombination model.\n","        X1_tt, X2_tt, X3_tt, X4_tt (torch.Tensor): Tensors of source and target entity embeddings (updated and original).\n","        src_entity_tensor_o, tgt_entity_tensor_o (torch.Tensor): Tensors of source and target entity indices.\n","        indexed_dict_src, indexed_dict_tgt (dict): Dictionaries mapping entity indices to URIs for source and target.\n","        output_file (str): Path to save the predictions and results.\n","        hits_at_k_values (list): List of k-values for which hits@k is evaluated.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    # Move the model to CPU and set it to evaluation mode\n","    model = model.to(\"cpu\")\n","    model.eval()\n","\n","    # Set batch size for evaluation\n","    batch_size_test = 32\n","\n","    # Create a DataLoader for the evaluation data\n","    test_dataset = TensorDataset(X1_tt, X2_tt, X3_tt, X4_tt)\n","    test_dataloader = DataLoader(test_dataset, batch_size=batch_size_test)\n","\n","    # Prepare for collecting predictions and results\n","    predictions = []\n","    results = []\n","    count_predictions = 0  # Counter for predictions above threshold (0.5)\n","\n","    # Measure prediction time\n","    start_time = time.time()\n","\n","    # Disable gradient computation for evaluation\n","    with torch.no_grad():\n","        # Iterate over batches and compute model predictions\n","        for batch_X1, batch_X2, batch_X3, batch_X4 in test_dataloader:\n","            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","            predictions.extend(outputs.cpu().numpy())  # Collect predictions in CPU memory\n","\n","    end_time = time.time()\n","    predicting_time = end_time - start_time\n","    print(f\"Predicting time: {predicting_time:.2f} seconds\")\n","\n","    # Convert tensors to lists for easier iteration\n","    src_indices = src_entity_tensor_o.tolist()\n","    tgt_indices = tgt_entity_tensor_o.tolist()\n","\n","    # Prepare results\n","    for i in range(len(predictions)):\n","        if predictions[i] >= 0.00:  # Consider only predictions greater than 0.5\n","            count_predictions += 1  # Increment the counter\n","\n","            # Map the source and target entity indices to their URIs\n","            src_code = src_indices[i]\n","            tgt_code = tgt_indices[i]\n","\n","            src_uri = indexed_dict_src.get(int(src_code), \"Unknown URI\")\n","            tgt_uri = indexed_dict_tgt.get(int(tgt_code), \"Unknown URI\")\n","\n","            # Get the model's predicted score for the current pair\n","            score = predictions[i]\n","\n","            # Append the results (with URIs instead of entity indices)\n","            results.append({\n","                'SrcEntity': src_uri,\n","                'TgtEntity': tgt_uri,\n","                'Score': score\n","            })\n","\n","    # Convert the results into a pandas DataFrame\n","    df_results = pd.DataFrame(results)\n","\n","    # Save the results to a TSV file\n","    df_results.to_csv(all_predictions_path, sep='\\t', index=False)\n","\n","    print(f\"Predictions saved to {all_predictions_path}\")"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1732228164414,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"TslUdYHBcGVj"},"outputs":[],"source":["def filter_highest_predictions(input_file_path, output_file_path, threshold=thres):\n","    # Load the all predictions file\n","    df = pd.read_csv(input_file_path, sep='\\t')\n","\n","    # Extract the similarity score from the list in the 'Score' column\n","    df['Score'] = df['Score'].apply(lambda x: float(x.strip('[]')))\n","\n","    # Sorting the dataframe by similarity score in descending order\n","    df_sorted = df.sort_values(by='Score', ascending=False).reset_index(drop=True)\n","\n","    # Initialize variables with threshold value\n","    source_concepts = set(df_sorted['SrcEntity'])\n","    target_concepts = set(df_sorted['TgtEntity'])\n","    matched_sources = set()\n","    matched_targets = set()\n","    result = []\n","\n","    # Iterate through the sorted dataframe and find highest correspondences\n","    for _, row in df_sorted.iterrows():\n","        source, target, similarity = row['SrcEntity'], row['TgtEntity'], row['Score']\n","\n","        # Check if the source or target has already been matched and if the similarity is above the threshold\n","        if source not in matched_sources and target not in matched_targets and similarity >= threshold:\n","            # Add the match to the result list\n","            result.append((source, target, similarity))\n","            # Mark the source and target as matched\n","            matched_sources.add(source)\n","            matched_targets.add(target)\n","\n","    # Create a dataframe for the matching results with threshold applied\n","    matching_results_df_threshold = pd.DataFrame(result, columns=['SrcEntity', 'TgtEntity', 'Score'])\n","\n","    # Save the matching results with the updated column names to a new TSV file\n","    matching_results_df_threshold.to_csv(output_file_path, sep='\\t', index=False)\n","\n","    # Print the number of predictions saved\n","    print(f\"Number of Positive predictions: {len(matching_results_df_threshold)}\")\n","\n","    return matching_results_df_threshold, len(matching_results_df_threshold)"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1732228164414,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"_ggVYlTiO_WA"},"outputs":[],"source":["def compute_mrr_and_hits(reference_file, predicted_file, output_file, k_values=[1, 5, 10]):\n","    \"\"\"\n","    Compute MRR and Hits@k for ontology matching predictions based on a reference file.\n","\n","    Args:\n","        reference_file (str): Path to the reference file (test.cands.tsv format).\n","        predicted_file (str): Path to the predictions file with scores.\n","        output_file (str): Path to save the scored results.\n","        k_values (list): List of k values for Hits@k.\n","\n","    Returns:\n","        dict: A dictionary containing MRR and Hits@k metrics.\n","    \"\"\"\n","    # Read the reference mappings\n","    test_candidate_mappings = read_table(reference_file).values.tolist()\n","    ranking_results = []\n","\n","    # Read the predicted scores\n","    predicted_data = pd.read_csv(predicted_file, sep=\"\\t\")\n","    predicted_data[\"Score\"] = predicted_data[\"Score\"].apply(lambda x: float(x.strip(\"[]\")))\n","\n","    # Create a lookup dictionary for predicted scores\n","    score_lookup = {}\n","    for _, row in predicted_data.iterrows():\n","        score_lookup[(row[\"SrcEntity\"], row[\"TgtEntity\"])] = row[\"Score\"]\n","\n","    for src_ref_class, tgt_ref_class, tgt_cands in test_candidate_mappings:\n","        tgt_cands = eval(tgt_cands)  # Convert string to list of candidates\n","        scored_cands = []\n","        for tgt_cand in tgt_cands:\n","            # Retrieve score for each candidate, defaulting to a very low score if not found\n","            matching_score = score_lookup.get((src_ref_class, tgt_cand), -1e9)\n","            scored_cands.append((tgt_cand, matching_score))\n","\n","        # Sort candidates by score in descending order\n","        scored_cands = sorted(scored_cands, key=lambda x: x[1], reverse=True)\n","        ranking_results.append((src_ref_class, tgt_ref_class, scored_cands))\n","\n","    # Save the ranked results to a file\n","    pd.DataFrame(ranking_results, columns=[\"SrcEntity\", \"TgtEntity\", \"TgtCandidates\"]).to_csv(output_file, sep=\"\\t\", index=False)\n","\n","    # Compute MRR and Hits@k\n","    total_entities = len(ranking_results)\n","    reciprocal_ranks = []\n","    hits_at_k = {k: 0 for k in k_values}\n","\n","    for src_entity, tgt_ref_class, tgt_cands in ranking_results:\n","        ranked_candidates = [candidate[0] for candidate in tgt_cands]\n","        if tgt_ref_class in ranked_candidates:\n","            rank = ranked_candidates.index(tgt_ref_class) + 1\n","            reciprocal_ranks.append(1 / rank)\n","            for k in k_values:\n","                if rank <= k:\n","                    hits_at_k[k] += 1\n","        else:\n","            reciprocal_ranks.append(0)\n","\n","    mrr = sum(reciprocal_ranks) / total_entities\n","    hits_at_k = {k: hits / total_entities for k, hits in hits_at_k.items()}\n","\n","    return {\"MRR\": mrr, \"Hits@k\": hits_at_k}"]},{"cell_type":"markdown","metadata":{"id":"1HyWMsw1MVhz"},"source":["# **Main Code**\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"IC37FlwGDqGM"},"source":["\n","\n","# Reading semantic node embeddings provided by the ENE"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":8033,"status":"ok","timestamp":1732228172439,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"FuEfSnw5mod0"},"outputs":[],"source":["# Read the source embeddings from a CSV file into a pandas DataFrame\n","df_embbedings_src = pd.read_csv(src_Emb, index_col=0)\n","\n","# Convert the DataFrame to a NumPy array, which will remove the index and store the data as a raw matrix\n","numpy_array = df_embbedings_src.to_numpy()\n","\n","# Convert the NumPy array into a PyTorch FloatTensor, which is the format required for PyTorch operations\n","x_src = torch.FloatTensor(numpy_array)"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":6401,"status":"ok","timestamp":1732228178836,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"STUwqMUXmlG2"},"outputs":[],"source":["# Read the target embeddings from a CSV file into a pandas DataFrame\n","df_embbedings_tgt = pd.read_csv(tgt_Emb, index_col=0)\n","\n","# Convert the DataFrame to a NumPy array, which removes the index and converts the data to a raw matrix\n","numpy_array = df_embbedings_tgt.to_numpy()\n","\n","# Convert the NumPy array into a PyTorch FloatTensor, which is required for PyTorch operations\n","x_tgt = torch.FloatTensor(numpy_array)"]},{"cell_type":"markdown","metadata":{"id":"jZIu9P08DqGN"},"source":["# Reading adjacency Matrix"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":402,"status":"ok","timestamp":1732228179234,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"pH69Up40mycz"},"outputs":[],"source":["# Read the source adjacency matrix from a CSV file into a pandas DataFrame\n","df_ma1 = pd.read_csv(src_Adjacence, index_col=0)\n","\n","# Convert the DataFrame to a list of lists (Python native list format)\n","ma1 = df_ma1.values.tolist()"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":290,"status":"ok","timestamp":1732228179521,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"hYCmAO5Ymzpl"},"outputs":[],"source":["# Read the target adjacency matrix from a CSV file into a pandas DataFrame\n","df_ma2 = pd.read_csv(tgt_Adjacence, index_col=0)\n","\n","# Convert the DataFrame to a list of lists (Python native list format)\n","ma2 = df_ma2.values.tolist()"]},{"cell_type":"markdown","metadata":{"id":"PSyksqh3TrU-"},"source":["# Convert Adjacency matrix (in list format) to an undirected edge index"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1732228179521,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"uVt-Pce5m5ll"},"outputs":[],"source":["# Convert the source adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n","edge_src = adjacency_matrix_to_undirected_edge_index(ma1)\n","\n","# Convert the target adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n","edge_tgt = adjacency_matrix_to_undirected_edge_index(ma2)"]},{"cell_type":"markdown","metadata":{"id":"H9wMTRdqT4aY"},"source":["# GIT Training"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1732228179522,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"eqiEKCLSMVh3"},"outputs":[],"source":["def train_model_gnn(model, x_src, edge_src, x_tgt, edge_tgt,\n","                    tensor_term1, tensor_term2, tensor_score,\n","                    learning_rate, weight_decay_value, num_epochs, print_interval=10):\n","    \"\"\"\n","    Trains a graph neural network (GNN) model using source and target embeddings and contrastive loss.\n","\n","    Args:\n","        model: The GNN model to be trained.\n","        x_src (torch.Tensor): Source node embeddings.\n","        edge_src (torch.Tensor): Source graph edges.\n","        x_tgt (torch.Tensor): Target node embeddings.\n","        edge_tgt (torch.Tensor): Target graph edges.\n","        tensor_term1 (torch.Tensor): Indices of the source nodes to be compared.\n","        tensor_term2 (torch.Tensor): Indices of the target nodes to be compared.\n","        tensor_score (torch.Tensor): Labels indicating if the pairs are matched (1) or not (0).\n","        learning_rate (float): Learning rate for the optimizer.\n","        weight_decay_value (float): Weight decay (L2 regularization) value for the optimizer.\n","        num_epochs (int): Number of epochs for training.\n","        print_interval (int): Interval at which training progress is printed (every `print_interval` epochs).\n","\n","    Returns:\n","        model: The trained GNN model.\n","    \"\"\"\n","\n","    # Step 1: Set device (GPU or CPU) for computation\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    # Step 2: Move the model and all inputs to the selected device\n","    model.to(device)\n","    x_tgt = x_tgt.to(device)               # Target node embeddings\n","    edge_tgt = edge_tgt.to(device)         # Target graph edges\n","    x_src = x_src.to(device)               # Source node embeddings\n","    edge_src = edge_src.to(device)         # Source graph edges\n","    tensor_term1 = tensor_term1.to(device) # Indices for source nodes\n","    tensor_term2 = tensor_term2.to(device) # Indices for target nodes\n","    tensor_score = tensor_score.to(device) # Ground truth labels\n","\n","    # Step 3: Define optimizer with learning rate and regularization\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay_value)\n","\n","    # Step 4: Initialize list to store training losses\n","    train_losses = []\n","\n","    # Record the start time of training\n","    start_time = time.time()\n","\n","    # Step 5: Training loop\n","    for epoch in range(num_epochs):\n","        # Zero out gradients from the previous iteration\n","        optimizer.zero_grad()\n","\n","        # Forward pass: Compute embeddings for source and target graphs\n","        out1 = model(x_src, edge_src)  # Updated source embeddings\n","        out2 = model(x_tgt, edge_tgt)  # Updated target embeddings\n","\n","        # Extract specific rows of embeddings for terms being compared\n","        src_embeddings = select_rows_by_index(out1, tensor_term1)\n","        tgt_embeddings = select_rows_by_index(out2, tensor_term2)\n","\n","        # Compute contrastive loss based on the embeddings and ground truth labels\n","        loss = contrastive_loss(src_embeddings, tgt_embeddings, tensor_score)\n","\n","        # Backward pass: Compute gradients\n","        loss.backward()\n","\n","        # Update the model's parameters\n","        optimizer.step()\n","\n","        # Append the loss for this iteration to the list\n","        train_losses.append(loss.item())\n","\n","        # Print loss every `print_interval` epochs\n","        if (epoch + 1) % print_interval == 0:\n","            print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item()}\")\n","\n","    # Step 6: Record end time of training\n","    end_time = time.time()\n","\n","    # Step 7: Plot the training loss over time\n","    plt.semilogy(range(1, num_epochs + 1), train_losses, label=\"Training Loss\", marker='o')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    # Print the total training time\n","    training_time = end_time - start_time\n","    print(f\"Training complete! Total training time: {training_time:.2f} seconds\")\n","\n","    # Step 8: Return the trained model\n","    return model"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1732228179522,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"6_tzUG_emtBg"},"outputs":[],"source":["# Initialize the GIT_mod model with the dimensionality of the target embeddings\n","# The first argument is the dimensionality of the target node embeddings (x_tgt.shape[1])\n","# The second argument (1) represents the number of RGIT layers in the model\n","GIT_model = RGIT_mod(x_tgt.shape[1], 1)"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":271,"status":"ok","timestamp":1732228179789,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"},"user_tz":-60},"id":"wVo-s7UQssSp"},"outputs":[],"source":["# Reading the training pairs from a CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(train_file, index_col=0)\n","\n","# Extract the 'SrcEntity' and 'TgtEntity' columns as NumPy arrays and convert them to integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)  # Source entity indices\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)  # Target entity indices\n","\n","# Extract the 'Score' column as a NumPy array and convert it to floats\n","tensor_score = df_embbedings['Score'].values.astype(float)  # Scores (labels) indicating if pairs match (1) or not (0)\n","\n","# Convert the NumPy arrays to PyTorch LongTensors (for indices) and FloatTensors (for scores)\n","tensor_term1_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)  # Source entity tensor\n","tensor_term2_o = torch.from_numpy(tensor_term2).type(torch.LongTensor)  # Target entity tensor\n","tensor_score_o = torch.from_numpy(tensor_score).type(torch.FloatTensor)  # Score tensor"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"agHlFNesMVh3","executionInfo":{"status":"ok","timestamp":1732229983845,"user_tz":-60,"elapsed":1804060,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"216f52f6-f166-432a-9296-e395fb3b8116"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [10/1000], Training Loss: 0.0023159882985055447\n","Epoch [20/1000], Training Loss: 0.0015887715853750706\n","Epoch [30/1000], Training Loss: 0.0014314816799014807\n","Epoch [40/1000], Training Loss: 0.0012656758772209287\n","Epoch [50/1000], Training Loss: 0.0011799141066148877\n","Epoch [60/1000], Training Loss: 0.0011182615999132395\n","Epoch [70/1000], Training Loss: 0.0010587264550849795\n","Epoch [80/1000], Training Loss: 0.001010118518024683\n","Epoch [90/1000], Training Loss: 0.0009679115028120577\n","Epoch [100/1000], Training Loss: 0.000929683621507138\n","Epoch [110/1000], Training Loss: 0.0008960768464021385\n","Epoch [120/1000], Training Loss: 0.0008655900019221008\n","Epoch [130/1000], Training Loss: 0.0008381089428439736\n","Epoch [140/1000], Training Loss: 0.0008132329094223678\n","Epoch [150/1000], Training Loss: 0.0007905431557446718\n","Epoch [160/1000], Training Loss: 0.0007696816464886069\n","Epoch [170/1000], Training Loss: 0.0007506603724323213\n","Epoch [180/1000], Training Loss: 0.0007332860259339213\n","Epoch [190/1000], Training Loss: 0.0007171609904617071\n","Epoch [200/1000], Training Loss: 0.0007021449273452163\n","Epoch [210/1000], Training Loss: 0.0006883268360979855\n","Epoch [220/1000], Training Loss: 0.0006755412905476987\n","Epoch [230/1000], Training Loss: 0.0006635882891714573\n","Epoch [240/1000], Training Loss: 0.0006523746415041387\n","Epoch [250/1000], Training Loss: 0.0006420777062885463\n","Epoch [260/1000], Training Loss: 0.0006325477734208107\n","Epoch [270/1000], Training Loss: 0.00062373565742746\n","Epoch [280/1000], Training Loss: 0.0006155180162750185\n","Epoch [290/1000], Training Loss: 0.0006076834397390485\n","Epoch [300/1000], Training Loss: 0.0006003545131534338\n","Epoch [310/1000], Training Loss: 0.000593506614677608\n","Epoch [320/1000], Training Loss: 0.00058702880050987\n","Epoch [330/1000], Training Loss: 0.0005809079157188535\n","Epoch [340/1000], Training Loss: 0.0005751022254116833\n","Epoch [350/1000], Training Loss: 0.0005695182480849326\n","Epoch [360/1000], Training Loss: 0.0005641948664560914\n","Epoch [370/1000], Training Loss: 0.0005592228262685239\n","Epoch [380/1000], Training Loss: 0.0005544164450839162\n","Epoch [390/1000], Training Loss: 0.0005498233367688954\n","Epoch [400/1000], Training Loss: 0.0005454556667245924\n","Epoch [410/1000], Training Loss: 0.0005412256577983499\n","Epoch [420/1000], Training Loss: 0.0005371175357140601\n","Epoch [430/1000], Training Loss: 0.0005332162254489958\n","Epoch [440/1000], Training Loss: 0.0005294689908623695\n","Epoch [450/1000], Training Loss: 0.0005258420133031905\n","Epoch [460/1000], Training Loss: 0.0005223075859248638\n","Epoch [470/1000], Training Loss: 0.0005188724608160555\n","Epoch [480/1000], Training Loss: 0.0005155247054062784\n","Epoch [490/1000], Training Loss: 0.0005122926668263972\n","Epoch [500/1000], Training Loss: 0.0005091350176371634\n","Epoch [510/1000], Training Loss: 0.0005060526309534907\n","Epoch [520/1000], Training Loss: 0.0005030721076764166\n","Epoch [530/1000], Training Loss: 0.0005001696408726275\n","Epoch [540/1000], Training Loss: 0.0004973150207661092\n","Epoch [550/1000], Training Loss: 0.0004945246037095785\n","Epoch [560/1000], Training Loss: 0.0004917990299873054\n","Epoch [570/1000], Training Loss: 0.0004891098360531032\n","Epoch [580/1000], Training Loss: 0.00048649171367287636\n","Epoch [590/1000], Training Loss: 0.0004839007742702961\n","Epoch [600/1000], Training Loss: 0.0004813665000256151\n","Epoch [610/1000], Training Loss: 0.000478897534776479\n","Epoch [620/1000], Training Loss: 0.00047645732411183417\n","Epoch [630/1000], Training Loss: 0.00047406897647306323\n","Epoch [640/1000], Training Loss: 0.00047175298095680773\n","Epoch [650/1000], Training Loss: 0.0004694974923040718\n","Epoch [660/1000], Training Loss: 0.00046728033339604735\n","Epoch [670/1000], Training Loss: 0.00046512807602994144\n","Epoch [680/1000], Training Loss: 0.00046302287955768406\n","Epoch [690/1000], Training Loss: 0.000460992829175666\n","Epoch [700/1000], Training Loss: 0.00045901682460680604\n","Epoch [710/1000], Training Loss: 0.00045709419646300375\n","Epoch [720/1000], Training Loss: 0.00045523393782787025\n","Epoch [730/1000], Training Loss: 0.00045342370867729187\n","Epoch [740/1000], Training Loss: 0.00045163510367274284\n","Epoch [750/1000], Training Loss: 0.00044989859452471137\n","Epoch [760/1000], Training Loss: 0.0004481533251237124\n","Epoch [770/1000], Training Loss: 0.0004464584344532341\n","Epoch [780/1000], Training Loss: 0.000444795994553715\n","Epoch [790/1000], Training Loss: 0.0004431453999131918\n","Epoch [800/1000], Training Loss: 0.0004415186122059822\n","Epoch [810/1000], Training Loss: 0.0004399267490953207\n","Epoch [820/1000], Training Loss: 0.00043835394899360836\n","Epoch [830/1000], Training Loss: 0.0004368203226476908\n","Epoch [840/1000], Training Loss: 0.00043527799425646663\n","Epoch [850/1000], Training Loss: 0.0004337563004810363\n","Epoch [860/1000], Training Loss: 0.00043225008994340897\n","Epoch [870/1000], Training Loss: 0.0004307807539589703\n","Epoch [880/1000], Training Loss: 0.000429328007157892\n","Epoch [890/1000], Training Loss: 0.000427883438533172\n","Epoch [900/1000], Training Loss: 0.00042642318294383585\n","Epoch [910/1000], Training Loss: 0.00042501019197516143\n","Epoch [920/1000], Training Loss: 0.0004236182139720768\n","Epoch [930/1000], Training Loss: 0.00042225420475006104\n","Epoch [940/1000], Training Loss: 0.00042089371709153056\n","Epoch [950/1000], Training Loss: 0.000419551448430866\n","Epoch [960/1000], Training Loss: 0.0004182248958386481\n","Epoch [970/1000], Training Loss: 0.0004168990417383611\n","Epoch [980/1000], Training Loss: 0.00041557307122275233\n","Epoch [990/1000], Training Loss: 0.00041427285759709775\n","Epoch [1000/1000], Training Loss: 0.00041296175913885236\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training complete! Total training time: 1802.64 seconds\n"]}],"source":["# Train the GNN model using the provided source and target graph embeddings, edges, and training data\n","trained_model = train_model_gnn(\n","    model=GIT_model,                # The GNN model to be trained (initialized earlier)\n","    x_src=x_src,                    # Source node embeddings (tensor for source graph)\n","    edge_src=edge_src,              # Source graph edges (undirected edge index for source graph)\n","    x_tgt=x_tgt,                    # Target node embeddings (tensor for target graph)\n","    edge_tgt=edge_tgt,              # Target graph edges (undirected edge index for target graph)\n","    tensor_term1=tensor_term1_o,    # Indices of source entities for training\n","    tensor_term2=tensor_term2_o,    # Indices of target entities for training\n","    tensor_score=tensor_score_o,    # Scores (labels) indicating if pairs match (1) or not (0)\n","    learning_rate=0.0001,            # Learning rate for the Adam optimizer\n","    weight_decay_value=1e-4,        # Weight decay for L2 regularization to prevent overfitting\n","    num_epochs=1000,                # Number of training epochs\n","    print_interval=10               # Interval at which to print training progress (every 10 epochs)\n",")"]},{"cell_type":"markdown","metadata":{"id":"MYyhvjcTUaae"},"source":["# GIT Application"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"BZ_VqP6tq6iD","executionInfo":{"status":"ok","timestamp":1732229984224,"user_tz":-60,"elapsed":382,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Determine if a GPU is available and move the computations to it; otherwise, use the CPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Assuming the model has been trained and hyperparameters (x_src, edge_src, x_tgt, edge_tgt) are set\n","\n","# Move the trained GIT_model to the device (GPU or CPU)\n","GIT_model.to(device)\n","\n","# Move the data tensors to the same device (GPU or CPU)\n","x_tgt = x_tgt.to(device)         # Target node embeddings\n","edge_tgt = edge_tgt.to(device)   # Target graph edges\n","x_src = x_src.to(device)         # Source node embeddings\n","edge_src = edge_src.to(device)   # Source graph edges\n","\n","# Set the model to evaluation mode; this disables dropout and batch normalization\n","GIT_model.eval()\n","\n","# Pass the source and target embeddings through the trained GNN model to update the embeddings\n","with torch.no_grad():  # Disable gradient computation (inference mode)\n","    embeddings_tgt = GIT_model(x_tgt, edge_tgt)  # Get updated embeddings for the target graph\n","    embeddings_src = GIT_model(x_src, edge_src)  # Get updated embeddings for the source graph\n","\n","# Detach the embeddings from the computation graph and move them back to the CPU\n","# This step is useful if you need to use the embeddings for tasks outside PyTorch (e.g., saving to disk)\n","embeddings_tgt = embeddings_tgt.detach().cpu()  # Target graph embeddings\n","embeddings_src = embeddings_src.detach().cpu()  # Source graph embeddings\n","\n","# At this point, embeddings_tgt and embeddings_src contain the updated embeddings, ready for downstream tasks"]},{"cell_type":"markdown","metadata":{"id":"Og5fdoGJrTCG"},"source":["# Selecting embedding pairs to train the Gated Network"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"J0nTwc-dnjLn","executionInfo":{"status":"ok","timestamp":1732229984224,"user_tz":-60,"elapsed":2,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the training pairs from a CSV file into a pandas DataFrame\n","df_embeddings = pd.read_csv(train_file, index_col=0)\n","\n","# Extract columns and convert to NumPy arrays\n","tensor_term1 = df_embeddings['SrcEntity'].values.astype(int)  # Source entity indices\n","tensor_term2 = df_embeddings['TgtEntity'].values.astype(int)  # Target entity indices\n","tensor_score = df_embeddings['Score'].values.astype(float)  # Matching scores\n","\n","# Split data into training and validation sets\n","tensor_term1_train, tensor_term1_val, tensor_term2_train, tensor_term2_val, tensor_score_train, tensor_score_val = train_test_split(\n","    tensor_term1, tensor_term2, tensor_score, test_size=0.3, random_state=42\n",")\n","\n","# Convert split data to PyTorch tensors\n","tensor_term1_train = torch.from_numpy(tensor_term1_train).type(torch.LongTensor)\n","tensor_term2_train = torch.from_numpy(tensor_term2_train).type(torch.LongTensor)\n","tensor_score_train = torch.from_numpy(tensor_score_train).type(torch.FloatTensor)\n","\n","tensor_term1_val = torch.from_numpy(tensor_term1_val).type(torch.LongTensor)\n","tensor_term2_val = torch.from_numpy(tensor_term2_val).type(torch.LongTensor)\n","tensor_score_val = torch.from_numpy(tensor_score_val).type(torch.FloatTensor)\n","\n","# Move the embeddings back to the CPU if not already there\n","x_tgt = x_tgt.cpu()  # Target node embeddings\n","x_src = x_src.cpu()  # Source node embeddings\n","\n","# Select embeddings for the training set\n","X1_train = select_rows_by_index(embeddings_src, tensor_term1_train)\n","X2_train = select_rows_by_index(x_src, tensor_term1_train)\n","X3_train = select_rows_by_index(embeddings_tgt, tensor_term2_train)\n","X4_train = select_rows_by_index(x_tgt, tensor_term2_train)\n","\n","# Select embeddings for the validation set\n","X1_val = select_rows_by_index(embeddings_src, tensor_term1_val)\n","X2_val = select_rows_by_index(x_src, tensor_term1_val)\n","X3_val = select_rows_by_index(embeddings_tgt, tensor_term2_val)\n","X4_val = select_rows_by_index(x_tgt, tensor_term2_val)\n","\n","# Now you have:\n","# - Training tensors: X1_train, X2_train, X3_train, X4_train, tensor_score_train\n","# - Validation tensors: X1_val, X2_val, X3_val, X4_val, tensor_score_val"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"wR3PbrbBETJA","executionInfo":{"status":"ok","timestamp":1732230501523,"user_tz":-60,"elapsed":269,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["positive_weight = len(tensor_score_train) / (weight_train * tensor_score_train.sum())"]},{"cell_type":"markdown","metadata":{"id":"fNdCgaTMExPK"},"source":["# Gated Network Training"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"Gof1eIPIWSVU","executionInfo":{"status":"ok","timestamp":1732230505465,"user_tz":-60,"elapsed":263,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def train_gated_combination_model(X1_t, X2_t, X3_t, X4_t, tensor_score_o,\n","                                  X1_val, X2_val, X3_val, X4_val, tensor_score_val,\n","                                  epochs=120, batch_size=32, learning_rate=0.001, weight_decay=1e-5):\n","    \"\"\"\n","    Trains the GatedCombination model with training and validation data, using ReduceLROnPlateau scheduler.\n","    \"\"\"\n","\n","    # Create datasets and DataLoaders\n","    train_dataset = TensorDataset(X1_t, X2_t, X3_t, X4_t, tensor_score_o)\n","    val_dataset = TensorDataset(X1_val, X2_val, X3_val, X4_val, tensor_score_val)\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = GatedCombination(X1_t.shape[1]).to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","\n","    # Use ReduceLROnPlateau scheduler\n","    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n","\n","    criterion = WeightedBCELoss(pos_weight=positive_weight).to(device)\n","\n","    train_losses, val_losses = [], []\n","\n","    start_time = time.time()\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        total_train_loss, y_true_train, y_pred_train = 0.0, [], []\n","\n","        for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in train_loader:\n","            batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (batch_X1.to(device), batch_X2.to(device),\n","                                                               batch_X3.to(device), batch_X4.to(device), batch_y.to(device))\n","            optimizer.zero_grad()\n","            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","            loss = criterion(outputs, batch_y.unsqueeze(1).float())\n","            loss.backward()\n","            optimizer.step()\n","            total_train_loss += loss.item()\n","            y_true_train.extend(batch_y.cpu().numpy())\n","            y_pred_train.extend((outputs > 0.2).float().cpu().numpy())\n","\n","        train_f1 = f1_score(y_true_train, y_pred_train)\n","        train_loss = total_train_loss / len(train_loader)\n","        train_losses.append(train_loss)\n","\n","        # Validation phase\n","        model.eval()\n","        total_val_loss, y_true_val, y_pred_val = 0.0, [], []\n","        with torch.no_grad():\n","            for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in val_loader:\n","                batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (batch_X1.to(device), batch_X2.to(device),\n","                                                                   batch_X3.to(device), batch_X4.to(device), batch_y.to(device))\n","                outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","                val_loss = criterion(outputs, batch_y.unsqueeze(1).float())\n","                total_val_loss += val_loss.item()\n","                y_true_val.extend(batch_y.cpu().numpy())\n","                y_pred_val.extend((outputs > 0.4).float().cpu().numpy())\n","\n","        val_f1 = f1_score(y_true_val, y_pred_val)\n","        avg_val_loss = total_val_loss / len(val_loader)\n","        val_losses.append(avg_val_loss)\n","\n","        # Step the scheduler with validation loss\n","        scheduler.step(avg_val_loss)\n","\n","        # Print training and validation metrics\n","        print(f\"Epoch [{epoch + 1}/{epochs}] Training Loss: {train_loss:.4f}, F1 Score: {train_f1:.4f} | \"\n","              f\"Validation Loss: {avg_val_loss:.4f}, F1 Score: {val_f1:.4f}\")\n","\n","    end_time = time.time()\n","\n","    # Plotting\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(train_losses, label=\"Training Loss\", marker='o')\n","    plt.plot(val_losses, label=\"Validation Loss\", marker='x')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    print(f\"Training complete! Total time: {end_time - start_time:.2f} seconds\")\n","    return model"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"l11dgb8ei69T","executionInfo":{"status":"ok","timestamp":1732231931775,"user_tz":-60,"elapsed":1419723,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"dddab05e-fbff-499d-cd02-c2de1ea88e53"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/100] Training Loss: 0.4821, F1 Score: 0.0219 | Validation Loss: 0.2157, F1 Score: 0.0000\n","Epoch [2/100] Training Loss: 0.1402, F1 Score: 0.5918 | Validation Loss: 0.0950, F1 Score: 0.2036\n","Epoch [3/100] Training Loss: 0.0715, F1 Score: 0.8262 | Validation Loss: 0.0560, F1 Score: 0.5353\n","Epoch [4/100] Training Loss: 0.0460, F1 Score: 0.8632 | Validation Loss: 0.0409, F1 Score: 0.5996\n","Epoch [5/100] Training Loss: 0.0361, F1 Score: 0.8841 | Validation Loss: 0.0340, F1 Score: 0.7682\n","Epoch [6/100] Training Loss: 0.0309, F1 Score: 0.8812 | Validation Loss: 0.0304, F1 Score: 0.7787\n","Epoch [7/100] Training Loss: 0.0272, F1 Score: 0.8719 | Validation Loss: 0.0263, F1 Score: 0.8638\n","Epoch [8/100] Training Loss: 0.0244, F1 Score: 0.8587 | Validation Loss: 0.0238, F1 Score: 0.8886\n","Epoch [9/100] Training Loss: 0.0222, F1 Score: 0.8601 | Validation Loss: 0.0220, F1 Score: 0.8958\n","Epoch [10/100] Training Loss: 0.0205, F1 Score: 0.8529 | Validation Loss: 0.0201, F1 Score: 0.8982\n","Epoch [11/100] Training Loss: 0.0191, F1 Score: 0.8428 | Validation Loss: 0.0189, F1 Score: 0.9078\n","Epoch [12/100] Training Loss: 0.0178, F1 Score: 0.8399 | Validation Loss: 0.0184, F1 Score: 0.8916\n","Epoch [13/100] Training Loss: 0.0171, F1 Score: 0.8324 | Validation Loss: 0.0170, F1 Score: 0.8983\n","Epoch [14/100] Training Loss: 0.0163, F1 Score: 0.8360 | Validation Loss: 0.0167, F1 Score: 0.8985\n","Epoch [15/100] Training Loss: 0.0157, F1 Score: 0.8317 | Validation Loss: 0.0158, F1 Score: 0.9072\n","Epoch [16/100] Training Loss: 0.0152, F1 Score: 0.8338 | Validation Loss: 0.0152, F1 Score: 0.9078\n","Epoch [17/100] Training Loss: 0.0147, F1 Score: 0.8407 | Validation Loss: 0.0147, F1 Score: 0.8994\n","Epoch [18/100] Training Loss: 0.0143, F1 Score: 0.8309 | Validation Loss: 0.0145, F1 Score: 0.9059\n","Epoch [19/100] Training Loss: 0.0140, F1 Score: 0.8350 | Validation Loss: 0.0142, F1 Score: 0.8983\n","Epoch [20/100] Training Loss: 0.0138, F1 Score: 0.8285 | Validation Loss: 0.0138, F1 Score: 0.9065\n","Epoch [21/100] Training Loss: 0.0134, F1 Score: 0.8271 | Validation Loss: 0.0137, F1 Score: 0.9101\n","Epoch [22/100] Training Loss: 0.0133, F1 Score: 0.8346 | Validation Loss: 0.0134, F1 Score: 0.9021\n","Epoch [23/100] Training Loss: 0.0129, F1 Score: 0.8343 | Validation Loss: 0.0130, F1 Score: 0.9065\n","Epoch [24/100] Training Loss: 0.0129, F1 Score: 0.8309 | Validation Loss: 0.0129, F1 Score: 0.9083\n","Epoch [25/100] Training Loss: 0.0126, F1 Score: 0.8346 | Validation Loss: 0.0133, F1 Score: 0.8999\n","Epoch [26/100] Training Loss: 0.0125, F1 Score: 0.8367 | Validation Loss: 0.0143, F1 Score: 0.9033\n","Epoch [27/100] Training Loss: 0.0123, F1 Score: 0.8356 | Validation Loss: 0.0126, F1 Score: 0.9168\n","Epoch [28/100] Training Loss: 0.0122, F1 Score: 0.8320 | Validation Loss: 0.0120, F1 Score: 0.9032\n","Epoch [29/100] Training Loss: 0.0121, F1 Score: 0.8416 | Validation Loss: 0.0124, F1 Score: 0.9067\n","Epoch [30/100] Training Loss: 0.0121, F1 Score: 0.8340 | Validation Loss: 0.0124, F1 Score: 0.9107\n","Epoch [31/100] Training Loss: 0.0118, F1 Score: 0.8404 | Validation Loss: 0.0122, F1 Score: 0.9044\n","Epoch [32/100] Training Loss: 0.0119, F1 Score: 0.8416 | Validation Loss: 0.0127, F1 Score: 0.9099\n","Epoch [33/100] Training Loss: 0.0117, F1 Score: 0.8319 | Validation Loss: 0.0124, F1 Score: 0.8969\n","Epoch [34/100] Training Loss: 0.0117, F1 Score: 0.8332 | Validation Loss: 0.0124, F1 Score: 0.9120\n","Epoch [35/100] Training Loss: 0.0117, F1 Score: 0.8331 | Validation Loss: 0.0119, F1 Score: 0.9124\n","Epoch [36/100] Training Loss: 0.0114, F1 Score: 0.8381 | Validation Loss: 0.0118, F1 Score: 0.8999\n","Epoch [37/100] Training Loss: 0.0115, F1 Score: 0.8321 | Validation Loss: 0.0123, F1 Score: 0.8790\n","Epoch [38/100] Training Loss: 0.0115, F1 Score: 0.8349 | Validation Loss: 0.0115, F1 Score: 0.9091\n","Epoch [39/100] Training Loss: 0.0114, F1 Score: 0.8344 | Validation Loss: 0.0114, F1 Score: 0.8910\n","Epoch [40/100] Training Loss: 0.0112, F1 Score: 0.8395 | Validation Loss: 0.0115, F1 Score: 0.9091\n","Epoch [41/100] Training Loss: 0.0112, F1 Score: 0.8325 | Validation Loss: 0.0113, F1 Score: 0.9058\n","Epoch [42/100] Training Loss: 0.0112, F1 Score: 0.8364 | Validation Loss: 0.0115, F1 Score: 0.9065\n","Epoch [43/100] Training Loss: 0.0112, F1 Score: 0.8251 | Validation Loss: 0.0116, F1 Score: 0.9117\n","Epoch [44/100] Training Loss: 0.0112, F1 Score: 0.8382 | Validation Loss: 0.0112, F1 Score: 0.9135\n","Epoch [45/100] Training Loss: 0.0111, F1 Score: 0.8364 | Validation Loss: 0.0121, F1 Score: 0.9030\n","Epoch [46/100] Training Loss: 0.0111, F1 Score: 0.8309 | Validation Loss: 0.0117, F1 Score: 0.9152\n","Epoch [47/100] Training Loss: 0.0110, F1 Score: 0.8397 | Validation Loss: 0.0114, F1 Score: 0.8917\n","Epoch [48/100] Training Loss: 0.0109, F1 Score: 0.8404 | Validation Loss: 0.0114, F1 Score: 0.9032\n","Epoch [49/100] Training Loss: 0.0109, F1 Score: 0.8371 | Validation Loss: 0.0113, F1 Score: 0.8990\n","Epoch [50/100] Training Loss: 0.0109, F1 Score: 0.8333 | Validation Loss: 0.0113, F1 Score: 0.9182\n","Epoch [51/100] Training Loss: 0.0108, F1 Score: 0.8334 | Validation Loss: 0.0110, F1 Score: 0.8947\n","Epoch [52/100] Training Loss: 0.0108, F1 Score: 0.8326 | Validation Loss: 0.0111, F1 Score: 0.9076\n","Epoch [53/100] Training Loss: 0.0109, F1 Score: 0.8357 | Validation Loss: 0.0141, F1 Score: 0.8848\n","Epoch [54/100] Training Loss: 0.0108, F1 Score: 0.8333 | Validation Loss: 0.0112, F1 Score: 0.8975\n","Epoch [55/100] Training Loss: 0.0107, F1 Score: 0.8324 | Validation Loss: 0.0110, F1 Score: 0.9006\n","Epoch [56/100] Training Loss: 0.0108, F1 Score: 0.8353 | Validation Loss: 0.0107, F1 Score: 0.9026\n","Epoch [57/100] Training Loss: 0.0106, F1 Score: 0.8365 | Validation Loss: 0.0108, F1 Score: 0.9038\n","Epoch [58/100] Training Loss: 0.0107, F1 Score: 0.8385 | Validation Loss: 0.0114, F1 Score: 0.9133\n","Epoch [59/100] Training Loss: 0.0107, F1 Score: 0.8327 | Validation Loss: 0.0109, F1 Score: 0.9046\n","Epoch [60/100] Training Loss: 0.0105, F1 Score: 0.8384 | Validation Loss: 0.0119, F1 Score: 0.9006\n","Epoch [61/100] Training Loss: 0.0107, F1 Score: 0.8428 | Validation Loss: 0.0109, F1 Score: 0.9180\n","Epoch [62/100] Training Loss: 0.0106, F1 Score: 0.8341 | Validation Loss: 0.0106, F1 Score: 0.9040\n","Epoch [63/100] Training Loss: 0.0107, F1 Score: 0.8349 | Validation Loss: 0.0106, F1 Score: 0.9048\n","Epoch [64/100] Training Loss: 0.0105, F1 Score: 0.8377 | Validation Loss: 0.0107, F1 Score: 0.9135\n","Epoch [65/100] Training Loss: 0.0106, F1 Score: 0.8362 | Validation Loss: 0.0107, F1 Score: 0.9101\n","Epoch [66/100] Training Loss: 0.0106, F1 Score: 0.8390 | Validation Loss: 0.0112, F1 Score: 0.9078\n","Epoch [67/100] Training Loss: 0.0105, F1 Score: 0.8389 | Validation Loss: 0.0106, F1 Score: 0.8980\n","Epoch [68/100] Training Loss: 0.0104, F1 Score: 0.8368 | Validation Loss: 0.0117, F1 Score: 0.8649\n","Epoch [69/100] Training Loss: 0.0104, F1 Score: 0.8388 | Validation Loss: 0.0109, F1 Score: 0.9143\n","Epoch [70/100] Training Loss: 0.0105, F1 Score: 0.8387 | Validation Loss: 0.0107, F1 Score: 0.9070\n","Epoch [71/100] Training Loss: 0.0105, F1 Score: 0.8382 | Validation Loss: 0.0106, F1 Score: 0.8963\n","Epoch [72/100] Training Loss: 0.0106, F1 Score: 0.8319 | Validation Loss: 0.0109, F1 Score: 0.9018\n","Epoch [73/100] Training Loss: 0.0104, F1 Score: 0.8416 | Validation Loss: 0.0106, F1 Score: 0.8952\n","Epoch [74/100] Training Loss: 0.0104, F1 Score: 0.8299 | Validation Loss: 0.0106, F1 Score: 0.9187\n","Epoch [75/100] Training Loss: 0.0104, F1 Score: 0.8374 | Validation Loss: 0.0111, F1 Score: 0.9159\n","Epoch [76/100] Training Loss: 0.0103, F1 Score: 0.8354 | Validation Loss: 0.0113, F1 Score: 0.9109\n","Epoch [77/100] Training Loss: 0.0106, F1 Score: 0.8329 | Validation Loss: 0.0112, F1 Score: 0.9096\n","Epoch [78/100] Training Loss: 0.0103, F1 Score: 0.8401 | Validation Loss: 0.0108, F1 Score: 0.8944\n","Epoch [79/100] Training Loss: 0.0102, F1 Score: 0.8366 | Validation Loss: 0.0107, F1 Score: 0.9111\n","Epoch [80/100] Training Loss: 0.0103, F1 Score: 0.8377 | Validation Loss: 0.0107, F1 Score: 0.9156\n","Epoch [81/100] Training Loss: 0.0102, F1 Score: 0.8488 | Validation Loss: 0.0118, F1 Score: 0.9050\n","Epoch 00082: reducing learning rate of group 0 to 1.0000e-04.\n","Epoch [82/100] Training Loss: 0.0103, F1 Score: 0.8338 | Validation Loss: 0.0110, F1 Score: 0.9101\n","Epoch [83/100] Training Loss: 0.0090, F1 Score: 0.8588 | Validation Loss: 0.0100, F1 Score: 0.9153\n","Epoch [84/100] Training Loss: 0.0087, F1 Score: 0.8579 | Validation Loss: 0.0100, F1 Score: 0.9148\n","Epoch [85/100] Training Loss: 0.0086, F1 Score: 0.8575 | Validation Loss: 0.0099, F1 Score: 0.9116\n","Epoch [86/100] Training Loss: 0.0086, F1 Score: 0.8607 | Validation Loss: 0.0099, F1 Score: 0.9142\n","Epoch [87/100] Training Loss: 0.0085, F1 Score: 0.8583 | Validation Loss: 0.0099, F1 Score: 0.9132\n","Epoch [88/100] Training Loss: 0.0085, F1 Score: 0.8584 | Validation Loss: 0.0099, F1 Score: 0.9176\n","Epoch [89/100] Training Loss: 0.0085, F1 Score: 0.8631 | Validation Loss: 0.0098, F1 Score: 0.9142\n","Epoch [90/100] Training Loss: 0.0084, F1 Score: 0.8617 | Validation Loss: 0.0098, F1 Score: 0.9168\n","Epoch [91/100] Training Loss: 0.0084, F1 Score: 0.8586 | Validation Loss: 0.0099, F1 Score: 0.9129\n","Epoch [92/100] Training Loss: 0.0084, F1 Score: 0.8613 | Validation Loss: 0.0099, F1 Score: 0.9181\n","Epoch [93/100] Training Loss: 0.0084, F1 Score: 0.8653 | Validation Loss: 0.0098, F1 Score: 0.9106\n","Epoch [94/100] Training Loss: 0.0083, F1 Score: 0.8573 | Validation Loss: 0.0099, F1 Score: 0.9218\n","Epoch [95/100] Training Loss: 0.0084, F1 Score: 0.8626 | Validation Loss: 0.0098, F1 Score: 0.9142\n","Epoch [96/100] Training Loss: 0.0084, F1 Score: 0.8651 | Validation Loss: 0.0098, F1 Score: 0.9116\n","Epoch [97/100] Training Loss: 0.0083, F1 Score: 0.8596 | Validation Loss: 0.0099, F1 Score: 0.9231\n","Epoch [98/100] Training Loss: 0.0084, F1 Score: 0.8631 | Validation Loss: 0.0098, F1 Score: 0.9207\n","Epoch [99/100] Training Loss: 0.0084, F1 Score: 0.8583 | Validation Loss: 0.0098, F1 Score: 0.9207\n","Epoch [100/100] Training Loss: 0.0084, F1 Score: 0.8629 | Validation Loss: 0.0099, F1 Score: 0.9181\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x500 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training complete! Total time: 1419.10 seconds\n"]}],"source":["# Train the GatedCombination model using training and validation data\n","trained_model = train_gated_combination_model(\n","    X1_train,          # Updated source embeddings (after applying the GNN model)\n","    X2_train,          # Original source embeddings (before applying the GNN model)\n","    X3_train,          # Updated target embeddings (after applying the GNN model)\n","    X4_train,          # Original target embeddings (before applying the GNN model)\n","    tensor_score_train, # Ground truth labels for the training set (1 for matched pairs, 0 for unmatched pairs)\n","\n","    X1_val,            # Updated source embeddings for the validation set\n","    X2_val,            # Original source embeddings for the validation set\n","    X3_val,            # Updated target embeddings for the validation set\n","    X4_val,            # Original target embeddings for the validation set\n","    tensor_score_val,  # Ground truth labels for the validation set (1 for matched pairs, 0 for unmatched pairs)\n","\n","    epochs=100,        # Number of epochs (iterations over the entire training dataset)\n","    batch_size=32,     # Number of training samples processed in one forward/backward pass\n","    learning_rate=0.001, # Learning rate for the optimizer (controls step size during optimization)\n","    weight_decay=1e-5  # Weight decay (L2 regularization) to prevent overfitting\n",")"]},{"cell_type":"markdown","metadata":{"id":"uAmLuMtGW9c2"},"source":["# **Mappings Selector**"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"lnFtpUAfJQHl","executionInfo":{"status":"ok","timestamp":1732232045144,"user_tz":-60,"elapsed":1111,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Build an indexed dictionary for the source ontology classes\n","# src_class is the file path to the JSON file containing the source ontology classes\n","indexed_dict_src = build_indexed_dict(src_class)\n","\n","# Build an indexed dictionary for the target ontology classes\n","# tgt_class is the file path to the JSON file containing the target ontology classes\n","indexed_dict_tgt = build_indexed_dict(tgt_class)"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"beipwavuJQHl","executionInfo":{"status":"ok","timestamp":1732232045785,"user_tz":-60,"elapsed":290,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the candidate pairs from a Candidates CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(candidates_Prediction, index_col=0)\n","\n","# Extract the 'SrcEntity' column (source entity indices) and convert it to a NumPy array of integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)\n","\n","# Extract the 'TgtEntity' column (target entity indices) and convert it to a NumPy array of integers\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)\n","\n","# Convert the source entity indices to a PyTorch LongTensor\n","src_entity_tensor_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)\n","\n","# Convert the target entity indices to a PyTorch LongTensor\n","tgt_entity_tenso_or = torch.from_numpy(tensor_term2).type(torch.LongTensor)"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"ECLhmxyKJQHl","executionInfo":{"status":"ok","timestamp":1732232050866,"user_tz":-60,"elapsed":373,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Select rows from the updated source embeddings based on the indices in src_entity_tensor_o\n","X1_tt = select_rows_by_index(embeddings_src, src_entity_tensor_o)\n","\n","# Select rows from the original source embeddings based on the indices in src_entity_tensor_o\n","X2_tt = select_rows_by_index(x_src, src_entity_tensor_o)\n","\n","# Select rows from the updated target embeddings based on the indices in tgt_entity_tenso_or\n","X3_tt = select_rows_by_index(embeddings_tgt, tgt_entity_tenso_or)\n","\n","# Select rows from the original target embeddings based on the indices in tgt_entity_tenso_or\n","X4_tt = select_rows_by_index(x_tgt, tgt_entity_tenso_or)"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"UFP6OQR-7D4N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732232204463,"user_tz":-60,"elapsed":32739,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"616fdfe9-eaf4-49a8-98b7-2be8903b7109"},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting time: 12.90 seconds\n","Predictions saved to /content/gdrive/My Drive/BioGITOM-VLDB/Experiments/neoplas/BERT_Model_Choice/Results/neoplas_all_predictions_Mini.tsv\n"]}],"source":["# Generate predictions for candidate mappings using the trained GatedCombination model\n","Prediction_with_candidates(\n","    model=trained_model,             # The trained GatedCombination model used to evaluate similarity\n","    X1_tt=X1_tt,                     # Updated source embeddings (after applying the GIT model)\n","    X2_tt=X2_tt,                     # Original source embeddings (before applying the GIT model)\n","    X3_tt=X3_tt,                     # Updated target embeddings (after applying the GIT model)\n","    X4_tt=X4_tt,                     # Original target embeddings (before applying the GIT model)\n","    src_entity_tensor_o=src_entity_tensor_o,  # Tensor of source entity indices used for evaluation\n","    tgt_entity_tensor_o=tgt_entity_tenso_or,  # Tensor of target entity indices used for evaluation\n","    indexed_dict_src=indexed_dict_src,        # Dictionary mapping source entity indices to their URIs\n","    indexed_dict_tgt=indexed_dict_tgt,        # Dictionary mapping target entity indices to their URIs\n","    all_predictions_path=all_predictions_path # Path to save all predictions with similarity scores in TSV format\n",")"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"mEc12J-B7D4N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732232217414,"user_tz":-60,"elapsed":12953,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"7256809d-e767-4d57-f8e2-8bc03eef2a88"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Positive predictions: 2345\n"]}],"source":["# Filter the highest scoring predictions from the predictions file and save the results to a new file\n","matching_results_df = filter_highest_predictions(\n","    all_predictions_path,  # Path to the file containing all predictions with scores for all candidate pairs\n","    prediction_path        # Path where the filtered predictions with highest scores will be saved\n",")"]},{"cell_type":"markdown","metadata":{"id":"BIx74lNV7D4O"},"source":["# **Evaluation**"]},{"cell_type":"markdown","metadata":{"id":"Pp3IpBBfWn9m"},"source":["# Global metrics calculation"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"bkOewzXr7D4O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732232218425,"user_tz":-60,"elapsed":1014,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"abfbcefe-c6e0-404a-c6d9-0d2fff635db8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Correct Predictions: 1743\n","{'P': 0.743, 'R': 0.655, 'F1': 0.696}\n"]}],"source":["# Retrieve the indices of the ignored classes (from source and target ontologies)\n","ignored_class_index = get_ignored_class_index(src_onto)  # Get ignored class indices from source ontology\n","ignored_class_index.update(get_ignored_class_index(tgt_onto))  # Update with ignored class indices from target ontology\n","\n","# Read the predicted mappings from the prediction results file\n","preds = EntityMapping.read_table_mappings(prediction_path)\n","\n","# Read the reference mappings from the ground truth test file\n","refs = ReferenceMapping.read_table_mappings(f\"{dataset_dir}/refs_equiv/test.tsv\")\n","\n","# Filter the predicted mappings to remove any mappings that involve ignored classes\n","preds = remove_ignored_mappings(preds, ignored_class_index)\n","\n","# Compute the precision, recall, and F1-score by comparing predictions with the reference mappings\n","results = AlignmentEvaluator.f1(preds, refs)\n","\n","preds2 = [p.to_tuple() for p in preds]\n","refs2 = [r.to_tuple() for r in refs]\n","\n","correct= len(set(preds2).intersection(set(refs2)))\n","\n","print(f\"Number of Correct Predictions: {correct}\")\n","\n","# Print the computed precision, recall, and F1-score metrics\n","print(results)"]},{"cell_type":"markdown","metadata":{"id":"aECB6igZW04C"},"source":["# Ranked-based metrics calculation"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"-AK-jADkSbTa","executionInfo":{"status":"ok","timestamp":1732232218853,"user_tz":-60,"elapsed":430,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the candidate pairs from a Candidates CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(candidates_Rank, index_col=0)\n","\n","# Extract the 'SrcEntity' column (source entity indices) and convert it to a NumPy array of integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)\n","\n","# Extract the 'TgtEntity' column (target entity indices) and convert it to a NumPy array of integers\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)\n","\n","# Convert the source entity indices to a PyTorch LongTensor\n","src_entity_tensor_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)\n","\n","# Convert the target entity indices to a PyTorch LongTensor\n","tgt_entity_tenso_or = torch.from_numpy(tensor_term2).type(torch.LongTensor)"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"oyOzcLv-SbTb","executionInfo":{"status":"ok","timestamp":1732232219095,"user_tz":-60,"elapsed":244,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Select rows from the updated source embeddings based on the indices in src_entity_tensor_o\n","X1_tt = select_rows_by_index(embeddings_src, src_entity_tensor_o)\n","\n","# Select rows from the original source embeddings based on the indices in src_entity_tensor_o\n","X2_tt = select_rows_by_index(x_src, src_entity_tensor_o)\n","\n","# Select rows from the updated target embeddings based on the indices in tgt_entity_tenso_or\n","X3_tt = select_rows_by_index(embeddings_tgt, tgt_entity_tenso_or)\n","\n","# Select rows from the original target embeddings based on the indices in tgt_entity_tenso_or\n","X4_tt = select_rows_by_index(x_tgt, tgt_entity_tenso_or)"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"-O2f7X6cSb-m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732232249232,"user_tz":-60,"elapsed":30138,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"e642237b-d9c5-42d8-811c-d5c6acb1342c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting time: 11.67 seconds\n","Predictions saved to /content/gdrive/My Drive/BioGITOM-VLDB/Experiments/neoplas/BERT_Model_Choice/Results/neoplas_all_predictions_ranked_All_Mini.tsv\n"]}],"source":["# Perform ranking-based predictions using the trained GatedCombination model\n","# Generate predictions for candidate mappings using the trained GatedCombination model\n","Prediction_with_candidates(\n","    model=trained_model,             # The trained GatedCombination model used to evaluate similarity\n","    X1_tt=X1_tt,                     # Updated source embeddings (after applying the GIT model)\n","    X2_tt=X2_tt,                     # Original source embeddings (before applying the GIT model)\n","    X3_tt=X3_tt,                     # Updated target embeddings (after applying the GIT model)\n","    X4_tt=X4_tt,                     # Original target embeddings (before applying the GIT model)\n","    src_entity_tensor_o=src_entity_tensor_o,  # Tensor of source entity indices used for evaluation\n","    tgt_entity_tensor_o=tgt_entity_tenso_or,  # Tensor of target entity indices used for evaluation\n","    indexed_dict_src=indexed_dict_src,        # Dictionary mapping source entity indices to their URIs\n","    indexed_dict_tgt=indexed_dict_tgt,        # Dictionary mapping target entity indices to their URIs\n","    all_predictions_path=all_predictions_path_ranked, # Path where the ranked predictions will be saved in TSV format\n",")"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"_402seVv7D4O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732232264423,"user_tz":-60,"elapsed":15193,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"bae37a6c-7c31-4681-aa58-4bd7c2fbd6ca"},"outputs":[{"output_type":"stream","name":"stdout","text":["MRR and Hits@k Results:\n","{'MRR': 0.8642322515375558, 'Hits@k': {1: 0.7945925647765678, 5: 0.9481787457754413, 10: 0.971085242208036}}\n"]}],"source":["# Compute MRR and Hits@k metrics\n","# This function evaluates the predicted rankings against the reference mappings\n","results = compute_mrr_and_hits(\n","    reference_file=test_cands,             # Reference file with true ranks\n","    predicted_file=all_predictions_path_ranked,             # File containing predicted rankings\n","    output_file=formatted_predictions_path,    # File path to save formatted predictions\n","    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",")\n","\n","# Display the computed metrics\n","print(\"MRR and Hits@k Results:\")\n","print(results)  # Output the Mean Reciprocal Rank (MRR) and Hits@k metrics"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"wStfa4eZ7D4O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732232268131,"user_tz":-60,"elapsed":3710,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"d7775e5d-0669-4b92-c998-95cd6e238a12"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ranking Evaluation Results at K=1, 5, and 10:\n","{'MRR': 0.8642322515375558, 'Hits@1': 0.7945925647765678, 'Hits@5': 0.9481787457754413, 'Hits@10': 0.971085242208036}\n"]}],"source":["# Call the ranking evaluation function, passing the path to the formatted predictions file.\n","# Ks specifies the evaluation levels, checking if the correct target is within the top K candidates.\n","results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n","print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n","print(results)"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}