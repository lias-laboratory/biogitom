{"cells":[{"cell_type":"markdown","metadata":{"id":"MkAX88H3RNRW"},"source":["# **Package Installation**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SlL2v0xgmFJ-","outputId":"e086876b-3bc7-41ca-8f59-34e2f9fbd9b0","executionInfo":{"status":"ok","timestamp":1732224046952,"user_tz":-60,"elapsed":223269,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==2.0.0\n","  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.16.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n","  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n","  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n","  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n","  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n","  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n","  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.0.0 (from torch==2.0.0)\n","  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (75.1.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.45.0)\n","Collecting cmake (from triton==2.0.0->torch==2.0.0)\n","  Downloading cmake-3.31.0.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n","Collecting lit (from triton==2.0.0->torch==2.0.0)\n","  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n","Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m963.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading cmake-3.31.0.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.8/27.8 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, cmake, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.1+cpu\n","    Uninstalling torch-2.5.1+cpu:\n","      Successfully uninstalled torch-2.5.1+cpu\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.5.1+cpu requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\n","torchvision 0.20.1+cpu requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed cmake-3.31.0.1 lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 triton-2.0.0\n","Collecting torch-geometric==2.4.0\n","  Downloading torch_geometric-2.4.0-py3-none-any.whl.metadata (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (4.66.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (3.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (2.32.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (3.2.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (1.5.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.4.0) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric==2.4.0) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.4.0) (2024.8.30)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.4.0) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric==2.4.0) (3.5.0)\n","Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-geometric\n","Successfully installed torch-geometric-2.4.0\n","Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_scatter-2.1.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (494 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_sparse-0.6.18%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-cluster\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_cluster-1.6.3%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (751 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.3/751.3 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-spline-conv\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (208 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n","Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n","Installing collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster\n","Successfully installed torch-cluster-1.6.3+pt20cpu torch-scatter-2.1.2+pt20cpu torch-sparse-0.6.18+pt20cpu torch-spline-conv-1.2.2+pt20cpu\n","Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.13.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.5.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.9/208.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.4/319.4 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting deeponto\n","  Downloading deeponto-0.9.2-py3-none-any.whl.metadata (15 kB)\n","Collecting JPype1 (from deeponto)\n","  Downloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting yacs (from deeponto)\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deeponto) (2.0.0)\n","Collecting anytree (from deeponto)\n","  Downloading anytree-2.12.1-py3-none-any.whl.metadata (8.1 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from deeponto) (8.1.7)\n","Collecting dill (from deeponto)\n","  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from deeponto) (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deeponto) (1.26.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deeponto) (1.5.2)\n","Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (from deeponto) (4.46.2)\n","Collecting datasets (from deeponto)\n","  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.7.5)\n","Collecting pprintpp (from deeponto)\n","  Downloading pprintpp-0.4.0-py2.py3-none-any.whl.metadata (7.9 kB)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.4.2)\n","Collecting lxml (from deeponto)\n","  Downloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n","Collecting textdistance (from deeponto)\n","  Downloading textdistance-4.6.3-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from deeponto) (7.7.1)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from deeponto) (5.5.6)\n","Collecting enlighten (from deeponto)\n","  Downloading enlighten-1.12.4-py2.py3-none-any.whl.metadata (18 kB)\n","Collecting rdflib (from deeponto)\n","  Downloading rdflib-7.1.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from deeponto) (3.9.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anytree->deeponto) (1.16.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (18.0.0)\n","Collecting dill (from deeponto)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (4.66.6)\n","Collecting xxhash (from datasets->deeponto)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets->deeponto)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->deeponto)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (3.11.7)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (0.26.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->deeponto) (6.0.2)\n","Collecting blessed>=1.17.7 (from enlighten->deeponto)\n","  Downloading blessed-1.20.0-py2.py3-none-any.whl.metadata (13 kB)\n","Collecting prefixed>=0.3.2 (from enlighten->deeponto)\n","  Downloading prefixed-0.9.0-py2.py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (0.2.0)\n","Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (7.34.0)\n","Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (5.7.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (6.1.12)\n","Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->deeponto) (6.3.3)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->deeponto) (3.6.10)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->deeponto) (3.0.13)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->deeponto) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->deeponto) (2024.11.6)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->deeponto) (2024.2)\n","Collecting isodate<1.0.0,>=0.7.2 (from rdflib->deeponto)\n","  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib->deeponto) (3.2.0)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deeponto) (1.13.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deeponto) (3.5.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (0.13.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (2.9.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.1.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (75.1.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->deeponto) (3.4.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (1.13.1)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->deeponto) (2.0.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->deeponto) (0.45.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deeponto) (3.31.0.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deeponto) (18.1.8)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (0.20.3)\n","Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]->deeponto) (1.1.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->transformers[torch]->deeponto) (5.9.5)\n","Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.7->enlighten->deeponto) (0.2.13)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.3.1)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (5.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (0.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->deeponto) (1.18.0)\n","Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->deeponto)\n","  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (5.1.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (3.0.48)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (2.18.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->deeponto) (4.9.0)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.2.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->deeponto) (2024.8.30)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->deeponto) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->deeponto) (0.1.5)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (0.20.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (7.0.5)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.5.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy->deeponto) (3.0.2)\n","Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->deeponto) (5.7.2)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->deeponto) (24.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deeponto) (1.3.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->deeponto) (0.8.4)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel->deeponto) (4.3.6)\n","Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.2.1)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (23.1.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (5.10.4)\n","Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (7.16.4)\n","Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.6.0)\n","Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.3)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.18.1)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.21.0)\n","Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.1.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel->deeponto) (0.7.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (3.0.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->deeponto) (1.14.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (0.1.2)\n","Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.2.4)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.12.3)\n","Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.2.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.7.1)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.3.0)\n","Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.0.2)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.10.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.5.1)\n","Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.4.0)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.20.0)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.23.0)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (21.2.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.5.1)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.21.0)\n","Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.24.0)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.17.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.6)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.22)\n","Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.7.1)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.2.2)\n","Downloading deeponto-0.9.2-py3-none-any.whl (89.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading anytree-2.12.1-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading enlighten-1.12.4-py2.py3-none-any.whl (41 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jpype1-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.8/493.8 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n","Downloading rdflib-7.1.1-py3-none-any.whl (562 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m562.4/562.4 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading textdistance-4.6.3-py3-none-any.whl (31 kB)\n","Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n","Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading prefixed-0.9.0-py2.py3-none-any.whl (13 kB)\n","Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: prefixed, pprintpp, yacs, xxhash, textdistance, lxml, JPype1, jedi, isodate, fsspec, dill, blessed, anytree, rdflib, multiprocess, enlighten, datasets, deeponto\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","Successfully installed JPype1-1.5.1 anytree-2.12.1 blessed-1.20.0 datasets-3.1.0 deeponto-0.9.2 dill-0.3.8 enlighten-1.12.4 fsspec-2024.9.0 isodate-0.7.2 jedi-0.19.2 lxml-5.3.0 multiprocess-0.70.16 pprintpp-0.4.0 prefixed-0.9.0 rdflib-7.1.1 textdistance-4.6.3 xxhash-3.5.0 yacs-0.1.8\n","/bin/bash: line 1: username: No such file or directory\n"]}],"source":["# We assume that PyTorch is already installed in the environment.\n","# If not, this command installs it.\n","!pip install torch==2.0.0\n","\n","# Install PyTorch Geometric, a library for creating graph neural networks using PyTorch.\n","!pip install torch-geometric==2.4.0\n","\n","# Import PyTorch to access its functionalities.\n","import torch\n","\n","# Install additional PyTorch Geometric dependencies for graph processing (scatter, sparse, cluster, spline-conv).\n","# These packages enable operations like sparse tensors and convolutions on graphs.\n","!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","\n","# Reinstall PyTorch Geometric to ensure all dependencies are correctly loaded.\n","!pip install torch-geometric\n","\n","# Retrieve the installed version of PyTorch to ensure compatibility with other packages.\n","torchversion = torch.__version__\n","\n","# Install the latest version of PyTorch Geometric directly from the GitHub repository.\n","# This allows access to the most recent updates and features for graph-based neural networks.\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","\n","# Install DeepOnto, a package specifically designed for ontology matching, particularly useful in biomedical applications.\n","!pip install deeponto\n","\n","# Install a custom version of DeepOnto from a GitHub repository.\n","# The '<username>' part should be replaced with the actual GitHub username of the repository maintainer.\n","!pip install git+https://github.com/<username>/deeponto.git\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"HPAlAgjLMVhw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e26257fc-8132-45d5-cbcc-3069954fceb9","executionInfo":{"status":"ok","timestamp":1732224101370,"user_tz":-60,"elapsed":54427,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Please enter the maximum memory located to JVM [8g]: 8g\n","\n"]}],"source":["# Import pandas for data manipulation and analysis, such as loading, processing, and saving tabular data.\n","import pandas as pd\n","\n","# Import pickle for saving and loading serialized objects (e.g., trained models or preprocessed data).\n","import pickle\n","\n","# Import function to convert a directed graph to an undirected one, useful for certain graph algorithms.\n","from torch_geometric.utils import to_undirected\n","\n","# Import optimizer module from PyTorch for training models using gradient-based optimization techniques.\n","import torch.optim as optim\n","\n","# Import PyTorch's modules for defining neural network architectures and operations:\n","from torch.nn import (\n","    Linear,       # For linear transformations (dense layers).\n","    Sequential,   # For stacking layers sequentially.\n","    BatchNorm1d,  # For normalizing input within mini-batches.\n","    PReLU,        # Parametric ReLU activation function.\n","    Dropout       # For regularization by randomly dropping connections during training.\n",")\n","\n","# Import functional API from PyTorch for operations like activations and loss functions.\n","import torch.nn.functional as F\n","\n","# Import Matplotlib for visualizations, such as plotting training loss curves.\n","import matplotlib.pyplot as plt\n","\n","# Import PyTorch Geometric's graph convolutional layers:\n","from torch_geometric.nn import GCNConv, GINConv\n","\n","# Import pooling operations for aggregating node embeddings to graph-level representations:\n","from torch_geometric.nn import global_mean_pool, global_add_pool\n","\n","# Import NumPy for numerical operations, such as working with arrays and matrices.\n","import numpy as np\n","\n","# Import time module for measuring execution time of code blocks.\n","import time\n","\n","# Import typing module for specifying types in function arguments and return values.\n","from typing import Optional, Tuple, Union, Callable\n","\n","# Import PyTorch's DataLoader and TensorDataset for handling data batching and loading during training.\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","# Import PyTorch's Parameter class for defining learnable parameters in custom models.\n","from torch.nn import Parameter\n","\n","# Import math module for performing mathematical computations.\n","import math\n","\n","# Import Tensor type from PyTorch for defining and manipulating tensors.\n","from torch import Tensor\n","\n","# Import PyTorch's nn module for defining and building neural network architectures.\n","import torch.nn as nn\n","\n","# Import initialization utilities from PyTorch Geometric for resetting weights and biases in layers.\n","from torch_geometric.nn.inits import reset\n","\n","# Import the base class for defining message-passing layers in graph neural networks (GNNs).\n","from torch_geometric.nn.conv import MessagePassing\n","\n","# Import linear transformation utilities for creating dense representations in graph models.\n","from torch_geometric.nn.dense.linear import Linear\n","\n","# Import typing utilities for defining adjacency matrices and tensor types specific to PyTorch Geometric.\n","from torch_geometric.typing import Adj, OptTensor, PairTensor, SparseTensor\n","\n","# Import softmax function for normalizing attention scores in GNNs.\n","from torch_geometric.utils import softmax\n","\n","# Import initialization utilities for weight initialization (e.g., Glorot initialization).\n","from torch_geometric.nn.inits import glorot, zeros\n","\n","# Import F1 score metric from scikit-learn for evaluating model performance in binary/multi-class tasks.\n","from sklearn.metrics import f1_score\n","\n","# Import JSON module for reading and writing JSON files, useful for storing configuration or ontology data.\n","import json\n","\n","# Import Ontology class from DeepOnto for representing and manipulating ontologies in the pipeline.\n","from deeponto.onto import Ontology\n","\n","# Import tools from DeepOnto for handling Ontology Alignment Evaluation Initiative (OAEI) tasks.\n","from deeponto.align.oaei import *\n","\n","# Import evaluation tools from DeepOnto for assessing alignment results using metrics like precision, recall, and F1.\n","from deeponto.align.evaluation import AlignmentEvaluator\n","\n","# Import mapping utilities from DeepOnto for working with reference mappings and entity pairs.\n","from deeponto.align.mapping import ReferenceMapping, EntityMapping\n","\n","# Import utility function for reading tables (e.g., TSV, CSV) from DeepOnto.\n","from deeponto.utils import read_table\n","\n","# Importing the train_test_split function from sklearn's model_selection module.\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"-abbBHOoRdWl"},"source":["# **Paths Definition**"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AVgl_Bb42naS","outputId":"ac91b95d-d6d6-4ef2-e3a8-59ceba232559","executionInfo":{"status":"ok","timestamp":1732224123574,"user_tz":-60,"elapsed":22212,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# Importing the 'drive' module from Google Colab to interact with Google Drive\n","from google.colab import drive\n","\n","# Mount the user's Google Drive to the Colab environment\n","# After running this, a link will appear to authorize access, and Google Drive will be mounted at '/content/gdrive'\n","drive.mount('/content/gdrive')\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"36ttssQ3W7cx","executionInfo":{"status":"ok","timestamp":1732224123574,"user_tz":-60,"elapsed":6,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Define the source ontology name\n","src_ent = \"snomed.neoplas\"\n","\n","# Define the target ontology name\n","tgt_ent = \"ncit.neoplas\"\n","\n","# Define the task name for this ontology matching process\n","task = \"neoplas\"\n","\n","# Define the weight for the training data\n","# This weight is likely used to balance the training process, giving more emphasis to certain examples.\n","# For instance, a weight of 10.0 could be applied to penalize errors in certain types of predictions more heavily.\n","weight_train = 10.0\n","\n","# Define the similarity threshold for validating matches\n","thres = 0.2"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"SJpvkdwVSQye","executionInfo":{"status":"ok","timestamp":1732224123574,"user_tz":-60,"elapsed":5,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["dir = f\"/content/gdrive/My Drive/BioGITOM-VLDB/Experiments/{task}\"\n","\n","dataset=\"/content/gdrive/My Drive/BioGITOM-VLDB/\"\n","\n","# Define the directory for the dataset containing source and target ontologies\n","dataset_dir = f\"{dataset}/Datasets/{task}\"\n","\n","# Define the data directory for storing embeddings, adjacency matrices, and related files\n","data_dir = f\"{dir}/Data\"\n","\n","\n","# Define the directory for storing the results\n","results_dir = f\"{dir}/BERT_Model_Choice/Results\""]},{"cell_type":"code","execution_count":6,"metadata":{"id":"eFDNSFef23er","executionInfo":{"status":"ok","timestamp":1732224148520,"user_tz":-60,"elapsed":24951,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Load the Source ontology using the Ontology class from DeepOnto\n","# This initializes the source ontology by loading its .owl file.\n","src_onto = Ontology(f\"{dataset_dir}/{src_ent}.owl\")\n","\n","# Load the Target ontology using the Ontology class from DeepOnto\n","# This initializes the target ontology by loading its .owl file.\n","tgt_onto = Ontology(f\"{dataset_dir}/{tgt_ent}.owl\")\n","\n","# Define the file path for the Source embeddings CSV file\n","# Embeddings for the source ontology entities are stored in this file.\n","src_Emb = f\"{data_dir}/{src_ent}_All_Mini_emb.csv\"\n","\n","# Define the file path for the Target embeddings CSV file\n","# Embeddings for the target ontology entities are stored in this file.\n","tgt_Emb = f\"{data_dir}/{tgt_ent}_All_Mini_emb.csv\"\n","\n","# Define the file path for the Source adjacency matrix\n","# This file represents the relationships (edges) between entities in the source ontology.\n","src_Adjacence = f\"{data_dir}/{src_ent}_adjacence.csv\"\n","\n","# Define the file path for the Target adjacency matrix\n","# This file represents the relationships (edges) between entities in the target ontology.\n","tgt_Adjacence = f\"{data_dir}/{tgt_ent}_adjacence.csv\"\n","\n","# Define the file path for the JSON file containing the Source ontology class labels\n","# This file maps the source ontology entities to their labels or names.\n","src_class = f\"{data_dir}/{src_ent}_classes.json\"\n","\n","# Define the file path for the JSON file containing the Target ontology class labels\n","# This file maps the target ontology entities to their labels or names.\n","tgt_class = f\"{data_dir}/{tgt_ent}_classes.json\"\n","\n","# Define the file path for the train data\n","train_file = f\"{data_dir}/{task}_train_100.csv\"\n","\n","# Define the file path for the test data\n","# The test file contains reference mappings (ground truth) between the source and target ontologies.\n","test_file = f\"{dataset_dir}/refs_equiv/test.tsv\"\n","\n","# Define the file path for the candidate mappings used during testing\n","# This file includes the candidate pairs (source and target entities) for ranking and evaluation.\n","test_cands = f\"{dataset_dir}/refs_equiv/test.cands.tsv\"\n","\n","# Define the file path for the candidate mappings between Source to Target entities\n","# This file contains cleaned, combined, and encoded candidates used for predictions.\n","candidates_Prediction = f\"{data_dir}/{task}_candidates_prediction.csv\"\n","\n","# Define the file path for the candidate mappings between Source to Target entities for ranking-based metrics\n","# This file is used to compute ranking-based metrics like MRR and Hits@k.\n","candidates_Rank = f\"{data_dir}/{task}_candidates.csv\"\n","\n","# Define the path where the prediction results will be saved in TSV format\n","# This file will store the final predictions (mappings) between source and target entities.\n","prediction_path = f\"{results_dir}/{task}_matching_results_All_Mini.tsv\"\n","\n","# Define the path where all prediction results will be saved in TSV format\n","# This file will store detailed prediction results, including all candidate scores.\n","all_predictions_path = f\"{results_dir}/{task}_all_predictions_Mini.tsv\"\n","\n","# Define the path where all ranking prediction results will be saved in TSV format\n","# This file will store predictions sorted by rank based on their scores.\n","all_predictions_path_ranked = f\"{results_dir}/{task}_all_predictions_ranked_All_Mini.tsv\"\n","\n","# Define the path where formatted ranking predictions will be saved in TSV format\n","# This file will contain predictions formatted for evaluation using ranking-based metrics.\n","formatted_predictions_path = f\"{results_dir}/{task}_formatted_predictions_All_Mini.tsv\""]},{"cell_type":"markdown","metadata":{"id":"zqEXsgPGMVhw"},"source":["# **GIT Architecture**\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"A_d6XCsUMVhx","executionInfo":{"status":"ok","timestamp":1732224148520,"user_tz":-60,"elapsed":17,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# RGIT class definition which inherits from PyTorch Geometric's MessagePassing class\n","class RGIT(MessagePassing):\n","\n","    _alpha: OptTensor  # Define _alpha as an optional tensor for storing attention weights\n","\n","    def __init__(\n","        self,\n","        nn: Callable,  # Neural network to be used in the final layer of the GNN\n","        in_channels: Union[int, Tuple[int, int]],  # Input dimension, can be a single or pair of integers\n","        out_channels: int,  # Output dimension of the GNN\n","        eps: float = 0.,  # GIN parameter: epsilon for GIN aggregation\n","        train_eps: bool = False,  # GIN parameter: whether epsilon should be learnable\n","        heads: int = 1,  # Transformer parameter: number of attention heads\n","        dropout: float = 0.,  # Dropout rate for attention weights\n","        edge_dim: Optional[int] = None,  # Dimension for edge attributes (optional)\n","        bias: bool = True,  # Whether to use bias in linear layers\n","        root_weight: bool = True,  # GIN parameter: whether to apply root weight in aggregation\n","        **kwargs,  # Additional arguments passed to the parent class\n","    ):\n","        # Set the aggregation type to 'add' and initialize the parent class with node_dim=0\n","        kwargs.setdefault('aggr', 'add')\n","        super().__init__(node_dim=0, **kwargs)\n","\n","        # Initialize input/output dimensions, neural network, and GIN/transformer parameters\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.nn = nn  # Neural network used by the GNN\n","        self.initial_eps = eps  # Initial value of epsilon for GIN\n","\n","        # Set epsilon to be learnable or fixed\n","        if train_eps:\n","            self.eps = torch.nn.Parameter(torch.empty(1))  # Learnable epsilon\n","        else:\n","            self.register_buffer('eps', torch.empty(1))  # Non-learnable epsilon (fixed)\n","\n","        # Initialize transformer-related parameters\n","        self.heads = heads\n","        self.dropout = dropout\n","        self.edge_dim = edge_dim\n","        self._alpha = None  # Placeholder for attention weights\n","\n","        # Handle case where in_channels is a single integer or a tuple\n","        if isinstance(in_channels, int):\n","            in_channels = (in_channels, in_channels)\n","\n","        # Define the linear layers for key, query, and value for the transformer mechanism\n","        self.lin_key = Linear(in_channels[0], heads * out_channels)\n","        self.lin_query = Linear(in_channels[1], heads * out_channels)\n","        self.lin_value = Linear(in_channels[0], heads * out_channels)\n","\n","        # Define linear transformation for edge embeddings if provided\n","        if edge_dim is not None:\n","            self.lin_edge = Linear(edge_dim, heads * out_channels, bias=False)\n","        else:\n","            self.lin_edge = self.register_parameter('lin_edge', None)\n","\n","        # Reset all parameters to their initial values\n","        self.reset_parameters()\n","\n","    # Function to reset model parameters\n","    def reset_parameters(self):\n","        super().reset_parameters()  # Call parent class reset method\n","        self.lin_key.reset_parameters()  # Reset key linear layer\n","        self.lin_query.reset_parameters()  # Reset query linear layer\n","        self.lin_value.reset_parameters()  # Reset value linear layer\n","        if self.edge_dim:\n","            self.lin_edge.reset_parameters()  # Reset edge linear layer if used\n","        reset(self.nn)  # Reset the neural network provided\n","        self.eps.data.fill_(self.initial_eps)  # Initialize epsilon with the starting value\n","\n","    # Forward function defining how the input data flows through the model\n","    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj,\n","                edge_attr: OptTensor = None, return_attention_weights=None):\n","        # Unpack number of heads and output channels\n","        H, C = self.heads, self.out_channels\n","\n","        # If x is a tensor, treat it as a pair of tensors (source and target embeddings)\n","        if isinstance(x, Tensor):\n","            x: PairTensor = (x, x)\n","\n","        # Extract source node embeddings\n","        x_t = x[0]\n","\n","        # Apply linear transformations and reshape query, key, and value for multi-head attention\n","        query = self.lin_query(x[1]).view(-1, H, C)\n","        key = self.lin_key(x[0]).view(-1, H, C)\n","        value = self.lin_value(x[0]).view(-1, H, C)\n","\n","        # Propagate messages through the graph using the propagate function\n","        out = self.propagate(edge_index, query=query, key=key, value=value,\n","                             edge_attr=edge_attr, size=None)\n","\n","        # Retrieve attention weights and reset them\n","        alpha = self._alpha\n","        self._alpha = None  # Reset _alpha after use\n","        out = out.mean(dim=1)  # Take the mean over all attention heads\n","\n","        # Apply GIN aggregation by adding epsilon-scaled original node embeddings\n","        out = out + (1 + self.eps) * x_t\n","        return self.nn(out)  # Pass through the neural network\n","\n","    # Message passing function which calculates attention and combines messages\n","    def message(self, query_i: Tensor, key_j: Tensor, value_j: Tensor,\n","                edge_attr: OptTensor, index: Tensor, ptr: OptTensor,\n","                size_i: Optional[int]) -> Tensor:\n","        # If edge attributes are used, apply linear transformation and add them to the key\n","        if self.lin_edge is not None:\n","            assert edge_attr is not None\n","            edge_attr = self.lin_edge(edge_attr).view(-1, self.heads, self.out_channels)\n","            key_j = key_j + edge_attr\n","\n","        # Calculate attention (alpha) using the dot product between query and key\n","        alpha = (query_i * key_j).sum(dim=-1) / math.sqrt(self.out_channels)\n","        alpha = softmax(alpha, index, ptr, size_i)  # Apply softmax to normalize attention\n","        self._alpha = alpha  # Store attention weights\n","        alpha = F.dropout(alpha, p=self.dropout, training=self.training)  # Apply dropout\n","\n","        # Calculate the output message by applying attention to the value\n","        out = value_j\n","        if edge_attr is not None:\n","            out = out + edge_attr  # Add edge embeddings to the output if present\n","        out = out * alpha.view(-1, self.heads, 1)  # Scale by attention weights\n","        return out\n","\n","    # String representation function for debugging or printing\n","    def __repr__(self) -> str:\n","        return (f'{self.__class__.__name__}({self.in_channels}, '\n","                f'{self.out_channels}, heads={self.heads})')"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"qwFv6RgHmGCf","executionInfo":{"status":"ok","timestamp":1732224148521,"user_tz":-60,"elapsed":16,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Define the RGIT_mod class, a multi-layer GNN that uses both RGIT and linear layers\n","class RGIT_mod(torch.nn.Module):\n","    \"\"\"Multi-layer RGIT with optional linear layers\"\"\"\n","\n","    # Initialize the model with hidden dimension, number of RGIT layers, and number of linear layers\n","    def __init__(self, dim_h, num_layers, num_linear_layers=1):\n","        super(RGIT_mod, self).__init__()\n","        self.num_layers = num_layers  # Number of RGIT layers\n","        self.num_linear_layers = num_linear_layers  # Number of linear layers\n","        self.linears = torch.nn.ModuleList()  # List to store linear layers\n","        self.rgit_layers = torch.nn.ModuleList()  # List to store RGIT layers\n","\n","        # Create a list of Linear and PReLU layers (for encoding entity names)\n","        for _ in range(num_linear_layers):\n","            self.linears.append(Linear(dim_h, dim_h))  # Linear transformation layer\n","            self.linears.append(PReLU(num_parameters=dim_h))  # Parametric ReLU activation function\n","\n","        # Create a list of RGIT layers\n","        for _ in range(num_layers):\n","            self.rgit_layers.append(RGIT(  # Each RGIT layer contains a small MLP with Linear and PReLU\n","                Sequential(Linear(dim_h, dim_h), PReLU(num_parameters=dim_h),\n","                           Linear(dim_h, dim_h), PReLU(num_parameters=dim_h)), dim_h, dim_h))\n","\n","    # Forward pass through the model\n","    def forward(self, x, edge_index):\n","        # Apply the linear layers first to the input\n","        for layer in self.linears:\n","            x = layer(x)\n","\n","        # Then apply the RGIT layers for message passing\n","        for layer in self.rgit_layers:\n","            x = layer(x, edge_index)\n","\n","        return x  # Return the final node embeddings after all layers\n"]},{"cell_type":"markdown","metadata":{"id":"zxCn5ztKVztw"},"source":["# **Gated Network Architecture**"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"7MKQUv7o7zay","executionInfo":{"status":"ok","timestamp":1732224148521,"user_tz":-60,"elapsed":14,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Define the GatedCombination class for combining two pairs of embeddings using a gating mechanism\n","class GatedCombination(nn.Module):\n","    def __init__(self, input_dim):\n","        \"\"\"\n","        Initialize the GatedCombination model.\n","\n","        Args:\n","            input_dim (int): The dimensionality of the input embeddings (x1, x2, x3, x4).\n","        \"\"\"\n","        super(GatedCombination, self).__init__()\n","\n","        # Define a linear layer (gate) for combining embeddings x1 and x2 (first pair)\n","        self.gate_A_fc = nn.Linear(input_dim, input_dim)\n","\n","        # Define a linear layer (gate) for combining embeddings x3 and x4 (second pair)\n","        self.gate_B_fc = nn.Linear(input_dim, input_dim)\n","\n","        # A final fully connected layer that outputs a single neuron (binary classification)\n","        self.fc = nn.Linear(1, 1)\n","\n","    def forward(self, x1, x2, x3, x4):\n","        \"\"\"\n","        Forward pass through the gating mechanism and cosine similarity.\n","\n","        Args:\n","            x1 (torch.Tensor): First set of embeddings (source embeddings after update).\n","            x2 (torch.Tensor): Second set of embeddings (original source embeddings).\n","            x3 (torch.Tensor): Third set of embeddings (target embeddings after update).\n","            x4 (torch.Tensor): Fourth set of embeddings (original target embeddings).\n","\n","        Returns:\n","            torch.Tensor: Output of the model (probability score for binary classification).\n","        \"\"\"\n","        # Compute gate values for the first pair (x1 and x2) using a sigmoid activation\n","        gate_values1 = torch.sigmoid(self.gate_A_fc(x1))\n","\n","        # Combine x1 and x2 using the gate values\n","        # The result is a weighted combination of x1 and x2\n","        a = x1 * gate_values1 + x2 * (1 - gate_values1)\n","\n","        # Compute gate values for the second pair (x3 and x4) using a sigmoid activation\n","        gate_values2 = torch.sigmoid(self.gate_B_fc(x3))\n","\n","        # Combine x3 and x4 using the gate values\n","        # The result is a weighted combination of x3 and x4\n","        b = x3 * gate_values2 + x4 * (1 - gate_values2)\n","\n","        # Compute cosine similarity between the combined vectors a and b\n","        x = torch.cosine_similarity(a, b, dim=1)\n","\n","        # Pass the cosine similarity result through a fully connected layer (fc) for classification\n","        # Use a sigmoid activation to output a probability for binary classification\n","        out = torch.sigmoid(self.fc(x.unsqueeze(1)))  # unsqueeze(1) to match the input shape for the fc layer\n","        return out\n","\n"]},{"cell_type":"code","source":["class WeightedBCELoss(nn.Module):\n","    def __init__(self, pos_weight):\n","        \"\"\"\n","        Weighted Binary Cross-Entropy Loss.\n","\n","        Args:\n","            pos_weight (float): Weight for the positive class.\n","        \"\"\"\n","        super(WeightedBCELoss, self).__init__()\n","        self.pos_weight = pos_weight\n","\n","    def forward(self, outputs, targets):\n","        \"\"\"\n","        Args:\n","            outputs (torch.Tensor): Predicted probabilities from the model (after sigmoid).\n","            targets (torch.Tensor): Ground truth labels (0 or 1).\n","\n","        Returns:\n","            torch.Tensor: Computed weighted binary cross-entropy loss.\n","        \"\"\"\n","        # Compute weighted BCE loss\n","        loss = - (self.pos_weight * targets * torch.log(outputs + 1e-8) +\n","                  (1 - targets) * torch.log(1 - outputs + 1e-8))\n","        return loss.mean()"],"metadata":{"id":"PCzq6hHCD8vg","executionInfo":{"status":"ok","timestamp":1732224148521,"user_tz":-60,"elapsed":13,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","execution_count":11,"metadata":{"id":"4kO42TTCqQZ8","executionInfo":{"status":"ok","timestamp":1732224148521,"user_tz":-60,"elapsed":12,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["class FocalLoss(nn.Module):\n","    def __init__(self, alpha=0.25, gamma=2):\n","        \"\"\"\n","        Focal Loss for binary classification.\n","\n","        Args:\n","            alpha (float): Balancing factor for positive/negative classes.\n","            gamma (float): Focusing parameter for hard examples.\n","        \"\"\"\n","        super(FocalLoss, self).__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","\n","    def forward(self, outputs, targets):\n","        \"\"\"\n","        Args:\n","            outputs (torch.Tensor): Predicted probabilities from the model (after sigmoid).\n","            targets (torch.Tensor): Ground truth labels (0 or 1).\n","\n","        Returns:\n","            torch.Tensor: Computed focal loss.\n","        \"\"\"\n","        # Compute binary cross-entropy loss\n","        bce_loss = F.binary_cross_entropy(outputs, targets, reduction='none')\n","\n","        # Compute modulating factor (1 - p_t)^gamma\n","        pt = torch.where(targets == 1, outputs, 1 - outputs)  # pt = p if y==1 else 1-p\n","        modulating_factor = (1 - pt) ** self.gamma\n","\n","        # Apply alpha and modulating factor\n","        focal_loss = self.alpha * modulating_factor * bce_loss\n","        return focal_loss.mean()"]},{"cell_type":"markdown","metadata":{"id":"aLJ5j9FNMVhy"},"source":["# **Utility functions**"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"k0L86DgUQjMU","executionInfo":{"status":"ok","timestamp":1732224148521,"user_tz":-60,"elapsed":11,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def adjacency_matrix_to_undirected_edge_index(adjacency_matrix):\n","    \"\"\"\n","    Converts an adjacency matrix into an undirected edge index for use in graph-based neural networks.\n","\n","    Args:\n","        adjacency_matrix: A 2D list or array representing the adjacency matrix of a graph.\n","\n","    Returns:\n","        edge_index_undirected: A PyTorch tensor representing the undirected edges.\n","    \"\"\"\n","    # Convert each element in the adjacency matrix to an integer (from boolean or float)\n","    adjacency_matrix = [[int(element) for element in sublist] for sublist in adjacency_matrix]\n","\n","    # Convert the adjacency matrix into a PyTorch LongTensor (used for indexing)\n","    edge_index = torch.tensor(adjacency_matrix, dtype=torch.long)\n","\n","    # Transpose the edge_index tensor so that rows represent edges in the form [source, target]\n","    edge_index = edge_index.t().contiguous()\n","\n","    # Convert the directed edge_index into an undirected edge_index, meaning both directions are added (i.e., (i, j) and (j, i))\n","    edge_index_undirected = to_undirected(edge_index)\n","\n","    return edge_index_undirected  # Return the undirected edge index"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"YvmOxkLcpf9w","executionInfo":{"status":"ok","timestamp":1732224148522,"user_tz":-60,"elapsed":12,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def build_indexed_dict(file_path):\n","    \"\"\"\n","    Builds a dictionary with numeric indexes for each key from a JSON file.\n","\n","    Args:\n","        file_path (str): The path to the JSON file.\n","\n","    Returns:\n","        indexed_dict (dict): A new dictionary where each key from the JSON file is assigned a numeric index.\n","    \"\"\"\n","    # Load the JSON file into a Python dictionary\n","    with open(file_path, 'r') as file:\n","        data = json.load(file)\n","\n","    # Create a new dictionary with numeric indexes as keys and the original JSON keys as values\n","    indexed_dict = {index: key for index, key in enumerate(data.keys())}\n","\n","    return indexed_dict  # Return the newly created dictionary"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"QgFINoPGl9Wg","executionInfo":{"status":"ok","timestamp":1732224148523,"user_tz":-60,"elapsed":12,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def select_rows_by_index(embedding_vector, index_vector):\n","    \"\"\"\n","    Select rows from an embedding vector using an index vector.\n","\n","    Args:\n","        embedding_vector (torch.Tensor): 2D tensor representing the embedding vector with shape [num_rows, embedding_size].\n","        index_vector (torch.Tensor): 1D tensor representing the index vector.\n","\n","    Returns:\n","        torch.Tensor: New tensor with selected rows from the embedding vector.\n","    \"\"\"\n","    # Use torch.index_select to select the desired rows\n","    new_tensor = torch.index_select(embedding_vector, 0, index_vector)\n","\n","    return new_tensor"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"a12L7vEmmCJq","executionInfo":{"status":"ok","timestamp":1732224148523,"user_tz":-60,"elapsed":12,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def contrastive_loss(source_embeddings, target_embeddings, labels, margin=1.0):\n","    \"\"\"\n","    Computes the contrastive loss, a type of loss function used to train models in tasks like matching or similarity learning.\n","\n","    Args:\n","        source_embeddings (torch.Tensor): Embeddings of the source graphs, shape [batch_size, embedding_size].\n","        target_embeddings (torch.Tensor): Embeddings of the target graphs, shape [batch_size, embedding_size].\n","        labels (torch.Tensor): Binary labels indicating if the pairs are matched (1) or not (0), shape [batch_size].\n","        margin (float): Margin value for the contrastive loss. Defaults to 1.0.\n","\n","    Returns:\n","        torch.Tensor: The contrastive loss value.\n","    \"\"\"\n","    # Calculate the pairwise Euclidean distance between source and target embeddings\n","    distances = F.pairwise_distance(source_embeddings, target_embeddings)\n","\n","    # Compute the contrastive loss:\n","    # - For matched pairs (label == 1), the loss is the squared distance between embeddings.\n","    # - For non-matched pairs (label == 0), the loss is based on how far apart the embeddings are,\n","    #   but penalizes them only if the distance is less than the margin.\n","    loss = torch.mean(\n","        labels * 0.4 * distances.pow(2) +  # For positive pairs, minimize the distance (squared)\n","        (1 - labels) * 0.4 * torch.max(torch.zeros_like(distances), margin - distances).pow(2)  # For negative pairs, maximize the distance (up to the margin)\n","    )\n","\n","    return loss  # Return the computed contrastive loss\n"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"ZhCizXEb7D4N","executionInfo":{"status":"ok","timestamp":1732224148523,"user_tz":-60,"elapsed":11,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def Prediction_with_candidates(model, X1_tt, X2_tt, X3_tt, X4_tt, src_entity_tensor_o, tgt_entity_tensor_o,\n","                                   indexed_dict_src, indexed_dict_tgt, all_predictions_path):\n","    \"\"\"\n","    Evaluates the GatedCombination model using the given embeddings and candidate entity pairs.\n","    Saves the predictions and evaluation results to a file.\n","\n","    Args:\n","        model: Trained GatedCombination model.\n","        X1_tt, X2_tt, X3_tt, X4_tt (torch.Tensor): Tensors of source and target entity embeddings (updated and original).\n","        src_entity_tensor_o, tgt_entity_tensor_o (torch.Tensor): Tensors of source and target entity indices.\n","        indexed_dict_src, indexed_dict_tgt (dict): Dictionaries mapping entity indices to URIs for source and target.\n","        output_file (str): Path to save the predictions and results.\n","        hits_at_k_values (list): List of k-values for which hits@k is evaluated.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    # Move the model to CPU and set it to evaluation mode\n","    model = model.to(\"cpu\")\n","    model.eval()\n","\n","    # Set batch size for evaluation\n","    batch_size_test = 32\n","\n","    # Create a DataLoader for the evaluation data\n","    test_dataset = TensorDataset(X1_tt, X2_tt, X3_tt, X4_tt)\n","    test_dataloader = DataLoader(test_dataset, batch_size=batch_size_test)\n","\n","    # Prepare for collecting predictions and results\n","    predictions = []\n","    results = []\n","    count_predictions = 0  # Counter for predictions above threshold (0.5)\n","\n","    # Measure prediction time\n","    start_time = time.time()\n","\n","    # Disable gradient computation for evaluation\n","    with torch.no_grad():\n","        # Iterate over batches and compute model predictions\n","        for batch_X1, batch_X2, batch_X3, batch_X4 in test_dataloader:\n","            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","            predictions.extend(outputs.cpu().numpy())  # Collect predictions in CPU memory\n","\n","    end_time = time.time()\n","    predicting_time = end_time - start_time\n","    print(f\"Predicting time: {predicting_time:.2f} seconds\")\n","\n","    # Convert tensors to lists for easier iteration\n","    src_indices = src_entity_tensor_o.tolist()\n","    tgt_indices = tgt_entity_tensor_o.tolist()\n","\n","    # Prepare results\n","    for i in range(len(predictions)):\n","        if predictions[i] >= 0.00:  # Consider only predictions greater than 0.5\n","            count_predictions += 1  # Increment the counter\n","\n","            # Map the source and target entity indices to their URIs\n","            src_code = src_indices[i]\n","            tgt_code = tgt_indices[i]\n","\n","            src_uri = indexed_dict_src.get(int(src_code), \"Unknown URI\")\n","            tgt_uri = indexed_dict_tgt.get(int(tgt_code), \"Unknown URI\")\n","\n","            # Get the model's predicted score for the current pair\n","            score = predictions[i]\n","\n","            # Append the results (with URIs instead of entity indices)\n","            results.append({\n","                'SrcEntity': src_uri,\n","                'TgtEntity': tgt_uri,\n","                'Score': score\n","            })\n","\n","    # Convert the results into a pandas DataFrame\n","    df_results = pd.DataFrame(results)\n","\n","    # Save the results to a TSV file\n","    df_results.to_csv(all_predictions_path, sep='\\t', index=False)\n","\n","    print(f\"Predictions saved to {all_predictions_path}\")"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"TslUdYHBcGVj","executionInfo":{"status":"ok","timestamp":1732224148523,"user_tz":-60,"elapsed":11,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def filter_highest_predictions(input_file_path, output_file_path, threshold=thres):\n","    # Load the all predictions file\n","    df = pd.read_csv(input_file_path, sep='\\t')\n","\n","    # Extract the similarity score from the list in the 'Score' column\n","    df['Score'] = df['Score'].apply(lambda x: float(x.strip('[]')))\n","\n","    # Sorting the dataframe by similarity score in descending order\n","    df_sorted = df.sort_values(by='Score', ascending=False).reset_index(drop=True)\n","\n","    # Initialize variables with threshold value\n","    source_concepts = set(df_sorted['SrcEntity'])\n","    target_concepts = set(df_sorted['TgtEntity'])\n","    matched_sources = set()\n","    matched_targets = set()\n","    result = []\n","\n","    # Iterate through the sorted dataframe and find highest correspondences\n","    for _, row in df_sorted.iterrows():\n","        source, target, similarity = row['SrcEntity'], row['TgtEntity'], row['Score']\n","\n","        # Check if the source or target has already been matched and if the similarity is above the threshold\n","        if source not in matched_sources and target not in matched_targets and similarity >= threshold:\n","            # Add the match to the result list\n","            result.append((source, target, similarity))\n","            # Mark the source and target as matched\n","            matched_sources.add(source)\n","            matched_targets.add(target)\n","\n","    # Create a dataframe for the matching results with threshold applied\n","    matching_results_df_threshold = pd.DataFrame(result, columns=['SrcEntity', 'TgtEntity', 'Score'])\n","\n","    # Save the matching results with the updated column names to a new TSV file\n","    matching_results_df_threshold.to_csv(output_file_path, sep='\\t', index=False)\n","\n","    # Print the number of predictions saved\n","    print(f\"Number of Positive predictions: {len(matching_results_df_threshold)}\")\n","\n","    return matching_results_df_threshold, len(matching_results_df_threshold)"]},{"cell_type":"code","source":["def compute_mrr_and_hits(reference_file, predicted_file, output_file, k_values=[1, 5, 10]):\n","    \"\"\"\n","    Compute MRR and Hits@k for ontology matching predictions based on a reference file.\n","\n","    Args:\n","        reference_file (str): Path to the reference file (test.cands.tsv format).\n","        predicted_file (str): Path to the predictions file with scores.\n","        output_file (str): Path to save the scored results.\n","        k_values (list): List of k values for Hits@k.\n","\n","    Returns:\n","        dict: A dictionary containing MRR and Hits@k metrics.\n","    \"\"\"\n","    # Read the reference mappings\n","    test_candidate_mappings = read_table(reference_file).values.tolist()\n","    ranking_results = []\n","\n","    # Read the predicted scores\n","    predicted_data = pd.read_csv(predicted_file, sep=\"\\t\")\n","    predicted_data[\"Score\"] = predicted_data[\"Score\"].apply(lambda x: float(x.strip(\"[]\")))\n","\n","    # Create a lookup dictionary for predicted scores\n","    score_lookup = {}\n","    for _, row in predicted_data.iterrows():\n","        score_lookup[(row[\"SrcEntity\"], row[\"TgtEntity\"])] = row[\"Score\"]\n","\n","    for src_ref_class, tgt_ref_class, tgt_cands in test_candidate_mappings:\n","        tgt_cands = eval(tgt_cands)  # Convert string to list of candidates\n","        scored_cands = []\n","        for tgt_cand in tgt_cands:\n","            # Retrieve score for each candidate, defaulting to a very low score if not found\n","            matching_score = score_lookup.get((src_ref_class, tgt_cand), -1e9)\n","            scored_cands.append((tgt_cand, matching_score))\n","\n","        # Sort candidates by score in descending order\n","        scored_cands = sorted(scored_cands, key=lambda x: x[1], reverse=True)\n","        ranking_results.append((src_ref_class, tgt_ref_class, scored_cands))\n","\n","    # Save the ranked results to a file\n","    pd.DataFrame(ranking_results, columns=[\"SrcEntity\", \"TgtEntity\", \"TgtCandidates\"]).to_csv(output_file, sep=\"\\t\", index=False)\n","\n","    # Compute MRR and Hits@k\n","    total_entities = len(ranking_results)\n","    reciprocal_ranks = []\n","    hits_at_k = {k: 0 for k in k_values}\n","\n","    for src_entity, tgt_ref_class, tgt_cands in ranking_results:\n","        ranked_candidates = [candidate[0] for candidate in tgt_cands]\n","        if tgt_ref_class in ranked_candidates:\n","            rank = ranked_candidates.index(tgt_ref_class) + 1\n","            reciprocal_ranks.append(1 / rank)\n","            for k in k_values:\n","                if rank <= k:\n","                    hits_at_k[k] += 1\n","        else:\n","            reciprocal_ranks.append(0)\n","\n","    mrr = sum(reciprocal_ranks) / total_entities\n","    hits_at_k = {k: hits / total_entities for k, hits in hits_at_k.items()}\n","\n","    return {\"MRR\": mrr, \"Hits@k\": hits_at_k}"],"metadata":{"id":"_ggVYlTiO_WA","executionInfo":{"status":"ok","timestamp":1732224148523,"user_tz":-60,"elapsed":10,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1HyWMsw1MVhz"},"source":["# **Main Code**\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"IC37FlwGDqGM"},"source":["\n","\n","# Reading semantic node embeddings provided by the ENE"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"FuEfSnw5mod0","executionInfo":{"status":"ok","timestamp":1732224153647,"user_tz":-60,"elapsed":5134,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the source embeddings from a CSV file into a pandas DataFrame\n","df_embbedings_src = pd.read_csv(src_Emb, index_col=0)\n","\n","# Convert the DataFrame to a NumPy array, which will remove the index and store the data as a raw matrix\n","numpy_array = df_embbedings_src.to_numpy()\n","\n","# Convert the NumPy array into a PyTorch FloatTensor, which is the format required for PyTorch operations\n","x_src = torch.FloatTensor(numpy_array)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"STUwqMUXmlG2","executionInfo":{"status":"ok","timestamp":1732224156248,"user_tz":-60,"elapsed":2606,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the target embeddings from a CSV file into a pandas DataFrame\n","df_embbedings_tgt = pd.read_csv(tgt_Emb, index_col=0)\n","\n","# Convert the DataFrame to a NumPy array, which removes the index and converts the data to a raw matrix\n","numpy_array = df_embbedings_tgt.to_numpy()\n","\n","# Convert the NumPy array into a PyTorch FloatTensor, which is required for PyTorch operations\n","x_tgt = torch.FloatTensor(numpy_array)"]},{"cell_type":"markdown","metadata":{"id":"jZIu9P08DqGN"},"source":["# Reading adjacency Matrix"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"pH69Up40mycz","executionInfo":{"status":"ok","timestamp":1732224156248,"user_tz":-60,"elapsed":4,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the source adjacency matrix from a CSV file into a pandas DataFrame\n","df_ma1 = pd.read_csv(src_Adjacence, index_col=0)\n","\n","# Convert the DataFrame to a list of lists (Python native list format)\n","ma1 = df_ma1.values.tolist()"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"hYCmAO5Ymzpl","executionInfo":{"status":"ok","timestamp":1732224156506,"user_tz":-60,"elapsed":261,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the target adjacency matrix from a CSV file into a pandas DataFrame\n","df_ma2 = pd.read_csv(tgt_Adjacence, index_col=0)\n","\n","# Convert the DataFrame to a list of lists (Python native list format)\n","ma2 = df_ma2.values.tolist()"]},{"cell_type":"markdown","metadata":{"id":"PSyksqh3TrU-"},"source":["# Convert Adjacency matrix (in list format) to an undirected edge index"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"uVt-Pce5m5ll","executionInfo":{"status":"ok","timestamp":1732224156794,"user_tz":-60,"elapsed":291,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Convert the source adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n","edge_src = adjacency_matrix_to_undirected_edge_index(ma1)\n","\n","# Convert the target adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n","edge_tgt = adjacency_matrix_to_undirected_edge_index(ma2)"]},{"cell_type":"markdown","metadata":{"id":"H9wMTRdqT4aY"},"source":["# GIT Training"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"eqiEKCLSMVh3","executionInfo":{"status":"ok","timestamp":1732224156794,"user_tz":-60,"elapsed":4,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def train_model_gnn(model, x_src, edge_src, x_tgt, edge_tgt,\n","                    tensor_term1, tensor_term2, tensor_score,\n","                    learning_rate, weight_decay_value, num_epochs, print_interval=10):\n","    \"\"\"\n","    Trains a graph neural network (GNN) model using source and target embeddings and contrastive loss.\n","\n","    Args:\n","        model: The GNN model to be trained.\n","        x_src (torch.Tensor): Source node embeddings.\n","        edge_src (torch.Tensor): Source graph edges.\n","        x_tgt (torch.Tensor): Target node embeddings.\n","        edge_tgt (torch.Tensor): Target graph edges.\n","        tensor_term1 (torch.Tensor): Indices of the source nodes to be compared.\n","        tensor_term2 (torch.Tensor): Indices of the target nodes to be compared.\n","        tensor_score (torch.Tensor): Labels indicating if the pairs are matched (1) or not (0).\n","        learning_rate (float): Learning rate for the optimizer.\n","        weight_decay_value (float): Weight decay (L2 regularization) value for the optimizer.\n","        num_epochs (int): Number of epochs for training.\n","        print_interval (int): Interval at which training progress is printed (every `print_interval` epochs).\n","\n","    Returns:\n","        model: The trained GNN model.\n","    \"\"\"\n","\n","    # Step 1: Set device (GPU or CPU) for computation\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    # Step 2: Move the model and all inputs to the selected device\n","    model.to(device)\n","    x_tgt = x_tgt.to(device)               # Target node embeddings\n","    edge_tgt = edge_tgt.to(device)         # Target graph edges\n","    x_src = x_src.to(device)               # Source node embeddings\n","    edge_src = edge_src.to(device)         # Source graph edges\n","    tensor_term1 = tensor_term1.to(device) # Indices for source nodes\n","    tensor_term2 = tensor_term2.to(device) # Indices for target nodes\n","    tensor_score = tensor_score.to(device) # Ground truth labels\n","\n","    # Step 3: Define optimizer with learning rate and regularization\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay_value)\n","\n","    # Step 4: Initialize list to store training losses\n","    train_losses = []\n","\n","    # Record the start time of training\n","    start_time = time.time()\n","\n","    # Step 5: Training loop\n","    for epoch in range(num_epochs):\n","        # Zero out gradients from the previous iteration\n","        optimizer.zero_grad()\n","\n","        # Forward pass: Compute embeddings for source and target graphs\n","        out1 = model(x_src, edge_src)  # Updated source embeddings\n","        out2 = model(x_tgt, edge_tgt)  # Updated target embeddings\n","\n","        # Extract specific rows of embeddings for terms being compared\n","        src_embeddings = select_rows_by_index(out1, tensor_term1)\n","        tgt_embeddings = select_rows_by_index(out2, tensor_term2)\n","\n","        # Compute contrastive loss based on the embeddings and ground truth labels\n","        loss = contrastive_loss(src_embeddings, tgt_embeddings, tensor_score)\n","\n","        # Backward pass: Compute gradients\n","        loss.backward()\n","\n","        # Update the model's parameters\n","        optimizer.step()\n","\n","        # Append the loss for this iteration to the list\n","        train_losses.append(loss.item())\n","\n","        # Print loss every `print_interval` epochs\n","        if (epoch + 1) % print_interval == 0:\n","            print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item()}\")\n","\n","    # Step 6: Record end time of training\n","    end_time = time.time()\n","\n","    # Step 7: Plot the training loss over time\n","    plt.semilogy(range(1, num_epochs + 1), train_losses, label=\"Training Loss\", marker='o')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    # Print the total training time\n","    training_time = end_time - start_time\n","    print(f\"Training complete! Total training time: {training_time:.2f} seconds\")\n","\n","    # Step 8: Return the trained model\n","    return model"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"6_tzUG_emtBg","executionInfo":{"status":"ok","timestamp":1732224156794,"user_tz":-60,"elapsed":3,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Initialize the GIT_mod model with the dimensionality of the target embeddings\n","# The first argument is the dimensionality of the target node embeddings (x_tgt.shape[1])\n","# The second argument (1) represents the number of RGIT layers in the model\n","GIT_model = RGIT_mod(x_tgt.shape[1], 1)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"wVo-s7UQssSp","executionInfo":{"status":"ok","timestamp":1732224157137,"user_tz":-60,"elapsed":346,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Reading the training pairs from a CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(train_file, index_col=0)\n","\n","# Extract the 'SrcEntity' and 'TgtEntity' columns as NumPy arrays and convert them to integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)  # Source entity indices\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)  # Target entity indices\n","\n","# Extract the 'Score' column as a NumPy array and convert it to floats\n","tensor_score = df_embbedings['Score'].values.astype(float)  # Scores (labels) indicating if pairs match (1) or not (0)\n","\n","# Convert the NumPy arrays to PyTorch LongTensors (for indices) and FloatTensors (for scores)\n","tensor_term1_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)  # Source entity tensor\n","tensor_term2_o = torch.from_numpy(tensor_term2).type(torch.LongTensor)  # Target entity tensor\n","tensor_score_o = torch.from_numpy(tensor_score).type(torch.FloatTensor)  # Score tensor"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"agHlFNesMVh3","outputId":"ca967a72-8c5b-4df1-bed9-6f42db60ffcc","executionInfo":{"status":"ok","timestamp":1732224709777,"user_tz":-60,"elapsed":552643,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [10/1000], Training Loss: 0.25010964274406433\n","Epoch [20/1000], Training Loss: 0.16859453916549683\n","Epoch [30/1000], Training Loss: 0.13279801607131958\n","Epoch [40/1000], Training Loss: 0.10232808440923691\n","Epoch [50/1000], Training Loss: 0.06998196244239807\n","Epoch [60/1000], Training Loss: 0.045981161296367645\n","Epoch [70/1000], Training Loss: 0.0329451747238636\n","Epoch [80/1000], Training Loss: 0.02540554851293564\n","Epoch [90/1000], Training Loss: 0.020432597026228905\n","Epoch [100/1000], Training Loss: 0.01687050051987171\n","Epoch [110/1000], Training Loss: 0.014170941896736622\n","Epoch [120/1000], Training Loss: 0.012033908627927303\n","Epoch [130/1000], Training Loss: 0.010337041690945625\n","Epoch [140/1000], Training Loss: 0.009015044197440147\n","Epoch [150/1000], Training Loss: 0.008003597147762775\n","Epoch [160/1000], Training Loss: 0.007242437452077866\n","Epoch [170/1000], Training Loss: 0.006669241935014725\n","Epoch [180/1000], Training Loss: 0.006229996215552092\n","Epoch [190/1000], Training Loss: 0.005886536091566086\n","Epoch [200/1000], Training Loss: 0.005612080451101065\n","Epoch [210/1000], Training Loss: 0.005387164652347565\n","Epoch [220/1000], Training Loss: 0.005198576953262091\n","Epoch [230/1000], Training Loss: 0.005037535447627306\n","Epoch [240/1000], Training Loss: 0.0048978556878864765\n","Epoch [250/1000], Training Loss: 0.004774976521730423\n","Epoch [260/1000], Training Loss: 0.00466674380004406\n","Epoch [270/1000], Training Loss: 0.004570370074361563\n","Epoch [280/1000], Training Loss: 0.0044832248240709305\n","Epoch [290/1000], Training Loss: 0.00440412200987339\n","Epoch [300/1000], Training Loss: 0.004332135431468487\n","Epoch [310/1000], Training Loss: 0.0042661260813474655\n","Epoch [320/1000], Training Loss: 0.004205405246466398\n","Epoch [330/1000], Training Loss: 0.004148993641138077\n","Epoch [340/1000], Training Loss: 0.004096256103366613\n","Epoch [350/1000], Training Loss: 0.004046784248203039\n","Epoch [360/1000], Training Loss: 0.0040001473389565945\n","Epoch [370/1000], Training Loss: 0.003956002648919821\n","Epoch [380/1000], Training Loss: 0.003914008382707834\n","Epoch [390/1000], Training Loss: 0.0038738881703466177\n","Epoch [400/1000], Training Loss: 0.0038353127893060446\n","Epoch [410/1000], Training Loss: 0.00379802449606359\n","Epoch [420/1000], Training Loss: 0.0037619448266923428\n","Epoch [430/1000], Training Loss: 0.0037269406020641327\n","Epoch [440/1000], Training Loss: 0.0036927182227373123\n","Epoch [450/1000], Training Loss: 0.003659079782664776\n","Epoch [460/1000], Training Loss: 0.003625978948548436\n","Epoch [470/1000], Training Loss: 0.0035932317841798067\n","Epoch [480/1000], Training Loss: 0.003560635494068265\n","Epoch [490/1000], Training Loss: 0.0035280371084809303\n","Epoch [500/1000], Training Loss: 0.0034954112488776445\n","Epoch [510/1000], Training Loss: 0.0034626703709363937\n","Epoch [520/1000], Training Loss: 0.0034296223893761635\n","Epoch [530/1000], Training Loss: 0.0033961469307541847\n","Epoch [540/1000], Training Loss: 0.00336219253949821\n","Epoch [550/1000], Training Loss: 0.003327634185552597\n","Epoch [560/1000], Training Loss: 0.003292395267635584\n","Epoch [570/1000], Training Loss: 0.003256460651755333\n","Epoch [580/1000], Training Loss: 0.003219874110072851\n","Epoch [590/1000], Training Loss: 0.0031827078200876713\n","Epoch [600/1000], Training Loss: 0.0031450623646378517\n","Epoch [610/1000], Training Loss: 0.003107120282948017\n","Epoch [620/1000], Training Loss: 0.0030692012514919043\n","Epoch [630/1000], Training Loss: 0.003031544154509902\n","Epoch [640/1000], Training Loss: 0.00299434014596045\n","Epoch [650/1000], Training Loss: 0.0029578935354948044\n","Epoch [660/1000], Training Loss: 0.002922278828918934\n","Epoch [670/1000], Training Loss: 0.002887641079723835\n","Epoch [680/1000], Training Loss: 0.0028541586361825466\n","Epoch [690/1000], Training Loss: 0.0028219674713909626\n","Epoch [700/1000], Training Loss: 0.0027911788783967495\n","Epoch [710/1000], Training Loss: 0.0027618161402642727\n","Epoch [720/1000], Training Loss: 0.0027338380459696054\n","Epoch [730/1000], Training Loss: 0.0027072259690612555\n","Epoch [740/1000], Training Loss: 0.002681880723685026\n","Epoch [750/1000], Training Loss: 0.002657691016793251\n","Epoch [760/1000], Training Loss: 0.002634572796523571\n","Epoch [770/1000], Training Loss: 0.002612435957416892\n","Epoch [780/1000], Training Loss: 0.002591170836240053\n","Epoch [790/1000], Training Loss: 0.0025706738233566284\n","Epoch [800/1000], Training Loss: 0.0025508590042591095\n","Epoch [810/1000], Training Loss: 0.00253165140748024\n","Epoch [820/1000], Training Loss: 0.0025129872374236584\n","Epoch [830/1000], Training Loss: 0.00249477312900126\n","Epoch [840/1000], Training Loss: 0.0024769550655037165\n","Epoch [850/1000], Training Loss: 0.002459516515955329\n","Epoch [860/1000], Training Loss: 0.002442423952743411\n","Epoch [870/1000], Training Loss: 0.002425587736070156\n","Epoch [880/1000], Training Loss: 0.002408964093774557\n","Epoch [890/1000], Training Loss: 0.002392509952187538\n","Epoch [900/1000], Training Loss: 0.0023762036580592394\n","Epoch [910/1000], Training Loss: 0.0023600163403898478\n","Epoch [920/1000], Training Loss: 0.0023439174983650446\n","Epoch [930/1000], Training Loss: 0.0023279255256056786\n","Epoch [940/1000], Training Loss: 0.002312019933015108\n","Epoch [950/1000], Training Loss: 0.002296196296811104\n","Epoch [960/1000], Training Loss: 0.002280467888340354\n","Epoch [970/1000], Training Loss: 0.0022648065350949764\n","Epoch [980/1000], Training Loss: 0.0022491742856800556\n","Epoch [990/1000], Training Loss: 0.0022335799876600504\n","Epoch [1000/1000], Training Loss: 0.002218022011220455\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training complete! Total training time: 551.29 seconds\n"]}],"source":["# Train the GNN model using the provided source and target graph embeddings, edges, and training data\n","trained_model = train_model_gnn(\n","    model=GIT_model,                # The GNN model to be trained (initialized earlier)\n","    x_src=x_src,                    # Source node embeddings (tensor for source graph)\n","    edge_src=edge_src,              # Source graph edges (undirected edge index for source graph)\n","    x_tgt=x_tgt,                    # Target node embeddings (tensor for target graph)\n","    edge_tgt=edge_tgt,              # Target graph edges (undirected edge index for target graph)\n","    tensor_term1=tensor_term1_o,    # Indices of source entities for training\n","    tensor_term2=tensor_term2_o,    # Indices of target entities for training\n","    tensor_score=tensor_score_o,    # Scores (labels) indicating if pairs match (1) or not (0)\n","    learning_rate=0.0001,            # Learning rate for the Adam optimizer\n","    weight_decay_value=1e-4,        # Weight decay for L2 regularization to prevent overfitting\n","    num_epochs=1000,                # Number of training epochs\n","    print_interval=10               # Interval at which to print training progress (every 10 epochs)\n",")"]},{"cell_type":"markdown","metadata":{"id":"MYyhvjcTUaae"},"source":["# GIT Application"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"BZ_VqP6tq6iD","executionInfo":{"status":"ok","timestamp":1732224709777,"user_tz":-60,"elapsed":8,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Determine if a GPU is available and move the computations to it; otherwise, use the CPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Assuming the model has been trained and hyperparameters (x_src, edge_src, x_tgt, edge_tgt) are set\n","\n","# Move the trained GIT_model to the device (GPU or CPU)\n","GIT_model.to(device)\n","\n","# Move the data tensors to the same device (GPU or CPU)\n","x_tgt = x_tgt.to(device)         # Target node embeddings\n","edge_tgt = edge_tgt.to(device)   # Target graph edges\n","x_src = x_src.to(device)         # Source node embeddings\n","edge_src = edge_src.to(device)   # Source graph edges\n","\n","# Set the model to evaluation mode; this disables dropout and batch normalization\n","GIT_model.eval()\n","\n","# Pass the source and target embeddings through the trained GNN model to update the embeddings\n","with torch.no_grad():  # Disable gradient computation (inference mode)\n","    embeddings_tgt = GIT_model(x_tgt, edge_tgt)  # Get updated embeddings for the target graph\n","    embeddings_src = GIT_model(x_src, edge_src)  # Get updated embeddings for the source graph\n","\n","# Detach the embeddings from the computation graph and move them back to the CPU\n","# This step is useful if you need to use the embeddings for tasks outside PyTorch (e.g., saving to disk)\n","embeddings_tgt = embeddings_tgt.detach().cpu()  # Target graph embeddings\n","embeddings_src = embeddings_src.detach().cpu()  # Source graph embeddings\n","\n","# At this point, embeddings_tgt and embeddings_src contain the updated embeddings, ready for downstream tasks"]},{"cell_type":"markdown","metadata":{"id":"Og5fdoGJrTCG"},"source":["# Selecting embedding pairs to train the Gated Network"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"J0nTwc-dnjLn","executionInfo":{"status":"ok","timestamp":1732224709777,"user_tz":-60,"elapsed":6,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the training pairs from a CSV file into a pandas DataFrame\n","df_embeddings = pd.read_csv(train_file, index_col=0)\n","\n","# Extract columns and convert to NumPy arrays\n","tensor_term1 = df_embeddings['SrcEntity'].values.astype(int)  # Source entity indices\n","tensor_term2 = df_embeddings['TgtEntity'].values.astype(int)  # Target entity indices\n","tensor_score = df_embeddings['Score'].values.astype(float)  # Matching scores\n","\n","# Split data into training and validation sets\n","tensor_term1_train, tensor_term1_val, tensor_term2_train, tensor_term2_val, tensor_score_train, tensor_score_val = train_test_split(\n","    tensor_term1, tensor_term2, tensor_score, test_size=0.3, random_state=42\n",")\n","\n","# Convert split data to PyTorch tensors\n","tensor_term1_train = torch.from_numpy(tensor_term1_train).type(torch.LongTensor)\n","tensor_term2_train = torch.from_numpy(tensor_term2_train).type(torch.LongTensor)\n","tensor_score_train = torch.from_numpy(tensor_score_train).type(torch.FloatTensor)\n","\n","tensor_term1_val = torch.from_numpy(tensor_term1_val).type(torch.LongTensor)\n","tensor_term2_val = torch.from_numpy(tensor_term2_val).type(torch.LongTensor)\n","tensor_score_val = torch.from_numpy(tensor_score_val).type(torch.FloatTensor)\n","\n","# Move the embeddings back to the CPU if not already there\n","x_tgt = x_tgt.cpu()  # Target node embeddings\n","x_src = x_src.cpu()  # Source node embeddings\n","\n","# Select embeddings for the training set\n","X1_train = select_rows_by_index(embeddings_src, tensor_term1_train)\n","X2_train = select_rows_by_index(x_src, tensor_term1_train)\n","X3_train = select_rows_by_index(embeddings_tgt, tensor_term2_train)\n","X4_train = select_rows_by_index(x_tgt, tensor_term2_train)\n","\n","# Select embeddings for the validation set\n","X1_val = select_rows_by_index(embeddings_src, tensor_term1_val)\n","X2_val = select_rows_by_index(x_src, tensor_term1_val)\n","X3_val = select_rows_by_index(embeddings_tgt, tensor_term2_val)\n","X4_val = select_rows_by_index(x_tgt, tensor_term2_val)\n","\n","# Now you have:\n","# - Training tensors: X1_train, X2_train, X3_train, X4_train, tensor_score_train\n","# - Validation tensors: X1_val, X2_val, X3_val, X4_val, tensor_score_val"]},{"cell_type":"code","source":["positive_weight = len(tensor_score_train) / (weight_train * tensor_score_train.sum())"],"metadata":{"id":"wR3PbrbBETJA","executionInfo":{"status":"ok","timestamp":1732224709777,"user_tz":-60,"elapsed":6,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fNdCgaTMExPK"},"source":["# Gated Network Training"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"Gof1eIPIWSVU","executionInfo":{"status":"ok","timestamp":1732224710188,"user_tz":-60,"elapsed":3,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["def train_gated_combination_model(X1_t, X2_t, X3_t, X4_t, tensor_score_o,\n","                                  X1_val, X2_val, X3_val, X4_val, tensor_score_val,\n","                                  epochs=120, batch_size=32, learning_rate=0.001, weight_decay=1e-5):\n","    \"\"\"\n","    Trains the GatedCombination model with training and validation data, using ReduceLROnPlateau scheduler.\n","    \"\"\"\n","\n","    # Create datasets and DataLoaders\n","    train_dataset = TensorDataset(X1_t, X2_t, X3_t, X4_t, tensor_score_o)\n","    val_dataset = TensorDataset(X1_val, X2_val, X3_val, X4_val, tensor_score_val)\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = GatedCombination(X1_t.shape[1]).to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","\n","    # Use ReduceLROnPlateau scheduler\n","    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n","\n","    criterion = WeightedBCELoss(pos_weight=positive_weight).to(device)\n","\n","    train_losses, val_losses = [], []\n","\n","    start_time = time.time()\n","\n","    for epoch in range(epochs):\n","        model.train()\n","        total_train_loss, y_true_train, y_pred_train = 0.0, [], []\n","\n","        for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in train_loader:\n","            batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (batch_X1.to(device), batch_X2.to(device),\n","                                                               batch_X3.to(device), batch_X4.to(device), batch_y.to(device))\n","            optimizer.zero_grad()\n","            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","            loss = criterion(outputs, batch_y.unsqueeze(1).float())\n","            loss.backward()\n","            optimizer.step()\n","            total_train_loss += loss.item()\n","            y_true_train.extend(batch_y.cpu().numpy())\n","            y_pred_train.extend((outputs > 0.2).float().cpu().numpy())\n","\n","        train_f1 = f1_score(y_true_train, y_pred_train)\n","        train_loss = total_train_loss / len(train_loader)\n","        train_losses.append(train_loss)\n","\n","        # Validation phase\n","        model.eval()\n","        total_val_loss, y_true_val, y_pred_val = 0.0, [], []\n","        with torch.no_grad():\n","            for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in val_loader:\n","                batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (batch_X1.to(device), batch_X2.to(device),\n","                                                                   batch_X3.to(device), batch_X4.to(device), batch_y.to(device))\n","                outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n","                val_loss = criterion(outputs, batch_y.unsqueeze(1).float())\n","                total_val_loss += val_loss.item()\n","                y_true_val.extend(batch_y.cpu().numpy())\n","                y_pred_val.extend((outputs > 0.4).float().cpu().numpy())\n","\n","        val_f1 = f1_score(y_true_val, y_pred_val)\n","        avg_val_loss = total_val_loss / len(val_loader)\n","        val_losses.append(avg_val_loss)\n","\n","        # Step the scheduler with validation loss\n","        scheduler.step(avg_val_loss)\n","\n","        # Print training and validation metrics\n","        print(f\"Epoch [{epoch + 1}/{epochs}] Training Loss: {train_loss:.4f}, F1 Score: {train_f1:.4f} | \"\n","              f\"Validation Loss: {avg_val_loss:.4f}, F1 Score: {val_f1:.4f}\")\n","\n","    end_time = time.time()\n","\n","    # Plotting\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(train_losses, label=\"Training Loss\", marker='o')\n","    plt.plot(val_losses, label=\"Validation Loss\", marker='x')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","    print(f\"Training complete! Total time: {end_time - start_time:.2f} seconds\")\n","    return model"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"l11dgb8ei69T","outputId":"e7e6b984-7daa-4126-b3e9-a67dd9289a96","executionInfo":{"status":"ok","timestamp":1732225927213,"user_tz":-60,"elapsed":1217027,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/100] Training Loss: 0.5489, F1 Score: 0.0211 | Validation Loss: 0.3181, F1 Score: 0.4298\n","Epoch [2/100] Training Loss: 0.2357, F1 Score: 0.1850 | Validation Loss: 0.1875, F1 Score: 0.8258\n","Epoch [3/100] Training Loss: 0.1524, F1 Score: 0.3654 | Validation Loss: 0.1392, F1 Score: 0.8244\n","Epoch [4/100] Training Loss: 0.1175, F1 Score: 0.4659 | Validation Loss: 0.1109, F1 Score: 0.8417\n","Epoch [5/100] Training Loss: 0.0974, F1 Score: 0.4953 | Validation Loss: 0.0943, F1 Score: 0.8275\n","Epoch [6/100] Training Loss: 0.0840, F1 Score: 0.5071 | Validation Loss: 0.0823, F1 Score: 0.8411\n","Epoch [7/100] Training Loss: 0.0742, F1 Score: 0.5268 | Validation Loss: 0.0734, F1 Score: 0.8273\n","Epoch [8/100] Training Loss: 0.0666, F1 Score: 0.5362 | Validation Loss: 0.0674, F1 Score: 0.8256\n","Epoch [9/100] Training Loss: 0.0607, F1 Score: 0.5536 | Validation Loss: 0.0619, F1 Score: 0.8176\n","Epoch [10/100] Training Loss: 0.0562, F1 Score: 0.5595 | Validation Loss: 0.0587, F1 Score: 0.8361\n","Epoch [11/100] Training Loss: 0.0528, F1 Score: 0.5697 | Validation Loss: 0.0541, F1 Score: 0.8010\n","Epoch [12/100] Training Loss: 0.0497, F1 Score: 0.5737 | Validation Loss: 0.0510, F1 Score: 0.8285\n","Epoch [13/100] Training Loss: 0.0473, F1 Score: 0.5856 | Validation Loss: 0.0487, F1 Score: 0.8074\n","Epoch [14/100] Training Loss: 0.0448, F1 Score: 0.5955 | Validation Loss: 0.0483, F1 Score: 0.8338\n","Epoch [15/100] Training Loss: 0.0434, F1 Score: 0.5920 | Validation Loss: 0.0458, F1 Score: 0.8417\n","Epoch [16/100] Training Loss: 0.0416, F1 Score: 0.5929 | Validation Loss: 0.0446, F1 Score: 0.8250\n","Epoch [17/100] Training Loss: 0.0398, F1 Score: 0.6099 | Validation Loss: 0.0465, F1 Score: 0.8467\n","Epoch [18/100] Training Loss: 0.0391, F1 Score: 0.6146 | Validation Loss: 0.0429, F1 Score: 0.8472\n","Epoch [19/100] Training Loss: 0.0381, F1 Score: 0.6151 | Validation Loss: 0.0403, F1 Score: 0.8287\n","Epoch [20/100] Training Loss: 0.0368, F1 Score: 0.6175 | Validation Loss: 0.0398, F1 Score: 0.8285\n","Epoch [21/100] Training Loss: 0.0363, F1 Score: 0.6195 | Validation Loss: 0.0393, F1 Score: 0.8153\n","Epoch [22/100] Training Loss: 0.0352, F1 Score: 0.6254 | Validation Loss: 0.0394, F1 Score: 0.7863\n","Epoch [23/100] Training Loss: 0.0349, F1 Score: 0.6281 | Validation Loss: 0.0377, F1 Score: 0.8323\n","Epoch [24/100] Training Loss: 0.0341, F1 Score: 0.6356 | Validation Loss: 0.0369, F1 Score: 0.7995\n","Epoch [25/100] Training Loss: 0.0334, F1 Score: 0.6321 | Validation Loss: 0.0408, F1 Score: 0.8609\n","Epoch [26/100] Training Loss: 0.0326, F1 Score: 0.6444 | Validation Loss: 0.0379, F1 Score: 0.8333\n","Epoch [27/100] Training Loss: 0.0319, F1 Score: 0.6418 | Validation Loss: 0.0368, F1 Score: 0.8153\n","Epoch [28/100] Training Loss: 0.0320, F1 Score: 0.6333 | Validation Loss: 0.0354, F1 Score: 0.8265\n","Epoch [29/100] Training Loss: 0.0309, F1 Score: 0.6463 | Validation Loss: 0.0378, F1 Score: 0.7405\n","Epoch [30/100] Training Loss: 0.0308, F1 Score: 0.6496 | Validation Loss: 0.0337, F1 Score: 0.8014\n","Epoch [31/100] Training Loss: 0.0301, F1 Score: 0.6455 | Validation Loss: 0.0364, F1 Score: 0.8198\n","Epoch [32/100] Training Loss: 0.0304, F1 Score: 0.6452 | Validation Loss: 0.0347, F1 Score: 0.7995\n","Epoch [33/100] Training Loss: 0.0295, F1 Score: 0.6502 | Validation Loss: 0.0342, F1 Score: 0.8112\n","Epoch [34/100] Training Loss: 0.0293, F1 Score: 0.6546 | Validation Loss: 0.0347, F1 Score: 0.8490\n","Epoch [35/100] Training Loss: 0.0288, F1 Score: 0.6599 | Validation Loss: 0.0339, F1 Score: 0.8373\n","Epoch [36/100] Training Loss: 0.0292, F1 Score: 0.6564 | Validation Loss: 0.0335, F1 Score: 0.7813\n","Epoch [37/100] Training Loss: 0.0280, F1 Score: 0.6587 | Validation Loss: 0.0365, F1 Score: 0.8516\n","Epoch [38/100] Training Loss: 0.0284, F1 Score: 0.6612 | Validation Loss: 0.0322, F1 Score: 0.8048\n","Epoch [39/100] Training Loss: 0.0282, F1 Score: 0.6562 | Validation Loss: 0.0347, F1 Score: 0.8211\n","Epoch [40/100] Training Loss: 0.0281, F1 Score: 0.6570 | Validation Loss: 0.0317, F1 Score: 0.8187\n","Epoch [41/100] Training Loss: 0.0276, F1 Score: 0.6647 | Validation Loss: 0.0306, F1 Score: 0.8159\n","Epoch [42/100] Training Loss: 0.0272, F1 Score: 0.6661 | Validation Loss: 0.0313, F1 Score: 0.8195\n","Epoch [43/100] Training Loss: 0.0276, F1 Score: 0.6698 | Validation Loss: 0.0327, F1 Score: 0.7981\n","Epoch [44/100] Training Loss: 0.0272, F1 Score: 0.6607 | Validation Loss: 0.0335, F1 Score: 0.8266\n","Epoch [45/100] Training Loss: 0.0265, F1 Score: 0.6722 | Validation Loss: 0.0303, F1 Score: 0.8122\n","Epoch [46/100] Training Loss: 0.0264, F1 Score: 0.6730 | Validation Loss: 0.0339, F1 Score: 0.8422\n","Epoch [47/100] Training Loss: 0.0265, F1 Score: 0.6707 | Validation Loss: 0.0352, F1 Score: 0.8644\n","Epoch [48/100] Training Loss: 0.0262, F1 Score: 0.6745 | Validation Loss: 0.0319, F1 Score: 0.8369\n","Epoch [49/100] Training Loss: 0.0262, F1 Score: 0.6745 | Validation Loss: 0.0314, F1 Score: 0.8185\n","Epoch [50/100] Training Loss: 0.0263, F1 Score: 0.6687 | Validation Loss: 0.0301, F1 Score: 0.8033\n","Epoch [51/100] Training Loss: 0.0263, F1 Score: 0.6719 | Validation Loss: 0.0306, F1 Score: 0.8298\n","Epoch [52/100] Training Loss: 0.0253, F1 Score: 0.6792 | Validation Loss: 0.0303, F1 Score: 0.8206\n","Epoch [53/100] Training Loss: 0.0256, F1 Score: 0.6687 | Validation Loss: 0.0311, F1 Score: 0.8426\n","Epoch [54/100] Training Loss: 0.0255, F1 Score: 0.6798 | Validation Loss: 0.0342, F1 Score: 0.8602\n","Epoch [55/100] Training Loss: 0.0253, F1 Score: 0.6786 | Validation Loss: 0.0290, F1 Score: 0.8048\n","Epoch [56/100] Training Loss: 0.0248, F1 Score: 0.6807 | Validation Loss: 0.0302, F1 Score: 0.8202\n","Epoch [57/100] Training Loss: 0.0251, F1 Score: 0.6763 | Validation Loss: 0.0317, F1 Score: 0.8403\n","Epoch [58/100] Training Loss: 0.0246, F1 Score: 0.6813 | Validation Loss: 0.0308, F1 Score: 0.8333\n","Epoch [59/100] Training Loss: 0.0248, F1 Score: 0.6730 | Validation Loss: 0.0298, F1 Score: 0.8386\n","Epoch [60/100] Training Loss: 0.0244, F1 Score: 0.6804 | Validation Loss: 0.0312, F1 Score: 0.8143\n","Epoch [61/100] Training Loss: 0.0248, F1 Score: 0.6786 | Validation Loss: 0.0298, F1 Score: 0.8352\n","Epoch [62/100] Training Loss: 0.0238, F1 Score: 0.6798 | Validation Loss: 0.0315, F1 Score: 0.8246\n","Epoch [63/100] Training Loss: 0.0242, F1 Score: 0.6849 | Validation Loss: 0.0283, F1 Score: 0.7957\n","Epoch [64/100] Training Loss: 0.0241, F1 Score: 0.6897 | Validation Loss: 0.0280, F1 Score: 0.8348\n","Epoch [65/100] Training Loss: 0.0239, F1 Score: 0.6862 | Validation Loss: 0.0302, F1 Score: 0.8087\n","Epoch [66/100] Training Loss: 0.0233, F1 Score: 0.6831 | Validation Loss: 0.0326, F1 Score: 0.8557\n","Epoch [67/100] Training Loss: 0.0242, F1 Score: 0.6906 | Validation Loss: 0.0312, F1 Score: 0.8564\n","Epoch [68/100] Training Loss: 0.0235, F1 Score: 0.6824 | Validation Loss: 0.0293, F1 Score: 0.8448\n","Epoch [69/100] Training Loss: 0.0241, F1 Score: 0.6889 | Validation Loss: 0.0283, F1 Score: 0.8091\n","Epoch [70/100] Training Loss: 0.0235, F1 Score: 0.6822 | Validation Loss: 0.0305, F1 Score: 0.7177\n","Epoch [71/100] Training Loss: 0.0240, F1 Score: 0.6798 | Validation Loss: 0.0308, F1 Score: 0.8112\n","Epoch [72/100] Training Loss: 0.0237, F1 Score: 0.6834 | Validation Loss: 0.0291, F1 Score: 0.8350\n","Epoch [73/100] Training Loss: 0.0236, F1 Score: 0.6882 | Validation Loss: 0.0289, F1 Score: 0.7838\n","Epoch [74/100] Training Loss: 0.0223, F1 Score: 0.6922 | Validation Loss: 0.0290, F1 Score: 0.7668\n","Epoch 00075: reducing learning rate of group 0 to 1.0000e-04.\n","Epoch [75/100] Training Loss: 0.0235, F1 Score: 0.6819 | Validation Loss: 0.0341, F1 Score: 0.8640\n","Epoch [76/100] Training Loss: 0.0200, F1 Score: 0.7335 | Validation Loss: 0.0281, F1 Score: 0.8340\n","Epoch [77/100] Training Loss: 0.0193, F1 Score: 0.7263 | Validation Loss: 0.0284, F1 Score: 0.8335\n","Epoch [78/100] Training Loss: 0.0190, F1 Score: 0.7293 | Validation Loss: 0.0277, F1 Score: 0.8263\n","Epoch [79/100] Training Loss: 0.0190, F1 Score: 0.7266 | Validation Loss: 0.0277, F1 Score: 0.8232\n","Epoch [80/100] Training Loss: 0.0189, F1 Score: 0.7212 | Validation Loss: 0.0286, F1 Score: 0.8441\n","Epoch [81/100] Training Loss: 0.0189, F1 Score: 0.7341 | Validation Loss: 0.0274, F1 Score: 0.8107\n","Epoch [82/100] Training Loss: 0.0189, F1 Score: 0.7197 | Validation Loss: 0.0284, F1 Score: 0.8398\n","Epoch [83/100] Training Loss: 0.0188, F1 Score: 0.7218 | Validation Loss: 0.0296, F1 Score: 0.8502\n","Epoch [84/100] Training Loss: 0.0190, F1 Score: 0.7348 | Validation Loss: 0.0277, F1 Score: 0.8202\n","Epoch [85/100] Training Loss: 0.0189, F1 Score: 0.7232 | Validation Loss: 0.0285, F1 Score: 0.8398\n","Epoch [86/100] Training Loss: 0.0189, F1 Score: 0.7247 | Validation Loss: 0.0286, F1 Score: 0.8452\n","Epoch [87/100] Training Loss: 0.0189, F1 Score: 0.7279 | Validation Loss: 0.0281, F1 Score: 0.8346\n","Epoch [88/100] Training Loss: 0.0189, F1 Score: 0.7242 | Validation Loss: 0.0282, F1 Score: 0.8356\n","Epoch [89/100] Training Loss: 0.0188, F1 Score: 0.7223 | Validation Loss: 0.0281, F1 Score: 0.8315\n","Epoch [90/100] Training Loss: 0.0188, F1 Score: 0.7298 | Validation Loss: 0.0281, F1 Score: 0.8253\n","Epoch [91/100] Training Loss: 0.0188, F1 Score: 0.7281 | Validation Loss: 0.0281, F1 Score: 0.8315\n","Epoch 00092: reducing learning rate of group 0 to 1.0000e-05.\n","Epoch [92/100] Training Loss: 0.0188, F1 Score: 0.7224 | Validation Loss: 0.0286, F1 Score: 0.8388\n","Epoch [93/100] Training Loss: 0.0182, F1 Score: 0.7384 | Validation Loss: 0.0284, F1 Score: 0.8377\n","Epoch [94/100] Training Loss: 0.0182, F1 Score: 0.7329 | Validation Loss: 0.0284, F1 Score: 0.8377\n","Epoch [95/100] Training Loss: 0.0182, F1 Score: 0.7336 | Validation Loss: 0.0283, F1 Score: 0.8367\n","Epoch [96/100] Training Loss: 0.0182, F1 Score: 0.7319 | Validation Loss: 0.0283, F1 Score: 0.8367\n","Epoch [97/100] Training Loss: 0.0182, F1 Score: 0.7332 | Validation Loss: 0.0283, F1 Score: 0.8367\n","Epoch [98/100] Training Loss: 0.0182, F1 Score: 0.7353 | Validation Loss: 0.0282, F1 Score: 0.8356\n","Epoch [99/100] Training Loss: 0.0182, F1 Score: 0.7308 | Validation Loss: 0.0282, F1 Score: 0.8367\n","Epoch [100/100] Training Loss: 0.0182, F1 Score: 0.7343 | Validation Loss: 0.0282, F1 Score: 0.8356\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x500 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training complete! Total time: 1216.49 seconds\n"]}],"source":["# Train the GatedCombination model using training and validation data\n","trained_model = train_gated_combination_model(\n","    X1_train,          # Updated source embeddings (after applying the GNN model)\n","    X2_train,          # Original source embeddings (before applying the GNN model)\n","    X3_train,          # Updated target embeddings (after applying the GNN model)\n","    X4_train,          # Original target embeddings (before applying the GNN model)\n","    tensor_score_train, # Ground truth labels for the training set (1 for matched pairs, 0 for unmatched pairs)\n","\n","    X1_val,            # Updated source embeddings for the validation set\n","    X2_val,            # Original source embeddings for the validation set\n","    X3_val,            # Updated target embeddings for the validation set\n","    X4_val,            # Original target embeddings for the validation set\n","    tensor_score_val,  # Ground truth labels for the validation set (1 for matched pairs, 0 for unmatched pairs)\n","\n","    epochs=100,        # Number of epochs (iterations over the entire training dataset)\n","    batch_size=32,     # Number of training samples processed in one forward/backward pass\n","    learning_rate=0.001, # Learning rate for the optimizer (controls step size during optimization)\n","    weight_decay=1e-5  # Weight decay (L2 regularization) to prevent overfitting\n",")"]},{"cell_type":"markdown","metadata":{"id":"uAmLuMtGW9c2"},"source":["# **Mappings Selector**"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"lnFtpUAfJQHl","executionInfo":{"status":"ok","timestamp":1732225927952,"user_tz":-60,"elapsed":747,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Build an indexed dictionary for the source ontology classes\n","# src_class is the file path to the JSON file containing the source ontology classes\n","indexed_dict_src = build_indexed_dict(src_class)\n","\n","# Build an indexed dictionary for the target ontology classes\n","# tgt_class is the file path to the JSON file containing the target ontology classes\n","indexed_dict_tgt = build_indexed_dict(tgt_class)"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"beipwavuJQHl","executionInfo":{"status":"ok","timestamp":1732225928388,"user_tz":-60,"elapsed":440,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the candidate pairs from a Candidates CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(candidates_Prediction, index_col=0)\n","\n","# Extract the 'SrcEntity' column (source entity indices) and convert it to a NumPy array of integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)\n","\n","# Extract the 'TgtEntity' column (target entity indices) and convert it to a NumPy array of integers\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)\n","\n","# Convert the source entity indices to a PyTorch LongTensor\n","src_entity_tensor_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)\n","\n","# Convert the target entity indices to a PyTorch LongTensor\n","tgt_entity_tenso_or = torch.from_numpy(tensor_term2).type(torch.LongTensor)"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"ECLhmxyKJQHl","executionInfo":{"status":"ok","timestamp":1732225928389,"user_tz":-60,"elapsed":4,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Select rows from the updated source embeddings based on the indices in src_entity_tensor_o\n","X1_tt = select_rows_by_index(embeddings_src, src_entity_tensor_o)\n","\n","# Select rows from the original source embeddings based on the indices in src_entity_tensor_o\n","X2_tt = select_rows_by_index(x_src, src_entity_tensor_o)\n","\n","# Select rows from the updated target embeddings based on the indices in tgt_entity_tenso_or\n","X3_tt = select_rows_by_index(embeddings_tgt, tgt_entity_tenso_or)\n","\n","# Select rows from the original target embeddings based on the indices in tgt_entity_tenso_or\n","X4_tt = select_rows_by_index(x_tgt, tgt_entity_tenso_or)"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5bc2441a-44f6-4acd-9c41-c9bdea93aac9","id":"UFP6OQR-7D4N","executionInfo":{"status":"ok","timestamp":1732225959845,"user_tz":-60,"elapsed":31460,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting time: 10.65 seconds\n","Predictions saved to /content/gdrive/My Drive/BioGITOM-VLDB/Experiments/neoplas/BERT_Model_Choice/Results/neoplas_all_predictions_Mini.tsv\n"]}],"source":["# Generate predictions for candidate mappings using the trained GatedCombination model\n","Prediction_with_candidates(\n","    model=trained_model,             # The trained GatedCombination model used to evaluate similarity\n","    X1_tt=X1_tt,                     # Updated source embeddings (after applying the GIT model)\n","    X2_tt=X2_tt,                     # Original source embeddings (before applying the GIT model)\n","    X3_tt=X3_tt,                     # Updated target embeddings (after applying the GIT model)\n","    X4_tt=X4_tt,                     # Original target embeddings (before applying the GIT model)\n","    src_entity_tensor_o=src_entity_tensor_o,  # Tensor of source entity indices used for evaluation\n","    tgt_entity_tensor_o=tgt_entity_tenso_or,  # Tensor of target entity indices used for evaluation\n","    indexed_dict_src=indexed_dict_src,        # Dictionary mapping source entity indices to their URIs\n","    indexed_dict_tgt=indexed_dict_tgt,        # Dictionary mapping target entity indices to their URIs\n","    all_predictions_path=all_predictions_path # Path to save all predictions with similarity scores in TSV format\n",")"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"mEc12J-B7D4N","colab":{"base_uri":"https://localhost:8080/"},"outputId":"09b8dcbe-95fe-41d5-b7cc-1f11e1b01d6b","executionInfo":{"status":"ok","timestamp":1732225972351,"user_tz":-60,"elapsed":12518,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Positive predictions: 2427\n"]}],"source":["# Filter the highest scoring predictions from the predictions file and save the results to a new file\n","matching_results_df = filter_highest_predictions(\n","    all_predictions_path,  # Path to the file containing all predictions with scores for all candidate pairs\n","    prediction_path        # Path where the filtered predictions with highest scores will be saved\n",")"]},{"cell_type":"markdown","metadata":{"id":"BIx74lNV7D4O"},"source":["# **Evaluation**"]},{"cell_type":"markdown","source":["# Global metrics calculation"],"metadata":{"id":"Pp3IpBBfWn9m"}},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bkOewzXr7D4O","outputId":"4be18d59-c91a-49bf-d536-d8125423a915","executionInfo":{"status":"ok","timestamp":1732225973650,"user_tz":-60,"elapsed":1303,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Correct Predictions: 1713\n","{'P': 0.706, 'R': 0.643, 'F1': 0.673}\n"]}],"source":["# Retrieve the indices of the ignored classes (from source and target ontologies)\n","ignored_class_index = get_ignored_class_index(src_onto)  # Get ignored class indices from source ontology\n","ignored_class_index.update(get_ignored_class_index(tgt_onto))  # Update with ignored class indices from target ontology\n","\n","# Read the predicted mappings from the prediction results file\n","preds = EntityMapping.read_table_mappings(prediction_path)\n","\n","# Read the reference mappings from the ground truth test file\n","refs = ReferenceMapping.read_table_mappings(f\"{dataset_dir}/refs_equiv/test.tsv\")\n","\n","# Filter the predicted mappings to remove any mappings that involve ignored classes\n","preds = remove_ignored_mappings(preds, ignored_class_index)\n","\n","# Compute the precision, recall, and F1-score by comparing predictions with the reference mappings\n","results = AlignmentEvaluator.f1(preds, refs)\n","\n","preds2 = [p.to_tuple() for p in preds]\n","refs2 = [r.to_tuple() for r in refs]\n","\n","correct= len(set(preds2).intersection(set(refs2)))\n","\n","print(f\"Number of Correct Predictions: {correct}\")\n","\n","# Print the computed precision, recall, and F1-score metrics\n","print(results)"]},{"cell_type":"markdown","source":["# Ranked-based metrics calculation"],"metadata":{"id":"aECB6igZW04C"}},{"cell_type":"code","execution_count":39,"metadata":{"id":"-AK-jADkSbTa","executionInfo":{"status":"ok","timestamp":1732225974118,"user_tz":-60,"elapsed":471,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Read the candidate pairs from a Candidates CSV file into a pandas DataFrame\n","df_embbedings = pd.read_csv(candidates_Rank, index_col=0)\n","\n","# Extract the 'SrcEntity' column (source entity indices) and convert it to a NumPy array of integers\n","tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)\n","\n","# Extract the 'TgtEntity' column (target entity indices) and convert it to a NumPy array of integers\n","tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)\n","\n","# Convert the source entity indices to a PyTorch LongTensor\n","src_entity_tensor_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)\n","\n","# Convert the target entity indices to a PyTorch LongTensor\n","tgt_entity_tenso_or = torch.from_numpy(tensor_term2).type(torch.LongTensor)"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"oyOzcLv-SbTb","executionInfo":{"status":"ok","timestamp":1732225974119,"user_tz":-60,"elapsed":5,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}}},"outputs":[],"source":["# Select rows from the updated source embeddings based on the indices in src_entity_tensor_o\n","X1_tt = select_rows_by_index(embeddings_src, src_entity_tensor_o)\n","\n","# Select rows from the original source embeddings based on the indices in src_entity_tensor_o\n","X2_tt = select_rows_by_index(x_src, src_entity_tensor_o)\n","\n","# Select rows from the updated target embeddings based on the indices in tgt_entity_tenso_or\n","X3_tt = select_rows_by_index(embeddings_tgt, tgt_entity_tenso_or)\n","\n","# Select rows from the original target embeddings based on the indices in tgt_entity_tenso_or\n","X4_tt = select_rows_by_index(x_tgt, tgt_entity_tenso_or)"]},{"cell_type":"code","source":["# Perform ranking-based predictions using the trained GatedCombination model\n","# Generate predictions for candidate mappings using the trained GatedCombination model\n","Prediction_with_candidates(\n","    model=trained_model,             # The trained GatedCombination model used to evaluate similarity\n","    X1_tt=X1_tt,                     # Updated source embeddings (after applying the GIT model)\n","    X2_tt=X2_tt,                     # Original source embeddings (before applying the GIT model)\n","    X3_tt=X3_tt,                     # Updated target embeddings (after applying the GIT model)\n","    X4_tt=X4_tt,                     # Original target embeddings (before applying the GIT model)\n","    src_entity_tensor_o=src_entity_tensor_o,  # Tensor of source entity indices used for evaluation\n","    tgt_entity_tensor_o=tgt_entity_tenso_or,  # Tensor of target entity indices used for evaluation\n","    indexed_dict_src=indexed_dict_src,        # Dictionary mapping source entity indices to their URIs\n","    indexed_dict_tgt=indexed_dict_tgt,        # Dictionary mapping target entity indices to their URIs\n","    all_predictions_path=all_predictions_path_ranked, # Path where the ranked predictions will be saved in TSV format\n",")"],"metadata":{"id":"-O2f7X6cSb-m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732226002390,"user_tz":-60,"elapsed":28275,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"af730942-1f3f-4312-916d-29a987829a8c"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting time: 10.23 seconds\n","Predictions saved to /content/gdrive/My Drive/BioGITOM-VLDB/Experiments/neoplas/BERT_Model_Choice/Results/neoplas_all_predictions_ranked_All_Mini.tsv\n"]}]},{"cell_type":"code","execution_count":42,"metadata":{"id":"_402seVv7D4O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732226016595,"user_tz":-60,"elapsed":14218,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"a4b7b4de-504b-4669-8636-31e7438ed2c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["MRR and Hits@k Results:\n","{'MRR': 0.8507759928239115, 'Hits@k': {1: 0.7761922643634999, 5: 0.9474277131055201, 10: 0.9744648892226812}}\n"]}],"source":["# Compute MRR and Hits@k metrics\n","# This function evaluates the predicted rankings against the reference mappings\n","results = compute_mrr_and_hits(\n","    reference_file=test_cands,             # Reference file with true ranks\n","    predicted_file=all_predictions_path_ranked,             # File containing predicted rankings\n","    output_file=formatted_predictions_path,    # File path to save formatted predictions\n","    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",")\n","\n","# Display the computed metrics\n","print(\"MRR and Hits@k Results:\")\n","print(results)  # Output the Mean Reciprocal Rank (MRR) and Hits@k metrics"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"wStfa4eZ7D4O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732226020208,"user_tz":-60,"elapsed":3619,"user":{"displayName":"BioGITOM Ontology Matching","userId":"17792409086127109994"}},"outputId":"3d849fa6-e891-4666-b27e-5c6ba4311348"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ranking Evaluation Results at K=1, 5, and 10:\n","{'MRR': 0.8507759928239115, 'Hits@1': 0.7761922643634999, 'Hits@5': 0.9474277131055201, 'Hits@10': 0.9744648892226812}\n"]}],"source":["# Call the ranking evaluation function, passing the path to the formatted predictions file.\n","# Ks specifies the evaluation levels, checking if the correct target is within the top K candidates.\n","results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n","print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n","print(results)"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}