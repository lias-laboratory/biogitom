{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkAX88H3RNRW"
      },
      "source": [
        "# **Package Installation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bSuJvX5_qNhr",
        "outputId": "c8c87819-e6c9-455d-ff20-74130d4dc7ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch==2.6.0\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchvision==0.21.0\n",
            "  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting filelock (from torch==2.6.0)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch==2.6.0)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting networkx (from torch==2.6.0)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch==2.6.0)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch==2.6.0)\n",
            "  Downloading fsspec-2025.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.6.0)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch==2.6.0)\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting sympy==1.13.1 (from torch==2.6.0)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting numpy (from torchvision==0.21.0)\n",
            "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.21.0)\n",
            "  Downloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch==2.6.0)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.6.0)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m453.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2025.5.0-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.13.2\n",
            "    Uninstalling typing_extensions-4.13.2:\n",
            "      Successfully uninstalled typing_extensions-4.13.2\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.2.1\n",
            "    Uninstalling pillow-11.2.1:\n",
            "      Successfully uninstalled pillow-11.2.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.18.0\n",
            "    Uninstalling filelock-3.18.0:\n",
            "      Successfully uninstalled filelock-3.18.0\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cpu\n",
            "    Uninstalling torch-2.6.0+cpu:\n",
            "      Successfully uninstalled torch-2.6.0+cpu\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cpu\n",
            "    Uninstalling torchvision-0.21.0+cpu:\n",
            "      Successfully uninstalled torchvision-0.21.0+cpu\n",
            "Successfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.5.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 pillow-11.2.1 sympy-1.13.1 torch-2.6.0 torchvision-0.21.0 triton-3.2.0 typing-extensions-4.13.2\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "eb3aba28c33646bd8f2ff8598dee5836",
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "!pip install torch==2.6.0 torchvision==0.21.0 --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlL2v0xgmFJ-",
        "outputId": "9727ae37-76af-4872-c285-f977473c220e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch-geometric==2.4.0\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (2.2.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (1.15.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (3.1.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (3.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (1.6.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric==2.4.0) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric==2.4.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.4.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.4.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.4.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric==2.4.0) (2025.4.26)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->torch-geometric==2.4.0) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->torch-geometric==2.4.0) (3.6.0)\n",
            "Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.4.0\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_scatter-2.1.2%2Bpt20cpu-cp311-cp311-linux_x86_64.whl (494 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.0/494.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_sparse-0.6.18%2Bpt20cpu-cp311-cp311-linux_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_cluster-1.6.3%2Bpt20cpu-cp311-cp311-linux_x86_64.whl (750 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.9/750.9 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt20cpu-cp311-cp311-linux_x86_64.whl (208 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (2.2.6)\n",
            "Installing collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt20cpu torch-scatter-2.1.2+pt20cpu torch-sparse-0.6.18+pt20cpu torch-spline-conv-1.2.2+pt20cpu\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.2.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.15.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.6.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.4.26)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->torch-geometric) (3.6.0)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting deeponto\n",
            "  Downloading deeponto-0.9.3-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting JPype1 (from deeponto)\n",
            "  Downloading jpype1-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting yacs (from deeponto)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from deeponto) (2.6.0)\n",
            "Collecting anytree (from deeponto)\n",
            "  Downloading anytree-2.13.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from deeponto) (8.2.0)\n",
            "Collecting dill (from deeponto)\n",
            "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from deeponto) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deeponto) (2.2.6)\n",
            "Requirement already satisfied: scikit_learn in /usr/local/lib/python3.11/dist-packages (from deeponto) (1.6.1)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.11/dist-packages (from deeponto) (4.51.3)\n",
            "Collecting datasets (from deeponto)\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (from deeponto) (3.8.5)\n",
            "Collecting pprintpp (from deeponto)\n",
            "  Downloading pprintpp-0.4.0-py2.py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from deeponto) (3.4.2)\n",
            "Collecting lxml (from deeponto)\n",
            "  Downloading lxml-5.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting textdistance (from deeponto)\n",
            "  Downloading textdistance-4.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from deeponto) (7.7.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from deeponto) (6.17.1)\n",
            "Collecting enlighten (from deeponto)\n",
            "  Downloading enlighten-1.14.1-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Collecting rdflib (from deeponto)\n",
            "  Downloading rdflib-7.1.4-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from deeponto) (3.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (20.0.0)\n",
            "Collecting dill (from deeponto)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (3.5.0)\n",
            "Collecting multiprocess<0.70.17 (from datasets->deeponto)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (0.31.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->deeponto) (6.0.2)\n",
            "Collecting blessed>=1.17.7 (from enlighten->deeponto)\n",
            "  Downloading blessed-1.21.0-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Collecting prefixed>=0.3.2 (from enlighten->deeponto)\n",
            "  Downloading prefixed-0.9.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (6.4.2)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->deeponto) (5.7.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->deeponto) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->deeponto) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->deeponto) (3.0.15)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->deeponto) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->deeponto) (2024.11.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->deeponto) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->deeponto) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->deeponto) (2025.2)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from rdflib->deeponto) (3.2.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn->deeponto) (1.15.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn->deeponto) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (0.15.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (2.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy->deeponto) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (4.13.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->deeponto) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->deeponto) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->deeponto) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->deeponto) (0.5.3)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]->deeponto) (1.6.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.11/dist-packages (from blessed>=1.17.7->enlighten->deeponto) (0.2.13)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (3.11.15)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->deeponto)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (5.2.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->deeponto) (4.9.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel->deeponto) (5.7.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->deeponto) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->deeponto) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->deeponto) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->deeponto) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->deeponto) (2025.4.26)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->deeponto) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->deeponto) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->deeponto) (14.0.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->deeponto) (7.1.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.5.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy->deeponto) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->deeponto) (1.20.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->deeponto) (0.8.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel->deeponto) (4.3.8)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->deeponto) (1.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.3.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->deeponto) (0.7.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (3.0.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->deeponto) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->deeponto) (0.1.2)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.23.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (0.24.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->deeponto) (1.3.1)\n",
            "Downloading deeponto-0.9.3-py3-none-any.whl (89.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anytree-2.13.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading enlighten-1.14.1-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jpype1-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (494 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lxml-5.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m116.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Downloading rdflib-7.1.4-py3-none-any.whl (565 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.1/565.1 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading textdistance-4.6.3-py3-none-any.whl (31 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading blessed-1.21.0-py2.py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.7/84.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prefixed-0.9.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: prefixed, pprintpp, yacs, textdistance, rdflib, lxml, JPype1, jedi, fsspec, dill, blessed, anytree, multiprocess, enlighten, datasets, deeponto\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.5.0\n",
            "    Uninstalling fsspec-2025.5.0:\n",
            "      Successfully uninstalled fsspec-2025.5.0\n",
            "Successfully installed JPype1-1.5.2 anytree-2.13.0 blessed-1.21.0 datasets-3.6.0 deeponto-0.9.3 dill-0.3.8 enlighten-1.14.1 fsspec-2025.3.0 jedi-0.19.2 lxml-5.4.0 multiprocess-0.70.16 pprintpp-0.4.0 prefixed-0.9.0 rdflib-7.1.4 textdistance-4.6.3 yacs-0.1.8\n",
            "/bin/bash: line 1: username: No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# We assume that PyTorch is already installed in the environment.\n",
        "# If not, this command installs it.\n",
        "\n",
        "# Install PyTorch Geometric, a library for creating graph neural networks using PyTorch.\n",
        "!pip install torch-geometric==2.4.0\n",
        "\n",
        "# Import PyTorch to access its functionalities.\n",
        "import torch\n",
        "\n",
        "# Install additional PyTorch Geometric dependencies for graph processing (scatter, sparse, cluster, spline-conv).\n",
        "# These packages enable operations like sparse tensors and convolutions on graphs.\n",
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
        "\n",
        "# Reinstall PyTorch Geometric to ensure all dependencies are correctly loaded.\n",
        "!pip install torch-geometric\n",
        "\n",
        "# Retrieve the installed version of PyTorch to ensure compatibility with other packages.\n",
        "torchversion = torch.__version__\n",
        "\n",
        "# Install the latest version of PyTorch Geometric directly from the GitHub repository.\n",
        "# This allows access to the most recent updates and features for graph-based neural networks.\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "# Install DeepOnto, a package specifically designed for ontology matching, particularly useful in biomedical applications.\n",
        "!pip install deeponto\n",
        "\n",
        "# Install a custom version of DeepOnto from a GitHub repository.\n",
        "# The '<username>' part should be replaced with the actual GitHub username of the repository maintainer.\n",
        "!pip install git+https://github.com/<username>/deeponto.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tM68ErvYpMws",
        "outputId": "168bc894-1cb1-461c-c28b-0bd3e2025c58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.2.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPAlAgjLMVhw"
      },
      "outputs": [],
      "source": [
        "# Import pandas for data manipulation and analysis, such as loading, processing, and saving tabular data.\n",
        "import pandas as pd\n",
        "\n",
        "# Import pickle for saving and loading serialized objects (e.g., trained models or preprocessed data).\n",
        "import pickle\n",
        "\n",
        "# Import function to convert a directed graph to an undirected one, useful for certain graph algorithms.\n",
        "from torch_geometric.utils import to_undirected\n",
        "\n",
        "# Import optimizer module from PyTorch for training models using gradient-based optimization techniques.\n",
        "import torch.optim as optim\n",
        "\n",
        "# Import PyTorch's modules for defining neural network architectures and operations:\n",
        "from torch.nn import (\n",
        "    Linear,       # For linear transformations (dense layers).\n",
        "    Sequential,   # For stacking layers sequentially.\n",
        "    BatchNorm1d,  # For normalizing input within mini-batches.\n",
        "    PReLU,        # Parametric ReLU activation function.\n",
        "    Dropout       # For regularization by randomly dropping connections during training.\n",
        ")\n",
        "\n",
        "# Import functional API from PyTorch for operations like activations and loss functions.\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Import Matplotlib for visualizations, such as plotting training loss curves.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import PyTorch Geometric's graph convolutional layers:\n",
        "from torch_geometric.nn import GCNConv, GINConv\n",
        "\n",
        "# Import pooling operations for aggregating node embeddings to graph-level representations:\n",
        "from torch_geometric.nn import global_mean_pool, global_add_pool\n",
        "\n",
        "# Import NumPy for numerical operations, such as working with arrays and matrices.\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Import time module for measuring execution time of code blocks.\n",
        "import time\n",
        "\n",
        "# Import typing module for specifying types in function arguments and return values.\n",
        "from typing import Optional, Tuple, Union, Callable\n",
        "\n",
        "# Import PyTorch's DataLoader and TensorDataset for handling data batching and loading during training.\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Import PyTorch's Parameter class for defining learnable parameters in custom models.\n",
        "from torch.nn import Parameter\n",
        "\n",
        "# Import math module for performing mathematical computations.\n",
        "import math\n",
        "\n",
        "# Import Tensor type from PyTorch for defining and manipulating tensors.\n",
        "from torch import Tensor\n",
        "\n",
        "# Import PyTorch's nn module for defining and building neural network architectures.\n",
        "import torch.nn as nn\n",
        "\n",
        "# Import initialization utilities from PyTorch Geometric for resetting weights and biases in layers.\n",
        "from torch_geometric.nn.inits import reset\n",
        "\n",
        "# Import the base class for defining message-passing layers in graph neural networks (GNNs).\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "\n",
        "# Import linear transformation utilities for creating dense representations in graph models.\n",
        "from torch_geometric.nn.dense.linear import Linear\n",
        "\n",
        "# Import typing utilities for defining adjacency matrices and tensor types specific to PyTorch Geometric.\n",
        "from torch_geometric.typing import Adj, OptTensor, PairTensor, SparseTensor\n",
        "\n",
        "# Import softmax function for normalizing attention scores in GNNs.\n",
        "from torch_geometric.utils import softmax\n",
        "\n",
        "# Import initialization utilities for weight initialization (e.g., Glorot initialization).\n",
        "from torch_geometric.nn.inits import glorot, zeros\n",
        "\n",
        "# Import F1 score metric from scikit-learn for evaluating model performance in binary/multi-class tasks.\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Import JSON module for reading and writing JSON files, useful for storing configuration or ontology data.\n",
        "import json\n",
        "\n",
        "# Import Ontology class from DeepOnto for representing and manipulating ontologies in the pipeline.\n",
        "from deeponto.onto import Ontology\n",
        "\n",
        "# Import tools from DeepOnto for handling Ontology Alignment Evaluation Initiative (OAEI) tasks.\n",
        "from deeponto.align.oaei import *\n",
        "\n",
        "# Import evaluation tools from DeepOnto for assessing alignment results using metrics like precision, recall, and F1.\n",
        "from deeponto.align.evaluation import AlignmentEvaluator\n",
        "\n",
        "# Import mapping utilities from DeepOnto for working with reference mappings and entity pairs.\n",
        "from deeponto.align.mapping import ReferenceMapping, EntityMapping\n",
        "\n",
        "# Import utility function for reading tables (e.g., TSV, CSV) from DeepOnto.\n",
        "from deeponto.utils import read_table\n",
        "\n",
        "# Importing the train_test_split function from sklearn's model_selection module.\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WNn0OMQW2CS"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "# Set the seed for PyTorch's random number generator to ensure reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Set the seed for NumPy's random number generator to ensure reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Set the seed for Python's built-in random module to ensure reproducibility\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-abbBHOoRdWl"
      },
      "source": [
        "# **Paths Definition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVgl_Bb42naS"
      },
      "outputs": [],
      "source": [
        "# Importing the 'drive' module from Google Colab to interact with Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount the user's Google Drive to the Colab environment\n",
        "# After running this, a link will appear to authorize access, and Google Drive will be mounted at '/content/gdrive'\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36ttssQ3W7cx"
      },
      "outputs": [],
      "source": [
        "# Define the source ontology name\n",
        "src_ent = \"snomed.neoplas\"\n",
        "\n",
        "# Define the target ontology name\n",
        "tgt_ent = \"ncit.neoplas\"\n",
        "\n",
        "# Define the task name for this ontology matching process\n",
        "task = \"neoplas\"\n",
        "\n",
        "# Define the similarity threshold for validating matches\n",
        "thres = 0.20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJpvkdwVSQye"
      },
      "outputs": [],
      "source": [
        "dir = \"/content/gdrive/My Drive/BioGITOM-VLDB/\"\n",
        "\n",
        "# Define the directory for the dataset containing source and target ontologies\n",
        "dataset_dir = f\"{dir}/Datasets/{task}\"\n",
        "\n",
        "# Define the data directory for storing embeddings, adjacency matrices, and related files\n",
        "data_dir = f\"{dir}/{task}/Data\"\n",
        "\n",
        "# Define the directory for storing the results\n",
        "results_dir = f\"{dir}/{task}/Results\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFDNSFef23er"
      },
      "outputs": [],
      "source": [
        "# Load the Source ontology using the Ontology class from DeepOnto\n",
        "# This initializes the source ontology by loading its .owl file.\n",
        "src_onto = Ontology(f\"{dataset_dir}/{src_ent}.owl\")\n",
        "\n",
        "# Load the Target ontology using the Ontology class from DeepOnto\n",
        "# This initializes the target ontology by loading its .owl file.\n",
        "tgt_onto = Ontology(f\"{dataset_dir}/{tgt_ent}.owl\")\n",
        "\n",
        "# Define the file path for the Source embeddings CSV file\n",
        "# Embeddings for the source ontology entities are stored in this file.\n",
        "src_Emb = f\"{data_dir}/{src_ent}_Sentence_SapBERT_emb.csv\"\n",
        "\n",
        "# Define the file path for the Target embeddings CSV file\n",
        "# Embeddings for the target ontology entities are stored in this file.\n",
        "tgt_Emb = f\"{data_dir}/{tgt_ent}_Sentence_SapBERT_emb.csv\"\n",
        "\n",
        "# Define the file path for the Source adjacency matrix\n",
        "# This file represents the relationships (edges) between entities in the source ontology.\n",
        "src_Adjacence = f\"{data_dir}/{src_ent}_adjacence.csv\"\n",
        "\n",
        "# Define the file path for the Target adjacency matrix\n",
        "# This file represents the relationships (edges) between entities in the target ontology.\n",
        "tgt_Adjacence = f\"{data_dir}/{tgt_ent}_adjacence.csv\"\n",
        "\n",
        "# Define the file path for the JSON file containing the Source ontology class labels\n",
        "# This file maps the source ontology entities to their labels or names.\n",
        "src_class = f\"{data_dir}/{src_ent}_classes.json\"\n",
        "\n",
        "# Define the file path for the JSON file containing the Target ontology class labels\n",
        "# This file maps the target ontology entities to their labels or names.\n",
        "tgt_class = f\"{data_dir}/{tgt_ent}_classes.json\"\n",
        "\n",
        "# Define the file path for the train data\n",
        "train_file = f\"{data_dir}/{task}_train.csv\"\n",
        "\n",
        "# Define the file path for the test data\n",
        "# The test file contains reference mappings (ground truth) between the source and target ontologies.\n",
        "test_file = f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "\n",
        "# Define the file path for the candidate mappings used during testing\n",
        "# This file includes the candidate pairs (source and target entities) for ranking and evaluation.\n",
        "test_cands = f\"{dataset_dir}/refs_equiv/test.cands.tsv\"\n",
        "\n",
        "# Define the file path for the candidate mappings between Source to Target entities\n",
        "# This file contains cleaned, combined, and encoded candidates used for predictions.\n",
        "candidates_Prediction = \"/content/gdrive/My Drive/BioGITOM-VLDB/neoplas/Results/neoplas_top1000_mappings_euclidean2_filtered_encoded.csv\"\n",
        "\n",
        "# Define the file path for the candidate mappings between Source to Target entities for ranking-based metrics\n",
        "# This file is used to compute ranking-based metrics like MRR and Hits@k.\n",
        "candidates_Rank = f\"{data_dir}/{task}_candidates.csv\"\n",
        "\n",
        "# Define the path where the prediction results will be saved in TSV format\n",
        "# This file will store the final predictions (mappings) between source and target entities.\n",
        "prediction_path = f\"{results_dir}/{task}_matching_results.tsv\"\n",
        "\n",
        "# Define the path where all prediction results will be saved in TSV format\n",
        "# This file will store detailed prediction results, including all candidate scores.\n",
        "all_predictions_path = f\"{results_dir}/{task}_all_predictions.tsv\"\n",
        "\n",
        "# Define the path where all ranking prediction results will be saved in TSV format\n",
        "# This file will store predictions sorted by rank based on their scores.\n",
        "all_predictions_path_ranked = f\"{results_dir}/{task}_all_predictions_ranked.tsv\"\n",
        "\n",
        "# Define the path where formatted ranking predictions will be saved in TSV format\n",
        "# This file will contain predictions formatted for evaluation using ranking-based metrics.\n",
        "formatted_predictions_path = f\"{results_dir}/{task}_formatted_predictions.tsv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqEXsgPGMVhw"
      },
      "source": [
        "# **GIT Architecture**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_d6XCsUMVhx"
      },
      "outputs": [],
      "source": [
        "# RGIT class definition which inherits from PyTorch Geometric's MessagePassing class\n",
        "class RGIT(MessagePassing):\n",
        "\n",
        "    _alpha: OptTensor  # Define _alpha as an optional tensor for storing attention weights\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        nn: Callable,  # Neural network to be used in the final layer of the GNN\n",
        "        in_channels: Union[int, Tuple[int, int]],  # Input dimension, can be a single or pair of integers\n",
        "        out_channels: int,  # Output dimension of the GNN\n",
        "        eps: float = 0.,  # GIN parameter: epsilon for GIN aggregation\n",
        "        train_eps: bool = False,  # GIN parameter: whether epsilon should be learnable\n",
        "        heads: int = 1,  # Transformer parameter: number of attention heads\n",
        "        dropout: float = 0.,  # Dropout rate for attention weights\n",
        "        edge_dim: Optional[int] = None,  # Dimension for edge attributes (optional)\n",
        "        bias: bool = True,  # Whether to use bias in linear layers\n",
        "        root_weight: bool = True,  # GIN parameter: whether to apply root weight in aggregation\n",
        "        **kwargs,  # Additional arguments passed to the parent class\n",
        "    ):\n",
        "        # Set the aggregation type to 'add' and initialize the parent class with node_dim=0\n",
        "        kwargs.setdefault('aggr', 'add')\n",
        "        super().__init__(node_dim=0, **kwargs)\n",
        "\n",
        "        # Initialize input/output dimensions, neural network, and GIN/transformer parameters\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.nn = nn  # Neural network used by the GNN\n",
        "        self.initial_eps = eps  # Initial value of epsilon for GIN\n",
        "\n",
        "        # Set epsilon to be learnable or fixed\n",
        "        if train_eps:\n",
        "            self.eps = torch.nn.Parameter(torch.empty(1))  # Learnable epsilon\n",
        "        else:\n",
        "            self.register_buffer('eps', torch.empty(1))  # Non-learnable epsilon (fixed)\n",
        "\n",
        "        # Initialize transformer-related parameters\n",
        "        self.heads = heads\n",
        "        self.dropout = dropout\n",
        "        self.edge_dim = edge_dim\n",
        "        self._alpha = None  # Placeholder for attention weights\n",
        "\n",
        "        # Handle case where in_channels is a single integer or a tuple\n",
        "        if isinstance(in_channels, int):\n",
        "            in_channels = (in_channels, in_channels)\n",
        "\n",
        "        # Define the linear layers for key, query, and value for the transformer mechanism\n",
        "        self.lin_key = Linear(in_channels[0], heads * out_channels)\n",
        "        self.lin_query = Linear(in_channels[1], heads * out_channels)\n",
        "        self.lin_value = Linear(in_channels[0], heads * out_channels)\n",
        "\n",
        "        # Define linear transformation for edge embeddings if provided\n",
        "        if edge_dim is not None:\n",
        "            self.lin_edge = Linear(edge_dim, heads * out_channels, bias=False)\n",
        "        else:\n",
        "            self.lin_edge = self.register_parameter('lin_edge', None)\n",
        "\n",
        "        # Reset all parameters to their initial values\n",
        "        self.reset_parameters()\n",
        "\n",
        "    # Function to reset model parameters\n",
        "    def reset_parameters(self):\n",
        "        super().reset_parameters()  # Call parent class reset method\n",
        "        self.lin_key.reset_parameters()  # Reset key linear layer\n",
        "        self.lin_query.reset_parameters()  # Reset query linear layer\n",
        "        self.lin_value.reset_parameters()  # Reset value linear layer\n",
        "        if self.edge_dim:\n",
        "            self.lin_edge.reset_parameters()  # Reset edge linear layer if used\n",
        "        reset(self.nn)  # Reset the neural network provided\n",
        "        self.eps.data.fill_(self.initial_eps)  # Initialize epsilon with the starting value\n",
        "\n",
        "    # Forward function defining how the input data flows through the model\n",
        "    def forward(self, x: Union[Tensor, PairTensor], edge_index: Adj,\n",
        "                edge_attr: OptTensor = None, return_attention_weights=None):\n",
        "        # Unpack number of heads and output channels\n",
        "        H, C = self.heads, self.out_channels\n",
        "\n",
        "        # If x is a tensor, treat it as a pair of tensors (source and target embeddings)\n",
        "        if isinstance(x, Tensor):\n",
        "            x: PairTensor = (x, x)\n",
        "\n",
        "        # Extract source node embeddings\n",
        "        x_t = x[0]\n",
        "\n",
        "        # Apply linear transformations and reshape query, key, and value for multi-head attention\n",
        "        query = self.lin_query(x[1]).view(-1, H, C)\n",
        "        key = self.lin_key(x[0]).view(-1, H, C)\n",
        "        value = self.lin_value(x[0]).view(-1, H, C)\n",
        "\n",
        "        # Propagate messages through the graph using the propagate function\n",
        "        out = self.propagate(edge_index, query=query, key=key, value=value,\n",
        "                             edge_attr=edge_attr, size=None)\n",
        "\n",
        "        # Retrieve attention weights and reset them\n",
        "        alpha = self._alpha\n",
        "        self._alpha = None  # Reset _alpha after use\n",
        "        out = out.mean(dim=1)  # Take the mean over all attention heads\n",
        "\n",
        "        # Apply GIN aggregation by adding epsilon-scaled original node embeddings\n",
        "        out = out + (1 + self.eps) * x_t\n",
        "        return self.nn(out)  # Pass through the neural network\n",
        "\n",
        "    # Message passing function which calculates attention and combines messages\n",
        "    def message(self, query_i: Tensor, key_j: Tensor, value_j: Tensor,\n",
        "                edge_attr: OptTensor, index: Tensor, ptr: OptTensor,\n",
        "                size_i: Optional[int]) -> Tensor:\n",
        "        # If edge attributes are used, apply linear transformation and add them to the key\n",
        "        if self.lin_edge is not None:\n",
        "            assert edge_attr is not None\n",
        "            edge_attr = self.lin_edge(edge_attr).view(-1, self.heads, self.out_channels)\n",
        "            key_j = key_j + edge_attr\n",
        "\n",
        "        # Calculate attention (alpha) using the dot product between query and key\n",
        "        alpha = (query_i * key_j).sum(dim=-1) / math.sqrt(self.out_channels)\n",
        "        alpha = softmax(alpha, index, ptr, size_i)  # Apply softmax to normalize attention\n",
        "        self._alpha = alpha  # Store attention weights\n",
        "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)  # Apply dropout\n",
        "\n",
        "        # Calculate the output message by applying attention to the value\n",
        "        out = value_j\n",
        "        if edge_attr is not None:\n",
        "            out = out + edge_attr  # Add edge embeddings to the output if present\n",
        "        out = out * alpha.view(-1, self.heads, 1)  # Scale by attention weights\n",
        "        return out\n",
        "\n",
        "    # String representation function for debugging or printing\n",
        "    def __repr__(self) -> str:\n",
        "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
        "                f'{self.out_channels}, heads={self.heads})')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwFv6RgHmGCf"
      },
      "outputs": [],
      "source": [
        "# Define the RGIT_mod class, a multi-layer GNN that uses both RGIT and linear layers\n",
        "class RGIT_mod(torch.nn.Module):\n",
        "    \"\"\"Multi-layer RGIT with optional linear layers\"\"\"\n",
        "\n",
        "    # Initialize the model with hidden dimension, number of RGIT layers, and number of linear layers\n",
        "    def __init__(self, dim_h, num_layers, num_linear_layers=1):\n",
        "        super(RGIT_mod, self).__init__()\n",
        "        self.num_layers = num_layers  # Number of RGIT layers\n",
        "        self.num_linear_layers = num_linear_layers  # Number of linear layers\n",
        "        self.linears = torch.nn.ModuleList()  # List to store linear layers\n",
        "        self.rgit_layers = torch.nn.ModuleList()  # List to store RGIT layers\n",
        "\n",
        "        # Create a list of Linear and PReLU layers (for encoding entity names)\n",
        "        for _ in range(num_linear_layers):\n",
        "            self.linears.append(Linear(dim_h, dim_h))  # Linear transformation layer\n",
        "            self.linears.append(PReLU(num_parameters=dim_h))  # Parametric ReLU activation function\n",
        "\n",
        "        # Create a list of RGIT layers\n",
        "        for _ in range(num_layers):\n",
        "            self.rgit_layers.append(RGIT(  # Each RGIT layer contains a small MLP with Linear and PReLU\n",
        "                Sequential(Linear(dim_h, dim_h), PReLU(num_parameters=dim_h),\n",
        "                           Linear(dim_h, dim_h), PReLU(num_parameters=dim_h)), dim_h, dim_h))\n",
        "\n",
        "    # Forward pass through the model\n",
        "    def forward(self, x, edge_index):\n",
        "        # Apply the linear layers first to the input\n",
        "        for layer in self.linears:\n",
        "            x = layer(x)\n",
        "\n",
        "        # Then apply the RGIT layers for message passing\n",
        "        for layer in self.rgit_layers:\n",
        "            x = layer(x, edge_index)\n",
        "\n",
        "        return x  # Return the final node embeddings after all layers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxCn5ztKVztw"
      },
      "source": [
        "# **Gated Network Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MKQUv7o7zay"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GatedCombination(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(GatedCombination, self).__init__()\n",
        "        self.gate_A_fc = nn.Linear(input_dim, input_dim)\n",
        "        self.gate_B_fc = nn.Linear(input_dim, input_dim)\n",
        "        self.fc = nn.Linear(1, 1)\n",
        "\n",
        "    def euclidean_distance(self, a, b):\n",
        "        \"\"\"\n",
        "        Compute the Euclidean distance between two tensors.\n",
        "        Args:\n",
        "            a: Tensor of shape [batch, dim]\n",
        "            b: Tensor of shape [batch, dim]\n",
        "        Returns:\n",
        "            Tensor of shape [batch] representing the L2 distance.\n",
        "        \"\"\"\n",
        "        return torch.norm(a - b, p=2, dim=1)\n",
        "\n",
        "    def forward(self, x1, x2, x3, x4, return_embeddings=False):\n",
        "        gate_values1 = torch.sigmoid(self.gate_A_fc(x1))\n",
        "        a = x1 * gate_values1 + x2 * (1 - gate_values1)\n",
        "\n",
        "        gate_values2 = torch.sigmoid(self.gate_B_fc(x3))\n",
        "        b = x3 * gate_values2 + x4 * (1 - gate_values2)\n",
        "\n",
        "        if return_embeddings:\n",
        "            return a, b\n",
        "\n",
        "        # Utilisation de la distance Euclidienne\n",
        "        distance = self.euclidean_distance(a, b)\n",
        "\n",
        "        # Passage dans couche de classification\n",
        "        out = torch.sigmoid(self.fc(distance.unsqueeze(1)))\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLJ5j9FNMVhy"
      },
      "source": [
        "# **Utility functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0L86DgUQjMU"
      },
      "outputs": [],
      "source": [
        "def adjacency_matrix_to_undirected_edge_index(adjacency_matrix):\n",
        "    \"\"\"\n",
        "    Converts an adjacency matrix into an undirected edge index for use in graph-based neural networks.\n",
        "\n",
        "    Args:\n",
        "        adjacency_matrix: A 2D list or array representing the adjacency matrix of a graph.\n",
        "\n",
        "    Returns:\n",
        "        edge_index_undirected: A PyTorch tensor representing the undirected edges.\n",
        "    \"\"\"\n",
        "    # Convert each element in the adjacency matrix to an integer (from boolean or float)\n",
        "    adjacency_matrix = [[int(element) for element in sublist] for sublist in adjacency_matrix]\n",
        "\n",
        "    # Convert the adjacency matrix into a PyTorch LongTensor (used for indexing)\n",
        "    edge_index = torch.tensor(adjacency_matrix, dtype=torch.long)\n",
        "\n",
        "    # Transpose the edge_index tensor so that rows represent edges in the form [source, target]\n",
        "    edge_index = edge_index.t().contiguous()\n",
        "\n",
        "    # Convert the directed edge_index into an undirected edge_index, meaning both directions are added (i.e., (i, j) and (j, i))\n",
        "    edge_index_undirected = to_undirected(edge_index)\n",
        "\n",
        "    return edge_index_undirected  # Return the undirected edge index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvmOxkLcpf9w"
      },
      "outputs": [],
      "source": [
        "def build_indexed_dict(file_path):\n",
        "    \"\"\"\n",
        "    Builds a dictionary with numeric indexes for each key from a JSON file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): The path to the JSON file.\n",
        "\n",
        "    Returns:\n",
        "        indexed_dict (dict): A new dictionary where each key from the JSON file is assigned a numeric index.\n",
        "    \"\"\"\n",
        "    # Load the JSON file into a Python dictionary\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    # Create a new dictionary with numeric indexes as keys and the original JSON keys as values\n",
        "    indexed_dict = {index: key for index, key in enumerate(data.keys())}\n",
        "\n",
        "    return indexed_dict  # Return the newly created dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgFINoPGl9Wg"
      },
      "outputs": [],
      "source": [
        "def select_rows_by_index(embedding_vector, index_vector):\n",
        "    \"\"\"\n",
        "    Select rows from an embedding vector using an index vector.\n",
        "\n",
        "    Args:\n",
        "        embedding_vector (torch.Tensor): 2D tensor representing the embedding vector with shape [num_rows, embedding_size].\n",
        "        index_vector (torch.Tensor): 1D tensor representing the index vector.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: New tensor with selected rows from the embedding vector.\n",
        "    \"\"\"\n",
        "    # Use torch.index_select to select the desired rows\n",
        "    new_tensor = torch.index_select(embedding_vector, 0, index_vector)\n",
        "\n",
        "    return new_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a12L7vEmmCJq"
      },
      "outputs": [],
      "source": [
        "def contrastive_loss(source_embeddings, target_embeddings, labels, margin=1.0):\n",
        "    \"\"\"\n",
        "    Computes the contrastive loss, a type of loss function used to train models in tasks like matching or similarity learning.\n",
        "\n",
        "    Args:\n",
        "        source_embeddings (torch.Tensor): Embeddings of the source graphs, shape [batch_size, embedding_size].\n",
        "        target_embeddings (torch.Tensor): Embeddings of the target graphs, shape [batch_size, embedding_size].\n",
        "        labels (torch.Tensor): Binary labels indicating if the pairs are matched (1) or not (0), shape [batch_size].\n",
        "        margin (float): Margin value for the contrastive loss. Defaults to 1.0.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The contrastive loss value.\n",
        "    \"\"\"\n",
        "    # Calculate the pairwise Euclidean distance between source and target embeddings\n",
        "    distances = F.pairwise_distance(source_embeddings, target_embeddings)\n",
        "\n",
        "    # Compute the contrastive loss:\n",
        "    # - For matched pairs (label == 1), the loss is the squared distance between embeddings.\n",
        "    # - For non-matched pairs (label == 0), the loss is based on how far apart the embeddings are,\n",
        "    #   but penalizes them only if the distance is less than the margin.\n",
        "    loss = torch.mean(\n",
        "        labels * 0.4 * distances.pow(2) +  # For positive pairs, minimize the distance (squared)\n",
        "        (1 - labels) * 0.4 * torch.max(torch.zeros_like(distances), margin - distances).pow(2)  # For negative pairs, maximize the distance (up to the margin)\n",
        "    )\n",
        "\n",
        "    return loss  # Return the computed contrastive loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YluEB4MC0IvA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "def compute_diem(a, b, eps=1e-8):\n",
        "    \"\"\"\n",
        "    Compute DIEM distance: squared L2 distance / (||a|| * ||b||)\n",
        "    \"\"\"\n",
        "    diff = a - b\n",
        "    euclidean_sq = torch.sum(diff ** 2, dim=1)\n",
        "    norm_a = torch.norm(a, dim=1)\n",
        "    norm_b = torch.norm(b, dim=1)\n",
        "    denom = norm_a * norm_b + eps\n",
        "    return euclidean_sq / denom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhCizXEb7D4N"
      },
      "outputs": [],
      "source": [
        "def Prediction_with_candidates(model, X1_tt, X2_tt, X3_tt, X4_tt,\n",
        "                               src_entity_tensor_o, tgt_entity_tensor_o,\n",
        "                               indexed_dict_src, indexed_dict_tgt, all_predictions_path):\n",
        "    \"\"\"\n",
        "    Evaluates similarity scores between candidate pairs using DIEM distance\n",
        "    after combining embeddings with a gating mechanism.\n",
        "    \"\"\"\n",
        "    model = model.to(\"cpu\")\n",
        "    model.eval()\n",
        "    batch_size_test = 32\n",
        "\n",
        "    test_dataset = TensorDataset(X1_tt, X2_tt, X3_tt, X4_tt)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size_test)\n",
        "\n",
        "    predictions = []\n",
        "    results = []\n",
        "    count_predictions = 0\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_X1, batch_X2, batch_X3, batch_X4 in test_dataloader:\n",
        "            a, b = model(batch_X1, batch_X2, batch_X3, batch_X4, return_embeddings=True)\n",
        "            diem_scores = compute_diem(a, b)\n",
        "            predictions.extend(diem_scores.cpu().numpy())\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Predicting time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "    # Convert tensors to list\n",
        "    src_indices = src_entity_tensor_o.tolist()\n",
        "    tgt_indices = tgt_entity_tensor_o.tolist()\n",
        "\n",
        "    for i in range(len(predictions)):\n",
        "        score = predictions[i]\n",
        "        src_code = src_indices[i]\n",
        "        tgt_code = tgt_indices[i]\n",
        "\n",
        "        src_uri = indexed_dict_src.get(int(src_code), \"Unknown URI\")\n",
        "        tgt_uri = indexed_dict_tgt.get(int(tgt_code), \"Unknown URI\")\n",
        "\n",
        "        # DIEM est une distance : on peut convertir en similarité si nécessaire\n",
        "        similarity = 1 / (1 + score)  # optionnel\n",
        "\n",
        "        results.append({\n",
        "            'SrcEntity': src_uri,\n",
        "            'TgtEntity': tgt_uri,\n",
        "            'Score': similarity  # ou score si tu préfères la distance brute\n",
        "        })\n",
        "        count_predictions += 1\n",
        "\n",
        "    df_results = pd.DataFrame(results)\n",
        "    df_results.to_csv(all_predictions_path, sep='\\t', index=False)\n",
        "    print(f\"Predictions saved to {all_predictions_path}\")\n",
        "\n",
        "\n",
        "    # Convert the results into a pandas DataFrame\n",
        "    df_results = pd.DataFrame(results)\n",
        "\n",
        "    # Save the results to a TSV file\n",
        "    df_results.to_csv(all_predictions_path, sep='\\t', index=False)\n",
        "\n",
        "    print(f\"Predictions saved to {all_predictions_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TslUdYHBcGVj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def filter_highest_predictions(input_file, output_file, threshold=0.3):\n",
        "    \"\"\"\n",
        "    Filter the highest scoring predictions for each source entity from a TSV file.\n",
        "\n",
        "    Args:\n",
        "        input_file (str): Path to the TSV file containing predictions with 'SrcEntity', 'TgtEntity', 'Score'.\n",
        "        output_file (str): Path to save the filtered predictions.\n",
        "        threshold (float): Minimum score to consider a mapping.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame containing filtered top-1 mappings.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(input_file, sep='\\t')\n",
        "\n",
        "    # Ensure Score column is float, even if saved as strings with brackets\n",
        "    def safe_parse(x):\n",
        "        if isinstance(x, str):\n",
        "            x = x.strip('[]')\n",
        "        return float(x)\n",
        "\n",
        "    df['Score'] = df['Score'].apply(safe_parse)\n",
        "\n",
        "    # Keep only mappings with score above threshold\n",
        "    df = df[df['Score'] >= threshold]\n",
        "\n",
        "    # Select top-1 TgtEntity per SrcEntity (highest scoring)\n",
        "    df_sorted = df.sort_values(by='Score', ascending=False)\n",
        "    df_top = df_sorted.groupby('SrcEntity').first().reset_index()\n",
        "\n",
        "    # Save filtered predictions\n",
        "    df_top.to_csv(output_file, sep='\\t', index=False)\n",
        "    print(f\"Filtered top-1 predictions saved to: {output_file}\")\n",
        "    return df_top\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ggVYlTiO_WA"
      },
      "outputs": [],
      "source": [
        "def compute_mrr_and_hits(reference_file, predicted_file, output_file, k_values=[1, 5, 10]):\n",
        "    \"\"\"\n",
        "    Compute MRR and Hits@k for ontology matching predictions based on a reference file.\n",
        "\n",
        "    Args:\n",
        "        reference_file (str): Path to the reference file (test.cands.tsv format).\n",
        "        predicted_file (str): Path to the predictions file with scores.\n",
        "        output_file (str): Path to save the scored results.\n",
        "        k_values (list): List of k values for Hits@k.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing MRR and Hits@k metrics.\n",
        "    \"\"\"\n",
        "    # Read the reference mappings\n",
        "    test_candidate_mappings = read_table(reference_file).values.tolist()\n",
        "    ranking_results = []\n",
        "\n",
        "    # Read the predicted scores\n",
        "    predicted_data = pd.read_csv(predicted_file, sep=\"\\t\")\n",
        "    predicted_data[\"Score\"] = predicted_data[\"Score\"].apply(lambda x: float(x.strip(\"[]\")) if isinstance(x, str) else float(x)\n",
        ")\n",
        "\n",
        "    # Create a lookup dictionary for predicted scores\n",
        "    score_lookup = {}\n",
        "    for _, row in predicted_data.iterrows():\n",
        "        score_lookup[(row[\"SrcEntity\"], row[\"TgtEntity\"])] = row[\"Score\"]\n",
        "\n",
        "    for src_ref_class, tgt_ref_class, tgt_cands in test_candidate_mappings:\n",
        "        tgt_cands = eval(tgt_cands)  # Convert string to list of candidates\n",
        "        scored_cands = []\n",
        "        for tgt_cand in tgt_cands:\n",
        "            # Retrieve score for each candidate, defaulting to a very low score if not found\n",
        "            matching_score = score_lookup.get((src_ref_class, tgt_cand), -1e9)\n",
        "            scored_cands.append((tgt_cand, matching_score))\n",
        "\n",
        "        # Sort candidates by score in descending order\n",
        "        scored_cands = sorted(scored_cands, key=lambda x: x[1], reverse=True)\n",
        "        ranking_results.append((src_ref_class, tgt_ref_class, scored_cands))\n",
        "\n",
        "    # Save the ranked results to a file\n",
        "    pd.DataFrame(ranking_results, columns=[\"SrcEntity\", \"TgtEntity\", \"TgtCandidates\"]).to_csv(output_file, sep=\"\\t\", index=False)\n",
        "\n",
        "    # Compute MRR and Hits@k\n",
        "    total_entities = len(ranking_results)\n",
        "    reciprocal_ranks = []\n",
        "    hits_at_k = {k: 0 for k in k_values}\n",
        "\n",
        "    for src_entity, tgt_ref_class, tgt_cands in ranking_results:\n",
        "        ranked_candidates = [candidate[0] for candidate in tgt_cands]\n",
        "        if tgt_ref_class in ranked_candidates:\n",
        "            rank = ranked_candidates.index(tgt_ref_class) + 1\n",
        "            reciprocal_ranks.append(1 / rank)\n",
        "            for k in k_values:\n",
        "                if rank <= k:\n",
        "                    hits_at_k[k] += 1\n",
        "        else:\n",
        "            reciprocal_ranks.append(0)\n",
        "\n",
        "    mrr = sum(reciprocal_ranks) / total_entities\n",
        "    hits_at_k = {k: hits / total_entities for k, hits in hits_at_k.items()}\n",
        "\n",
        "    return {\"MRR\": mrr, \"Hits@k\": hits_at_k}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HyWMsw1MVhz"
      },
      "source": [
        "# **Main Code**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC37FlwGDqGM"
      },
      "source": [
        "\n",
        "\n",
        "# Reading semantic node embeddings provided by the ENE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuEfSnw5mod0"
      },
      "outputs": [],
      "source": [
        "# Read the source embeddings from a CSV file into a pandas DataFrame\n",
        "df_embbedings_src = pd.read_csv(src_Emb, index_col=0)\n",
        "\n",
        "# Convert the DataFrame to a NumPy array, which will remove the index and store the data as a raw matrix\n",
        "numpy_array = df_embbedings_src.to_numpy()\n",
        "\n",
        "# Convert the NumPy array into a PyTorch FloatTensor, which is the format required for PyTorch operations\n",
        "x_src = torch.FloatTensor(numpy_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STUwqMUXmlG2"
      },
      "outputs": [],
      "source": [
        "# Read the target embeddings from a CSV file into a pandas DataFrame\n",
        "df_embbedings_tgt = pd.read_csv(tgt_Emb, index_col=0)\n",
        "\n",
        "# Convert the DataFrame to a NumPy array, which removes the index and converts the data to a raw matrix\n",
        "numpy_array = df_embbedings_tgt.to_numpy()\n",
        "\n",
        "# Convert the NumPy array into a PyTorch FloatTensor, which is required for PyTorch operations\n",
        "x_tgt = torch.FloatTensor(numpy_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZIu9P08DqGN"
      },
      "source": [
        "# Reading adjacency Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pH69Up40mycz"
      },
      "outputs": [],
      "source": [
        "# Read the source adjacency matrix from a CSV file into a pandas DataFrame\n",
        "df_ma1 = pd.read_csv(src_Adjacence, index_col=0)\n",
        "\n",
        "# Convert the DataFrame to a list of lists (Python native list format)\n",
        "ma1 = df_ma1.values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYCmAO5Ymzpl"
      },
      "outputs": [],
      "source": [
        "# Read the target adjacency matrix from a CSV file into a pandas DataFrame\n",
        "df_ma2 = pd.read_csv(tgt_Adjacence, index_col=0)\n",
        "\n",
        "# Convert the DataFrame to a list of lists (Python native list format)\n",
        "ma2 = df_ma2.values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSyksqh3TrU-"
      },
      "source": [
        "# Convert Adjacency matrix (in list format) to an undirected edge index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVt-Pce5m5ll"
      },
      "outputs": [],
      "source": [
        "# Convert the source adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n",
        "edge_src = adjacency_matrix_to_undirected_edge_index(ma1)\n",
        "\n",
        "# Convert the target adjacency matrix (in list format) to an undirected edge index for PyTorch Geometric\n",
        "edge_tgt = adjacency_matrix_to_undirected_edge_index(ma2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9wMTRdqT4aY"
      },
      "source": [
        "# GIT Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqiEKCLSMVh3"
      },
      "outputs": [],
      "source": [
        "def train_model_gnn(model, x_src, edge_src, x_tgt, edge_tgt,\n",
        "                    tensor_term1, tensor_term2, tensor_score,\n",
        "                    learning_rate, weight_decay_value, num_epochs, print_interval=10):\n",
        "    \"\"\"\n",
        "    Trains a graph neural network (GNN) model using source and target embeddings and contrastive loss.\n",
        "\n",
        "    Args:\n",
        "        model: The GNN model to be trained.\n",
        "        x_src (torch.Tensor): Source node embeddings.\n",
        "        edge_src (torch.Tensor): Source graph edges.\n",
        "        x_tgt (torch.Tensor): Target node embeddings.\n",
        "        edge_tgt (torch.Tensor): Target graph edges.\n",
        "        tensor_term1 (torch.Tensor): Indices of the source nodes to be compared.\n",
        "        tensor_term2 (torch.Tensor): Indices of the target nodes to be compared.\n",
        "        tensor_score (torch.Tensor): Labels indicating if the pairs are matched (1) or not (0).\n",
        "        learning_rate (float): Learning rate for the optimizer.\n",
        "        weight_decay_value (float): Weight decay (L2 regularization) value for the optimizer.\n",
        "        num_epochs (int): Number of epochs for training.\n",
        "        print_interval (int): Interval at which training progress is printed (every `print_interval` epochs).\n",
        "\n",
        "    Returns:\n",
        "        model: The trained GNN model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 1: Set device (GPU or CPU) for computation\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Step 2: Move the model and all inputs to the selected device\n",
        "    model.to(device)\n",
        "    x_tgt = x_tgt.to(device)               # Target node embeddings\n",
        "    edge_tgt = edge_tgt.to(device)         # Target graph edges\n",
        "    x_src = x_src.to(device)               # Source node embeddings\n",
        "    edge_src = edge_src.to(device)         # Source graph edges\n",
        "    tensor_term1 = tensor_term1.to(device) # Indices for source nodes\n",
        "    tensor_term2 = tensor_term2.to(device) # Indices for target nodes\n",
        "    tensor_score = tensor_score.to(device) # Ground truth labels\n",
        "\n",
        "    # Step 3: Define optimizer with learning rate and regularization\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay_value)\n",
        "\n",
        "    # Step 4: Initialize list to store training losses\n",
        "    train_losses = []\n",
        "\n",
        "    # Record the start time of training\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Step 5: Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        # Zero out gradients from the previous iteration\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass: Compute embeddings for source and target graphs\n",
        "        out1 = model(x_src, edge_src)  # Updated source embeddings\n",
        "        out2 = model(x_tgt, edge_tgt)  # Updated target embeddings\n",
        "\n",
        "        # Extract specific rows of embeddings for terms being compared\n",
        "        src_embeddings = select_rows_by_index(out1, tensor_term1)\n",
        "        tgt_embeddings = select_rows_by_index(out2, tensor_term2)\n",
        "\n",
        "        # Compute contrastive loss based on the embeddings and ground truth labels\n",
        "        loss = contrastive_loss(src_embeddings, tgt_embeddings, tensor_score)\n",
        "\n",
        "        # Backward pass: Compute gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the model's parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Append the loss for this iteration to the list\n",
        "        train_losses.append(loss.item())\n",
        "\n",
        "        # Print loss every `print_interval` epochs\n",
        "        if (epoch + 1) % print_interval == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {loss.item()}\")\n",
        "\n",
        "    # Step 6: Record end time of training\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Step 7: Plot the training loss over time\n",
        "    plt.semilogy(range(1, num_epochs + 1), train_losses, label=\"Training Loss\", marker='o')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Print the total training time\n",
        "    training_time = end_time - start_time\n",
        "    print(f\"Training complete! Total training time: {training_time:.2f} seconds\")\n",
        "\n",
        "    # Step 8: Return the trained model\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_tzUG_emtBg"
      },
      "outputs": [],
      "source": [
        "# Initialize the GIT_mod model with the dimensionality of the target embeddings\n",
        "# The first argument is the dimensionality of the target node embeddings (x_tgt.shape[1])\n",
        "# The second argument (1) represents the number of RGIT layers in the model\n",
        "GIT_model = RGIT_mod(x_tgt.shape[1], 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVo-s7UQssSp"
      },
      "outputs": [],
      "source": [
        "# Reading the training pairs from a CSV file into a pandas DataFrame\n",
        "df_embbedings = pd.read_csv(train_file, index_col=0)\n",
        "\n",
        "# Extract the 'SrcEntity' and 'TgtEntity' columns as NumPy arrays and convert them to integers\n",
        "tensor_term1 = df_embbedings['SrcEntity'].values.astype(int)  # Source entity indices\n",
        "tensor_term2 = df_embbedings['TgtEntity'].values.astype(int)  # Target entity indices\n",
        "\n",
        "# Extract the 'Score' column as a NumPy array and convert it to floats\n",
        "tensor_score = df_embbedings['Score'].values.astype(float)  # Scores (labels) indicating if pairs match (1) or not (0)\n",
        "\n",
        "# Convert the NumPy arrays to PyTorch LongTensors (for indices) and FloatTensors (for scores)\n",
        "tensor_term1_o = torch.from_numpy(tensor_term1).type(torch.LongTensor)  # Source entity tensor\n",
        "tensor_term2_o = torch.from_numpy(tensor_term2).type(torch.LongTensor)  # Target entity tensor\n",
        "tensor_score_o = torch.from_numpy(tensor_score).type(torch.FloatTensor)  # Score tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "agHlFNesMVh3",
        "outputId": "6ff6af89-520a-406a-a7b2-fb11bd33a25a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/1000], Training Loss: 0.0012123031774535775\n",
            "Epoch [20/1000], Training Loss: 0.0010304501047357917\n",
            "Epoch [30/1000], Training Loss: 0.0009226836264133453\n",
            "Epoch [40/1000], Training Loss: 0.0008444603299722075\n",
            "Epoch [50/1000], Training Loss: 0.0007805248606018722\n",
            "Epoch [60/1000], Training Loss: 0.0007267696782946587\n",
            "Epoch [70/1000], Training Loss: 0.000680740806274116\n",
            "Epoch [80/1000], Training Loss: 0.000640733283944428\n",
            "Epoch [90/1000], Training Loss: 0.0006054544937796891\n",
            "Epoch [100/1000], Training Loss: 0.0005741106579080224\n",
            "Epoch [110/1000], Training Loss: 0.0005459738313220441\n",
            "Epoch [120/1000], Training Loss: 0.0005211565876379609\n",
            "Epoch [130/1000], Training Loss: 0.000499098387081176\n",
            "Epoch [140/1000], Training Loss: 0.0004799014132004231\n",
            "Epoch [150/1000], Training Loss: 0.000463052187114954\n",
            "Epoch [160/1000], Training Loss: 0.00044837623136118054\n",
            "Epoch [170/1000], Training Loss: 0.0004354756965767592\n",
            "Epoch [180/1000], Training Loss: 0.0004240996204316616\n",
            "Epoch [190/1000], Training Loss: 0.00041412824066355824\n",
            "Epoch [200/1000], Training Loss: 0.0004054151941090822\n",
            "Epoch [210/1000], Training Loss: 0.0003978025633841753\n",
            "Epoch [220/1000], Training Loss: 0.00039113263483159244\n",
            "Epoch [230/1000], Training Loss: 0.0003853263333439827\n",
            "Epoch [240/1000], Training Loss: 0.000380210141884163\n",
            "Epoch [250/1000], Training Loss: 0.00037576601607725024\n",
            "Epoch [260/1000], Training Loss: 0.0003718039079103619\n",
            "Epoch [270/1000], Training Loss: 0.00036824794369749725\n",
            "Epoch [280/1000], Training Loss: 0.0003650466096587479\n",
            "Epoch [290/1000], Training Loss: 0.000362140970537439\n",
            "Epoch [300/1000], Training Loss: 0.0003595475573092699\n",
            "Epoch [310/1000], Training Loss: 0.00035710076917894185\n",
            "Epoch [320/1000], Training Loss: 0.000354828720446676\n",
            "Epoch [330/1000], Training Loss: 0.000352643895894289\n",
            "Epoch [340/1000], Training Loss: 0.00035053561441600323\n",
            "Epoch [350/1000], Training Loss: 0.0003485203778836876\n",
            "Epoch [360/1000], Training Loss: 0.00034662216785363853\n",
            "Epoch [370/1000], Training Loss: 0.00034482128103263676\n",
            "Epoch [380/1000], Training Loss: 0.00034305654116906226\n",
            "Epoch [390/1000], Training Loss: 0.0003415184619370848\n",
            "Epoch [400/1000], Training Loss: 0.0003401192370802164\n",
            "Epoch [410/1000], Training Loss: 0.0003388397744856775\n",
            "Epoch [420/1000], Training Loss: 0.0003376654349267483\n",
            "Epoch [430/1000], Training Loss: 0.0003365444717928767\n",
            "Epoch [440/1000], Training Loss: 0.00033547315979376435\n",
            "Epoch [450/1000], Training Loss: 0.00033445365261286497\n",
            "Epoch [460/1000], Training Loss: 0.0003334904904477298\n",
            "Epoch [470/1000], Training Loss: 0.0003325174911879003\n",
            "Epoch [480/1000], Training Loss: 0.0003315286012366414\n",
            "Epoch [490/1000], Training Loss: 0.0003305293503217399\n",
            "Epoch [500/1000], Training Loss: 0.00032945393468253314\n",
            "Epoch [510/1000], Training Loss: 0.0003283653350081295\n",
            "Epoch [520/1000], Training Loss: 0.00032727865618653595\n",
            "Epoch [530/1000], Training Loss: 0.0003262061800342053\n",
            "Epoch [540/1000], Training Loss: 0.0003251689486205578\n",
            "Epoch [550/1000], Training Loss: 0.00032417679904028773\n",
            "Epoch [560/1000], Training Loss: 0.00032326672226190567\n",
            "Epoch [570/1000], Training Loss: 0.0003223654057364911\n",
            "Epoch [580/1000], Training Loss: 0.0003214765165466815\n",
            "Epoch [590/1000], Training Loss: 0.00032062813988886774\n",
            "Epoch [600/1000], Training Loss: 0.00031978206243366003\n",
            "Epoch [610/1000], Training Loss: 0.00031894943094812334\n",
            "Epoch [620/1000], Training Loss: 0.0003181369393132627\n",
            "Epoch [630/1000], Training Loss: 0.000317336933221668\n",
            "Epoch [640/1000], Training Loss: 0.0003165398084092885\n",
            "Epoch [650/1000], Training Loss: 0.00031573441810905933\n",
            "Epoch [660/1000], Training Loss: 0.000314921053359285\n",
            "Epoch [670/1000], Training Loss: 0.0003141292545478791\n",
            "Epoch [680/1000], Training Loss: 0.0003133536665700376\n",
            "Epoch [690/1000], Training Loss: 0.00031254111672751606\n",
            "Epoch [700/1000], Training Loss: 0.00031171966111287475\n",
            "Epoch [710/1000], Training Loss: 0.0003108693636022508\n",
            "Epoch [720/1000], Training Loss: 0.0003099982859566808\n",
            "Epoch [730/1000], Training Loss: 0.0003090610262006521\n",
            "Epoch [740/1000], Training Loss: 0.0003080223686993122\n",
            "Epoch [750/1000], Training Loss: 0.0003069174417760223\n",
            "Epoch [760/1000], Training Loss: 0.0003057533467654139\n",
            "Epoch [770/1000], Training Loss: 0.0003045519406441599\n",
            "Epoch [780/1000], Training Loss: 0.00030340655939653516\n",
            "Epoch [790/1000], Training Loss: 0.00030235055601224303\n",
            "Epoch [800/1000], Training Loss: 0.0003013079985976219\n",
            "Epoch [810/1000], Training Loss: 0.00030031311325728893\n",
            "Epoch [820/1000], Training Loss: 0.0002993424714077264\n",
            "Epoch [830/1000], Training Loss: 0.0002984016318805516\n",
            "Epoch [840/1000], Training Loss: 0.00029746105428785086\n",
            "Epoch [850/1000], Training Loss: 0.00029653290403075516\n",
            "Epoch [860/1000], Training Loss: 0.00029565230943262577\n",
            "Epoch [870/1000], Training Loss: 0.00029479488148353994\n",
            "Epoch [880/1000], Training Loss: 0.00029392956639640033\n",
            "Epoch [890/1000], Training Loss: 0.0002930810151156038\n",
            "Epoch [900/1000], Training Loss: 0.0002922479761764407\n",
            "Epoch [910/1000], Training Loss: 0.00029142340645194054\n",
            "Epoch [920/1000], Training Loss: 0.0002906383597292006\n",
            "Epoch [930/1000], Training Loss: 0.0002898111124522984\n",
            "Epoch [940/1000], Training Loss: 0.00028900898178108037\n",
            "Epoch [950/1000], Training Loss: 0.00028822707827202976\n",
            "Epoch [960/1000], Training Loss: 0.0002874226192943752\n",
            "Epoch [970/1000], Training Loss: 0.0002866491849999875\n",
            "Epoch [980/1000], Training Loss: 0.0002858791849575937\n",
            "Epoch [990/1000], Training Loss: 0.0002851177705451846\n",
            "Epoch [1000/1000], Training Loss: 0.0002843774273060262\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training complete! Total training time: 1596.70 seconds\n"
          ]
        }
      ],
      "source": [
        "# Train the GNN model using the provided source and target graph embeddings, edges, and training data\n",
        "trained_model = train_model_gnn(\n",
        "    model=GIT_model,                # The GNN model to be trained (initialized earlier)\n",
        "    x_src=x_src,                    # Source node embeddings (tensor for source graph)\n",
        "    edge_src=edge_src,              # Source graph edges (undirected edge index for source graph)\n",
        "    x_tgt=x_tgt,                    # Target node embeddings (tensor for target graph)\n",
        "    edge_tgt=edge_tgt,              # Target graph edges (undirected edge index for target graph)\n",
        "    tensor_term1=tensor_term1_o,    # Indices of source entities for training\n",
        "    tensor_term2=tensor_term2_o,    # Indices of target entities for training\n",
        "    tensor_score=tensor_score_o,    # Scores (labels) indicating if pairs match (1) or not (0)\n",
        "    learning_rate=0.0001,            # Learning rate for the Adam optimizer\n",
        "    weight_decay_value=1e-4,        # Weight decay for L2 regularization to prevent overfitting\n",
        "    num_epochs=1000,                # Number of training epochs\n",
        "    print_interval=10               # Interval at which to print training progress (every 10 epochs)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYyhvjcTUaae"
      },
      "source": [
        "# GIT Application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZ_VqP6tq6iD"
      },
      "outputs": [],
      "source": [
        "# Determine if a GPU is available and move the computations to it; otherwise, use the CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Assuming the model has been trained and hyperparameters (x_src, edge_src, x_tgt, edge_tgt) are set\n",
        "\n",
        "# Move the trained GIT_model to the device (GPU or CPU)\n",
        "GIT_model.to(device)\n",
        "\n",
        "# Move the data tensors to the same device (GPU or CPU)\n",
        "x_tgt = x_tgt.to(device)         # Target node embeddings\n",
        "edge_tgt = edge_tgt.to(device)   # Target graph edges\n",
        "x_src = x_src.to(device)         # Source node embeddings\n",
        "edge_src = edge_src.to(device)   # Source graph edges\n",
        "\n",
        "# Set the model to evaluation mode; this disables dropout and batch normalization\n",
        "GIT_model.eval()\n",
        "\n",
        "# Pass the source and target embeddings through the trained GNN model to update the embeddings\n",
        "with torch.no_grad():  # Disable gradient computation (inference mode)\n",
        "    embeddings_tgt = GIT_model(x_tgt, edge_tgt)  # Get updated embeddings for the target graph\n",
        "    embeddings_src = GIT_model(x_src, edge_src)  # Get updated embeddings for the source graph\n",
        "\n",
        "# Detach the embeddings from the computation graph and move them back to the CPU\n",
        "# This step is useful if you need to use the embeddings for tasks outside PyTorch (e.g., saving to disk)\n",
        "embeddings_tgt = embeddings_tgt.detach().cpu()  # Target graph embeddings\n",
        "embeddings_src = embeddings_src.detach().cpu()  # Source graph embeddings\n",
        "\n",
        "# At this point, embeddings_tgt and embeddings_src contain the updated embeddings, ready for downstream tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og5fdoGJrTCG"
      },
      "source": [
        "# Selecting embedding pairs to train the Gated Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0nTwc-dnjLn"
      },
      "outputs": [],
      "source": [
        "# Read the training pairs from a CSV file into a pandas DataFrame\n",
        "df_embeddings = pd.read_csv(train_file, index_col=0)\n",
        "\n",
        "# Extract columns and convert to NumPy arrays\n",
        "tensor_term1 = df_embeddings['SrcEntity'].values.astype(int)  # Source entity indices\n",
        "tensor_term2 = df_embeddings['TgtEntity'].values.astype(int)  # Target entity indices\n",
        "tensor_score = df_embeddings['Score'].values.astype(float)  # Matching scores\n",
        "\n",
        "# Split data into training and validation sets\n",
        "tensor_term1_train, tensor_term1_val, tensor_term2_train, tensor_term2_val, tensor_score_train, tensor_score_val = train_test_split(\n",
        "    tensor_term1, tensor_term2, tensor_score, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Convert split data to PyTorch tensors\n",
        "tensor_term1_train = torch.from_numpy(tensor_term1_train).type(torch.LongTensor)\n",
        "tensor_term2_train = torch.from_numpy(tensor_term2_train).type(torch.LongTensor)\n",
        "tensor_score_train = torch.from_numpy(tensor_score_train).type(torch.FloatTensor)\n",
        "\n",
        "tensor_term1_val = torch.from_numpy(tensor_term1_val).type(torch.LongTensor)\n",
        "tensor_term2_val = torch.from_numpy(tensor_term2_val).type(torch.LongTensor)\n",
        "tensor_score_val = torch.from_numpy(tensor_score_val).type(torch.FloatTensor)\n",
        "\n",
        "# Move the embeddings back to the CPU if not already there\n",
        "x_tgt = x_tgt.cpu()  # Target node embeddings\n",
        "x_src = x_src.cpu()  # Source node embeddings\n",
        "\n",
        "# Select embeddings for the training set\n",
        "X1_train = select_rows_by_index(embeddings_src, tensor_term1_train)\n",
        "X2_train = select_rows_by_index(x_src, tensor_term1_train)\n",
        "X3_train = select_rows_by_index(embeddings_tgt, tensor_term2_train)\n",
        "X4_train = select_rows_by_index(x_tgt, tensor_term2_train)\n",
        "\n",
        "# Select embeddings for the validation set\n",
        "X1_val = select_rows_by_index(embeddings_src, tensor_term1_val)\n",
        "X2_val = select_rows_by_index(x_src, tensor_term1_val)\n",
        "X3_val = select_rows_by_index(embeddings_tgt, tensor_term2_val)\n",
        "X4_val = select_rows_by_index(x_tgt, tensor_term2_val)\n",
        "\n",
        "# Now you have:\n",
        "# - Training tensors: X1_train, X2_train, X3_train, X4_train, tensor_score_train\n",
        "# - Validation tensors: X1_val, X2_val, X3_val, X4_val, tensor_score_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNdCgaTMExPK"
      },
      "source": [
        "# Gated Network Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gof1eIPIWSVU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def train_gated_combination_model(X1_t, X2_t, X3_t, X4_t, tensor_score_o,\n",
        "                                  X1_val, X2_val, X3_val, X4_val, tensor_score_val,\n",
        "                                  epochs=120, batch_size=32, learning_rate=0.001, weight_decay=1e-5):\n",
        "    \"\"\"\n",
        "    Trains the GatedCombination model with training and validation data, using ReduceLROnPlateau scheduler.\n",
        "    Also calculates and displays F1-score during training and validation.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create datasets and DataLoaders\n",
        "    train_dataset = TensorDataset(X1_t, X2_t, X3_t, X4_t, tensor_score_o)\n",
        "    val_dataset = TensorDataset(X1_val, X2_val, X3_val, X4_val, tensor_score_val)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = GatedCombination(X1_t.shape[1]).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # Use ReduceLROnPlateau scheduler\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_train_loss = 0.0\n",
        "        y_true_train, y_pred_train = [], []\n",
        "\n",
        "        for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in train_loader:\n",
        "            batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (\n",
        "                batch_X1.to(device),\n",
        "                batch_X2.to(device),\n",
        "                batch_X3.to(device),\n",
        "                batch_X4.to(device),\n",
        "                batch_y.to(device),\n",
        "            )\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = F.binary_cross_entropy(outputs, batch_y.unsqueeze(1).float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # Store true labels and predictions for F1-score\n",
        "            y_true_train.extend(batch_y.cpu().numpy())\n",
        "            y_pred_train.extend((outputs > 0.5).float().cpu().numpy())\n",
        "\n",
        "        train_loss = total_train_loss / len(train_loader)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        # Calculate F1-score for training\n",
        "        train_f1 = f1_score(y_true_train, y_pred_train)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        total_val_loss = 0.0\n",
        "        y_true_val, y_pred_val = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_X1, batch_X2, batch_X3, batch_X4, batch_y in val_loader:\n",
        "                batch_X1, batch_X2, batch_X3, batch_X4, batch_y = (\n",
        "                    batch_X1.to(device),\n",
        "                    batch_X2.to(device),\n",
        "                    batch_X3.to(device),\n",
        "                    batch_X4.to(device),\n",
        "                    batch_y.to(device),\n",
        "                )\n",
        "                outputs = model(batch_X1, batch_X2, batch_X3, batch_X4)\n",
        "\n",
        "                # Compute loss\n",
        "                val_loss = F.binary_cross_entropy(outputs, batch_y.unsqueeze(1).float())\n",
        "                total_val_loss += val_loss.item()\n",
        "\n",
        "                # Store true labels and predictions for F1-score\n",
        "                y_true_val.extend(batch_y.cpu().numpy())\n",
        "                y_pred_val.extend((outputs > 0.5).float().cpu().numpy())\n",
        "\n",
        "        avg_val_loss = total_val_loss / len(val_loader)\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        # Calculate F1-score for validation\n",
        "        val_f1 = f1_score(y_true_val, y_pred_val)\n",
        "\n",
        "        # Step the scheduler with validation loss\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        # Print training and validation metrics\n",
        "        print(f\"Epoch [{epoch + 1}/{epochs}] Training Loss: {train_loss:.4f}, F1 Score: {train_f1:.4f} | \"\n",
        "              f\"Validation Loss: {avg_val_loss:.4f}, F1 Score: {val_f1:.4f}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Plotting training and validation loss\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(train_losses, label=\"Training Loss\", marker='o')\n",
        "    plt.plot(val_losses, label=\"Validation Loss\", marker='x')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Training complete! Total time: {end_time - start_time:.2f} seconds\")\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QrpFp6aDbtSW",
        "outputId": "6319002d-a378-45c6-ba93-e838a5f8dd9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/100] Training Loss: 0.0282, F1 Score: 0.0000 | Validation Loss: 0.0277, F1 Score: 0.0000\n",
            "Epoch [2/100] Training Loss: 0.0250, F1 Score: 0.0076 | Validation Loss: 0.0246, F1 Score: 0.0056\n",
            "Epoch [3/100] Training Loss: 0.0222, F1 Score: 0.0851 | Validation Loss: 0.0215, F1 Score: 0.1072\n",
            "Epoch [4/100] Training Loss: 0.0196, F1 Score: 0.2486 | Validation Loss: 0.0192, F1 Score: 0.2906\n",
            "Epoch [5/100] Training Loss: 0.0175, F1 Score: 0.3963 | Validation Loss: 0.0169, F1 Score: 0.4415\n",
            "Epoch [6/100] Training Loss: 0.0158, F1 Score: 0.4967 | Validation Loss: 0.0160, F1 Score: 0.4685\n",
            "Epoch [7/100] Training Loss: 0.0144, F1 Score: 0.5597 | Validation Loss: 0.0144, F1 Score: 0.6449\n",
            "Epoch [8/100] Training Loss: 0.0132, F1 Score: 0.6140 | Validation Loss: 0.0140, F1 Score: 0.6985\n",
            "Epoch [9/100] Training Loss: 0.0123, F1 Score: 0.6616 | Validation Loss: 0.0121, F1 Score: 0.6667\n",
            "Epoch [10/100] Training Loss: 0.0116, F1 Score: 0.6952 | Validation Loss: 0.0114, F1 Score: 0.6865\n",
            "Epoch [11/100] Training Loss: 0.0110, F1 Score: 0.7214 | Validation Loss: 0.0111, F1 Score: 0.7207\n",
            "Epoch [12/100] Training Loss: 0.0104, F1 Score: 0.7403 | Validation Loss: 0.0103, F1 Score: 0.7276\n",
            "Epoch [13/100] Training Loss: 0.0100, F1 Score: 0.7632 | Validation Loss: 0.0099, F1 Score: 0.7299\n",
            "Epoch [14/100] Training Loss: 0.0096, F1 Score: 0.7741 | Validation Loss: 0.0098, F1 Score: 0.7344\n",
            "Epoch [15/100] Training Loss: 0.0093, F1 Score: 0.7779 | Validation Loss: 0.0094, F1 Score: 0.7456\n",
            "Epoch [16/100] Training Loss: 0.0090, F1 Score: 0.7823 | Validation Loss: 0.0088, F1 Score: 0.7884\n",
            "Epoch [17/100] Training Loss: 0.0088, F1 Score: 0.7918 | Validation Loss: 0.0090, F1 Score: 0.8442\n",
            "Epoch [18/100] Training Loss: 0.0086, F1 Score: 0.8003 | Validation Loss: 0.0084, F1 Score: 0.8114\n",
            "Epoch [19/100] Training Loss: 0.0083, F1 Score: 0.8128 | Validation Loss: 0.0083, F1 Score: 0.8114\n",
            "Epoch [20/100] Training Loss: 0.0082, F1 Score: 0.8080 | Validation Loss: 0.0083, F1 Score: 0.8460\n",
            "Epoch [21/100] Training Loss: 0.0081, F1 Score: 0.8201 | Validation Loss: 0.0079, F1 Score: 0.8087\n",
            "Epoch [22/100] Training Loss: 0.0079, F1 Score: 0.8244 | Validation Loss: 0.0081, F1 Score: 0.8094\n",
            "Epoch [23/100] Training Loss: 0.0079, F1 Score: 0.8241 | Validation Loss: 0.0079, F1 Score: 0.7966\n",
            "Epoch [24/100] Training Loss: 0.0078, F1 Score: 0.8249 | Validation Loss: 0.0080, F1 Score: 0.8047\n",
            "Epoch [25/100] Training Loss: 0.0077, F1 Score: 0.8212 | Validation Loss: 0.0075, F1 Score: 0.8423\n",
            "Epoch [26/100] Training Loss: 0.0076, F1 Score: 0.8286 | Validation Loss: 0.0079, F1 Score: 0.8662\n",
            "Epoch [27/100] Training Loss: 0.0075, F1 Score: 0.8307 | Validation Loss: 0.0075, F1 Score: 0.8366\n",
            "Epoch [28/100] Training Loss: 0.0075, F1 Score: 0.8313 | Validation Loss: 0.0072, F1 Score: 0.8460\n",
            "Epoch [29/100] Training Loss: 0.0075, F1 Score: 0.8341 | Validation Loss: 0.0073, F1 Score: 0.8347\n",
            "Epoch [30/100] Training Loss: 0.0074, F1 Score: 0.8402 | Validation Loss: 0.0073, F1 Score: 0.8385\n",
            "Epoch [31/100] Training Loss: 0.0074, F1 Score: 0.8368 | Validation Loss: 0.0072, F1 Score: 0.8608\n",
            "Epoch [32/100] Training Loss: 0.0073, F1 Score: 0.8371 | Validation Loss: 0.0070, F1 Score: 0.8516\n",
            "Epoch [33/100] Training Loss: 0.0072, F1 Score: 0.8429 | Validation Loss: 0.0072, F1 Score: 0.8212\n",
            "Epoch [34/100] Training Loss: 0.0073, F1 Score: 0.8448 | Validation Loss: 0.0071, F1 Score: 0.8385\n",
            "Epoch [35/100] Training Loss: 0.0073, F1 Score: 0.8345 | Validation Loss: 0.0072, F1 Score: 0.8366\n",
            "Epoch [36/100] Training Loss: 0.0072, F1 Score: 0.8395 | Validation Loss: 0.0070, F1 Score: 0.8442\n",
            "Epoch [37/100] Training Loss: 0.0072, F1 Score: 0.8479 | Validation Loss: 0.0078, F1 Score: 0.8186\n",
            "Epoch [38/100] Training Loss: 0.0071, F1 Score: 0.8438 | Validation Loss: 0.0076, F1 Score: 0.8047\n",
            "Epoch [39/100] Training Loss: 0.0071, F1 Score: 0.8344 | Validation Loss: 0.0068, F1 Score: 0.8498\n",
            "Epoch [40/100] Training Loss: 0.0071, F1 Score: 0.8481 | Validation Loss: 0.0071, F1 Score: 0.8460\n",
            "Epoch [41/100] Training Loss: 0.0071, F1 Score: 0.8409 | Validation Loss: 0.0069, F1 Score: 0.8680\n",
            "Epoch [42/100] Training Loss: 0.0071, F1 Score: 0.8465 | Validation Loss: 0.0072, F1 Score: 0.8309\n",
            "Epoch [43/100] Training Loss: 0.0071, F1 Score: 0.8454 | Validation Loss: 0.0071, F1 Score: 0.8644\n",
            "Epoch [44/100] Training Loss: 0.0071, F1 Score: 0.8423 | Validation Loss: 0.0069, F1 Score: 0.8590\n",
            "Epoch [45/100] Training Loss: 0.0070, F1 Score: 0.8484 | Validation Loss: 0.0068, F1 Score: 0.8535\n",
            "Epoch [46/100] Training Loss: 0.0070, F1 Score: 0.8514 | Validation Loss: 0.0068, F1 Score: 0.8626\n",
            "Epoch [47/100] Training Loss: 0.0070, F1 Score: 0.8479 | Validation Loss: 0.0070, F1 Score: 0.8347\n",
            "Epoch [48/100] Training Loss: 0.0071, F1 Score: 0.8451 | Validation Loss: 0.0069, F1 Score: 0.8738\n",
            "Epoch [49/100] Training Loss: 0.0070, F1 Score: 0.8440 | Validation Loss: 0.0073, F1 Score: 0.8231\n",
            "Epoch [50/100] Training Loss: 0.0070, F1 Score: 0.8490 | Validation Loss: 0.0070, F1 Score: 0.8328\n",
            "Epoch [51/100] Training Loss: 0.0070, F1 Score: 0.8463 | Validation Loss: 0.0067, F1 Score: 0.8571\n",
            "Epoch [52/100] Training Loss: 0.0069, F1 Score: 0.8490 | Validation Loss: 0.0077, F1 Score: 0.8074\n",
            "Epoch [53/100] Training Loss: 0.0071, F1 Score: 0.8444 | Validation Loss: 0.0068, F1 Score: 0.8479\n",
            "Epoch [54/100] Training Loss: 0.0070, F1 Score: 0.8409 | Validation Loss: 0.0069, F1 Score: 0.8479\n",
            "Epoch [55/100] Training Loss: 0.0070, F1 Score: 0.8463 | Validation Loss: 0.0066, F1 Score: 0.8752\n",
            "Epoch [56/100] Training Loss: 0.0070, F1 Score: 0.8428 | Validation Loss: 0.0068, F1 Score: 0.8553\n",
            "Epoch [57/100] Training Loss: 0.0070, F1 Score: 0.8403 | Validation Loss: 0.0068, F1 Score: 0.8553\n",
            "Epoch [58/100] Training Loss: 0.0070, F1 Score: 0.8459 | Validation Loss: 0.0068, F1 Score: 0.8442\n",
            "Epoch [59/100] Training Loss: 0.0070, F1 Score: 0.8514 | Validation Loss: 0.0071, F1 Score: 0.8251\n",
            "Epoch [60/100] Training Loss: 0.0070, F1 Score: 0.8457 | Validation Loss: 0.0067, F1 Score: 0.8698\n",
            "Epoch [61/100] Training Loss: 0.0069, F1 Score: 0.8463 | Validation Loss: 0.0067, F1 Score: 0.8680\n",
            "Epoch [62/100] Training Loss: 0.0070, F1 Score: 0.8467 | Validation Loss: 0.0067, F1 Score: 0.8752\n",
            "Epoch [63/100] Training Loss: 0.0070, F1 Score: 0.8436 | Validation Loss: 0.0068, F1 Score: 0.8460\n",
            "Epoch [64/100] Training Loss: 0.0069, F1 Score: 0.8492 | Validation Loss: 0.0073, F1 Score: 0.8251\n",
            "Epoch [65/100] Training Loss: 0.0070, F1 Score: 0.8465 | Validation Loss: 0.0066, F1 Score: 0.8787\n",
            "Epoch [66/100] Training Loss: 0.0070, F1 Score: 0.8477 | Validation Loss: 0.0068, F1 Score: 0.8662\n",
            "Epoch [67/100] Training Loss: 0.0065, F1 Score: 0.8569 | Validation Loss: 0.0063, F1 Score: 0.8680\n",
            "Epoch [68/100] Training Loss: 0.0065, F1 Score: 0.8608 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [69/100] Training Loss: 0.0065, F1 Score: 0.8577 | Validation Loss: 0.0064, F1 Score: 0.8716\n",
            "Epoch [70/100] Training Loss: 0.0065, F1 Score: 0.8598 | Validation Loss: 0.0065, F1 Score: 0.8571\n",
            "Epoch [71/100] Training Loss: 0.0065, F1 Score: 0.8608 | Validation Loss: 0.0064, F1 Score: 0.8680\n",
            "Epoch [72/100] Training Loss: 0.0065, F1 Score: 0.8586 | Validation Loss: 0.0064, F1 Score: 0.8680\n",
            "Epoch [73/100] Training Loss: 0.0065, F1 Score: 0.8588 | Validation Loss: 0.0065, F1 Score: 0.8716\n",
            "Epoch [74/100] Training Loss: 0.0065, F1 Score: 0.8584 | Validation Loss: 0.0064, F1 Score: 0.8805\n",
            "Epoch [75/100] Training Loss: 0.0065, F1 Score: 0.8577 | Validation Loss: 0.0064, F1 Score: 0.8571\n",
            "Epoch [76/100] Training Loss: 0.0065, F1 Score: 0.8557 | Validation Loss: 0.0064, F1 Score: 0.8716\n",
            "Epoch [77/100] Training Loss: 0.0065, F1 Score: 0.8592 | Validation Loss: 0.0064, F1 Score: 0.8734\n",
            "Epoch [78/100] Training Loss: 0.0065, F1 Score: 0.8569 | Validation Loss: 0.0064, F1 Score: 0.8716\n",
            "Epoch [79/100] Training Loss: 0.0064, F1 Score: 0.8630 | Validation Loss: 0.0064, F1 Score: 0.8680\n",
            "Epoch [80/100] Training Loss: 0.0064, F1 Score: 0.8614 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [81/100] Training Loss: 0.0064, F1 Score: 0.8592 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [82/100] Training Loss: 0.0064, F1 Score: 0.8616 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [83/100] Training Loss: 0.0064, F1 Score: 0.8608 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [84/100] Training Loss: 0.0064, F1 Score: 0.8600 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [85/100] Training Loss: 0.0064, F1 Score: 0.8614 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [86/100] Training Loss: 0.0064, F1 Score: 0.8608 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [87/100] Training Loss: 0.0064, F1 Score: 0.8614 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [88/100] Training Loss: 0.0064, F1 Score: 0.8614 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [89/100] Training Loss: 0.0064, F1 Score: 0.8598 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [90/100] Training Loss: 0.0064, F1 Score: 0.8616 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [91/100] Training Loss: 0.0064, F1 Score: 0.8616 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [92/100] Training Loss: 0.0064, F1 Score: 0.8616 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [93/100] Training Loss: 0.0064, F1 Score: 0.8616 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [94/100] Training Loss: 0.0064, F1 Score: 0.8616 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [95/100] Training Loss: 0.0064, F1 Score: 0.8616 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [96/100] Training Loss: 0.0064, F1 Score: 0.8616 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [97/100] Training Loss: 0.0064, F1 Score: 0.8616 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [98/100] Training Loss: 0.0064, F1 Score: 0.8616 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [99/100] Training Loss: 0.0064, F1 Score: 0.8616 | Validation Loss: 0.0064, F1 Score: 0.8698\n",
            "Epoch [100/100] Training Loss: 0.0064, F1 Score: 0.8616 | Validation Loss: 0.0064, F1 Score: 0.8698\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training complete! Total time: 1337.70 seconds\n"
          ]
        }
      ],
      "source": [
        "# Train the GatedCombination model using training and validation data\n",
        "trained_model = train_gated_combination_model(\n",
        "    X1_train,          # Updated source embeddings (after applying the GNN model)\n",
        "    X2_train,          # Original source embeddings (before applying the GNN model)\n",
        "    X3_train,          # Updated target embeddings (after applying the GNN model)\n",
        "    X4_train,          # Original target embeddings (before applying the GNN model)\n",
        "    tensor_score_train, # Ground truth labels for the training set (1 for matched pairs, 0 for unmatched pairs)\n",
        "\n",
        "    X1_val,            # Updated source embeddings for the validation set\n",
        "    X2_val,            # Original source embeddings for the validation set\n",
        "    X3_val,            # Updated target embeddings for the validation set\n",
        "    X4_val,            # Original target embeddings for the validation set\n",
        "    tensor_score_val,  # Ground truth labels for the validation set (1 for matched pairs, 0 for unmatched pairs)\n",
        "\n",
        "    epochs=100,        # Number of epochs (iterations over the entire training dataset)\n",
        "    batch_size=32,     # Number of training samples processed in one forward/backward pass\n",
        "    learning_rate=0.001, # Learning rate for the optimizer (controls step size during optimization)\n",
        "    weight_decay=1e-4 # Weight decay (L2 regularization) to prevent overfitting\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAmLuMtGW9c2"
      },
      "source": [
        "# **Second Round Modifications**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVDqN5AxFu9m"
      },
      "source": [
        "# **Generate Embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmzBcuHZDOs3"
      },
      "outputs": [],
      "source": [
        "def save_gated_embeddings(gated_model, embeddings_src, x_src, embeddings_tgt, x_tgt,\n",
        "                          indexed_dict_src, indexed_dict_tgt,\n",
        "                          output_file_src, output_file_tgt):\n",
        "    \"\"\"\n",
        "    Compute and save the final entity embeddings generated by the GatedCombination model\n",
        "    for both source and target ontologies. Outputs include entity URIs and their final vectors.\n",
        "    Measures and prints the execution time of the entire operation.\n",
        "\n",
        "    Args:\n",
        "        gated_model (nn.Module): The trained GatedCombination model.\n",
        "        embeddings_src (Tensor): Structural embeddings for the source ontology.\n",
        "        x_src (Tensor): Semantic embeddings for the source ontology.\n",
        "        embeddings_tgt (Tensor): Structural embeddings for the target ontology.\n",
        "        x_tgt (Tensor): Semantic embeddings for the target ontology.\n",
        "        indexed_dict_src (dict): Index-to-URI mapping for the source ontology.\n",
        "        indexed_dict_tgt (dict): Index-to-URI mapping for the target ontology.\n",
        "        output_file_src (str): Path to save source embeddings (TSV).\n",
        "        output_file_tgt (str): Path to save target embeddings (TSV).\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "    import torch\n",
        "    import time\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Use GPU if available\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    gated_model = gated_model.to(device)\n",
        "    gated_model.eval()\n",
        "\n",
        "    # Move inputs to the same device\n",
        "    embeddings_src = embeddings_src.to(device)\n",
        "    x_src = x_src.to(device)\n",
        "    embeddings_tgt = embeddings_tgt.to(device)\n",
        "    x_tgt = x_tgt.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # === Source ontology ===\n",
        "        gate_src = torch.sigmoid(gated_model.gate_A_fc(embeddings_src))\n",
        "        final_src = embeddings_src * gate_src + x_src * (1 - gate_src)\n",
        "        final_src = final_src.cpu().numpy()\n",
        "\n",
        "        # === Target ontology ===\n",
        "        gate_tgt = torch.sigmoid(gated_model.gate_B_fc(embeddings_tgt))\n",
        "        final_tgt = embeddings_tgt * gate_tgt + x_tgt * (1 - gate_tgt)\n",
        "        final_tgt = final_tgt.cpu().numpy()\n",
        "\n",
        "    # Create DataFrames with Concept URI and embedding values\n",
        "    df_src = pd.DataFrame(final_src)\n",
        "    df_src.insert(0, \"Concept\", [indexed_dict_src[i] for i in range(len(df_src))])\n",
        "\n",
        "    df_tgt = pd.DataFrame(final_tgt)\n",
        "    df_tgt.insert(0, \"Concept\", [indexed_dict_tgt[i] for i in range(len(df_tgt))])\n",
        "\n",
        "    # Save embeddings to file\n",
        "    df_src.to_csv(output_file_src, sep='\\t', index=False)\n",
        "    df_tgt.to_csv(output_file_tgt, sep='\\t', index=False)\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"✅ Gated embeddings saved:\\n- Source: {output_file_src}\\n- Target: {output_file_tgt}\")\n",
        "    print(f\"⏱️ Execution time: {elapsed_time:.2f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITZZcElm8qRN"
      },
      "outputs": [],
      "source": [
        "# Build an indexed dictionary for the source ontology classes\n",
        "# src_class is the file path to the JSON file containing the source ontology classes\n",
        "indexed_dict_src = build_indexed_dict(src_class)\n",
        "\n",
        "# Build an indexed dictionary for the target ontology classes\n",
        "# tgt_class is the file path to the JSON file containing the target ontology classes\n",
        "indexed_dict_tgt = build_indexed_dict(tgt_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbSbmPlRDOs3",
        "outputId": "5f6c7ca5-052a-44e4-a528-8d9aab682b38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Gated embeddings saved:\n",
            "- Source: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings.tsv\n",
            "- Target: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings.tsv\n",
            "⏱️ Execution time: 53.45 seconds\n"
          ]
        }
      ],
      "source": [
        "# Define output file paths for final embeddings of source and target ontologies\n",
        "output_file_src = f\"{data_dir}/{src_ent}_final_embeddings.tsv\"\n",
        "output_file_tgt = f\"{data_dir}/{tgt_ent}_final_embeddings.tsv\"\n",
        "\n",
        "# Save the final gated embeddings for all concepts in source and target ontologies\n",
        "save_gated_embeddings(\n",
        "    gated_model=trained_model,          # The trained GatedCombination model\n",
        "    embeddings_src=embeddings_src,      # GNN-transformed embeddings for source entities\n",
        "    x_src=x_src,                        # Initial semantic embeddings for source entities\n",
        "    embeddings_tgt=embeddings_tgt,      # GNN-transformed embeddings for target entities\n",
        "    x_tgt=x_tgt,                        # Initial semantic embeddings for target entities\n",
        "    indexed_dict_src=indexed_dict_src,  # Index-to-URI mapping for source ontology\n",
        "    indexed_dict_tgt=indexed_dict_tgt,  # Index-to-URI mapping for target ontology\n",
        "    output_file_src=output_file_src,    # Destination file path for source embeddings\n",
        "    output_file_tgt=output_file_tgt     # Destination file path for target embeddings\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIDvbZj2GIGo"
      },
      "source": [
        "# **Filter No Used Concepts**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KZdtF46GHL4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def filter_ignored_class(src_emb_path, tgt_emb_path, src_onto, tgt_onto):\n",
        "    \"\"\"\n",
        "    Filters the source and target embedding files by removing concepts considered \"ignored classes\"\n",
        "    (e.g., owl:Thing, deprecated entities, etc.) based on both source and target ontologies.\n",
        "\n",
        "    Args:\n",
        "        src_emb_path (str): Path to the TSV file containing source embeddings with 'Concept' column.\n",
        "        tgt_emb_path (str): Path to the TSV file containing target embeddings with 'Concept' column.\n",
        "        src_onto (Ontology): Source ontology object loaded with DeepOnto.\n",
        "        tgt_onto (Ontology): Target ontology object loaded with DeepOnto.\n",
        "\n",
        "    Returns:\n",
        "        (str, str): Paths to the cleaned source and target embedding files.\n",
        "    \"\"\"\n",
        "\n",
        "    # === Load the embedding files ===\n",
        "    df_src = pd.read_csv(src_emb_path, sep='\\t', dtype=str)\n",
        "    print(f\"🔍 Initial source file: {len(df_src)} rows\")\n",
        "\n",
        "    df_tgt = pd.read_csv(tgt_emb_path, sep='\\t', dtype=str)\n",
        "    print(f\"🔍 Initial target file: {len(df_tgt)} rows\")\n",
        "\n",
        "    # === Step 1: Retrieve ignored classes from both ontologies ===\n",
        "    ignored_class_index = get_ignored_class_index(src_onto)  # e.g., owl:Thing, non-usable classes\n",
        "    ignored_class_index.update(get_ignored_class_index(tgt_onto))  # Merge with target ontology's ignored classes\n",
        "    ignored_uris = set(str(uri).strip() for uri in ignored_class_index)\n",
        "\n",
        "    # === Step 2: Remove rows where the 'Concept' column matches ignored URIs ===\n",
        "    df_src_cleaned = df_src[~df_src['Concept'].isin(ignored_uris)].reset_index(drop=True)\n",
        "    df_tgt_cleaned = df_tgt[~df_tgt['Concept'].isin(ignored_uris)].reset_index(drop=True)\n",
        "\n",
        "    print(f\"✅ Source after removing ignored classes: {len(df_src_cleaned)} rows\")\n",
        "    print(f\"✅ Target after removing ignored classes: {len(df_tgt_cleaned)} rows\")\n",
        "\n",
        "    # === Step 3: Save the cleaned embedding files ===\n",
        "    output_file_src = src_emb_path.replace(\".tsv\", \"_ignored_class_cleaned.tsv\")\n",
        "    output_file_tgt = tgt_emb_path.replace(\".tsv\", \"_ignored_class_cleaned.tsv\")\n",
        "\n",
        "    df_src_cleaned.to_csv(output_file_src, sep='\\t', index=False)\n",
        "    df_tgt_cleaned.to_csv(output_file_tgt, sep='\\t', index=False)\n",
        "\n",
        "    print(f\"📁 Cleaned source file saved to: {output_file_src}\")\n",
        "    print(f\"📁 Cleaned target file saved to: {output_file_tgt}\")\n",
        "\n",
        "    return output_file_src, output_file_tgt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Gl_wUG9KADo",
        "outputId": "3124e6e6-49cd-4ae2-d745-1b2d1f6dd662"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial source file: 23107 rows\n",
            "🔍 Initial target file: 20498 rows\n",
            "✅ Source after removing ignored classes: 11407 rows\n",
            "✅ Target after removing ignored classes: 14207 rows\n",
            "📁 Cleaned source file saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned.tsv\n",
            "📁 Cleaned target file saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned.tsv\n"
          ]
        }
      ],
      "source": [
        "# Call the function to filter out ignored concepts (e.g., owl:Thing, deprecated, etc.)\n",
        "# from the source and target ontology embeddings.\n",
        "\n",
        "# Input:\n",
        "# - src_emb_path: Path to the TSV file containing embeddings for the source ontology\n",
        "# - tgt_emb_path: Path to the TSV file containing embeddings for the target ontology\n",
        "# - src_onto / tgt_onto: DeepOnto ontology objects used to identify ignored concepts\n",
        "\n",
        "# Output:\n",
        "# - src_file: Path to the cleaned source embeddings (with ignored concepts removed)\n",
        "# - tgt_file: Path to the cleaned target embeddings (with ignored concepts removed)\n",
        "\n",
        "src_file, tgt_file = filter_ignored_class(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings.tsv\",\n",
        "    src_onto=src_onto,\n",
        "    tgt_onto=tgt_onto\n",
        "\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "treat-ftHFma"
      },
      "source": [
        "# **Encoders' Definitions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjbEKCmYvM4I",
        "outputId": "5bbef6b8-6922-4413-ef09-3053f109211f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.15.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna  # Install the Optuna library, a powerful framework for hyperparameter optimization using efficient search algorithms (e.g., TPE, CMA-ES, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAkNWvpevDH3"
      },
      "outputs": [],
      "source": [
        "# === Data Manipulation and Warnings ===\n",
        "import pandas as pd               # For handling tabular data\n",
        "import numpy as np                # For numerical operations on arrays\n",
        "import warnings, gc               # To suppress warnings and manage garbage collection\n",
        "warnings.filterwarnings('ignore') # Ignore all warnings during execution to keep output clean\n",
        "\n",
        "# === PyTorch and GNN Modules ===\n",
        "import torch                      # Core PyTorch library for tensor operations and models\n",
        "from torch import optim, Tensor   # Optimizers and Tensor object\n",
        "import torch.nn as nn             # Base class for neural network modules\n",
        "import torch.nn.functional as F   # Functional interface for neural network layers and loss functions\n",
        "\n",
        "# PyTorch Geometric modules for graph neural networks\n",
        "from torch_geometric.nn.conv import MessagePassing  # Base class for implementing GNN layers\n",
        "from torch_geometric.data import Data               # Container for graph data\n",
        "from torch_geometric.loader import DataLoader       # DataLoader for batched graph processing\n",
        "\n",
        "# === Scikit-learn Modules ===\n",
        "from sklearn.preprocessing import LabelEncoder      # Encode categorical labels as integers\n",
        "from sklearn.model_selection import train_test_split # Split data into training and test sets\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, precision_score, accuracy_score\n",
        "# Common metrics for evaluating regression and classification performance\n",
        "\n",
        "# === Hyperparameter Optimization ===\n",
        "import optuna                     # For automated hyperparameter tuning using Bayesian optimization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6UK5TrpdVJi"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# === Simple Linear Encoder ===\n",
        "class LinearEncoder(nn.Module):\n",
        "    def __init__(self, embedding_dim):\n",
        "        super(LinearEncoder, self).__init__()\n",
        "        # A single linear transformation layer: y = Wx + b\n",
        "        self.linear = nn.Linear(embedding_dim, embedding_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass: apply the linear transformation\n",
        "        return self.linear(x)\n",
        "\n",
        "# === Multi-Layer Perceptron (MLP) Encoder ===\n",
        "class MLPEncoder(nn.Module):\n",
        "    def __init__(self, embedding_dim):\n",
        "        super(MLPEncoder, self).__init__()\n",
        "        # A 2-layer MLP with ReLU activation\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(embedding_dim, embedding_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(embedding_dim, embedding_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass through the MLP\n",
        "        return self.net(x)\n",
        "\n",
        "# === Residual MLP Encoder ===\n",
        "class ResMLPEncoder(nn.Module):\n",
        "    def __init__(self, embedding_dim):\n",
        "        super(ResMLPEncoder, self).__init__()\n",
        "        # Two linear layers with ReLU activation\n",
        "        self.linear1 = nn.Linear(embedding_dim, embedding_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(embedding_dim, embedding_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Residual connection: output = x + F(x)\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        return x + out\n",
        "\n",
        "# === Transformer-based Encoder ===\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, embedding_dim, nhead=4, num_layers=1):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        # Define a Transformer encoder layer with multi-head attention\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=embedding_dim, nhead=nhead)\n",
        "        # Stack the encoder layer `num_layers` times\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Add sequence dimension (required by PyTorch Transformer)\n",
        "        x = x.unsqueeze(1)             # [batch_size, 1, embedding_dim]\n",
        "        x = x.transpose(0, 1)          # [1, batch_size, embedding_dim] (seq_len first)\n",
        "        x = self.transformer_encoder(x) # Pass through transformer\n",
        "        x = x.transpose(0, 1).squeeze(1) # Remove added dimensions\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAsAVJEy3o9a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "def encode_embeddings_with_concept_column(encoder_model, input_file, output_file):\n",
        "    \"\"\"\n",
        "    Applies an encoder model to a set of embeddings (while preserving the 'Concept' column),\n",
        "    and saves the encoded results in the same tabular format.\n",
        "\n",
        "    Args:\n",
        "        encoder_model: A PyTorch model (e.g., LinearEncoder, MLPEncoder, etc.)\n",
        "        input_file (str): Path to the input TSV file containing 'Concept' and embedding vectors.\n",
        "        output_file (str): Path to save the encoded embeddings.\n",
        "    \"\"\"\n",
        "\n",
        "    # Select device (GPU if available, else CPU)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Move the encoder model to the selected device and set it to evaluation mode\n",
        "    encoder_model = encoder_model.to(device)\n",
        "    encoder_model.eval()\n",
        "\n",
        "    # Load the input TSV file containing concept URIs and embeddings\n",
        "    df = pd.read_csv(input_file, sep='\\t')\n",
        "\n",
        "    # Extract the 'Concept' column to preserve URIs\n",
        "    concepts = df['Concept'].tolist()\n",
        "\n",
        "    # Extract the numerical embedding values (excluding the 'Concept' column)\n",
        "    embedding_values = df.drop(columns=['Concept']).values\n",
        "\n",
        "    # Convert the embedding matrix into a PyTorch tensor and move to the device\n",
        "    embeddings = torch.FloatTensor(embedding_values).to(device)\n",
        "\n",
        "    # Pass the embeddings through the encoder model without computing gradients\n",
        "    with torch.no_grad():\n",
        "        encoded = encoder_model(embeddings).cpu().numpy()\n",
        "\n",
        "    # Reconstruct a new DataFrame with the encoded vectors and corresponding URIs\n",
        "    df_encoded = pd.DataFrame(encoded, columns=[f'dim_{i}' for i in range(encoded.shape[1])])\n",
        "    df_encoded.insert(0, \"Concept\", concepts)  # Re-insert the 'Concept' column at the first position\n",
        "\n",
        "    # Save the encoded embeddings to a TSV file\n",
        "    df_encoded.to_csv(output_file, sep='\\t', index=False)\n",
        "    print(f\"✅ Encoded embeddings saved to: {output_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRbz-pwBjKjX"
      },
      "source": [
        "# **Similarity Metrics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1Li_973lDgW"
      },
      "source": [
        "# **Euclidean Distance**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVKbIK8fDOs3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import pairwise_distances\n",
        "import time\n",
        "\n",
        "def topk_euclidean_with_uris(src_emb_path, tgt_emb_path, top_k=15, output_file=\"topk_mappings_euclidean_final.tsv\"):\n",
        "    start_time = time.time()  # ⏱️ Début du chronométrage\n",
        "\n",
        "    # Load source and target embedding files (each with a 'Concept' column and embedding columns)\n",
        "    df_src = pd.read_csv(src_emb_path, sep='\\t')\n",
        "    df_tgt = pd.read_csv(tgt_emb_path, sep='\\t')\n",
        "\n",
        "    # Extract concept URIs from the 'Concept' column\n",
        "    uris_src = df_src[\"Concept\"].values\n",
        "    uris_tgt = df_tgt[\"Concept\"].values\n",
        "\n",
        "    # Extract embedding vectors as numpy arrays (drop the 'Concept' column)\n",
        "    src_vecs = df_src.drop(columns=[\"Concept\"]).values\n",
        "    tgt_vecs = df_tgt.drop(columns=[\"Concept\"]).values\n",
        "\n",
        "    # Compute Euclidean (L2) distance between all source and target vectors\n",
        "    dist_matrix = pairwise_distances(src_vecs, tgt_vecs, metric='euclidean')\n",
        "\n",
        "    # Convert distance to similarity: the smaller the distance, the higher the similarity\n",
        "    sim_matrix = 1 / (1 + dist_matrix)\n",
        "\n",
        "    # For each source entity, find the indices of the top-k most similar target entities\n",
        "    topk_indices = np.argsort(-sim_matrix, axis=1)[:, :top_k]  # sort by similarity descending\n",
        "    topk_scores = np.take_along_axis(sim_matrix, topk_indices, axis=1)  # retrieve top-k similarity scores\n",
        "\n",
        "    # Construct the output DataFrame with URIs and similarity scores\n",
        "    rows = []\n",
        "    for i, (indices, scores) in enumerate(zip(topk_indices, topk_scores)):\n",
        "        src_uri = uris_src[i]\n",
        "        for tgt_idx, score in zip(indices, scores):\n",
        "            tgt_uri = uris_tgt[tgt_idx]\n",
        "            rows.append((src_uri, tgt_uri, score))  # store the source, target, and score\n",
        "\n",
        "    # Create a DataFrame and save the results to a TSV file\n",
        "    df_result = pd.DataFrame(rows, columns=[\"SrcEntity\", \"TgtEntity\", \"Score\"])\n",
        "    df_result.to_csv(output_file, sep='\\t', index=False)\n",
        "\n",
        "    # ⏱️ Fin du chronométrage\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"✅ Top-{top_k} Euclidean similarity results saved to: {output_file}\")\n",
        "    print(f\"⏱️ Execution time: {elapsed_time:.2f} seconds\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HigIe6n_lQ8X"
      },
      "source": [
        "# **FAISS Similarity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR2aehclj6VZ",
        "outputId": "343ab3ce-f402-41f3-ce6c-f3ec9126b040"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.2.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.11.0\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for faiss-gpu\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install the FAISS library for CPU-based approximate nearest neighbor search\n",
        "!pip install faiss-cpu\n",
        "\n",
        "# Alternatively, install the FAISS library optimized for GPU acceleration (if CUDA is available)\n",
        "!pip install faiss-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaX6JH9wj_WR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import faiss\n",
        "import time\n",
        "\n",
        "def load_embeddings(src_emb_path, tgt_emb_path):\n",
        "    df_src = pd.read_csv(src_emb_path, sep='\\t')\n",
        "    df_tgt = pd.read_csv(tgt_emb_path, sep='\\t')\n",
        "    uris_src = df_src[\"Concept\"].values\n",
        "    uris_tgt = df_tgt[\"Concept\"].values\n",
        "    src_vecs = df_src.drop(columns=[\"Concept\"]).values.astype('float32')\n",
        "    tgt_vecs = df_tgt.drop(columns=[\"Concept\"]).values.astype('float32')\n",
        "    return uris_src, uris_tgt, src_vecs, tgt_vecs\n",
        "\n",
        "def save_results(uris_src, uris_tgt, indices, scores, output_file, top_k):\n",
        "    rows = []\n",
        "    for i, (ind_row, score_row) in enumerate(zip(indices, scores)):\n",
        "        src_uri = uris_src[i]\n",
        "        for j, tgt_idx in enumerate(ind_row):\n",
        "            tgt_uri = uris_tgt[tgt_idx]\n",
        "            score = score_row[j]\n",
        "            rows.append((src_uri, tgt_uri, score))\n",
        "    df_result = pd.DataFrame(rows, columns=[\"SrcEntity\", \"TgtEntity\", \"Score\"])\n",
        "    df_result.to_csv(output_file, sep='\\t', index=False)\n",
        "    print(f\"Top-{top_k} FAISS similarity results saved to: {output_file}\")\n",
        "\n",
        "def topk_faiss_l2(src_emb_path, tgt_emb_path, top_k=15, output_file=\"topk_l2.tsv\"):\n",
        "    print(\"🔹 Using L2 (Euclidean) distance with FAISS\")\n",
        "    start = time.time()\n",
        "\n",
        "    uris_src, uris_tgt, src_vecs, tgt_vecs = load_embeddings(src_emb_path, tgt_emb_path)\n",
        "    dim = src_vecs.shape[1]\n",
        "    index = faiss.IndexFlatL2(dim)\n",
        "    index.add(tgt_vecs)\n",
        "    distances, indices = index.search(src_vecs, top_k)\n",
        "    similarity_scores = 1 / (1 + distances)\n",
        "\n",
        "    save_results(uris_src, uris_tgt, indices, similarity_scores, output_file, top_k)\n",
        "\n",
        "    print(f\"⏱️ Execution time: {time.time() - start:.2f} seconds\")\n",
        "\n",
        "def topk_faiss_inner_product(src_emb_path, tgt_emb_path, top_k=15, output_file=\"topk_ip.tsv\"):\n",
        "    print(\"🔹 Using Inner Product (dot product) with FAISS\")\n",
        "    start = time.time()\n",
        "\n",
        "    uris_src, uris_tgt, src_vecs, tgt_vecs = load_embeddings(src_emb_path, tgt_emb_path)\n",
        "    dim = src_vecs.shape[1]\n",
        "    index = faiss.IndexFlatIP(dim)\n",
        "    index.add(tgt_vecs)\n",
        "    indices_scores, indices = index.search(src_vecs, top_k)\n",
        "\n",
        "    save_results(uris_src, uris_tgt, indices, indices_scores, output_file, top_k)\n",
        "\n",
        "    print(f\"⏱️ Execution time: {time.time() - start:.2f} seconds\")\n",
        "\n",
        "def topk_faiss_cosine(src_emb_path, tgt_emb_path, top_k=15, output_file=\"topk_mappings_faiss_cosine.tsv\"):\n",
        "    df_src = pd.read_csv(src_emb_path, sep='\\t')\n",
        "    df_tgt = pd.read_csv(tgt_emb_path, sep='\\t')\n",
        "\n",
        "    uris_src = df_src[\"Concept\"].values\n",
        "    uris_tgt = df_tgt[\"Concept\"].values\n",
        "\n",
        "    src_vecs = df_src.drop(columns=[\"Concept\"]).values.astype('float32')\n",
        "    tgt_vecs = df_tgt.drop(columns=[\"Concept\"]).values.astype('float32')\n",
        "\n",
        "    # Normalize for cosine similarity\n",
        "    src_vecs = src_vecs / np.linalg.norm(src_vecs, axis=1, keepdims=True)\n",
        "    tgt_vecs = tgt_vecs / np.linalg.norm(tgt_vecs, axis=1, keepdims=True)\n",
        "\n",
        "    # Ensure arrays are C-contiguous\n",
        "    src_vecs = np.ascontiguousarray(src_vecs)\n",
        "    tgt_vecs = np.ascontiguousarray(tgt_vecs)\n",
        "\n",
        "    # Build FAISS index\n",
        "    index = faiss.IndexFlatIP(tgt_vecs.shape[1])  # inner product == cosine similarity if vectors are normalized\n",
        "    index.add(tgt_vecs)\n",
        "\n",
        "    # Perform search\n",
        "    scores, indices = index.search(src_vecs, top_k)\n",
        "\n",
        "    # Save results\n",
        "    with open(output_file, \"w\") as f:\n",
        "        f.write(\"SrcEntity\\tTgtEntity\\tScore\\n\")\n",
        "        for i, (row_scores, row_indices) in enumerate(zip(scores, indices)):\n",
        "            for score, idx in zip(row_scores, row_indices):\n",
        "                f.write(f\"{uris_src[i]}\\t{uris_tgt[idx]}\\t{score:.6f}\\n\")\n",
        "\n",
        "    print(f\"✅ Top-{top_k} cosine similarity results saved to: {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKXpLFv8lrLi"
      },
      "source": [
        "# **ANNOY Similarity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAGRX3PyqedX",
        "outputId": "c5c81054-7020-4054-d21e-db2c87986505"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting annoy\n",
            "  Downloading annoy-1.17.3.tar.gz (647 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/647.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.0/647.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.5/647.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: annoy\n",
            "  Building wheel for annoy (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for annoy: filename=annoy-1.17.3-cp311-cp311-linux_x86_64.whl size=551738 sha256=91ee3563c6d2455c9eca79578df55fa93ad81c07dcaebb466299b1cd2ec93f80\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/e5/58/0a3e34b92bedf09b4c57e37a63ff395ade6f6c1099ba59877c\n",
            "Successfully built annoy\n",
            "Installing collected packages: annoy\n",
            "Successfully installed annoy-1.17.3\n"
          ]
        }
      ],
      "source": [
        "# Install the Annoy library for approximate nearest neighbor search using tree-based indexing (good for fast read operations)\n",
        "!pip install annoy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDsLO0_-qllJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from annoy import AnnoyIndex\n",
        "import time\n",
        "\n",
        "def load_embeddings_annoy(src_emb_path, tgt_emb_path):\n",
        "    df_src = pd.read_csv(src_emb_path, sep='\\t')\n",
        "    df_tgt = pd.read_csv(tgt_emb_path, sep='\\t')\n",
        "    uris_src = df_src[\"Concept\"].values\n",
        "    uris_tgt = df_tgt[\"Concept\"].values\n",
        "    src_vecs = df_src.drop(columns=[\"Concept\"]).values.astype(\"float32\")\n",
        "    tgt_vecs = df_tgt.drop(columns=[\"Concept\"]).values.astype(\"float32\")\n",
        "    return uris_src, uris_tgt, src_vecs, tgt_vecs\n",
        "\n",
        "def save_annoy_results(uris_src, uris_tgt, all_results, output_file, top_k):\n",
        "    df_result = pd.DataFrame(all_results, columns=[\"SrcEntity\", \"TgtEntity\", \"Score\"])\n",
        "    df_result.to_csv(output_file, sep='\\t', index=False)\n",
        "    print(f\"Top-{top_k} Annoy similarity results saved to: {output_file}\")\n",
        "\n",
        "def topk_annoy(src_emb_path, tgt_emb_path, top_k=15, output_file=\"topk_annoy.tsv\", metric='euclidean'):\n",
        "    print(f\"🔹 Using Annoy with metric: {metric}\")\n",
        "    start = time.time()\n",
        "\n",
        "    uris_src, uris_tgt, src_vecs, tgt_vecs = load_embeddings_annoy(src_emb_path, tgt_emb_path)\n",
        "    dim = tgt_vecs.shape[1]\n",
        "    index = AnnoyIndex(dim, metric)\n",
        "\n",
        "    for i, vec in enumerate(tgt_vecs):\n",
        "        index.add_item(i, vec)\n",
        "\n",
        "    index.build(n_trees=10)\n",
        "\n",
        "    results = []\n",
        "    for i, src_vec in enumerate(src_vecs):\n",
        "        idxs, dists = index.get_nns_by_vector(src_vec, top_k, include_distances=True)\n",
        "        for j, (idx, dist) in enumerate(zip(idxs, dists)):\n",
        "            score = 1 / (1 + dist)  # Convert distance to similarity\n",
        "            results.append((uris_src[i], uris_tgt[idx], score))\n",
        "\n",
        "    save_annoy_results(uris_src, uris_tgt, results, output_file, top_k)\n",
        "    print(f\"⏱️ Execution time: {time.time() - start:.2f} seconds\")\n",
        "\n",
        "# Wrapper for Euclidean\n",
        "def topk_annoy_euclidean(src_emb_path, tgt_emb_path, top_k=15, output_file=\"topk_annoy_euclidean.tsv\"):\n",
        "    topk_annoy(src_emb_path, tgt_emb_path, top_k, output_file, metric='euclidean')\n",
        "\n",
        "# Wrapper for Cosine (approximate, via angular)\n",
        "def topk_annoy_cosine(src_emb_path, tgt_emb_path, top_k=15, output_file=\"topk_annoy_cosine.tsv\"):\n",
        "    topk_annoy(src_emb_path, tgt_emb_path, top_k, output_file, metric='angular')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7Yxt_LymEod"
      },
      "source": [
        "# **DIEM Similarity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lX6gJeFs1kJg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def compute_diem_matrix(A, B, eps=1e-8):\n",
        "    \"\"\"\n",
        "    Compute DIEM distance matrix between A and B:\n",
        "    diem(a, b) = ||a - b||^2 / (||a|| * ||b||)\n",
        "    \"\"\"\n",
        "    norm_A = np.linalg.norm(A, axis=1).reshape(-1, 1)\n",
        "    norm_B = np.linalg.norm(B, axis=1).reshape(1, -1)\n",
        "\n",
        "    dot_prod = np.dot(A, B.T)\n",
        "\n",
        "    a_sq = np.sum(A**2, axis=1).reshape(-1, 1)\n",
        "    b_sq = np.sum(B**2, axis=1).reshape(1, -1)\n",
        "    l2_squared = a_sq + b_sq - 2 * dot_prod\n",
        "\n",
        "    denom = norm_A * norm_B + eps\n",
        "    diem = l2_squared / denom\n",
        "    return diem\n",
        "\n",
        "def topk_diem(src_emb_path, tgt_emb_path, top_k=15, output_file=\"topk_mappings_diem.tsv\"):\n",
        "    print(\"🔹 Using DIEM similarity measure\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Load embeddings\n",
        "    df_src = pd.read_csv(src_emb_path, sep='\\t')\n",
        "    df_tgt = pd.read_csv(tgt_emb_path, sep='\\t')\n",
        "\n",
        "    uris_src = df_src[\"Concept\"].values\n",
        "    uris_tgt = df_tgt[\"Concept\"].values\n",
        "    src_vecs = df_src.drop(columns=[\"Concept\"]).values.astype('float32')\n",
        "    tgt_vecs = df_tgt.drop(columns=[\"Concept\"]).values.astype('float32')\n",
        "\n",
        "    # Compute DIEM similarity matrix\n",
        "    diem_matrix = compute_diem_matrix(src_vecs, tgt_vecs)\n",
        "    sim_matrix = 1 / (1 + diem_matrix)\n",
        "\n",
        "    # Select top-k most similar target concepts\n",
        "    topk_indices = np.argsort(-sim_matrix, axis=1)[:, :top_k]\n",
        "    topk_scores = np.take_along_axis(sim_matrix, topk_indices, axis=1)\n",
        "\n",
        "    rows = []\n",
        "    for i, (indices, scores) in enumerate(zip(topk_indices, topk_scores)):\n",
        "        src_uri = uris_src[i]\n",
        "        for tgt_idx, score in zip(indices, scores):\n",
        "            tgt_uri = uris_tgt[tgt_idx]\n",
        "            rows.append((src_uri, tgt_uri, score))\n",
        "\n",
        "    df_result = pd.DataFrame(rows, columns=[\"SrcEntity\", \"TgtEntity\", \"Score\"])\n",
        "    df_result.to_csv(output_file, sep='\\t', index=False)\n",
        "    print(f\"Top-{top_k} DIEM similarity results saved to: {output_file}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"⏱️ Execution time: {end_time - start_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmilJuh4mjj_"
      },
      "source": [
        "# **Cosine From Transformer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8A8IWA5hM1e",
        "outputId": "4a808320-cd64-42cc-94a2-1a87644ad6c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.31.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n",
            "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.7/345.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentence-transformers\n",
            "Successfully installed sentence-transformers-4.1.0\n"
          ]
        }
      ],
      "source": [
        "# Install the Sentence Transformers library, which provides pre-trained models like BERT, RoBERTa, and SapBERT for computing dense vector representations of text (suitable for semantic similarity tasks)\n",
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b4tuxMdhJ7K"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import time\n",
        "from sentence_transformers import util\n",
        "\n",
        "def topk_cosine(src_emb_path, tgt_emb_path, top_k=15, output_file=\"topk_mappings_cosine.tsv\"):\n",
        "    print(\"🔹 Using Cosine Similarity (Sentence-Transformers)\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Load embeddings with URIs\n",
        "    df_src = pd.read_csv(src_emb_path, sep='\\t')\n",
        "    df_tgt = pd.read_csv(tgt_emb_path, sep='\\t')\n",
        "\n",
        "    uris_src = df_src[\"Concept\"].values\n",
        "    uris_tgt = df_tgt[\"Concept\"].values\n",
        "\n",
        "    src_vecs = torch.tensor(df_src.drop(columns=[\"Concept\"]).values, dtype=torch.float32)\n",
        "    tgt_vecs = torch.tensor(df_tgt.drop(columns=[\"Concept\"]).values, dtype=torch.float32)\n",
        "\n",
        "    # Normalize vectors for cosine similarity\n",
        "    src_vecs = torch.nn.functional.normalize(src_vecs, p=2, dim=1)\n",
        "    tgt_vecs = torch.nn.functional.normalize(tgt_vecs, p=2, dim=1)\n",
        "\n",
        "    # Compute cosine similarity matrix\n",
        "    sim_matrix = util.cos_sim(src_vecs, tgt_vecs)  # shape: [src x tgt]\n",
        "\n",
        "    # Top-k per row\n",
        "    top_k_scores, top_k_indices = torch.topk(sim_matrix, k=top_k, dim=1)\n",
        "\n",
        "    rows = []\n",
        "    for i, (indices_row, scores_row) in enumerate(zip(top_k_indices, top_k_scores)):\n",
        "        src_uri = uris_src[i]\n",
        "        for j in range(top_k):\n",
        "            tgt_uri = uris_tgt[indices_row[j]]\n",
        "            score = scores_row[j].item()\n",
        "            rows.append((src_uri, tgt_uri, score))\n",
        "\n",
        "    # Save results\n",
        "    df_result = pd.DataFrame(rows, columns=[\"SrcEntity\", \"TgtEntity\", \"Score\"])\n",
        "    df_result.to_csv(output_file, sep='\\t', index=False)\n",
        "    print(f\"Top-{top_k} cosine similarity results saved to: {output_file}\")\n",
        "\n",
        "    print(f\"⏱️ Execution time: {time.time() - start_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zF_Ihc7pOADP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "\n",
        "def topk_sharpened_cosine_with_uris(\n",
        "    src_emb_path, tgt_emb_path, top_k=15, output_file=\"topk_mappings_sharpened_cosine.tsv\", sharpening_power=2\n",
        "):\n",
        "    start_time = time.time()  # Chronométrage début\n",
        "\n",
        "    # Chargement des embeddings source et target\n",
        "    df_src = pd.read_csv(src_emb_path, sep='\\t')\n",
        "    df_tgt = pd.read_csv(tgt_emb_path, sep='\\t')\n",
        "\n",
        "    uris_src = df_src[\"Concept\"].values\n",
        "    uris_tgt = df_tgt[\"Concept\"].values\n",
        "\n",
        "    # Conversion des vecteurs en tenseurs torch\n",
        "    src_vecs = torch.tensor(df_src.drop(columns=[\"Concept\"]).values, dtype=torch.float32)\n",
        "    tgt_vecs = torch.tensor(df_tgt.drop(columns=[\"Concept\"]).values, dtype=torch.float32)\n",
        "\n",
        "    # Normalisation des vecteurs pour produit scalaire = cosinus\n",
        "    src_vecs = torch.nn.functional.normalize(src_vecs, p=2, dim=1)\n",
        "    tgt_vecs = torch.nn.functional.normalize(tgt_vecs, p=2, dim=1)\n",
        "\n",
        "    # Calcul des similarités cosinus\n",
        "    sim_matrix = torch.matmul(src_vecs, tgt_vecs.T)\n",
        "\n",
        "    # Appliquer la mise au carré pour sharpened cosine\n",
        "    sim_matrix = sim_matrix ** sharpening_power\n",
        "\n",
        "    # Sélection des top-k indices et scores\n",
        "    topk_scores, topk_indices = torch.topk(sim_matrix, k=top_k, dim=1)\n",
        "\n",
        "    # Construction des résultats\n",
        "    rows = []\n",
        "    for i, (indices, scores) in enumerate(zip(topk_indices, topk_scores)):\n",
        "        src_uri = uris_src[i]\n",
        "        for tgt_idx, score in zip(indices.tolist(), scores.tolist()):\n",
        "            tgt_uri = uris_tgt[tgt_idx]\n",
        "            rows.append((src_uri, tgt_uri, float(score)))\n",
        "\n",
        "    df_result = pd.DataFrame(rows, columns=[\"SrcEntity\", \"TgtEntity\", \"Score\"])\n",
        "    df_result.to_csv(output_file, sep='\\t', index=False)\n",
        "\n",
        "    print(f\"Top-{top_k} sharpened cosine similarity results saved to: {output_file}\")\n",
        "    print(f\"⏱️ Execution time: {time.time() - start_time:.2f} seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjUYOFO7pdCg"
      },
      "source": [
        "# **Mappings Evaluation Functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6m04nFw_R00"
      },
      "source": [
        "# **Precision, Recall, F1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBz_LHpYnFIx"
      },
      "outputs": [],
      "source": [
        "def select_best_candidates_per_src_with_margin(df, score_margin=0.01):\n",
        "    \"\"\"\n",
        "    For each SrcEntity, retain all candidate mappings whose similarity score is\n",
        "    within 99% of the best score (default margin = 0.01).\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing columns ['SrcEntity', 'TgtEntity', 'Score'].\n",
        "        score_margin (float): Score margin. 0.01 means keep scores ≥ 99% of best score.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Filtered DataFrame with multiple high-quality candidates per SrcEntity.\n",
        "    \"\"\"\n",
        "    selected_rows = []\n",
        "\n",
        "    for src, group in df.groupby(\"SrcEntity\"):\n",
        "        group_sorted = group.sort_values(by=\"Score\", ascending=False)\n",
        "        best_score = group_sorted.iloc[0][\"Score\"]\n",
        "        threshold = best_score * (1 - score_margin)\n",
        "\n",
        "        # Keep all target entities with score >= threshold\n",
        "        close_matches = group_sorted[group_sorted[\"Score\"] >= threshold]\n",
        "        selected_rows.append(close_matches)\n",
        "\n",
        "    result_df = pd.concat(selected_rows).reset_index(drop=True)\n",
        "    print(f\"🏆 Selected candidates within {(1 - score_margin) * 100:.1f}% of best score per SrcEntity: {len(result_df)} rows\")\n",
        "    return result_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdP6iYirLJW6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def filter_and_evaluate_predictions_top1(\n",
        "    topk_file,\n",
        "    train_file,\n",
        "    test_file,\n",
        "    src_onto,\n",
        "    tgt_onto,\n",
        "    threshold=0.0  # Similarity score threshold\n",
        "):\n",
        "    # === Step 1: Load prediction and reference files ===\n",
        "    df = pd.read_csv(topk_file, sep='\\t', dtype=str)\n",
        "    train_df = pd.read_csv(train_file, sep=\"\\t\", dtype=str)\n",
        "    test_df = pd.read_csv(test_file, sep=\"\\t\", dtype=str)\n",
        "    print(f\"🔍 Initial file: {len(df)} rows\")\n",
        "\n",
        "    # === Step 2: Remove URIs only present in train set ===\n",
        "    train_uris = set(train_df['SrcEntity']) | set(train_df['TgtEntity'])\n",
        "    test_uris = set(test_df['SrcEntity']) | set(test_df['TgtEntity'])\n",
        "    uris_to_exclude = train_uris - test_uris\n",
        "    df = df[~(df['SrcEntity'].isin(uris_to_exclude) | df['TgtEntity'].isin(uris_to_exclude))].reset_index(drop=True)\n",
        "    print(f\"✅ After removing train-only URIs: {len(df)} rows\")\n",
        "\n",
        "    # === Step 3: Remove ignored ontology classes ===\n",
        "    ignored_class_index = get_ignored_class_index(src_onto)\n",
        "    ignored_class_index.update(get_ignored_class_index(tgt_onto))\n",
        "    ignored_uris = {str(uri).strip() for uri in ignored_class_index}\n",
        "    df = df[~(df['SrcEntity'].isin(ignored_uris) | df['TgtEntity'].isin(ignored_uris))].reset_index(drop=True)\n",
        "    print(f\"✅ After removing ignored classes: {len(df)} rows\")\n",
        "\n",
        "    # === Step 4: Keep only predictions with source entities from the test set ===\n",
        "    test_src_entities = set(test_df['SrcEntity'])\n",
        "    df = df[df['SrcEntity'].isin(test_src_entities)].reset_index(drop=True)\n",
        "    print(f\"✅ After keeping only test SrcEntities: {len(df)} rows\")\n",
        "\n",
        "    # === Step 5: Apply similarity threshold ===\n",
        "    df['Score'] = df['Score'].astype(float)\n",
        "    df = df[df['Score'] >= threshold]\n",
        "    print(f\"✅ After applying threshold ≥ {threshold}: {len(df)} rows\")\n",
        "\n",
        "    # === Step 6: Save all filtered predictions (before top-1 selection) ===\n",
        "    output_file_all = topk_file.replace(\".tsv\", f\"_filtered.tsv\")\n",
        "    df.to_csv(output_file_all, sep='\\t', index=False)\n",
        "    print(f\"📁 Filtered predictions saved: {output_file_all}\")\n",
        "\n",
        "    # === Step 7: Select best candidates per source with relaxed top-k margin ===\n",
        "    df_top1 = select_best_candidates_per_src_with_margin(df, score_margin=0.0035)\n",
        "\n",
        "    # === Step 8: Save relaxed Top-1 filtered results ===\n",
        "    output_file_top1 = topk_file.replace(\".tsv\", f\"_filtered_top1_th{threshold}.tsv\")\n",
        "    df_top1.to_csv(output_file_top1, sep='\\t', index=False)\n",
        "    print(f\"📁 Filtered Top-1 file saved: {output_file_top1}\")\n",
        "\n",
        "    # === Step 9: Evaluate Top-1 results ===\n",
        "    preds = EntityMapping.read_table_mappings(output_file_top1)\n",
        "    refs = ReferenceMapping.read_table_mappings(test_file)\n",
        "    preds = remove_ignored_mappings(preds, ignored_class_index)\n",
        "\n",
        "    results = AlignmentEvaluator.f1(preds, refs)\n",
        "\n",
        "    preds2 = [p.to_tuple() for p in preds]\n",
        "    refs2 = [r.to_tuple() for r in refs]\n",
        "    correct = len(set(preds2).intersection(set(refs2)))\n",
        "\n",
        "    print(f\"🎯 Correct mappings (Top-1): {correct}\")\n",
        "    print(f\"📊 Evaluation (P / R / F1): {results}\")\n",
        "\n",
        "    return output_file_top1, results, correct\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVxztBa6FwPp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file,\n",
        "    train_file,\n",
        "    test_file\n",
        "):\n",
        "    # === Step 1: Load files ===\n",
        "    df = pd.read_csv(topk_file, sep='\\t', dtype=str)\n",
        "    train_df = pd.read_csv(train_file, sep=\"\\t\", dtype=str)\n",
        "    test_df = pd.read_csv(test_file, sep=\"\\t\", dtype=str)\n",
        "\n",
        "    print(f\"🔍 Initial file: {len(df)} rows\")\n",
        "\n",
        "    # === Step 2: Identify common entities (source or target) ===\n",
        "    test_entities = set(test_df['SrcEntity']).union(set(test_df['TgtEntity']))\n",
        "    train_entities = set(train_df['SrcEntity']).union(set(train_df['TgtEntity']))\n",
        "    common_entities = test_entities & train_entities\n",
        "    print(f\"❗ Common entities to remove: {len(common_entities)}\")\n",
        "\n",
        "    # === Step 3: Filter test set and keep only pure test entities ===\n",
        "    filtered_test_df = test_df[\n",
        "        ~(test_df['SrcEntity'].isin(common_entities) | test_df['TgtEntity'].isin(common_entities))\n",
        "    ].reset_index(drop=True)\n",
        "\n",
        "    src_entities_test = set(filtered_test_df['SrcEntity'])\n",
        "\n",
        "    # === Step 4: Filter topk predictions to only include valid test sources ===\n",
        "    df['SrcEntity'] = df['SrcEntity'].str.strip()\n",
        "    df = df[df['SrcEntity'].isin(src_entities_test)].reset_index(drop=True)\n",
        "    print(f\"✅ After filtering to test SrcEntities only: {len(df)} rows\")\n",
        "\n",
        "    # === Step 5: Convert Score and compute Top-1 ===\n",
        "    df['Score'] = df['Score'].astype(float)\n",
        "    df_top1 = df.sort_values(by=[\"SrcEntity\", \"Score\"], ascending=[True, False]) \\\n",
        "                .groupby(\"SrcEntity\", as_index=False).first()\n",
        "\n",
        "    # === Step 6: Add missing SrcEntities (not in df_top1) ===\n",
        "    missing_srcs = src_entities_test - set(df_top1['SrcEntity'])\n",
        "    if missing_srcs:\n",
        "        print(f\"⚠️ Adding {len(missing_srcs)} missing SrcEntities with no prediction\")\n",
        "        missing_rows = pd.DataFrame({\n",
        "            \"SrcEntity\": list(missing_srcs),\n",
        "            \"TgtEntity\": [None] * len(missing_srcs),\n",
        "            \"Score\": [0.0] * len(missing_srcs)\n",
        "        })\n",
        "        df_top1 = pd.concat([df_top1, missing_rows], ignore_index=True)\n",
        "\n",
        "    df_top1 = df_top1.sort_values(by=\"SrcEntity\").reset_index(drop=True)\n",
        "    print(f\"🏆 After Top-1 selection: {len(df_top1)} rows\")\n",
        "\n",
        "    # === Step 7: Save final Top-1 predictions ===\n",
        "    output_file = topk_file.replace(\".tsv\", f\"_Top1_testclean.tsv\")\n",
        "    df_top1.to_csv(output_file, sep='\\t', index=False)\n",
        "    print(f\"📁 Final Top-1 file saved: {output_file}\")\n",
        "\n",
        "    # === Step 8: Evaluate against filtered test set ===\n",
        "    refs_set = set(zip(filtered_test_df['SrcEntity'], filtered_test_df['TgtEntity']))\n",
        "    preds_set = set(zip(df_top1['SrcEntity'], df_top1['TgtEntity']))\n",
        "\n",
        "    correct = len(preds_set & refs_set)\n",
        "    precision = correct / len(preds_set) if preds_set else 0.0\n",
        "    recall = correct / len(refs_set) if refs_set else 0.0\n",
        "    f1 = (2 * precision * recall) / (precision + recall + 1e-8) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "    results = {\n",
        "        \"Precision\": round(precision, 4),\n",
        "        \"Recall\": round(recall, 4),\n",
        "        \"F1\": round(f1, 4)\n",
        "    }\n",
        "\n",
        "    print(f\"🎯 Correct mappings (Top-1): {correct}\")\n",
        "    print(f\"📊 Evaluation (P / R / F1): {results}\")\n",
        "\n",
        "    return output_file, results, correct\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPuzmu6f_Y8W"
      },
      "source": [
        "# **Precision@k, Recall@k, F1@k**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqhpmKKZ_YXH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "def filter_topk(\n",
        "    topk_file,\n",
        "    train_file,\n",
        "    test_file,\n",
        "    src_onto,\n",
        "    tgt_onto,\n",
        "    k=10,\n",
        "    threshold=0.0\n",
        "):\n",
        "    \"\"\"\n",
        "    Filtre les prédictions top-k pour ne garder que les concepts source du test set,\n",
        "    exclut les classes ignorées et évalue Precision@k / Recall@k / F1@k.\n",
        "    \"\"\"\n",
        "    # === Load data ===\n",
        "    df = pd.read_csv(topk_file, sep='\\t', dtype=str)\n",
        "    train_df = pd.read_csv(train_file, sep='\\t', dtype=str)\n",
        "    test_df = pd.read_csv(test_file, sep='\\t', dtype=str)\n",
        "\n",
        "    print(f\"🔍 Initial candidate mappings: {len(df)}\")\n",
        "\n",
        "    # === Score conversion and threshold ===\n",
        "    df['Score'] = df['Score'].apply(lambda x: float(str(x).strip('[]')) if pd.notnull(x) else 0.0)\n",
        "    df = df[df['Score'] >= threshold]\n",
        "    print(f\"✅ After applying threshold {threshold}: {len(df)}\")\n",
        "\n",
        "    # === Remove train-only URIs ===\n",
        "    train_uris = set(train_df['SrcEntity']) | set(train_df['TgtEntity'])\n",
        "    test_uris = set(test_df['SrcEntity']) | set(test_df['TgtEntity'])\n",
        "    uris_to_exclude = train_uris - test_uris\n",
        "    df = df[~(df['SrcEntity'].isin(uris_to_exclude) | df['TgtEntity'].isin(uris_to_exclude))]\n",
        "    print(f\"✅ After removing train-only URIs: {len(df)}\")\n",
        "\n",
        "    # === Remove ignored classes ===\n",
        "    ignored_class_index = get_ignored_class_index(src_onto)\n",
        "    ignored_class_index.update(get_ignored_class_index(tgt_onto))\n",
        "    ignored_uris = {str(uri).strip() for uri in ignored_class_index}\n",
        "    df = df[~(df['SrcEntity'].isin(ignored_uris) | df['TgtEntity'].isin(ignored_uris))]\n",
        "    print(f\"✅ After removing ignored classes: {len(df)}\")\n",
        "\n",
        "    # === Keep only source entities from test set ===\n",
        "    test_src_entities = set(test_df['SrcEntity'])\n",
        "    df = df[df['SrcEntity'].isin(test_src_entities)]\n",
        "    print(f\"✅ After keeping only test SrcEntities: {len(df)}\")\n",
        "\n",
        "    # === Save filtered predictions ===\n",
        "    output_file = topk_file.replace(\".tsv\", f\"_filtered_top{k}_th{threshold}.tsv\")\n",
        "    df.to_csv(output_file, sep='\\t', index=False)\n",
        "    print(f\"📁 Filtered top-k saved to: {output_file}\")\n",
        "\n",
        "    # === Evaluate Precision@k / Recall@k / F1@k ===\n",
        "    results = evaluate_topk(df, test_df, k=k)\n",
        "    print(f\"📊 Evaluation results (Top-{k}): {results}\")\n",
        "\n",
        "    return output_file, results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwdxR-ZzAgS3"
      },
      "outputs": [],
      "source": [
        "def evaluate_topk(predictions_df, reference_df, k=10):\n",
        "    ref_dict = defaultdict(set)\n",
        "    for _, row in reference_df.iterrows():\n",
        "        ref_dict[row['SrcEntity']].add(row['TgtEntity'])\n",
        "\n",
        "    topk_df = predictions_df.sort_values(by='Score', ascending=False).groupby('SrcEntity').head(k)\n",
        "\n",
        "    total_tp = total_pred = total_ref = 0\n",
        "\n",
        "    for src, group in topk_df.groupby('SrcEntity'):\n",
        "        predicted = set(group['TgtEntity'])\n",
        "        true = ref_dict.get(src, set())\n",
        "        tp = len(predicted & true)\n",
        "        total_tp += tp\n",
        "        total_pred += len(predicted)\n",
        "        total_ref += len(true)\n",
        "\n",
        "    precision = total_tp / total_pred if total_pred else 0.0\n",
        "    recall = total_tp / total_ref if total_ref else 0.0\n",
        "    f1 = 2 * precision * recall / (precision + recall + 1e-8) if precision + recall > 0 else 0.0\n",
        "\n",
        "    return {\n",
        "        f'Precision@{k}': round(precision, 4),\n",
        "        f'Recall@{k}': round(recall, 4),\n",
        "        f'F1@{k}': round(f1, 4)\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf6vZML-KewM"
      },
      "source": [
        "# **Local MRR and Hit@k**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xXm15EQKeE_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# === Étape 1 : Charger les fichiers ===\n",
        "# Chemins vers les fichiers\n",
        "cands_path = candidates_Rank = f\"{data_dir}/{task}_cands.csv\"\n",
        "src_emb_path = f\"{data_dir}/{src_ent}_final_embeddings.tsv\"\n",
        "tgt_emb_path = f\"{data_dir}/{tgt_ent}_final_embeddings.tsv\"\n",
        "\n",
        "# Lire les fichiers\n",
        "df_cands = pd.read_csv(cands_path)\n",
        "src_emb_df = pd.read_csv(src_emb_path, sep=\"\\t\")\n",
        "tgt_emb_df = pd.read_csv(tgt_emb_path, sep=\"\\t\")\n",
        "\n",
        "# === Étape 2 : Extraire les URI uniques des sources et des cibles ===\n",
        "unique_src_df = pd.DataFrame(df_cands[\"SrcEntity\"].unique(), columns=[\"Concept\"])\n",
        "unique_tgt_df = pd.DataFrame(df_cands[\"TgtEntity\"].unique(), columns=[\"Concept\"])\n",
        "\n",
        "# === Étape 3 : Rattacher les embeddings à chaque concept ===\n",
        "merged_src_df = pd.merge(unique_src_df, src_emb_df, on=\"Concept\", how=\"left\")\n",
        "merged_tgt_df = pd.merge(unique_tgt_df, tgt_emb_df, on=\"Concept\", how=\"left\")\n",
        "\n",
        "# === Étape 4 : Sauvegarder les résultats ===\n",
        "merged_src_df.to_csv(f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\", sep=\"\\t\", index=False)\n",
        "merged_tgt_df.to_csv(f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\", sep=\"\\t\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpUklR4xnVMH"
      },
      "source": [
        "# **Mappings Generation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vr6C8BVBndY2"
      },
      "source": [
        "# **Using Euclidean**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43OPr4HlHaI-"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfGAxYWzHaI-",
        "outputId": "3780c7f2-6c1f-448a-ebb9-9f305793254e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-1 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_euclidean.tsv\n",
            "⏱️ Execution time: 9.83 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_euclidean.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyXDnwkCKJuS",
        "outputId": "0cd0cdec-4fa1-49df-b68d-2ee0cf994fcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_euclidean_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1486\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7456, 'Recall': 0.721, 'F1': 0.7331}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_euclidean.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7dAZz9sHaI_",
        "outputId": "d4228cba-537f-45de-afe4-c8659a200673"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9338 rows\n",
            "✅ After removing ignored classes: 9338 rows\n",
            "✅ After keeping only test SrcEntities: 2401 rows\n",
            "✅ After applying threshold ≥ 0.0: 2401 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_euclidean_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2401 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_euclidean_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1815\n",
            "📊 Evaluation (P / R / F1): {'P': 0.756, 'R': 0.682, 'F1': 0.717}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_euclidean.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7QN_ezBfDz7",
        "outputId": "d54bbee3-eae9-459e-a6e9-c9a5de2e48e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7559, 'Recall@1': 0.7071, 'F1@1': 0.7307}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/neoplas_top_1_mappings_euclidean_filtered.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxXKS1i5f-xc",
        "outputId": "ed4376e5-4be4-4d5d-ac96-a6b5b56f6380"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-1 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_euclidean_mrr_hit.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_euclidean_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_402seVv7D4O"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_euclidean_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ex0Q_1k5h4ul",
        "outputId": "510a5f9a-8cdd-4377-f0d5-d52747f940ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6909033534555333, 'Hits@1': 0.681562147953436, 'Hits@5': 0.681562147953436, 'Hits@10': 0.681562147953436}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smmk5M39fC7r"
      },
      "source": [
        "# **K=5**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPWH06IIfC7r",
        "outputId": "4353c03d-53b2-4ecb-9dc8-1b65dc7802bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-5 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_5_mappings_euclidean.tsv\n",
            "⏱️ Execution time: 9.69 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=5,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_5_mappings_euclidean.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SXquucqfC7r",
        "outputId": "21e0fd5b-6c81-47a2-92bf-b2a57b166b69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 57035 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 9965 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_5_mappings_euclidean_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1486\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7456, 'Recall': 0.721, 'F1': 0.7331}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_5_mappings_euclidean.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPaUoZkefC7r",
        "outputId": "82c4570f-2a3f-4ace-9181-926ff1110bd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 57035 rows\n",
            "✅ After removing train-only URIs: 46753 rows\n",
            "✅ After removing ignored classes: 46753 rows\n",
            "✅ After keeping only test SrcEntities: 11240 rows\n",
            "✅ After applying threshold ≥ 0.0: 11240 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_5_mappings_euclidean_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2526 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_5_mappings_euclidean_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1879\n",
            "📊 Evaluation (P / R / F1): {'P': 0.744, 'R': 0.706, 'F1': 0.724}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_5_mappings_euclidean.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Geu7jjRVfC7r",
        "outputId": "c0ae3244-4e5d-4141-97eb-8dca1a56eafd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7492, 'Recall@1': 0.7, 'F1@1': 0.7237}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_5_mappings_euclidean_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRu8OMeyfC7s",
        "outputId": "18ba0198-28b6-4159-a068-6c437740059a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-5 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_5_mappings_euclidean_mrr_hit.tsv\n",
            "⏱️ Execution time: 4.06 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=5,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_5_mappings_euclidean_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzzgIpT5fC7s"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_5_mappings_euclidean_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDTbqnpgfC7s",
        "outputId": "9fe66fb7-f197-4f0f-d813-22a5b574a1e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8825049681028113, 'Hits@1': 0.8516710476905746, 'Hits@5': 0.9121291776192264, 'Hits@10': 0.9121291776192264}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bsb5Nm_XxOOC"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhkQdJ7jUa1f",
        "outputId": "3989724c-6602-4d04-9e78-7283fce22127"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-10 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_euclidean.tsv\n",
            "⏱️ Execution time: 10.82 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_euclidean.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbSCzWcCLarG",
        "outputId": "bc68ad5e-4f3a-4168-83a2-aa7f2cfc4314"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_euclidean_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1486\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7456, 'Recall': 0.721, 'F1': 0.7331}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_euclidean.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmAItphJUa1f",
        "outputId": "4d3f9700-f3ba-4eab-8cf6-1f5cfa68afe7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 93974 rows\n",
            "✅ After removing ignored classes: 93974 rows\n",
            "✅ After keeping only test SrcEntities: 22353 rows\n",
            "✅ After applying threshold ≥ 0.0: 22353 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_euclidean_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2526 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_euclidean_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1879\n",
            "📊 Evaluation (P / R / F1): {'P': 0.744, 'R': 0.706, 'F1': 0.724}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_euclidean.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxQQ-3PCUa1f",
        "outputId": "66fd6d8c-e84b-4607-a7a6-e52fa9c2ab76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7492, 'Recall@1': 0.7, 'F1@1': 0.7237}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_euclidean_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODy-TM0XUa1f",
        "outputId": "997fedc6-26bf-4abe-a008-60db0b2addb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-10 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_euclidean_mrr_hit.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_euclidean_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ga4KWjZUa1f"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_euclidean_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i6bsfGcUa1f",
        "outputId": "57963b34-5cb7-4a0a-fd60-307d28b2caed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9087012240228131, 'Hits@1': 0.8708223807735637, 'Hits@5': 0.9504318437852046, 'Hits@10': 0.9504318437852046}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKYNajnLxFLn"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwKGDwauacpA",
        "outputId": "92deb3db-41d5-4140-fc87-039899c003f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-30 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_euclidean.tsv\n",
            "⏱️ Execution time: 12.45 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_euclidean.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnBwpHOwLqfv",
        "outputId": "ce69a5d3-349b-42ca-f2da-473d58380108"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_euclidean_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1486\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7456, 'Recall': 0.721, 'F1': 0.7331}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_euclidean.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fdIdIcWacpA",
        "outputId": "ae04d05b-5270-43fa-890b-0ed277d9c3c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 284213 rows\n",
            "✅ After removing ignored classes: 284213 rows\n",
            "✅ After keeping only test SrcEntities: 67469 rows\n",
            "✅ After applying threshold ≥ 0.0: 67469 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_euclidean_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2526 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_euclidean_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1879\n",
            "📊 Evaluation (P / R / F1): {'P': 0.744, 'R': 0.706, 'F1': 0.724}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_euclidean.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3TtdHSCacpA",
        "outputId": "24faa91e-c24e-433b-f697-e4ef91edc7f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7492, 'Recall@1': 0.7, 'F1@1': 0.7237}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_euclidean_filtered.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Fyo9S7DacpB",
        "outputId": "764ba361-8e58-44a9-aa4c-d68fa8fef5e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-30 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_euclidean_mrr_hit.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_euclidean_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8VxfyKQacpB"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_euclidean_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRmk_vUwacpB",
        "outputId": "13f06694-3812-4961-a617-6fd874245a0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9210168581050832, 'Hits@1': 0.8768306421329328, 'Hits@5': 0.97371385655276, 'Hits@10': 0.9778445362373264}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZgnxkFgxfvd"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OR6QoDcLbVyG",
        "outputId": "52f58db1-61e3-4e90-e45d-e6705226ef8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-100 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_euclidean.tsv\n",
            "⏱️ Execution time: 19.06 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_euclidean.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfMr9F2YMqOO",
        "outputId": "7389d51d-bed4-43a2-ede6-2b7c5d008a02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_euclidean_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1486\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7456, 'Recall': 0.721, 'F1': 0.7331}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_euclidean.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhJAjqP9bVyG",
        "outputId": "87f4e77f-79c1-46fd-9ec9-3ee906cf14e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 953701 rows\n",
            "✅ After removing ignored classes: 953701 rows\n",
            "✅ After keeping only test SrcEntities: 226196 rows\n",
            "✅ After applying threshold ≥ 0.0: 226196 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_euclidean_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2526 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_euclidean_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1879\n",
            "📊 Evaluation (P / R / F1): {'P': 0.744, 'R': 0.706, 'F1': 0.724}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_euclidean.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ml_J9lX6bVyG",
        "outputId": "c5384a6c-742f-4f9c-9afe-6a959318456e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7492, 'Recall@1': 0.7, 'F1@1': 0.7237}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_euclidean_filtered.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYuViWpIbVyG",
        "outputId": "8c0500b2-b96a-45ff-bbab-4816ece39971"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-100 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_euclidean_mrr_hit.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_euclidean_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZD0pQlKVbVyG"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_euclidean_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTczYdvnbVyH",
        "outputId": "014c2e71-6247-4556-b5c3-e888eaadae6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9249873795274303, 'Hits@1': 0.8775816748028539, 'Hits@5': 0.984228313931656, 'Hits@10': 0.9906120916259857}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SBB15EXdYiO"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdPwds3VdYiP",
        "outputId": "53baee9f-1f64-41b9-e298-521e17928596"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-200 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_euclidean.tsv\n",
            "⏱️ Execution time: 28.54 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_euclidean.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Rc3TI6bMyud",
        "outputId": "cdd9e82f-4466-4e40-90ff-4fd8cad744df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_euclidean_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1486\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7456, 'Recall': 0.721, 'F1': 0.7331}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_euclidean.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh0N2NobdYiP",
        "outputId": "90354986-8637-46fa-81ce-a261f011536e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1912330 rows\n",
            "✅ After removing ignored classes: 1912330 rows\n",
            "✅ After keeping only test SrcEntities: 453381 rows\n",
            "✅ After applying threshold ≥ 0.0: 453381 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_euclidean_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2526 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_euclidean_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1879\n",
            "📊 Evaluation (P / R / F1): {'P': 0.744, 'R': 0.706, 'F1': 0.724}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_euclidean.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPh5nSD5dYiP",
        "outputId": "2e13c77c-4b1b-4a3f-cf39-7a947133107a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7492, 'Recall@1': 0.7, 'F1@1': 0.7237}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_euclidean_filtered.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IlIsm7FdYiP",
        "outputId": "36b7636e-590e-4076-c2c5-5623eb2bbd5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-200 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_euclidean_mrr_hit.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_euclidean_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwueaeXtdYiP"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_euclidean_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-K9sF1BdYiP",
        "outputId": "a64185f0-7b23-4894-cdde-f8a79843019b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.925705592253055, 'Hits@1': 0.8779571911378145, 'Hits@5': 0.9849793466015772, 'Hits@10': 0.9932407059707097}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEvf28AgzPMm"
      },
      "source": [
        "# **With Encoders**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhg4-v4ABDor"
      },
      "source": [
        "# **ResMLPEncoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO_gkpWk59B0",
        "outputId": "987ee6db-4e71-4709-8885-7988a039dde7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = ResMLPEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfUpbjhs6UKr",
        "outputId": "0241e02e-f913-4360-a371-a8dd5b7fd95a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69ZWA8a4h1LR",
        "outputId": "2fc756ae-49a3-4630-9154-8e3b2349c28d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_cands_with_embeddings_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCxtUFUJhaOE",
        "outputId": "b92c5006-5632-4369-dfd6-88ff5933b792"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_cands_with_embeddings_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wV7TqW0ZPCQ5"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQmMLo0SPCQ5",
        "outputId": "2ad19352-4db6-40be-f696-cfb95fc702b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-1 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_euclidean_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using Euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the Euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_euclidean_with_uris(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_euclidean_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ai2AaRGM7VM",
        "outputId": "f315a77e-1cb4-42ae-a515-a7b64b7bf375"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_euclidean_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1491\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7481, 'Recall': 0.7234, 'F1': 0.7356}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_euclidean_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwJ-leCKPCQ5",
        "outputId": "fc89ed6b-4af0-4a88-d196-cdba4d9bacd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9342 rows\n",
            "✅ After removing ignored classes: 9342 rows\n",
            "✅ After keeping only test SrcEntities: 2399 rows\n",
            "✅ After applying threshold ≥ 0.0: 2399 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_euclidean_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2399 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_euclidean_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1818\n",
            "📊 Evaluation (P / R / F1): {'P': 0.758, 'R': 0.683, 'F1': 0.718}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_euclidean_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyT7suiNhTqx",
        "outputId": "559d7487-fec9-42b4-b9f2-e799db6b2683"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7511, 'Recall@1': 0.7023, 'F1@1': 0.7259}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_euclidean_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvzHj8lNhTqy",
        "outputId": "e2084981-1898-4cc7-998e-c0f429ba54e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-1 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_euclidean_mrr_hit_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_euclidean_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQ6WvQaehTqy"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_euclidean_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIqGwvGXhTqy",
        "outputId": "98de8de9-bdab-4d42-d7cd-b7ad26cf40a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6919970842260992, 'Hits@1': 0.6826886969583177, 'Hits@5': 0.6826886969583177, 'Hits@10': 0.6826886969583177}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al3Cl8ukC0V1"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDNF4oD1C0V1",
        "outputId": "26e66df7-5a4d-4bdd-bd53-046bc76df4de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-10 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_euclidean_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using Euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the Euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_euclidean_with_uris(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_euclidean_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ff8QeoSNYb0",
        "outputId": "0531e950-41b9-43a3-928f-7050ed2c201d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_euclidean_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1491\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7481, 'Recall': 0.7234, 'F1': 0.7356}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_euclidean_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onsFy8gaC0V2",
        "outputId": "bf2a8fa0-b300-45a6-9736-4161249f3a97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 93920 rows\n",
            "✅ After removing ignored classes: 93920 rows\n",
            "✅ After keeping only test SrcEntities: 22319 rows\n",
            "✅ After applying threshold ≥ 0.0: 22319 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_euclidean_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2524 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_euclidean_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1880\n",
            "📊 Evaluation (P / R / F1): {'P': 0.745, 'R': 0.706, 'F1': 0.725}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_euclidean_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqkbaqgWjgr6",
        "outputId": "ab30804c-3435-4bd8-8a90-023fd7f223e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7436, 'Recall@1': 0.6947, 'F1@1': 0.7183}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_euclidean_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DPmDY2Rjgr7",
        "outputId": "a5c47844-c33b-4ab1-90d0-63deb32dc002"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-10 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_euclidean_mrr_hit_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_euclidean_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEa6botvjgr7"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_euclidean_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nszMXr9jgr7",
        "outputId": "30facfe3-034c-4ad9-9444-9044ad2b2150"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9090877674247528, 'Hits@1': 0.8719489297784454, 'Hits@5': 0.950056327450244, 'Hits@10': 0.950056327450244}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gbQdQCtPZpD"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IBCF8vZPZpD",
        "outputId": "36bf8a73-141d-498a-ce35-490818ee2198"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-30 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_euclidean_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using Euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the Euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_euclidean_with_uris(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_euclidean_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2svKc_NNmoq",
        "outputId": "36378b55-639e-4e36-b9cb-d98a26b12894"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_euclidean_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1491\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7481, 'Recall': 0.7234, 'F1': 0.7356}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_euclidean_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfPAbDVFPZpD",
        "outputId": "d98d429b-deb0-4f8f-d56a-aad1b1dcdc5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 284018 rows\n",
            "✅ After removing ignored classes: 284018 rows\n",
            "✅ After keeping only test SrcEntities: 67461 rows\n",
            "✅ After applying threshold ≥ 0.0: 67461 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_euclidean_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2524 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_euclidean_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1880\n",
            "📊 Evaluation (P / R / F1): {'P': 0.745, 'R': 0.706, 'F1': 0.725}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_euclidean_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzoOAwBLlncC",
        "outputId": "86dcce51-e65f-4bf3-933c-0ac4acaf0a56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7436, 'Recall@1': 0.6947, 'F1@1': 0.7183}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_euclidean_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6rJPXSSlncD",
        "outputId": "4c7f049f-4173-440e-dd1c-490ae6193466"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-30 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_euclidean_mrr_hit_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_euclidean_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMhJcbuulncD"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_euclidean_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDMV_jV3lncD",
        "outputId": "4813c6eb-2b5a-4add-cfc2-1a56370c91fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9211469652236597, 'Hits@1': 0.8772061584678934, 'Hits@5': 0.97371385655276, 'Hits@10': 0.9774690199023658}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDaW2pQxl_70"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPedo8qxl_71",
        "outputId": "8dea09e6-068f-4d8f-d5c3-b98c2e913f60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-100 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_euclidean_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using Euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the Euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_euclidean_with_uris(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_euclidean_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3ku4zZZNy_H",
        "outputId": "3a844889-0299-479e-a00a-75a56d88a07c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_euclidean_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1491\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7481, 'Recall': 0.7234, 'F1': 0.7356}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_euclidean_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPJPkwPal_71",
        "outputId": "8e96379c-66d7-42fe-a14e-7ec75c91015c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 953425 rows\n",
            "✅ After removing ignored classes: 953425 rows\n",
            "✅ After keeping only test SrcEntities: 226116 rows\n",
            "✅ After applying threshold ≥ 0.0: 226116 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_euclidean_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2524 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_euclidean_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1880\n",
            "📊 Evaluation (P / R / F1): {'P': 0.745, 'R': 0.706, 'F1': 0.725}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_euclidean_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JEM4nQgl_71",
        "outputId": "c299e0ed-c622-41e0-c9a4-84a34d498adb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7436, 'Recall@1': 0.6947, 'F1@1': 0.7183}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_euclidean_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_oQid7pl_72",
        "outputId": "8b03c02d-d09e-406d-f4c7-b0391e57b381"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-100 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_euclidean_mrr_hit_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_euclidean_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yXAfGSsl_72"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_euclidean_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_8mD66tl_72",
        "outputId": "f0685c2c-5b3a-4911-f29a-42860827714d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9255115896064701, 'Hits@1': 0.878332707472775, 'Hits@5': 0.984228313931656, 'Hits@10': 0.9902365752910252}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqlHePrLC0V2"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLmTVxAEC0V2",
        "outputId": "cf1cc7a4-2ddc-4e80-f03d-39f45c47fb5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-200 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_euclidean_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using Euclidean distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_euclidean_with_uris(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_euclidean_ResMLPencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zimbFLBBN8OH",
        "outputId": "86e2d0a4-28d2-457d-dc5f-cc48ccca8e7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_euclidean_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1491\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7481, 'Recall': 0.7234, 'F1': 0.7356}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_euclidean_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFxNOGR7C0V2",
        "outputId": "bdeda41c-187e-40cc-deb7-a303d16a54a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1911373 rows\n",
            "✅ After removing ignored classes: 1911373 rows\n",
            "✅ After keeping only test SrcEntities: 453155 rows\n",
            "✅ After applying threshold ≥ 0.0: 453155 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_euclidean_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2524 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_euclidean_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1880\n",
            "📊 Evaluation (P / R / F1): {'P': 0.745, 'R': 0.706, 'F1': 0.725}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_euclidean_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzGaZ8Fqmf6c",
        "outputId": "62aa7ebd-979c-44fd-d653-ab6262076d62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7436, 'Recall@1': 0.6947, 'F1@1': 0.7183}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_euclidean_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0L0bBwYFmf6d",
        "outputId": "9fc64ab1-bdbb-44cb-cdbf-3bb5c6ba1dae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-200 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_euclidean_mrr_hit_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_euclidean_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNFv7OMpmf6d"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_euclidean_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DdrfkRBmf6d",
        "outputId": "9e5a7962-f146-4cbc-c131-c8b206c64aba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9259205080966103, 'Hits@1': 0.878332707472775, 'Hits@5': 0.9849793466015772, 'Hits@10': 0.9928651896357491}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYZLrpy0HTjh"
      },
      "source": [
        "# **MLPEncoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEQYmEycpf-A",
        "outputId": "d343acde-9b6c-4f98-e8ea-a53dcff092e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = MLPEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab9rqbDopf-B",
        "outputId": "8958ff6a-ff3b-4675-e85d-35de8f2d2bf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXzKFBXGpf-B",
        "outputId": "c84ce1e7-2013-4a13-cbc6-4e78a30dd971"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_cands_with_embeddings_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QD-qXXccpf-C",
        "outputId": "d0aed5c0-3ba2-4bfb-e3a2-d12b4b4d9497"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_cands_with_embeddings_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-KAiZ9Hpf-C"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJLXSAm3pf-C",
        "outputId": "e8ec99a5-8605-43a9-b0ad-592a9a5d4846"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-1 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_euclidean_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using Euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the Euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_euclidean_with_uris(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_euclidean_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StIVjsmGOKMI",
        "outputId": "224d9a0a-13e3-405d-ab84-aab0e5fea5ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_euclidean_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1483\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7441, 'Recall': 0.7196, 'F1': 0.7316}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_euclidean_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUlUa9B5pf-C",
        "outputId": "2ffeadcb-6d54-42e6-88bf-03fad36ff3b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9388 rows\n",
            "✅ After removing ignored classes: 9388 rows\n",
            "✅ After keeping only test SrcEntities: 2407 rows\n",
            "✅ After applying threshold ≥ 0.0: 2407 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_euclidean_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2407 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_euclidean_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1804\n",
            "📊 Evaluation (P / R / F1): {'P': 0.749, 'R': 0.677, 'F1': 0.712}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_euclidean_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkGlxVhgpf-D",
        "outputId": "f56fd9ad-0e43-4aed-dccf-2aa95ecc753d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7405, 'Recall@1': 0.6935, 'F1@1': 0.7163}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_euclidean_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ve8dEOOTpf-D",
        "outputId": "49701686-39e5-44d5-84cc-259b6104c0b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-1 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_euclidean_mrr_hit_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_euclidean_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcZ0I7z8pf-D"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_euclidean_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmkMHTvOpf-D",
        "outputId": "29139610-38ce-4415-8009-8d9fb1ad730f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6868941643499249, 'Hits@1': 0.6774314682688697, 'Hits@5': 0.6774314682688697, 'Hits@10': 0.6774314682688697}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66KR8gUkpf-D"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNyxmNExpf-E",
        "outputId": "7af43227-8822-4ef1-80ea-e656e80b5b73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-10 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_euclidean_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using Euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the Euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_euclidean_with_uris(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_euclidean_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAxZROVZOUNQ",
        "outputId": "62f401e0-3118-4a10-956c-cbae691b1084"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_euclidean_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1483\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7441, 'Recall': 0.7196, 'F1': 0.7316}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_euclidean_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i64WPWCdpf-E",
        "outputId": "11ec91cd-dbf7-417a-f5e1-1349b84053be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 93990 rows\n",
            "✅ After removing ignored classes: 93990 rows\n",
            "✅ After keeping only test SrcEntities: 22382 rows\n",
            "✅ After applying threshold ≥ 0.0: 22382 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_euclidean_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2571 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_euclidean_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1866\n",
            "📊 Evaluation (P / R / F1): {'P': 0.726, 'R': 0.701, 'F1': 0.713}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_euclidean_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpK0s-zcpf-E",
        "outputId": "f79820af-0426-4e3d-e295-b026d89d0a4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7335, 'Recall@1': 0.6853, 'F1@1': 0.7086}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_euclidean_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReoEUgltpf-E",
        "outputId": "3544e0e4-272f-4e06-f808-43fb39218bf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-10 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_euclidean_mrr_hit_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_euclidean_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEjF5_IQpf-E"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_euclidean_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pxi_PDUpf-F",
        "outputId": "8c18cead-0ff1-4d29-ac4b-94bca3b0ac13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9090877674247528, 'Hits@1': 0.8719489297784454, 'Hits@5': 0.950056327450244, 'Hits@10': 0.950056327450244}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2WwHWmLpf-F"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUe12GxOpf-F",
        "outputId": "08aa662a-3c5b-40df-b7ca-e93ab57f2601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-30 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_euclidean_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using Euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the Euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_euclidean_with_uris(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_euclidean_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJJ7hhD6OexI",
        "outputId": "15839ab3-038a-4606-a771-83674719f274"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_euclidean_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1483\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7441, 'Recall': 0.7196, 'F1': 0.7316}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_euclidean_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuyHvxJbpf-F",
        "outputId": "2b832ecd-ac7b-422d-974e-32291171b0cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 283640 rows\n",
            "✅ After removing ignored classes: 283640 rows\n",
            "✅ After keeping only test SrcEntities: 67291 rows\n",
            "✅ After applying threshold ≥ 0.0: 67291 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_euclidean_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2571 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_euclidean_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1866\n",
            "📊 Evaluation (P / R / F1): {'P': 0.726, 'R': 0.701, 'F1': 0.713}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_euclidean_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMsC3sfgpf-G",
        "outputId": "7cb92782-8072-428b-d5b2-11c024172373"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7283, 'Recall@1': 0.6804, 'F1@1': 0.7036}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_euclidean_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Jt4NqHhpf-G",
        "outputId": "30382f23-6e6f-49a0-db6f-a652eaed2435"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-30 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_euclidean_mrr_hit_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_euclidean_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_-051xppf-G"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_euclidean_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2ArRTexpf-G",
        "outputId": "acf859f1-1246-4e74-cc31-6696fad67083"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9176873232267122, 'Hits@1': 0.873075478783327, 'Hits@5': 0.9703342095381149, 'Hits@10': 0.97371385655276}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WuC7V0spf-G"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xh24Uunspf-G",
        "outputId": "51086798-7562-4a55-e9fa-015d60c5b362"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-100 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_euclidean_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using Euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the Euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_euclidean_with_uris(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_euclidean_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0m9fTjgOns3",
        "outputId": "7e23b4b7-426a-4bcb-d556-dc6ad702cd5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_euclidean_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1483\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7441, 'Recall': 0.7196, 'F1': 0.7316}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_euclidean_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT770IKvpf-H",
        "outputId": "397def46-5ba4-4ec7-9d5d-d188a65ebeaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 950237 rows\n",
            "✅ After removing ignored classes: 950237 rows\n",
            "✅ After keeping only test SrcEntities: 225382 rows\n",
            "✅ After applying threshold ≥ 0.0: 225382 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_euclidean_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2571 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_euclidean_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1866\n",
            "📊 Evaluation (P / R / F1): {'P': 0.726, 'R': 0.701, 'F1': 0.713}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_euclidean_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JH8cvzBOpf-H",
        "outputId": "ea40f53f-d4a2-4369-d295-314231feedd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7283, 'Recall@1': 0.6804, 'F1@1': 0.7036}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_euclidean_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjKWA89Cpf-H",
        "outputId": "9a6c583d-d7c7-45b0-9f17-5bf43b57f5e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-100 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_euclidean_mrr_hit_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_euclidean_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDRyR3d2pf-I"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_euclidean_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fOVfSKypf-J",
        "outputId": "cdb7f976-d8b4-4819-dd35-dbc708e721bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9221417372326226, 'Hits@1': 0.8749530604581299, 'Hits@5': 0.9800976342470897, 'Hits@10': 0.9876079609463012}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpebsHF3pf-J"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5dFqPjnpf-K",
        "outputId": "af60fd0f-1c8c-4c0e-e04e-f13ed89bd1d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-200 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_euclidean_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using Euclidean distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_euclidean_with_uris(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_euclidean_MLPencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uwr8uyupOyhu",
        "outputId": "d2dc82b0-5d0c-4070-b7c8-107b21659a65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_euclidean_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1483\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7441, 'Recall': 0.7196, 'F1': 0.7316}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_euclidean_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSBMDI0Xpf-K",
        "outputId": "b3b5103d-53e2-48be-c37c-2b39b22f3597"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1903564 rows\n",
            "✅ After removing ignored classes: 1903564 rows\n",
            "✅ After keeping only test SrcEntities: 451423 rows\n",
            "✅ After applying threshold ≥ 0.0: 451423 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_euclidean_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2571 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_euclidean_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1866\n",
            "📊 Evaluation (P / R / F1): {'P': 0.726, 'R': 0.701, 'F1': 0.713}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_euclidean_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVmxh3e4pf-K",
        "outputId": "4394e4c6-fd45-4225-cf71-b39b4c21762a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7283, 'Recall@1': 0.6804, 'F1@1': 0.7036}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_euclidean_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpC1hUYFpf-L",
        "outputId": "5b2e9a75-2324-4f3d-a2c5-d5ec0564a0a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-200 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_euclidean_mrr_hit_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_euclidean_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxPYf7NYpf-L"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_euclidean_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsB__m9zrM9i",
        "outputId": "5e34bc41-95ea-42e4-b5c9-e1541a4f2887"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9233137232238512, 'Hits@1': 0.8757040931280511, 'Hits@5': 0.9823507322568532, 'Hits@10': 0.9898610589560646}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3M7l517rppj"
      },
      "source": [
        "# **LinearEncoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0p3ud4krppk",
        "outputId": "b7b92447-9178-4546-c86f-2406c57137c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = LinearEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4nsRqhPrppl",
        "outputId": "4e5d1d28-83d4-4ee6-98b3-69f7be28e3e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RnbRviBrppl",
        "outputId": "9d64b639-9f5e-49a9-bb2e-2ff1fbcf1bb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_cands_with_embeddings_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPLAYU6Prppl",
        "outputId": "0601c2b3-6b72-4f91-9c76-919fb90c0fd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_cands_with_embeddings_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mh7jb09Frppl"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTRKYulNrppl",
        "outputId": "002dc51d-33e3-4d60-e36a-535b476caa17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-1 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_euclidean_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using Euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the Euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_euclidean_with_uris(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_euclidean_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1oFVix3O9ad",
        "outputId": "9b3c2f62-c160-4d3b-aea4-c88bb2be0e80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_euclidean_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1498\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7516, 'Recall': 0.7268, 'F1': 0.739}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_euclidean_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjRfYw9lrppl",
        "outputId": "d34302bb-1a60-4aa3-d7d1-f5999d24c42c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9372 rows\n",
            "✅ After removing ignored classes: 9372 rows\n",
            "✅ After keeping only test SrcEntities: 2400 rows\n",
            "✅ After applying threshold ≥ 0.0: 2400 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_euclidean_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2400 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_euclidean_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1822\n",
            "📊 Evaluation (P / R / F1): {'P': 0.759, 'R': 0.684, 'F1': 0.72}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_euclidean_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_UAs4aYrppl",
        "outputId": "f9a45ca9-88be-4a55-eafb-434ab9e32e42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7491, 'Recall@1': 0.7005, 'F1@1': 0.724}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_euclidean_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKt-vmFTrppm",
        "outputId": "5529082c-cb6c-455f-e7f6-06b53c2eb030"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-1 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_euclidean_mrr_hit_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_euclidean_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EURtPpMQrppm"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_euclidean_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jxh_8CXirppm",
        "outputId": "0dcccd85-52f8-424c-a5d7-4329a6ea690b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6934537089338119, 'Hits@1': 0.68419076229816, 'Hits@5': 0.68419076229816, 'Hits@10': 0.68419076229816}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-Ty8CRurppm"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WUnbxYorppm",
        "outputId": "cdf926ce-7cd2-4929-c0af-a58b83e15168"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-10 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_euclidean_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using Euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the Euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_euclidean_with_uris(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_euclidean_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2CXEp9UPQQw",
        "outputId": "92aabbd2-ed8f-4b9c-a625-57fac1be6c56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_euclidean_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1498\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7516, 'Recall': 0.7268, 'F1': 0.739}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_euclidean_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_ir_h3Rrppm",
        "outputId": "b5791004-c136-44eb-d8e9-02a7bfd945ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 94044 rows\n",
            "✅ After removing ignored classes: 94044 rows\n",
            "✅ After keeping only test SrcEntities: 22364 rows\n",
            "✅ After applying threshold ≥ 0.0: 22364 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_euclidean_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2532 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_euclidean_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1879\n",
            "📊 Evaluation (P / R / F1): {'P': 0.742, 'R': 0.706, 'F1': 0.723}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_euclidean_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRUjajGGrppm",
        "outputId": "66f24188-aa83-49d0-aa8e-25fe9564ddfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.742, 'Recall@1': 0.6932, 'F1@1': 0.7168}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_euclidean_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT4Xh97Xrppn",
        "outputId": "b1b612f3-f98f-4aaa-c2fa-1f7ba58165aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-10 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_euclidean_mrr_hit_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_euclidean_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dla9pNh7rppn"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_euclidean_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpT9witgrppn",
        "outputId": "bedcf05f-b11b-4763-efc8-44069a123542"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9071688445542276, 'Hits@1': 0.8696958317686819, 'Hits@5': 0.9474277131055201, 'Hits@10': 0.9478032294404807}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK9n16-lrppn"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI6CVWXerppn",
        "outputId": "a8863a01-ab10-425b-9c97-0d4e20d11398"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-30 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_euclidean_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using Euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the Euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_euclidean_with_uris(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_euclidean_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJeM8wa5PnPa",
        "outputId": "2e0d5f6f-c733-47d6-836f-df3f641970a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_euclidean_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1498\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7516, 'Recall': 0.7268, 'F1': 0.739}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_euclidean_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2spOY-Eerppn",
        "outputId": "24094aa3-1bb1-4bcc-ec1e-fb77170c1571"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 284093 rows\n",
            "✅ After removing ignored classes: 284093 rows\n",
            "✅ After keeping only test SrcEntities: 67420 rows\n",
            "✅ After applying threshold ≥ 0.0: 67420 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_euclidean_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2532 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_euclidean_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1879\n",
            "📊 Evaluation (P / R / F1): {'P': 0.742, 'R': 0.706, 'F1': 0.723}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_euclidean_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tu061NQFrppn",
        "outputId": "1864568e-70e5-4ef1-faa0-97cb29a83402"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.742, 'Recall@1': 0.6932, 'F1@1': 0.7168}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_euclidean_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2dEdAVwrppn",
        "outputId": "638e0f05-04c1-4e2a-f89e-b64392901ac5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-30 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_euclidean_mrr_hit_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_euclidean_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awoz8jhUrppo"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_euclidean_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUYRpZLCrppo",
        "outputId": "2416080a-eb51-46ae-d30e-f73a196c7c6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9222392789554695, 'Hits@1': 0.8775816748028539, 'Hits@5': 0.9744648892226812, 'Hits@10': 0.9793466015771686}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYEBPp7grppo"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LxvOBUirppo",
        "outputId": "e9e0797a-5a43-49d5-fd90-8cacd11b07e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-100 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_euclidean_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using Euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the Euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_euclidean_with_uris(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_euclidean_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v897KAJpPyk4",
        "outputId": "f906e002-00d4-4812-b9bb-57aecd4564c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_euclidean_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1498\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7516, 'Recall': 0.7268, 'F1': 0.739}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_euclidean_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIoAWZ8Wrppo",
        "outputId": "4875e9ee-e3f4-4897-94ab-852c7afd3728"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 953176 rows\n",
            "✅ After removing ignored classes: 953176 rows\n",
            "✅ After keeping only test SrcEntities: 226206 rows\n",
            "✅ After applying threshold ≥ 0.0: 226206 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_euclidean_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2532 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_euclidean_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1879\n",
            "📊 Evaluation (P / R / F1): {'P': 0.742, 'R': 0.706, 'F1': 0.723}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_euclidean_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_rV-OOmrppp",
        "outputId": "4255531a-777c-44c9-d97d-e0a5a9e9fdda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.742, 'Recall@1': 0.6932, 'F1@1': 0.7168}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_euclidean_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyMb8-jlrppp",
        "outputId": "4f17006a-59c7-4660-afcb-f9075794a4a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-100 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_euclidean_mrr_hit_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_euclidean_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sTl6uswrppp"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_euclidean_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilwHdMlZrppp",
        "outputId": "9bc47eb3-b3cd-4284-e946-60374811d9bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9263841865020298, 'Hits@1': 0.8790837401426962, 'Hits@5': 0.9834772812617348, 'Hits@10': 0.9917386406308675}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZxHkr4_rppp"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmbZilABrppp",
        "outputId": "ae54a9ef-067f-4c78-f246-b3ab5e860514"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-200 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_euclidean_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using Euclidean distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_euclidean_with_uris(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_euclidean_Linencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j080HcYiQDn1",
        "outputId": "c3666c7a-13ec-4b32-cdf9-adaf7739bfe2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_euclidean_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1498\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7516, 'Recall': 0.7268, 'F1': 0.739}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_euclidean_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaYaY0pArppp",
        "outputId": "d3e02687-337a-4487-da65-1ee397ee7f17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1911596 rows\n",
            "✅ After removing ignored classes: 1911596 rows\n",
            "✅ After keeping only test SrcEntities: 453397 rows\n",
            "✅ After applying threshold ≥ 0.0: 453397 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_euclidean_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2532 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_euclidean_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1879\n",
            "📊 Evaluation (P / R / F1): {'P': 0.742, 'R': 0.706, 'F1': 0.723}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_euclidean_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoG9mxWLrppq",
        "outputId": "a6967553-d4ef-494c-f532-076fca5961d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.742, 'Recall@1': 0.6932, 'F1@1': 0.7168}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_euclidean_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLjCDqJ5rppq",
        "outputId": "7ed50b40-ca9c-4264-a6d8-78a380593e21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-200 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_euclidean_mrr_hit_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_euclidean_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUZvhaQwrppq"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_euclidean_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GDrRWAprppq",
        "outputId": "4382d11c-bf59-4673-c41a-1ff174d0545c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9265658185281622, 'Hits@1': 0.8790837401426962, 'Hits@5': 0.9834772812617348, 'Hits@10': 0.9932407059707097}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU7TWxxVunns"
      },
      "source": [
        "# **Transformer Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEUuiICTunnt",
        "outputId": "bfc20d24-5316-4ebd-a59e-613ae928a686"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = TransformerEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sL_xgGKSunnt",
        "outputId": "ff425fe7-468d-4261-d30c-db4e8fe960ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SwEjE-tunnt",
        "outputId": "9fe1a46e-2791-49d3-ec6d-ee6d2e2f3648"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_cands_with_embeddings_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBUU4uGnunnt",
        "outputId": "f7765804-c64e-4a91-9c4a-6c3371c7e53e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_cands_with_embeddings_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcGoikLxunnt"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "corOgSeuunnt",
        "outputId": "dcb7361d-f504-4ef1-b33f-a6d061d1d000"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-1 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_euclidean_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using Euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the Euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_euclidean_with_uris(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_euclidean_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWk-7eN_Qs8u",
        "outputId": "c35bb2d3-6016-43c5-d2ab-8e64422d8694"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_euclidean_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1451\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.728, 'Recall': 0.704, 'F1': 0.7158}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_euclidean_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix2-O4Drunnt",
        "outputId": "55d84af7-51a6-44e9-a0cd-94559b9eaa8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9486 rows\n",
            "✅ After removing ignored classes: 9486 rows\n",
            "✅ After keeping only test SrcEntities: 2402 rows\n",
            "✅ After applying threshold ≥ 0.0: 2402 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_euclidean_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2402 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_euclidean_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1772\n",
            "📊 Evaluation (P / R / F1): {'P': 0.738, 'R': 0.665, 'F1': 0.7}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_euclidean_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HPC8wGUunnt",
        "outputId": "9949776c-7ee3-42fe-e625-3c3f6596b03d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7385, 'Recall@1': 0.691, 'F1@1': 0.714}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_euclidean_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFsvShg_unnu",
        "outputId": "81302d0c-1b78-4840-e3b8-794efddefc6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-1 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_euclidean_mrr_hit_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_euclidean_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAhrLDwjunnu"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_euclidean_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VicJ_202unnu",
        "outputId": "cdaa5639-4b3f-49a0-d044-a3e13ee4c0a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6752298065301915, 'Hits@1': 0.6654149455501315, 'Hits@5': 0.6654149455501315, 'Hits@10': 0.6654149455501315}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJ72Rlafunnu"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHCTlEKuunnu",
        "outputId": "fd825f69-6185-42cc-da94-1c3f50b2ee4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-10 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_euclidean_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using Euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the Euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_euclidean_with_uris(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_euclidean_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVtGBXNuQ434",
        "outputId": "974f5f69-078e-4195-cc7e-e98db053f87b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_euclidean_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1451\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.728, 'Recall': 0.704, 'F1': 0.7158}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_euclidean_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgjZuALUunnu",
        "outputId": "fea3243c-42f8-4f1d-a525-9ca05f21070c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 96146 rows\n",
            "✅ After removing ignored classes: 96146 rows\n",
            "✅ After keeping only test SrcEntities: 22638 rows\n",
            "✅ After applying threshold ≥ 0.0: 22638 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_euclidean_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2531 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_euclidean_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1824\n",
            "📊 Evaluation (P / R / F1): {'P': 0.721, 'R': 0.685, 'F1': 0.702}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_euclidean_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9BALfy4unnu",
        "outputId": "4a50c3fd-9740-4db2-98a8-e6dc72983af6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7291, 'Recall@1': 0.6812, 'F1@1': 0.7043}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_euclidean_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jngyhZsRunnu",
        "outputId": "153084a6-23af-4eb2-e2b8-1e480726fd6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-10 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_euclidean_mrr_hit_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_euclidean_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXmCY1w2unnu"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_euclidean_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21uiIRFyunnu",
        "outputId": "d7b6b9c1-93b5-4606-f6b7-dd29eebfdac2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8984349166358322, 'Hits@1': 0.8603079233946677, 'Hits@5': 0.9391663537363876, 'Hits@10': 0.9391663537363876}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1RplZFCunnu"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QzH8K-bunnv",
        "outputId": "ce83184a-3cbd-4d47-9409-6ce4d9338a36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-30 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_euclidean_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using Euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the Euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_euclidean_with_uris(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_euclidean_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1tXHLy3RG5l",
        "outputId": "c8e93314-3b9b-47ac-8c4c-5e779e620922"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_euclidean_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1451\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.728, 'Recall': 0.704, 'F1': 0.7158}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_euclidean_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FbRFCOFunnv",
        "outputId": "a93b77ce-9313-44dc-d97d-28491e17904e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 291483 rows\n",
            "✅ After removing ignored classes: 291483 rows\n",
            "✅ After keeping only test SrcEntities: 68488 rows\n",
            "✅ After applying threshold ≥ 0.0: 68488 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_euclidean_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2531 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_euclidean_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1824\n",
            "📊 Evaluation (P / R / F1): {'P': 0.721, 'R': 0.685, 'F1': 0.702}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_euclidean_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lI3YlpXunnv",
        "outputId": "7dbd9fcd-0d9d-4631-d3f1-275f368818b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7291, 'Recall@1': 0.6812, 'F1@1': 0.7043}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_euclidean_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQUEIeecunnv",
        "outputId": "86e6cac9-4c80-4713-e66f-091933103a41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-30 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_euclidean_mrr_hit_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_euclidean_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BmkgG1cunnv"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_euclidean_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqHi-u-runnv",
        "outputId": "dd8d3ab0-e4ff-48fa-9baf-3c8129dc1953"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9168946417504511, 'Hits@1': 0.8711978971085242, 'Hits@5': 0.9722117912129178, 'Hits@10': 0.9744648892226812}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxwwSVg1unnv"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "857gXbcdunnv",
        "outputId": "b4228895-b2ae-4c2f-8ffa-1c0e313900a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-100 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_euclidean_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using Euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the Euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_euclidean_with_uris(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_euclidean_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNdNMegcRLW3",
        "outputId": "8265fb75-0efb-4995-e1a3-d5a896b9eca3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_euclidean_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1451\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.728, 'Recall': 0.704, 'F1': 0.7158}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_euclidean_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROSSLjk8unnv",
        "outputId": "6ae7a4ef-236d-4d51-a0e5-471bce35e43c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 981153 rows\n",
            "✅ After removing ignored classes: 981153 rows\n",
            "✅ After keeping only test SrcEntities: 230587 rows\n",
            "✅ After applying threshold ≥ 0.0: 230587 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_euclidean_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2531 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_euclidean_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1824\n",
            "📊 Evaluation (P / R / F1): {'P': 0.721, 'R': 0.685, 'F1': 0.702}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_euclidean_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdHHzMdwunnw",
        "outputId": "61a3aeb2-351b-4fa2-fb53-ec91c6f6e800"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7291, 'Recall@1': 0.6812, 'F1@1': 0.7043}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_euclidean_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvOKUw-Funnw",
        "outputId": "aafe0383-2b72-49c0-9f5c-c9f74a84270d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-100 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_euclidean_mrr_hit_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_euclidean_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOQkJEfBunnw"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_euclidean_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7C-HksDunnw",
        "outputId": "2840c712-1802-4e0b-f1c9-016d5e3ce367"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9226968207979722, 'Hits@1': 0.8734509951182876, 'Hits@5': 0.9846038302666166, 'Hits@10': 0.9913631242959069}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltiUP9F9unnw"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeZUx4z_unnw",
        "outputId": "3103cafb-800f-4c3b-a66c-e91c0e3f15bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-200 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_euclidean_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using Euclidean distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_euclidean_with_uris(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_euclidean_TRencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujTObwfzRQXl",
        "outputId": "d2f4db9c-46a2-444b-883a-324a7ed6209d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_euclidean_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1451\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.728, 'Recall': 0.704, 'F1': 0.7158}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_euclidean_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bW49UY7yunnx",
        "outputId": "9252f468-1ca4-44cc-eaf7-a8261092eb8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1970864 rows\n",
            "✅ After removing ignored classes: 1970864 rows\n",
            "✅ After keeping only test SrcEntities: 463457 rows\n",
            "✅ After applying threshold ≥ 0.0: 463457 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_euclidean_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2531 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_euclidean_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1824\n",
            "📊 Evaluation (P / R / F1): {'P': 0.721, 'R': 0.685, 'F1': 0.702}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_euclidean_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_syNiITunnx",
        "outputId": "1ba7e9e8-0a9e-452e-b6b9-9f3780ae74ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7291, 'Recall@1': 0.6812, 'F1@1': 0.7043}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_euclidean_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyRCywAkunnx",
        "outputId": "eca23cfe-43e3-4510-bfa8-2c8734b33358"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-200 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_euclidean_mrr_hit_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_euclidean_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RVcLj4Gunnx"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_euclidean_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0bzgfJ3unnx",
        "outputId": "e16242ec-696c-407a-9b8b-deb309f7ab4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9232885668953403, 'Hits@1': 0.8738265114532482, 'Hits@5': 0.9853548629365377, 'Hits@10': 0.9924896733007886}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRPxdU_HxcU5"
      },
      "source": [
        "# **Using ANNOY: topk_annoy_euclidean**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoQqKSKvTd75"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlvbRvQMTd76",
        "outputId": "31179b3a-eb35-4bac-d84c-92541f5061d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-1 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_euclidean.tsv\n",
            "⏱️ Execution time: 9.20 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_annoy_euclidean.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgtYVMPoTd76",
        "outputId": "6d6ab9a3-472d-4e30-d94a-bf75508ecbdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_euclidean_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1275\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6397, 'Recall': 0.6186, 'F1': 0.629}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_annoy_euclidean.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Hu9iWmETd76",
        "outputId": "7c40cb70-f5ac-407d-a883-c790342a380e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9366 rows\n",
            "✅ After removing ignored classes: 9366 rows\n",
            "✅ After keeping only test SrcEntities: 2373 rows\n",
            "✅ After applying threshold ≥ 0.0: 2373 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_euclidean_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2373 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_euclidean_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1558\n",
            "📊 Evaluation (P / R / F1): {'P': 0.657, 'R': 0.585, 'F1': 0.619}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_annoy_euclidean.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTPcvqTbTd76",
        "outputId": "fc358dfa-2ed2-4111-d523-ef36dfe38311"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6566, 'Recall@1': 0.6139, 'F1@1': 0.6345}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/neoplas_top_1_mappings_annoy_euclidean_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPW86hZBTd76",
        "outputId": "0974c024-b067-4092-c307-85d0aea5b86d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-1 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_euclidean_mrr_hit.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_annoy_euclidean_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE5VBCqhTd76"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_annoy_euclidean_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2V-x76veTd76",
        "outputId": "7f64a1a9-5741-4ea1-a190-1a5f42309c07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6909033534555333, 'Hits@1': 0.681562147953436, 'Hits@5': 0.681562147953436, 'Hits@10': 0.681562147953436}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5SjKJ2lTd77"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7jZUixOTd77",
        "outputId": "3f09db3e-542d-41d4-cb24-0e6ae0937950"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-10 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_euclidean.tsv\n",
            "⏱️ Execution time: 8.58 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdOdSb23Td77",
        "outputId": "bb1dbb76-238d-4582-f314-64c4d88ee287"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_euclidean_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1275\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6397, 'Recall': 0.6186, 'F1': 0.629}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAYzHDDRTd77",
        "outputId": "9fc40a33-b61b-415a-c9b5-466e1990b68b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 94016 rows\n",
            "✅ After removing ignored classes: 94016 rows\n",
            "✅ After keeping only test SrcEntities: 22385 rows\n",
            "✅ After applying threshold ≥ 0.0: 22385 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_euclidean_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2531 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_euclidean_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1597\n",
            "📊 Evaluation (P / R / F1): {'P': 0.631, 'R': 0.6, 'F1': 0.615}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tO8GGuskTd77",
        "outputId": "67fe80de-5005-4f02-8fd3-205ec0f725c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6387, 'Recall@1': 0.5967, 'F1@1': 0.617}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhRufH44Td77",
        "outputId": "ce68da11-ad05-4b8e-c262-83c6e9fc8ad0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-10 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_euclidean_mrr_hit.tsv\n",
            "⏱️ Execution time: 4.28 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQ9XyrivTd77"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tb5F5AWJTd77",
        "outputId": "11a32b5f-ad59-4f74-cbe7-0228900796dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.7015951534348566, 'Hits@1': 0.6744273375891852, 'Hits@5': 0.7153586180998873, 'Hits@10': 0.7153586180998873}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTOHeOxuTd77"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwfU2jL2Td77",
        "outputId": "2165447f-7915-42b4-93a6-fa4fe1b1595e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-30 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_euclidean.tsv\n",
            "⏱️ Execution time: 9.33 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYbTr-BdTd77",
        "outputId": "91ea83bd-84db-47db-d4f0-bf9d4e1b7e54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_euclidean_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1275\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6397, 'Recall': 0.6186, 'F1': 0.629}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzQGk9agTd77",
        "outputId": "43f1c6dc-a7b3-4efe-8839-553a1aa75313"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 282695 rows\n",
            "✅ After removing ignored classes: 282695 rows\n",
            "✅ After keeping only test SrcEntities: 67026 rows\n",
            "✅ After applying threshold ≥ 0.0: 67026 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_euclidean_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2531 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_euclidean_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1597\n",
            "📊 Evaluation (P / R / F1): {'P': 0.631, 'R': 0.6, 'F1': 0.615}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulPDvWJKTd77",
        "outputId": "cd3666eb-7684-4a94-84dd-80e492aa5c86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6387, 'Recall@1': 0.5967, 'F1@1': 0.617}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLWx5fSLTd77",
        "outputId": "7dee836a-05d1-41f0-b76f-4d211e94ae91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-30 Euclidean similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_euclidean_mrr_hit.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_euclidean_with_uris(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0DxUUIBTd78"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSnS0ElgTd78",
        "outputId": "fae0d809-e054-45db-e4ef-7b2c97306e97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9210168581050832, 'Hits@1': 0.8768306421329328, 'Hits@5': 0.97371385655276, 'Hits@10': 0.9778445362373264}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHyO_wvnTd78"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ABS8Cx8Td78",
        "outputId": "83caaf6e-df46-49f8-f5ef-d80d1874fe21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-100 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_euclidean.tsv\n",
            "⏱️ Execution time: 18.57 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKSxv55XTd78",
        "outputId": "27a25752-9409-4b59-95f6-66681ba146ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_euclidean_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1380\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6924, 'Recall': 0.6696, 'F1': 0.6808}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4zySvXzTd78",
        "outputId": "f112f40d-8585-43b4-f3f6-1061a1a3e343"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 946624 rows\n",
            "✅ After removing ignored classes: 946624 rows\n",
            "✅ After keeping only test SrcEntities: 224550 rows\n",
            "✅ After applying threshold ≥ 0.0: 224550 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_euclidean_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2523 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_euclidean_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1739\n",
            "📊 Evaluation (P / R / F1): {'P': 0.689, 'R': 0.653, 'F1': 0.671}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1G0f9zpfTd78",
        "outputId": "7597583c-9b96-4508-d58a-91d3b4522ae8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6941, 'Recall@1': 0.6485, 'F1@1': 0.6705}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8xvfmL5Td78",
        "outputId": "15b96d1b-3999-4f1c-a27c-df92622ec3e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-100 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_euclidean_mrr_hit.tsv\n",
            "⏱️ Execution time: 6.32 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0hD5GySTd78"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgxTvZNJTd78",
        "outputId": "1a42f92c-d827-43bd-aad8-e3f431ae3962"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.7972239597537332, 'Hits@1': 0.763800225309801, 'Hits@5': 0.8280135185880586, 'Hits@10': 0.8310176492677431}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBvGyE5ETd78"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A37sDw2STd78",
        "outputId": "97d44f0a-47f1-46e2-ba6c-962d27ea447b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-200 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_euclidean.tsv\n",
            "⏱️ Execution time: 28.61 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2kThu_OTd78",
        "outputId": "666ff9a8-6852-435a-f439-38fb1169d578"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_euclidean_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1420\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7125, 'Recall': 0.689, 'F1': 0.7005}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hhwwr1eoTd78",
        "outputId": "025c25ca-5b38-4377-882a-2df40d864653"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1898583 rows\n",
            "✅ After removing ignored classes: 1898583 rows\n",
            "✅ After keeping only test SrcEntities: 450298 rows\n",
            "✅ After applying threshold ≥ 0.0: 450298 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_euclidean_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2528 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_euclidean_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1791\n",
            "📊 Evaluation (P / R / F1): {'P': 0.708, 'R': 0.673, 'F1': 0.69}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qACru8lDTd78",
        "outputId": "9fbda609-5eb1-4d2f-a1c2-9ad9d89ea417"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7142, 'Recall@1': 0.6673, 'F1@1': 0.69}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnhoz2YmTd79",
        "outputId": "8d64d7ed-9014-4f16-a954-478daef4d6d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-200 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_euclidean_mrr_hit.tsv\n",
            "⏱️ Execution time: 10.20 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKxldsrSTd79"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YJMwEo6Td79",
        "outputId": "bc0cfa6a-2f4c-411b-aadf-2be71e747ad7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8477243858030415, 'Hits@1': 0.8103642508449117, 'Hits@5': 0.888847164851671, 'Hits@10': 0.8926023282012767}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnabgSllZdSf"
      },
      "source": [
        "# **K=500**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N83zsa5JZdSf",
        "outputId": "8e327fad-20ab-414c-b774-98e7adfa3cc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-500 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_annoy_euclidean.tsv\n",
            "⏱️ Execution time: 60.91 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=500,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_500_mappings_annoy_euclidean.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGoGNHDtZdSf",
        "outputId": "18fea22b-d6ad-49d4-bfb5-0b722e87b436"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 5703500 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 996500 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_annoy_euclidean_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1451\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.728, 'Recall': 0.704, 'F1': 0.7158}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_500_mappings_annoy_euclidean.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WaSBUrJZdSf",
        "outputId": "83fad2a8-fffb-4b6d-c598-9c3242fec7ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 5703500 rows\n",
            "✅ After removing train-only URIs: 4765166 rows\n",
            "✅ After removing ignored classes: 4765166 rows\n",
            "✅ After keeping only test SrcEntities: 1130165 rows\n",
            "✅ After applying threshold ≥ 0.0: 1130165 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_annoy_euclidean_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2528 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_annoy_euclidean_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1835\n",
            "📊 Evaluation (P / R / F1): {'P': 0.726, 'R': 0.689, 'F1': 0.707}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_500_mappings_annoy_euclidean.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yz88bmQNZdSg",
        "outputId": "f8aee2d9-1943-4632-8191-11987051f1cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7319, 'Recall@1': 0.6838, 'F1@1': 0.707}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_500_mappings_annoy_euclidean_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmslENG2ZdSg",
        "outputId": "9470a3eb-9537-4a24-a534-d885ed466d1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-500 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_annoy_euclidean_mrr_hit.tsv\n",
            "⏱️ Execution time: 15.86 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=500,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_500_mappings_annoy_euclidean_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tueWQXMrZdSg"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_500_mappings_annoy_euclidean_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amVUu_GDZdSg",
        "outputId": "c7274a87-e310-47e6-c530-e0d6a48f276d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8975030851554188, 'Hits@1': 0.8546751783702591, 'Hits@5': 0.949305294780323, 'Hits@10': 0.9556890724746526}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUQsFFM4aRTL"
      },
      "source": [
        "# **K=1000**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaFc1KcZaRTM",
        "outputId": "c1b3cdcb-e1db-49eb-9702-7796543ae298"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-1000 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_annoy_euclidean.tsv\n",
            "⏱️ Execution time: 112.04 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1000,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1000_mappings_annoy_euclidean.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0HjbAhAaRTM",
        "outputId": "c3c4462c-82bd-4826-8a24-5ac39493b2da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407000 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993000 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_annoy_euclidean_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1478\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7416, 'Recall': 0.7171, 'F1': 0.7292}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1000_mappings_annoy_euclidean.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwzNw6M1aRTM",
        "outputId": "afbd826d-aa0d-48e5-d441-3732b5ac4cff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407000 rows\n",
            "✅ After removing train-only URIs: 9564475 rows\n",
            "✅ After removing ignored classes: 9564475 rows\n",
            "✅ After keeping only test SrcEntities: 2268981 rows\n",
            "✅ After applying threshold ≥ 0.0: 2268981 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_annoy_euclidean_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2526 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_annoy_euclidean_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1871\n",
            "📊 Evaluation (P / R / F1): {'P': 0.741, 'R': 0.703, 'F1': 0.721}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1000_mappings_annoy_euclidean.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJzMX_n6aRTM",
        "outputId": "685553e2-95c8-4abc-f636-a4451bf1c3a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.746, 'Recall@1': 0.697, 'F1@1': 0.7206}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1000_mappings_annoy_euclidean_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqVm2ow3aRTM",
        "outputId": "2626c9e3-94dc-489c-faf0-7b6bd0d34e0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-1000 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_annoy_euclidean_mrr_hit.tsv\n",
            "⏱️ Execution time: 26.43 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1000,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1000_mappings_annoy_euclidean_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMtrA63paRTM"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1000_mappings_annoy_euclidean_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pd_TPyYfaRTM",
        "outputId": "c181e28b-5b9f-44b0-dff5-6cecbfbc1901"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9179797590704873, 'Hits@1': 0.872324446113406, 'Hits@5': 0.9744648892226812, 'Hits@10': 0.9819752159218926}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ayy9F2FkbBYd"
      },
      "source": [
        "# **K=2000**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsaeJB7vciJv",
        "outputId": "ec69ddfd-e2b5-4275-a7af-85ce5cd1e5f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-2000 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_annoy_euclidean.tsv\n",
            "⏱️ Execution time: 220.67 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=2000,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_2000_mappings_annoy_euclidean.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlV80vVJciJv",
        "outputId": "75c561c8-048b-48bf-f97d-732978c03187"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 22814000 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 3986000 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_annoy_euclidean_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1484\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7446, 'Recall': 0.72, 'F1': 0.7321}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_2000_mappings_annoy_euclidean.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1J7EDWmciJv",
        "outputId": "c1c22202-04fe-479f-fc12-83cabee5f3c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 22814000 rows\n",
            "✅ After removing train-only URIs: 19238783 rows\n",
            "✅ After removing ignored classes: 19238783 rows\n",
            "✅ After keeping only test SrcEntities: 4566194 rows\n",
            "✅ After applying threshold ≥ 0.0: 4566194 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_annoy_euclidean_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2526 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_annoy_euclidean_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1877\n",
            "📊 Evaluation (P / R / F1): {'P': 0.743, 'R': 0.705, 'F1': 0.723}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_2000_mappings_annoy_euclidean.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahVP3tIvciJv",
        "outputId": "30aef3ad-e929-4bf0-f539-54b582176aca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7484, 'Recall@1': 0.6992, 'F1@1': 0.723}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_2000_mappings_annoy_euclidean_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcz_-JGyciJv",
        "outputId": "6176bd47-b1c1-4e89-ac51-519d552e57a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-2000 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_annoy_euclidean_mrr_hit.tsv\n",
            "⏱️ Execution time: 49.70 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=2000,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_2000_mappings_annoy_euclidean_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IYbQFmQciJw"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_2000_mappings_annoy_euclidean_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE1rVViyciJw",
        "outputId": "5fb8b193-0d3e-4ccd-a3ec-d723b46b1d65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9253701919282805, 'Hits@1': 0.8772061584678934, 'Hits@5': 0.9846038302666166, 'Hits@10': 0.9936162223056703}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krq3_Bl_Td79"
      },
      "source": [
        "# **With Encoders**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4fJmWD8Td79"
      },
      "source": [
        "# **ResMLPEncoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlTUXygLTd79",
        "outputId": "5047cdbd-b29a-4075-9dc6-1ef5bdab5c82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = ResMLPEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfDg6DmbTd79",
        "outputId": "358841e5-1c9c-48be-b791-0c2e72bd9daa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79LvAvE1Td79",
        "outputId": "f4af3bcf-c9a7-4ced-e6a4-ae578f03134b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_cands_with_embeddings_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkODAYhrTd79",
        "outputId": "2b056f0c-6005-42ba-e5fd-080056bb4029"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_cands_with_embeddings_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvtJVvjLTd79"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKtaWpEuTd79",
        "outputId": "6b974e76-dbea-41a3-f444-ae258cd3f530"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-1 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_euclidean_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 8.10 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using Euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the Euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_euclidean(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_annoy_euclidean_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm6NoUqYTd79",
        "outputId": "b2f380db-3f4d-47e7-f732-4c5b24afc06f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_euclidean_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1286\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6453, 'Recall': 0.624, 'F1': 0.6344}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_annoy_euclidean_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqogNpgHTd79",
        "outputId": "08019557-add7-42bf-9ad8-c4ba9574679b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9379 rows\n",
            "✅ After removing ignored classes: 9379 rows\n",
            "✅ After keeping only test SrcEntities: 2379 rows\n",
            "✅ After applying threshold ≥ 0.0: 2379 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_euclidean_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2379 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_euclidean_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1573\n",
            "📊 Evaluation (P / R / F1): {'P': 0.661, 'R': 0.591, 'F1': 0.624}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_annoy_euclidean_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YA8mZ9w6Td79",
        "outputId": "28ee211a-5ef5-4d54-a565-8e7a51f23482"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6612, 'Recall@1': 0.6183, 'F1@1': 0.639}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_annoy_euclidean_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_BxHBybTd79",
        "outputId": "2bdac6cd-70ef-4ece-abb0-21a6568ce3ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-1 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_euclidean_mrr_hit_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 4.46 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_annoy_euclidean_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFSxfBhITd79"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_annoy_euclidean_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01XjcB04Td7-",
        "outputId": "bfe6d069-3b6d-4298-d182-8c92ba614535"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.5855596613410594, 'Hits@1': 0.573037927149831, 'Hits@5': 0.573037927149831, 'Hits@10': 0.573037927149831}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8hjmKBLTd7-"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFfqx2HvTd7-",
        "outputId": "2972997a-c01b-4ff0-b4c2-19b8e0898633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-10 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_euclidean_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 8.15 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using Euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the Euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_euclidean(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTgMH919Td7-",
        "outputId": "a6999551-f7fd-41c0-d63b-5d0e35b18e09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_euclidean_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1286\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6453, 'Recall': 0.624, 'F1': 0.6344}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrzyaPCjTd7-",
        "outputId": "97ec74dd-43e3-46eb-85ae-b62215dfd42b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 93874 rows\n",
            "✅ After removing ignored classes: 93874 rows\n",
            "✅ After keeping only test SrcEntities: 22378 rows\n",
            "✅ After applying threshold ≥ 0.0: 22378 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_euclidean_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2530 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_euclidean_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1616\n",
            "📊 Evaluation (P / R / F1): {'P': 0.639, 'R': 0.607, 'F1': 0.622}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gWu1mlLTd7-",
        "outputId": "dee5a326-6199-4c0a-f076-8a89ca0c2db4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6459, 'Recall@1': 0.6035, 'F1@1': 0.624}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQQW0_pDTd7-",
        "outputId": "9ac4e4fb-dcc2-469b-85c6-75f94f773576"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-10 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_euclidean_mrr_hit_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 4.64 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjfX5s97Td7-"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOIgmA71Td7-",
        "outputId": "aeaac14d-4532-4625-e5dc-e378dbb84562"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6982667656413073, 'Hits@1': 0.6702966579046189, 'Hits@5': 0.7119789710852422, 'Hits@10': 0.7119789710852422}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGCaUij4Td7-"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohY3hhXjTd7-",
        "outputId": "df4497f4-d555-4be5-d55d-f708ad583c24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-30 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_euclidean_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 9.66 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using Euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the Euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_euclidean(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAYmVIDwTd7_",
        "outputId": "3806255d-9f2a-4cf5-971e-c972bba4de13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_euclidean_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1286\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6453, 'Recall': 0.624, 'F1': 0.6344}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94P-AHdBTd7_",
        "outputId": "5c7973af-4d0e-4c04-f46d-78de8aad9361"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 282514 rows\n",
            "✅ After removing ignored classes: 282514 rows\n",
            "✅ After keeping only test SrcEntities: 66953 rows\n",
            "✅ After applying threshold ≥ 0.0: 66953 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_euclidean_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2530 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_euclidean_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1616\n",
            "📊 Evaluation (P / R / F1): {'P': 0.639, 'R': 0.607, 'F1': 0.622}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FerIoCxTd7_",
        "outputId": "bcd83126-a385-4350-9a53-e77528322ea5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6459, 'Recall@1': 0.6035, 'F1@1': 0.624}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVuJHtRPTd7_",
        "outputId": "25460009-73e9-4626-fcbb-f0ae699b1921"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-30 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_euclidean_mrr_hit_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 5.35 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPMc8sXvTd7_"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odfvswGxTd7_",
        "outputId": "a9089dc6-853d-42b2-b4d0-f79d7ff39c91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.7033237615826492, 'Hits@1': 0.673676304919264, 'Hits@5': 0.7213668794592565, 'Hits@10': 0.7213668794592565}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iOW9BpaTd7_"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reNUaf6bTd7_",
        "outputId": "a7e89a58-421e-4b5f-ca32-65d32e8e478d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-100 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_euclidean_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 19.17 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using Euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the Euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_euclidean(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4h_dwOoTd7_",
        "outputId": "219d2647-31ca-4786-d13a-7a25b22e7dce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_euclidean_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1388\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6964, 'Recall': 0.6735, 'F1': 0.6848}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AB4XSV4rTd7_",
        "outputId": "f16ef533-ba09-46a3-c2ab-0879364b8541"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 945727 rows\n",
            "✅ After removing ignored classes: 945727 rows\n",
            "✅ After keeping only test SrcEntities: 224376 rows\n",
            "✅ After applying threshold ≥ 0.0: 224376 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_euclidean_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2529 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_euclidean_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1749\n",
            "📊 Evaluation (P / R / F1): {'P': 0.692, 'R': 0.657, 'F1': 0.674}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmruuW69Td7_",
        "outputId": "8682a273-44e1-4cee-a682-4242d4ff333b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.699, 'Recall@1': 0.653, 'F1@1': 0.6752}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNOSMnyzTd7_",
        "outputId": "25a4118c-6d04-44a4-8767-6429ae036f3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-100 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_euclidean_mrr_hit_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 9.46 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvhupKCUTd7_"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTqSbINETd8A",
        "outputId": "a1cb74d1-c59a-4f1d-ce3f-9ad69f57295c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8084844677974998, 'Hits@1': 0.7731881336838152, 'Hits@5': 0.8419076229815997, 'Hits@10': 0.8437852046564025}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5yy-WUGTd8A"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-Enn5VeTd8A",
        "outputId": "64d0aca2-eed4-43dd-994a-c22f7957131b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-200 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_euclidean_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 30.13 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using Euclidean distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_annoy_euclidean(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean_ResMLPencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNyxcXWYTd8A",
        "outputId": "89b8d026-8c78-4255-bcb8-5927a458f833"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_euclidean_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1428\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7165, 'Recall': 0.6929, 'F1': 0.7045}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuWIrK0STd8A",
        "outputId": "700ab13c-3a32-4852-e0a0-91027447ace9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1895392 rows\n",
            "✅ After removing ignored classes: 1895392 rows\n",
            "✅ After keeping only test SrcEntities: 449856 rows\n",
            "✅ After applying threshold ≥ 0.0: 449856 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_euclidean_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2527 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_euclidean_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1800\n",
            "📊 Evaluation (P / R / F1): {'P': 0.712, 'R': 0.676, 'F1': 0.694}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coYoDjbQTd8A",
        "outputId": "d447f7fb-a5f0-4884-e4f8-3233ae9682a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7182, 'Recall@1': 0.671, 'F1@1': 0.6938}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkEGcVF3Td8A",
        "outputId": "2682a4fd-4c37-4d9f-b040-a04a5a84177e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-200 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_euclidean_mrr_hit_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 10.09 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1Bi0OwSTd8A"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpbkMEd6Td8A",
        "outputId": "0facdc45-c824-4870-f72c-34eddb359230"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8510010044153624, 'Hits@1': 0.811866316184754, 'Hits@5': 0.8933533608711979, 'Hits@10': 0.8963574915508825}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTmcVS95Td8A"
      },
      "source": [
        "# **MLPEncoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhB_JTd6Td8A",
        "outputId": "724a03b4-2d68-462b-d87c-ec50156c75f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = MLPEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDY1wdWxTd8A",
        "outputId": "0e5c83cf-d1a0-48ad-a87d-e7478a01afce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U19qek3tTd8A",
        "outputId": "b1995d06-a54a-4766-805d-d69b6f04f576"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_cands_with_embeddings_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GKAtuknTd8A",
        "outputId": "371292eb-9c12-4a7b-beed-e2587d157b25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_cands_with_embeddings_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9gsKzZzTd8A"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdyhGLxZTd8A",
        "outputId": "5005ee21-2888-4a22-a49d-1d55188df5f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-1 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_euclidean_MLPencoded.tsv\n",
            "⏱️ Execution time: 7.28 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using Euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the Euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_euclidean(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_annoy_euclidean_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OohZFA9nTd8B",
        "outputId": "ddcadf13-6608-4926-f471-873ebbf53017"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_euclidean_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1257\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6307, 'Recall': 0.6099, 'F1': 0.6201}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_annoy_euclidean_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmPhuWvLTd8B",
        "outputId": "7b03c618-a128-4ac8-c639-e7e9229ef4cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9370 rows\n",
            "✅ After removing ignored classes: 9370 rows\n",
            "✅ After keeping only test SrcEntities: 2363 rows\n",
            "✅ After applying threshold ≥ 0.0: 2363 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_euclidean_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2363 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_euclidean_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1539\n",
            "📊 Evaluation (P / R / F1): {'P': 0.651, 'R': 0.578, 'F1': 0.612}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_annoy_euclidean_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbAnYQweTd8B",
        "outputId": "4e86cc16-08cf-4521-89f3-ba2b2adbb20e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6513, 'Recall@1': 0.6093, 'F1@1': 0.6296}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_annoy_euclidean_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5n-sUr3KTd8B",
        "outputId": "20893d0d-099e-45a2-dc94-792cac57d4bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-1 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_euclidean_mrr_hit_MLPencoded.tsv\n",
            "⏱️ Execution time: 6.72 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_annoy_euclidean_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FETy1GS7Td8B"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_annoy_euclidean_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGbMX0dYTd8B",
        "outputId": "50f6995f-8b3b-43d1-a42e-c4415002b67b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.5680684891305295, 'Hits@1': 0.5550131430717237, 'Hits@5': 0.5550131430717237, 'Hits@10': 0.5550131430717237}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szQ5q-xVTd8B"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_no78REFTd8B",
        "outputId": "465aebed-b079-441d-b615-1aac48133267"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-10 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_euclidean_MLPencoded.tsv\n",
            "⏱️ Execution time: 8.61 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using Euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the Euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_euclidean(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJaIzcG2Td8B",
        "outputId": "a25421d5-dc4c-4f7b-e9cc-19e669866a7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_euclidean_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1257\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6307, 'Recall': 0.6099, 'F1': 0.6201}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twe_X-PJTd8B",
        "outputId": "4af03daf-d140-4faf-b5a2-882ca8e6eacc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 93861 rows\n",
            "✅ After removing ignored classes: 93861 rows\n",
            "✅ After keeping only test SrcEntities: 22287 rows\n",
            "✅ After applying threshold ≥ 0.0: 22287 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_euclidean_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2581 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_euclidean_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1570\n",
            "📊 Evaluation (P / R / F1): {'P': 0.608, 'R': 0.59, 'F1': 0.599}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NECnAILWTd8B",
        "outputId": "53be09b9-ccd6-457a-a4d7-cf7f0638adc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6266, 'Recall@1': 0.5854, 'F1@1': 0.6053}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac2etbG3Td8B",
        "outputId": "6af32fe7-914d-4814-d618-271f253405bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-10 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_euclidean_mrr_hit_MLPencoded.tsv\n",
            "⏱️ Execution time: 4.77 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3zapeWFTd8B"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LwBGGqBTd8B",
        "outputId": "ea4742ad-2178-4b77-bad2-fe581733e6e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6982667656413073, 'Hits@1': 0.6702966579046189, 'Hits@5': 0.7119789710852422, 'Hits@10': 0.7119789710852422}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLuit6heTd8B"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXXQbnoRTd8B",
        "outputId": "00fcbc5b-8af2-4558-d848-9334d9cc2bf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-30 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_euclidean_MLPencoded.tsv\n",
            "⏱️ Execution time: 9.93 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using Euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the Euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_euclidean(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sv8iHfo8Td8B",
        "outputId": "949d9aa2-130b-4ad0-adc0-d0edddc1ad53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_euclidean_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1257\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6307, 'Recall': 0.6099, 'F1': 0.6201}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKUupVK1Td8C",
        "outputId": "7c5bcfde-ea5f-4824-ad7b-5bba7fc365f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 282865 rows\n",
            "✅ After removing ignored classes: 282865 rows\n",
            "✅ After keeping only test SrcEntities: 67150 rows\n",
            "✅ After applying threshold ≥ 0.0: 67150 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_euclidean_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2581 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_euclidean_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1570\n",
            "📊 Evaluation (P / R / F1): {'P': 0.608, 'R': 0.59, 'F1': 0.599}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIdqE9f2Td8C",
        "outputId": "b7e44b60-5a31-4c2e-a710-13e595ea854d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6266, 'Recall@1': 0.5854, 'F1@1': 0.6053}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4WDpUEXTd8C",
        "outputId": "9d87589b-dc55-4dbe-f27d-f742f79a34b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-30 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_euclidean_mrr_hit_MLPencoded.tsv\n",
            "⏱️ Execution time: 5.24 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5s9XoKqQTd8C"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOQBriu8Td8C",
        "outputId": "98771d7c-1016-4c92-86b4-0a4baabda5a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6862085273671268, 'Hits@1': 0.6537739391663537, 'Hits@5': 0.7070972587307548, 'Hits@10': 0.707848291400676}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW4C9vpLTd8C"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQA3Kyq1Td8C",
        "outputId": "79fc9dac-793c-47d2-e612-30c7c25fdf12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-100 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_euclidean_MLPencoded.tsv\n",
            "⏱️ Execution time: 18.35 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using Euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the Euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_euclidean(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Xaxs0nUTd8C",
        "outputId": "21d74389-5148-4ec8-dd19-19b52db68e4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_euclidean_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1370\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6874, 'Recall': 0.6647, 'F1': 0.6759}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCgGhy-DTd8C",
        "outputId": "19e96c65-1322-494f-b474-77b9aa790f93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 947353 rows\n",
            "✅ After removing ignored classes: 947353 rows\n",
            "✅ After keeping only test SrcEntities: 224613 rows\n",
            "✅ After applying threshold ≥ 0.0: 224613 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_euclidean_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2560 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_euclidean_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1719\n",
            "📊 Evaluation (P / R / F1): {'P': 0.671, 'R': 0.646, 'F1': 0.658}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTTyovcMTd8C",
        "outputId": "412456a4-5b85-4b59-8f58-26dad62724b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6849, 'Recall@1': 0.6399, 'F1@1': 0.6616}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_F-S3rJ7Td8C",
        "outputId": "e743126e-be1f-4e49-da24-c6c8e5119249"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-100 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_euclidean_mrr_hit_MLPencoded.tsv\n",
            "⏱️ Execution time: 9.59 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MR_JsmxdTd8C"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLmoOUzlTd8C",
        "outputId": "5a5c84be-f452-4560-e1f4-838aa6ccb0c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.7995274757316854, 'Hits@1': 0.7630491926398798, 'Hits@5': 0.8358993616222306, 'Hits@10': 0.838152459631994}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP4_7jL8Td8C"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qdo-H8chTd8D",
        "outputId": "3aeb0e87-f5a8-434b-a416-1ae526ff574e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-200 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_euclidean_MLPencoded.tsv\n",
            "⏱️ Execution time: 30.87 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using Euclidean distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_annoy_euclidean(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean_MLPencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E41qHWnhTd8D",
        "outputId": "5e21f732-024e-476c-90ed-e8249f044f3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_euclidean_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1430\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7175, 'Recall': 0.6938, 'F1': 0.7055}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVnNg3tUTd8D",
        "outputId": "640329dd-6220-4753-db21-01453bb253c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1900699 rows\n",
            "✅ After removing ignored classes: 1900699 rows\n",
            "✅ After keeping only test SrcEntities: 450907 rows\n",
            "✅ After applying threshold ≥ 0.0: 450907 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_euclidean_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2560 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_euclidean_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1800\n",
            "📊 Evaluation (P / R / F1): {'P': 0.703, 'R': 0.676, 'F1': 0.689}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELfaqAJVTd8D",
        "outputId": "815114fd-248f-4529-fff8-468ff5c55f31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7162, 'Recall@1': 0.6692, 'F1@1': 0.6919}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1i08XzxTd8D",
        "outputId": "62a1b6a8-5b53-416c-c672-8a1c75844369"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-200 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_euclidean_mrr_hit_MLPencoded.tsv\n",
            "⏱️ Execution time: 10.63 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnYGb3tKTd8D"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oe4r1fBWTd8D",
        "outputId": "8d7ef02f-0fcb-474a-d40c-b143744eddda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8495749014917451, 'Hits@1': 0.8084866691701089, 'Hits@5': 0.8952309425460008, 'Hits@10': 0.899361622230567}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nccHOtNfTd8D"
      },
      "source": [
        "# **LinearEncoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QbH8OdvTd8D",
        "outputId": "85c2519e-e862-4c63-f863-b51674c74bbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = LinearEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wv3WfLuTd8D",
        "outputId": "379e045c-6a01-4a43-dd5e-6c458c0c3ac0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AedYrPoJTd8D",
        "outputId": "6cef23f7-2656-4b15-a9d5-932880282019"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_cands_with_embeddings_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hJNwDBWTd8D",
        "outputId": "d2fe2b86-4132-4ecf-e342-30546d1f9208"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_cands_with_embeddings_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLTpa1KVTd8D"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbR2IlDcTd8D",
        "outputId": "12f10aae-bb1b-4c52-f283-3ac895ec6f36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-1 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_euclidean_Linencoded.tsv\n",
            "⏱️ Execution time: 6.58 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using Euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the Euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_euclidean(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_annoy_euclidean_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFrn2IypTd8D",
        "outputId": "d73a3e74-f2c1-47cb-fdd4-624def440b31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_euclidean_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1224\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6141, 'Recall': 0.5939, 'F1': 0.6038}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_annoy_euclidean_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IH3sVje-Td8E",
        "outputId": "3ad73f69-b303-4b66-c29b-cf175bcc1748"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9344 rows\n",
            "✅ After removing ignored classes: 9344 rows\n",
            "✅ After keeping only test SrcEntities: 2368 rows\n",
            "✅ After applying threshold ≥ 0.0: 2368 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_euclidean_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2368 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_euclidean_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1513\n",
            "📊 Evaluation (P / R / F1): {'P': 0.639, 'R': 0.568, 'F1': 0.601}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_annoy_euclidean_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfS0jqQgTd8E",
        "outputId": "b14183ce-b5f3-4ff5-da36-ffd5010ca336"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6389, 'Recall@1': 0.5973, 'F1@1': 0.6174}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_annoy_euclidean_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4f4XowLTd8E",
        "outputId": "87548f47-f32c-4111-c0a1-7a7dd91bc484"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-1 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_euclidean_mrr_hit_Linencoded.tsv\n",
            "⏱️ Execution time: 4.30 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_euclidean_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P04-u_M-Td8E"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_annoy_euclidean_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHrZsTMoTd8E",
        "outputId": "119a2380-caa6-4541-b399-e6af801863f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.5516596463725412, 'Hits@1': 0.5381149079984979, 'Hits@5': 0.5381149079984979, 'Hits@10': 0.5381149079984979}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnek-7biTd8E"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJ8LlKrmTd8E",
        "outputId": "bafe127d-3bc3-453e-ff88-90a2c6cb8620"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-10 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_euclidean_Linencoded.tsv\n",
            "⏱️ Execution time: 8.23 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using Euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the Euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_euclidean(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVWTqs2QTd8E",
        "outputId": "4c125bb0-359f-4147-ac12-4946360102fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_euclidean_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1224\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6141, 'Recall': 0.5939, 'F1': 0.6038}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xliEOH1TTd8E",
        "outputId": "f2475d2f-4273-4944-83f7-d7c79ef34e0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 94032 rows\n",
            "✅ After removing ignored classes: 94032 rows\n",
            "✅ After keeping only test SrcEntities: 22301 rows\n",
            "✅ After applying threshold ≥ 0.0: 22301 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_euclidean_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2536 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_euclidean_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1544\n",
            "📊 Evaluation (P / R / F1): {'P': 0.609, 'R': 0.58, 'F1': 0.594}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVBE2qR5Td8E",
        "outputId": "f5e895bb-d8ff-47c4-f08f-5238e25bf6e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6174, 'Recall@1': 0.5768, 'F1@1': 0.5964}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYdla0iITd8E",
        "outputId": "c20f4b14-c161-4f9a-a249-8a0e2cb1979b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-10 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_euclidean_mrr_hit_Linencoded.tsv\n",
            "⏱️ Execution time: 5.02 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGPqJviATd8E"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "By4GxmxJTd8E",
        "outputId": "af4a6607-7ef9-44fe-f2ee-3d47bf7d6fa8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.7011835582079946, 'Hits@1': 0.6755538865940668, 'Hits@5': 0.7127300037551634, 'Hits@10': 0.7127300037551634}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hpi5XfHuTd8E"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anzGFSVxTd8E",
        "outputId": "45ae455c-d269-43b3-a90b-2ce51b4cea4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-30 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_euclidean_Linencoded.tsv\n",
            "⏱️ Execution time: 10.01 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using annoy_euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the annoy_euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_euclidean(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z-4EnNtTd8F",
        "outputId": "62213818-d4ff-47be-9a37-25522b3d0ba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_euclidean_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1224\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6141, 'Recall': 0.5939, 'F1': 0.6038}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Od0-Z-tTd8F",
        "outputId": "8faa1105-dacb-4bda-943d-1506b4063a85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 283174 rows\n",
            "✅ After removing ignored classes: 283174 rows\n",
            "✅ After keeping only test SrcEntities: 67055 rows\n",
            "✅ After applying threshold ≥ 0.0: 67055 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_euclidean_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2536 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_euclidean_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1545\n",
            "📊 Evaluation (P / R / F1): {'P': 0.609, 'R': 0.58, 'F1': 0.594}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgEmOlwYTd8F",
        "outputId": "2fc3eb15-a329-495a-aad1-9a966a06140e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6178, 'Recall@1': 0.5772, 'F1@1': 0.5968}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xi3MUsjmTd8F",
        "outputId": "58aa4370-fe41-4e5d-c795-405b9b786102"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-30 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_euclidean_mrr_hit_Linencoded.tsv\n",
            "⏱️ Execution time: 5.40 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApEcS8DNTd8F"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbbgx8aaTd8F",
        "outputId": "57650bd0-eea3-4bb8-bdaa-af9e56ff43f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.7059450771558113, 'Hits@1': 0.6785580172737514, 'Hits@5': 0.7213668794592565, 'Hits@10': 0.7213668794592565}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kShFbWMyTd8F"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LALH-dZoTd8F",
        "outputId": "23ef8071-cf2f-482f-a84b-58dc5a830271"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-100 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_euclidean_Linencoded.tsv\n",
            "⏱️ Execution time: 18.76 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using annoy_euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the annoy_euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_euclidean(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYyBt-VPTd8F",
        "outputId": "6598cc3a-e411-4b97-c36b-9b5ed973c056"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_euclidean_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1370\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6874, 'Recall': 0.6647, 'F1': 0.6759}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BE9aiSGmTd8F",
        "outputId": "2233ac5b-6f26-49c8-9562-14f6a027df8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 947297 rows\n",
            "✅ After removing ignored classes: 947297 rows\n",
            "✅ After keeping only test SrcEntities: 224403 rows\n",
            "✅ After applying threshold ≥ 0.0: 224403 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_euclidean_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2533 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_euclidean_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1718\n",
            "📊 Evaluation (P / R / F1): {'P': 0.678, 'R': 0.645, 'F1': 0.661}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MOB3VfVTd8F",
        "outputId": "286f7bd1-1ab3-4ce0-9833-3a8bb9392668"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6869, 'Recall@1': 0.6418, 'F1@1': 0.6636}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wStd4XGqTd8F",
        "outputId": "2b7613d1-fa8c-4b56-cbae-6ad3636d33b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-100 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_euclidean_mrr_hit_Linencoded.tsv\n",
            "⏱️ Execution time: 7.04 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsc14BtnTd8F"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxdvGqmQTd8G",
        "outputId": "f8d6acb5-6152-4de5-8209-4c9a02f0296b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.7999311126553633, 'Hits@1': 0.7649267743146827, 'Hits@5': 0.8325197146075854, 'Hits@10': 0.8343972962823882}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD8CRWfNTd8G"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0g2mqrLTd8G",
        "outputId": "a81bd4fa-f7e0-45d6-b1ef-a7774a1ce898"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-200 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_euclidean_Linencoded.tsv\n",
            "⏱️ Execution time: 29.22 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using annoy_euclidean distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_annoy_euclidean(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean_Linencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bwgm6DarTd8G",
        "outputId": "7c6a99b0-3437-4b92-dd26-d13b5952dc4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_euclidean_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1422\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7135, 'Recall': 0.69, 'F1': 0.7015}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdyeyErWTd8G",
        "outputId": "f67fe8d7-2fbb-4c6a-cab6-15846996073b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1900089 rows\n",
            "✅ After removing ignored classes: 1900089 rows\n",
            "✅ After keeping only test SrcEntities: 449769 rows\n",
            "✅ After applying threshold ≥ 0.0: 449769 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_euclidean_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2530 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_euclidean_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1782\n",
            "📊 Evaluation (P / R / F1): {'P': 0.704, 'R': 0.669, 'F1': 0.686}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwPgVn6qTd8G",
        "outputId": "01d2e390-c150-4b1e-a596-ca5885c69e9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7122, 'Recall@1': 0.6654, 'F1@1': 0.688}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nblf8pbdTd8G",
        "outputId": "2c277e1f-9b9c-47dd-e702-b5212f15002b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-200 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_euclidean_mrr_hit_Linencoded.tsv\n",
            "⏱️ Execution time: 10.59 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on annoy_euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxAcue1KTd8G"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJqXzU-4Td8G",
        "outputId": "259bbd5d-3140-4db6-fac7-0590ac583d89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8447749019974694, 'Hits@1': 0.8051070221554638, 'Hits@5': 0.8869695831768682, 'Hits@10': 0.8911002628614345}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bJ5PP8dTd8G"
      },
      "source": [
        "# **Transformer Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3FgXeDBTd8G",
        "outputId": "6e981960-f9e8-40fe-ea0b-4a33bbdae156"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = TransformerEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fajA-BsNTd8G"
      },
      "outputs": [],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpUyvFQjTd8G"
      },
      "outputs": [],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAf6r0sFTd8G"
      },
      "outputs": [],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QugEfYi4Td8G"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OQP720FTd8G"
      },
      "outputs": [],
      "source": [
        "# Compute the top-10 most similar mappings using Euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the Euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_euclidean(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_annoy_euclidean_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNS050LPTd8H"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_annoy_euclidean_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDr8vQhiTd8H"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_annoy_euclidean_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ea2Pe3epTd8H"
      },
      "outputs": [],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_annoy_euclidean_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSVqfygLTd8H"
      },
      "outputs": [],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_annoy_euclidean_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhBIgFAQTd8H"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_annoy_euclidean_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EF_H_tliTd8H",
        "outputId": "1043d49e-3032-466e-a5af-6866fbe0a4f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.5822873047078311, 'Hits@1': 0.5696582801351859, 'Hits@5': 0.5696582801351859, 'Hits@10': 0.5696582801351859}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwWIiVS7Td8H"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DcyTIy_Td8H",
        "outputId": "70ca67f0-48c4-4ce0-a384-06018f7fbba8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-10 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_euclidean_TRencoded.tsv\n",
            "⏱️ Execution time: 8.25 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using annoy_euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the annoy_euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_euclidean(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z834CMpiTd8H",
        "outputId": "590ed76e-e2a5-4ae7-e4d1-236358e5c923"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_euclidean_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1268\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6362, 'Recall': 0.6152, 'F1': 0.6256}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ac05hP9eTd8H",
        "outputId": "0348e199-a769-4ef6-a660-7bf3bfb5ba2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 95659 rows\n",
            "✅ After removing ignored classes: 95659 rows\n",
            "✅ After keeping only test SrcEntities: 22583 rows\n",
            "✅ After applying threshold ≥ 0.0: 22583 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_euclidean_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2525 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_euclidean_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1583\n",
            "📊 Evaluation (P / R / F1): {'P': 0.627, 'R': 0.594, 'F1': 0.61}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRHe-P3XTd8H",
        "outputId": "2686d116-d72c-4be6-b7d1-990266475333"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6346, 'Recall@1': 0.5929, 'F1@1': 0.6131}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVoJXKABTd8H",
        "outputId": "fdecdb28-4518-4d58-c6cd-a35c49cbc9ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-10 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_euclidean_mrr_hit_TRencoded.tsv\n",
            "⏱️ Execution time: 4.68 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vgo3tOd4Td8H"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_annoy_euclidean_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnfTzUPuTd8H",
        "outputId": "afdb5658-09e3-44cc-90e5-3f3ab2efecda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.7089664020246961, 'Hits@1': 0.6811866316184754, 'Hits@5': 0.7232444611340594, 'Hits@10': 0.7232444611340594}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJZbz7kBTd8H"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4ouP_0PTd8H",
        "outputId": "9c1bfe7f-ec95-4883-f2b2-9de386b32ef4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-30 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_euclidean_TRencoded.tsv\n",
            "⏱️ Execution time: 9.89 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using annoy_euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the annoy_euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_euclidean(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t91ziU-0Td8I",
        "outputId": "7990f395-545b-4df4-f866-17b335efd4a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_euclidean_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1268\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6362, 'Recall': 0.6152, 'F1': 0.6256}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRcuBp_PTd8I",
        "outputId": "dacc3303-dcb2-466c-b2cf-82d7c416c394"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 288281 rows\n",
            "✅ After removing ignored classes: 288281 rows\n",
            "✅ After keeping only test SrcEntities: 67758 rows\n",
            "✅ After applying threshold ≥ 0.0: 67758 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_euclidean_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2525 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_euclidean_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1583\n",
            "📊 Evaluation (P / R / F1): {'P': 0.627, 'R': 0.594, 'F1': 0.61}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpqSw-6PTd8I",
        "outputId": "55aa1ae9-1419-4b50-c1d7-16ca7bb59b19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6346, 'Recall@1': 0.5929, 'F1@1': 0.6131}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RV1WaJwnTd8I",
        "outputId": "ccfa9250-cf83-4e47-baad-6bb7b81ad61e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-30 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_euclidean_mrr_hit_TRencoded.tsv\n",
            "⏱️ Execution time: 5.12 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwX3c3BxTd8I"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_annoy_euclidean_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYEasvpITd8I",
        "outputId": "80abda08-9481-4ea8-c479-262d184a66ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.7137923720356095, 'Hits@1': 0.6834397296282388, 'Hits@5': 0.7337589185129553, 'Hits@10': 0.7337589185129553}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXJaIdFoTd8I"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtpNHpyPTd8I",
        "outputId": "adb30fc4-5dfa-415b-f244-1137d8c82d5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-100 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_euclidean_TRencoded.tsv\n",
            "⏱️ Execution time: 18.52 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using annoy_euclidean distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the annoy_euclidean distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_euclidean(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gLrmvwBTd8I",
        "outputId": "6002a6d6-fd1d-4dc7-94b5-cf8653ea1519"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_euclidean_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1361\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6829, 'Recall': 0.6604, 'F1': 0.6714}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLrAPYQ2Td8I",
        "outputId": "05a4277c-1dcc-40c6-b6f8-1e8003ed02d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 966776 rows\n",
            "✅ After removing ignored classes: 966776 rows\n",
            "✅ After keeping only test SrcEntities: 227498 rows\n",
            "✅ After applying threshold ≥ 0.0: 227498 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_euclidean_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2516 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_euclidean_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1697\n",
            "📊 Evaluation (P / R / F1): {'P': 0.674, 'R': 0.637, 'F1': 0.655}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiMEKNUOTd8I",
        "outputId": "786a4a49-49fc-4df0-8eb9-8d2716d51a0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6801, 'Recall@1': 0.6354, 'F1@1': 0.657}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KLxaS3zTd8I",
        "outputId": "46799b26-ab78-42b3-ae08-3765d85fe2be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-100 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_euclidean_mrr_hit_TRencoded.tsv\n",
            "⏱️ Execution time: 8.94 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "4JcWN4E8Td8I",
        "outputId": "ae44bac9-e1a2-420f-bf4a-0d95bf9e8228"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'compute_mrr_and_hits' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-861c01d37a1c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compute MRR and Hits@k metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# This function evaluates the predicted rankings against the reference mappings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m results = compute_mrr_and_hits(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mreference_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_cands\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0;31m# Reference file with true ranks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpredicted_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{results_dir}/{task}_top_100_mappings_annoy_euclidean_mrr_hit_TRencoded.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0;31m# File containing predicted rankings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'compute_mrr_and_hits' is not defined"
          ]
        }
      ],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_annoy_euclidean_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxJbQ3d6Td8I",
        "outputId": "ad391f03-f436-4e1e-89f8-c60e18a831e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.7990284128731151, 'Hits@1': 0.7604205782951559, 'Hits@5': 0.8362748779571911, 'Hits@10': 0.838152459631994}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5OTuz2rTd8I"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7Y6zPZ9Td8J",
        "outputId": "e81a35b9-5924-4ffe-d6f9-825df2e442e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-200 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_euclidean_TRencoded.tsv\n",
            "⏱️ Execution time: 35.44 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using annoy_euclidean distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_annoy_euclidean(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean_TRencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INrJNVkNTd8J",
        "outputId": "4d274be5-6ae3-47c8-e72f-8c674d60ae88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_euclidean_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1410\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7075, 'Recall': 0.6841, 'F1': 0.6956}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CayhdUoeTd8J",
        "outputId": "18cab2eb-0686-444b-a713-a03faab4bed9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1942766 rows\n",
            "✅ After removing ignored classes: 1942766 rows\n",
            "✅ After keeping only test SrcEntities: 457382 rows\n",
            "✅ After applying threshold ≥ 0.0: 457382 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_euclidean_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2516 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_euclidean_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1762\n",
            "📊 Evaluation (P / R / F1): {'P': 0.7, 'R': 0.662, 'F1': 0.68}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VMWvBYxTd8J",
        "outputId": "4d723af3-eee8-4565-f8f7-f25c250f3ccd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7058, 'Recall@1': 0.6594, 'F1@1': 0.6818}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_WWgbuvTd8J",
        "outputId": "08ad9f72-8450-4b66-ae24-cd484b3304aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: euclidean\n",
            "Top-200 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_euclidean_mrr_hit_TRencoded.tsv\n",
            "⏱️ Execution time: 10.20 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_euclidean(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on Euclidean distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "babq331tTd8J"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_annoy_euclidean_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLe3X_flTd8J",
        "outputId": "dea7caaf-a55d-458e-c7f9-26c17a9f4ebc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8461573976048632, 'Hits@1': 0.8039804731505821, 'Hits@5': 0.8911002628614345, 'Hits@10': 0.8937288772061585}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgrTeuQeTg0A"
      },
      "source": [
        "# **USING ANNOY COSINE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSvLa5vzdJ_2"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aP33DjcYdJ_2",
        "outputId": "1955179f-646b-4761-9577-8676296514f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-1 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_cosine.tsv\n",
            "⏱️ Execution time: 10.30 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_annoy_cosine.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUMB1rSLdKCT",
        "outputId": "82c74b02-9800-4d79-87d3-d7808a1da1bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_cosine_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1238\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6212, 'Recall': 0.6007, 'F1': 0.6108}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_annoy_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMNtWWiqdKCU",
        "outputId": "b5fb80d0-250d-4c1a-a69a-1410dec93894"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9550 rows\n",
            "✅ After removing ignored classes: 9550 rows\n",
            "✅ After keeping only test SrcEntities: 2369 rows\n",
            "✅ After applying threshold ≥ 0.0: 2369 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_cosine_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2369 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_cosine_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1508\n",
            "📊 Evaluation (P / R / F1): {'P': 0.637, 'R': 0.566, 'F1': 0.599}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_annoy_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DERyy-5XdKCU",
        "outputId": "b0342f65-04cb-40e5-d390-16485de28c07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6366, 'Recall@1': 0.5958, 'F1@1': 0.6155}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/neoplas_top_1_mappings_annoy_cosine_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjeRf4QudKCV",
        "outputId": "0e5f274e-f97d-4766-e39c-3d9ffb204619"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-1 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_cosine_mrr_hit.tsv\n",
            "⏱️ Execution time: 4.32 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_annoy_cosine_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyQhYjXPdKCV"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_annoy_cosine_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Il4LMFMdKCV",
        "outputId": "0e158bb8-3868-47be-ee36-a2bffa5e4e95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.5673395456567827, 'Hits@1': 0.5542621104018025, 'Hits@5': 0.5542621104018025, 'Hits@10': 0.5542621104018025}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1kRZFcedKCV"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_mrF4GndKCV",
        "outputId": "d525ccbf-8c5c-4766-c03f-fe4d9e4c36f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-10 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_cosine.tsv\n",
            "⏱️ Execution time: 8.19 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_annoy_cosine.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZNXTBMpdKCV",
        "outputId": "02b1815b-0c46-4230-89b6-1b48cc5a4c59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_cosine_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1238\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6212, 'Recall': 0.6007, 'F1': 0.6108}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_annoy_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJk9g1f4dKCW",
        "outputId": "6e4101de-3464-4f02-be7c-d9faf093d125"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 96252 rows\n",
            "✅ After removing ignored classes: 96252 rows\n",
            "✅ After keeping only test SrcEntities: 22573 rows\n",
            "✅ After applying threshold ≥ 0.0: 22573 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_cosine_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2612 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_cosine_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1542\n",
            "📊 Evaluation (P / R / F1): {'P': 0.59, 'R': 0.579, 'F1': 0.585}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_annoy_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17iGBCWrdKCW",
        "outputId": "5c89195b-a082-4e9a-9a34-5219badf3c64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6145, 'Recall@1': 0.5742, 'F1@1': 0.5937}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_annoy_cosine_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ej0ihvN4dKCW",
        "outputId": "c0bc416d-8778-4cab-c70b-d5fb3eb9923b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-10 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_cosine_mrr_hit.tsv\n",
            "⏱️ Execution time: 4.81 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_annoy_cosine_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGa6iMf8dKCW"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_annoy_cosine_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tl5b399sdKCW",
        "outputId": "ee7f898c-bd1d-4a65-f6fe-684ad91a00c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6872488379636772, 'Hits@1': 0.6597822005257229, 'Hits@5': 0.7003379647014645, 'Hits@10': 0.7003379647014645}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihFFu2ZmdKCW"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1HwmVssdKCW",
        "outputId": "22f36598-00ed-4c2b-e8a8-252889195496"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-30 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_cosine.tsv\n",
            "⏱️ Execution time: 10.24 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_annoy_cosine.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeiT9EUYdKCW",
        "outputId": "7e855fb8-bca4-483c-edcb-50784c493925"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_cosine_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1245\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6247, 'Recall': 0.6041, 'F1': 0.6142}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_annoy_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8JD8kmEdKCX",
        "outputId": "2ed73d02-7c83-4469-a22a-499688f6cedf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 290010 rows\n",
            "✅ After removing ignored classes: 290010 rows\n",
            "✅ After keeping only test SrcEntities: 67920 rows\n",
            "✅ After applying threshold ≥ 0.0: 67920 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_cosine_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2609 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_cosine_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1552\n",
            "📊 Evaluation (P / R / F1): {'P': 0.595, 'R': 0.583, 'F1': 0.589}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_annoy_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wleg1PnVdKCX",
        "outputId": "5c68d12b-0d19-4747-9d5d-879a6d0c8cfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6182, 'Recall@1': 0.5775, 'F1@1': 0.5972}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_annoy_cosine_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETmaAI_8dKCX",
        "outputId": "b7ba6992-8b7c-4ea3-b3b3-eaaf1f5d1262"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-30 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_cosine_mrr_hit.tsv\n",
            "⏱️ Execution time: 5.58 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_annoy_cosine_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87ZZ5LOLdKCX"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_annoy_cosine_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XOUKzQ1dKCX",
        "outputId": "b011ca5c-6f78-49ec-be49-2564ed5d0091"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6963353037877898, 'Hits@1': 0.6661659782200525, 'Hits@5': 0.7153586180998873, 'Hits@10': 0.7157341344348479}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZuh78HTdKCX"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5l-FpUf6dKCY",
        "outputId": "26cf424f-35e5-4af5-cd70-61a946fd5065"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-100 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_cosine.tsv\n",
            "⏱️ Execution time: 19.14 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_annoy_cosine.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ok3NP1_-dKCY",
        "outputId": "09e0ef48-966b-4328-9a17-67bfe6203e10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_cosine_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1336\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6703, 'Recall': 0.6482, 'F1': 0.6591}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_annoy_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYmEea1AdKCY",
        "outputId": "ee54937d-eca3-4665-b582-d7ef4e6d0eb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 972423 rows\n",
            "✅ After removing ignored classes: 972423 rows\n",
            "✅ After keeping only test SrcEntities: 227772 rows\n",
            "✅ After applying threshold ≥ 0.0: 227772 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_cosine_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2588 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_cosine_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1682\n",
            "📊 Evaluation (P / R / F1): {'P': 0.65, 'R': 0.632, 'F1': 0.641}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_annoy_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFUNsxBddKCZ",
        "outputId": "0ea43845-22fd-487c-e1cb-2641ae3465a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6692, 'Recall@1': 0.6252, 'F1@1': 0.6465}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_annoy_cosine_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ATAU87TdKCZ",
        "outputId": "4cdcffb0-cccb-428e-9cbd-6bd23e1d678c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-100 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_cosine_mrr_hit.tsv\n",
            "⏱️ Execution time: 9.31 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_annoy_cosine_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEsVevl8dKCZ"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_annoy_cosine_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4--3-Y5LdKCZ",
        "outputId": "0fb21f2b-ff76-445a-e00f-c726c581fdcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.7860011735885412, 'Hits@1': 0.7495306045812993, 'Hits@5': 0.8193766428839655, 'Hits@10': 0.8212542245587683}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5A5TqNAdKCa"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2HLnqf5dKCa",
        "outputId": "2cd12d66-5564-47a2-f9d6-61a3120b336c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-200 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_cosine.tsv\n",
            "⏱️ Execution time: 28.34 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_annoy_cosine.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cMzrTbodKCa",
        "outputId": "5cb82c7d-c1a9-437d-cef5-ae02c619b961"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_cosine_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1390\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6974, 'Recall': 0.6744, 'F1': 0.6857}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_annoy_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mD4zuH5gdKCb",
        "outputId": "993decbb-c365-41ac-af6c-59fee5fc0532"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1952461 rows\n",
            "✅ After removing ignored classes: 1952461 rows\n",
            "✅ After keeping only test SrcEntities: 457977 rows\n",
            "✅ After applying threshold ≥ 0.0: 457977 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_cosine_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2588 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_cosine_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1752\n",
            "📊 Evaluation (P / R / F1): {'P': 0.677, 'R': 0.658, 'F1': 0.667}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_annoy_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t_wwAzUdKCb",
        "outputId": "aadd3a8e-11b1-485c-d7fc-a2d58cddee96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6957, 'Recall@1': 0.65, 'F1@1': 0.6721}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_annoy_cosine_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ma5Pkji-dKCb",
        "outputId": "bc787fb2-809c-49c1-b54c-2e63f9374568"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-200 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_cosine_mrr_hit.tsv\n",
            "⏱️ Execution time: 8.93 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_annoy_cosine_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBEgMwh-dKCc"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_annoy_cosine_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fm15fS4FdKCc",
        "outputId": "6bb22451-37e9-4965-af2f-c919fde0f872"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8354774203163613, 'Hits@1': 0.7938415321066467, 'Hits@5': 0.8809613218174991, 'Hits@10': 0.8839654524971836}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiTYgSB9dKCc"
      },
      "source": [
        "# **K=500**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_3vgO5jdKCd",
        "outputId": "297c3665-c614-4ca2-803a-1ca3306f7248"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-500 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_annoy_cosine.tsv\n",
            "⏱️ Execution time: 63.34 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=500,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_500_mappings_annoy_cosine.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjNi-aUYdKCd",
        "outputId": "3576ea3d-4d86-46ef-d68b-043fb37079d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 5703500 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 996500 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_annoy_cosine_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1428\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7165, 'Recall': 0.6929, 'F1': 0.7045}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_500_mappings_annoy_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyBGDUzhdKCd",
        "outputId": "5d7212f2-9d81-4795-8dfc-b159ce8ca117"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 5703500 rows\n",
            "✅ After removing train-only URIs: 4914884 rows\n",
            "✅ After removing ignored classes: 4914884 rows\n",
            "✅ After keeping only test SrcEntities: 1155179 rows\n",
            "✅ After applying threshold ≥ 0.0: 1155179 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_annoy_cosine_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2573 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_annoy_cosine_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1806\n",
            "📊 Evaluation (P / R / F1): {'P': 0.702, 'R': 0.678, 'F1': 0.69}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_500_mappings_annoy_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQMkbIZudKCe",
        "outputId": "95c5129b-c556-4d75-ac58-56783c638077"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.717, 'Recall@1': 0.6699, 'F1@1': 0.6927}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_500_mappings_annoy_cosine_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWsvq_gHdKCe",
        "outputId": "45e5eff2-876a-4e79-f713-d5dbed1b6dd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-500 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_annoy_cosine_mrr_hit.tsv\n",
            "⏱️ Execution time: 16.90 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=500,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_500_mappings_annoy_cosine_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEi7YkDtdKCe"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_500_mappings_annoy_cosine_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHlshVvEdKCf",
        "outputId": "d1befacb-d37c-44ae-fbe7-1837e3ea4b52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8773990419302761, 'Hits@1': 0.8313931656027037, 'Hits@5': 0.9305294780322944, 'Hits@10': 0.9354111903867818}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRFMbq-1dKCf"
      },
      "source": [
        "# **K=1000**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpOm0Cf2dKCf",
        "outputId": "39487669-7024-492c-bb1d-8175c14b8ab1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-1000 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_annoy_cosine.tsv\n",
            "⏱️ Execution time: 112.49 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1000,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1000_mappings_annoy_cosine.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Spaqv37MdKCg",
        "outputId": "92ff6b85-1956-4655-8fb2-2425186405eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407000 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993000 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_annoy_cosine_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1444\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7245, 'Recall': 0.7006, 'F1': 0.7124}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1000_mappings_annoy_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dR_ZRd4OdKCg",
        "outputId": "5fbd8992-6e74-45b2-ccec-f04272b3c1c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407000 rows\n",
            "✅ After removing train-only URIs: 9891996 rows\n",
            "✅ After removing ignored classes: 9891996 rows\n",
            "✅ After keeping only test SrcEntities: 2330013 rows\n",
            "✅ After applying threshold ≥ 0.0: 2330013 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_annoy_cosine_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2576 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_annoy_cosine_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1828\n",
            "📊 Evaluation (P / R / F1): {'P': 0.71, 'R': 0.686, 'F1': 0.698}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1000_mappings_annoy_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chuHj4y7dKCg",
        "outputId": "b764751d-7920-410d-fc83-2d9995169ae5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7251, 'Recall@1': 0.6774, 'F1@1': 0.7004}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1000_mappings_annoy_cosine_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czbZJyGHdKCh",
        "outputId": "9e389637-665f-4b40-a60a-6f6922d7c0cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-1000 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_annoy_cosine_mrr_hit.tsv\n",
            "⏱️ Execution time: 27.09 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1000,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1000_mappings_annoy_cosine_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2lBrPi4dKCh"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1000_mappings_annoy_cosine_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAsmAxQqdKCi",
        "outputId": "138b07aa-38bb-49f6-cdf9-3772bb35de8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9047100607124008, 'Hits@1': 0.8558017273751408, 'Hits@5': 0.9635749155088247, 'Hits@10': 0.9699586932031543}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG9-hZ6fdKCi"
      },
      "source": [
        "# **K=2000**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvlrwrz-dKCi",
        "outputId": "250adcf3-bdec-4a8f-efae-5c7ccdb0ae67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-2000 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_annoy_cosine.tsv\n",
            "⏱️ Execution time: 210.92 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=2000,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_2000_mappings_annoy_cosine.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHnE2TIRdKCj",
        "outputId": "13958039-6fe8-4f1e-e05d-b78a592d58ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 22814000 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 3986000 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_annoy_cosine_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1456\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7306, 'Recall': 0.7065, 'F1': 0.7183}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_2000_mappings_annoy_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPMxRrUvdKCj",
        "outputId": "309cff7d-8dd8-4193-832c-fdfd74ecde68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 22814000 rows\n",
            "✅ After removing train-only URIs: 19888129 rows\n",
            "✅ After removing ignored classes: 19888129 rows\n",
            "✅ After keeping only test SrcEntities: 4698277 rows\n",
            "✅ After applying threshold ≥ 0.0: 4698277 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_annoy_cosine_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2574 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_annoy_cosine_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1844\n",
            "📊 Evaluation (P / R / F1): {'P': 0.716, 'R': 0.692, 'F1': 0.704}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_2000_mappings_annoy_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS86KjPndKCj",
        "outputId": "a3349db1-7c06-451c-95f1-31642697f40d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7311, 'Recall@1': 0.6831, 'F1@1': 0.7063}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_2000_mappings_annoy_cosine_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8DSAistdKCk",
        "outputId": "dcb353bb-09e6-4738-9451-057b51d02b74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-2000 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_annoy_cosine_mrr_hit.tsv\n",
            "⏱️ Execution time: 57.65 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=2000,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_2000_mappings_annoy_cosine_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWQQa1hxdKCk"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_2000_mappings_annoy_cosine_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcP4gGIYdKCl",
        "outputId": "4be8f5dc-f813-436e-eeeb-f381ba0b9302"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9152261956897951, 'Hits@1': 0.8640630867442733, 'Hits@5': 0.9778445362373264, 'Hits@10': 0.9864814119414195}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vAeD9IqdKCl"
      },
      "source": [
        "# **With Encoders**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN50H_TLdKCl"
      },
      "source": [
        "# **ResMLPEncoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLh4wIVhdKCl",
        "outputId": "7ae41120-1225-447a-c804-834747b2aa11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = ResMLPEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDvUEo1WdKCm",
        "outputId": "3faf6163-9f1e-4bd2-f92f-c0397b9c997e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P86PC-JdKCm",
        "outputId": "d4961498-2ab3-4d27-977e-9b0f63c4fc06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_cands_with_embeddings_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oY-iW0IAdKCm",
        "outputId": "6122cf2e-5a6a-42da-cc89-d73064a66f44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_cands_with_embeddings_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_gOQHKGdKCn"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-I5EqDZdKCn",
        "outputId": "a9919917-933a-48bb-a29f-e598015473fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-1 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_cosine_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 6.53 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_annoy_cosine_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YujJ8gH4dKCn",
        "outputId": "4aa793f9-5f5b-4d43-941a-4a9b8b39610f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_cosine_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1235\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6197, 'Recall': 0.5992, 'F1': 0.6093}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_annoy_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6QmHZ8FdKCn",
        "outputId": "984110ff-32b0-454d-dab4-e6c9e6300d37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9537 rows\n",
            "✅ After removing ignored classes: 9537 rows\n",
            "✅ After keeping only test SrcEntities: 2374 rows\n",
            "✅ After applying threshold ≥ 0.0: 2374 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_cosine_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2374 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_cosine_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1506\n",
            "📊 Evaluation (P / R / F1): {'P': 0.634, 'R': 0.566, 'F1': 0.598}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_annoy_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgnugfUtdKCo",
        "outputId": "e18bfef1-521c-4073-b1c7-d2e15628d874"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6344, 'Recall@1': 0.5936, 'F1@1': 0.6133}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_annoy_cosine_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9COVNzqSdKCo",
        "outputId": "493a086c-566f-4f43-ad02-beca602485ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-1 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_cosine_mrr_hit_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 6.50 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_annoy_cosine_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plCSpwdgdKCo"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_annoy_cosine_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yuK6vgNdKCo",
        "outputId": "d947f07b-7ae2-4c14-f2cc-b80644709f71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.5826476741654151, 'Hits@1': 0.5700337964701464, 'Hits@5': 0.5700337964701464, 'Hits@10': 0.5700337964701464}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HFeUUHidKCo"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjheznF6dKCo",
        "outputId": "88f3e072-dc75-4201-bc95-1ef13fc5184d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-10 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_cosine_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 7.66 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_annoy_cosine_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otahpXfvdKCp",
        "outputId": "903592aa-0ff7-4c82-9d8d-db2e85479d7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_cosine_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1235\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6197, 'Recall': 0.5992, 'F1': 0.6093}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_annoy_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohRXx88ldKCp",
        "outputId": "d87fc2ff-73c6-41ea-dd10-4c18bdb22492"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 96220 rows\n",
            "✅ After removing ignored classes: 96220 rows\n",
            "✅ After keeping only test SrcEntities: 22566 rows\n",
            "✅ After applying threshold ≥ 0.0: 22566 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_cosine_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2582 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_cosine_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1544\n",
            "📊 Evaluation (P / R / F1): {'P': 0.598, 'R': 0.58, 'F1': 0.589}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_annoy_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkdgbJEudKCp",
        "outputId": "54c0adbb-20c7-43d9-f77b-990b9c197359"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6145, 'Recall@1': 0.5742, 'F1@1': 0.5937}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_annoy_cosine_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9oi1OradKCp",
        "outputId": "09391f9f-5cde-42fa-afa3-9f550c317e20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-10 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_cosine_mrr_hit_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 4.48 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_annoy_cosine_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TFD9fe5dKCq"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_annoy_cosine_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErRBxiC3dKCq",
        "outputId": "ef4b3fc2-a054-4f3f-c4b5-a18cd26dc177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.7074817898471346, 'Hits@1': 0.6804355989485542, 'Hits@5': 0.7206158467893353, 'Hits@10': 0.7206158467893353}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRt1HqtKdKCq"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZZehCHcdKCq",
        "outputId": "257cb64a-6dd1-4943-e510-c6814562203f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-30 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_cosine_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 9.26 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_annoy_cosine_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5gTxUAjdKCq",
        "outputId": "1b30aee6-a462-4803-f784-e4a0ae605a50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_cosine_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1241\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6227, 'Recall': 0.6021, 'F1': 0.6122}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_annoy_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1I-8Vv64dKCr",
        "outputId": "75f944cc-ce56-441e-fdda-4f74e77c05c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 289888 rows\n",
            "✅ After removing ignored classes: 289888 rows\n",
            "✅ After keeping only test SrcEntities: 67936 rows\n",
            "✅ After applying threshold ≥ 0.0: 67936 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_cosine_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2582 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_cosine_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1552\n",
            "📊 Evaluation (P / R / F1): {'P': 0.601, 'R': 0.583, 'F1': 0.592}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_annoy_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTwiTYXQdKCr",
        "outputId": "5ea4673b-1f5c-411c-8901-56abd2db9d16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6178, 'Recall@1': 0.5772, 'F1@1': 0.5968}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_annoy_cosine_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YflyPECdKCr",
        "outputId": "afca824d-aa84-4c23-dbc0-ea8fa94b0e25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-30 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_cosine_mrr_hit_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 5.20 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_annoy_cosine_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPq3VurTdKCr"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_annoy_cosine_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0usHrIaodKCr",
        "outputId": "69ae1322-e37a-4c33-9f1d-0c8072c1a157"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.716443494477051, 'Hits@1': 0.6871948929778445, 'Hits@5': 0.734885467517837, 'Hits@10': 0.734885467517837}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGeugWgWdKCs"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFOjzIOKdKCs",
        "outputId": "619a896e-9230-45ac-a208-41ec5945ca27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-100 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_cosine_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 17.09 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_annoy_cosine_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bB9z7AcldKCs",
        "outputId": "1664dfe5-a96b-469f-cc62-3124d58db477"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_cosine_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1332\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6683, 'Recall': 0.6463, 'F1': 0.6571}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_annoy_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sUhowg0dKCs",
        "outputId": "abcf1e89-42d0-4b8d-d549-4180284bb9b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 972006 rows\n",
            "✅ After removing ignored classes: 972006 rows\n",
            "✅ After keeping only test SrcEntities: 227814 rows\n",
            "✅ After applying threshold ≥ 0.0: 227814 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_cosine_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2586 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_cosine_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1678\n",
            "📊 Evaluation (P / R / F1): {'P': 0.649, 'R': 0.63, 'F1': 0.639}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_annoy_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8U2sKwudKCs",
        "outputId": "f5bca8f8-0cb5-4ae1-f13d-b7e3ea473c42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6648, 'Recall@1': 0.6211, 'F1@1': 0.6422}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_annoy_cosine_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3uSt_0ldKCs",
        "outputId": "a6f973de-a3f0-440d-defe-5e2f1e5774c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-100 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_cosine_mrr_hit_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 6.68 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_annoy_cosine_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKUiR87BdKCs"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_annoy_cosine_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS1fbPLhdKCt",
        "outputId": "cc52e62e-0a07-4c11-c8d7-1a57adf381e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.7864795177545006, 'Hits@1': 0.7510326699211416, 'Hits@5': 0.8193766428839655, 'Hits@10': 0.8201276755538865}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owDkaziddKCt"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFVXv9v7dKCt",
        "outputId": "3452075d-9883-4576-f1e1-4f2c34d3e74b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-200 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_cosine_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 27.58 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using cosine distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_annoy_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_annoy_cosine_ResMLPencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE6dMGiRdKCt",
        "outputId": "22006a71-2283-4b50-b341-b340dcc8a678"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_cosine_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1391\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6979, 'Recall': 0.6749, 'F1': 0.6862}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_annoy_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WX4hEFrbdKCt",
        "outputId": "35107e98-e58a-4cc1-aff2-6c8f94b8054b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1953132 rows\n",
            "✅ After removing ignored classes: 1953132 rows\n",
            "✅ After keeping only test SrcEntities: 458208 rows\n",
            "✅ After applying threshold ≥ 0.0: 458208 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_cosine_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2577 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_cosine_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1755\n",
            "📊 Evaluation (P / R / F1): {'P': 0.681, 'R': 0.659, 'F1': 0.67}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_annoy_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpiNPo0SdKCu",
        "outputId": "c00c6359-2497-4b34-df47-3d8c485aaf68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6949, 'Recall@1': 0.6493, 'F1@1': 0.6713}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_annoy_cosine_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlB3wfisdKCu",
        "outputId": "eec291a5-38bb-4962-96f9-b10c2d6decdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-200 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_cosine_mrr_hit_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 9.68 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_annoy_cosine_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZKuOMEFdKCu"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_annoy_cosine_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXV_FHRHdKCu",
        "outputId": "f7ef7744-54e7-44be-a229-cd83c3f5d9a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8344448823337184, 'Hits@1': 0.79609463011641, 'Hits@5': 0.8749530604581299, 'Hits@10': 0.8768306421329328}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s2q1WYldKCv"
      },
      "source": [
        "# **MLPEncoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmfmTU4zdKCv",
        "outputId": "11e50544-07e0-4542-a663-5ce6fdaa985c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = MLPEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N17GfQsjdKCv",
        "outputId": "e7c485cf-fe9a-419a-a1a4-cb24b9e46391"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHkbc1VNdKCv",
        "outputId": "0c7ee1ae-98f6-4db4-da27-4a0a79650408"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_cands_with_embeddings_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ax4m89xJdKCw",
        "outputId": "d0cade64-6b6b-403f-d8f6-664644878e9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_cands_with_embeddings_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxS9w_VtdKCw"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR0l-Xl-dKCw",
        "outputId": "581a9b56-96f9-4b2f-e420-1e64ebfdb51d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-1 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_cosine_MLPencoded.tsv\n",
            "⏱️ Execution time: 9.51 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_annoy_cosine_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLHd8pz5dKCx",
        "outputId": "243e7bd3-419a-43b1-d075-3dd2c2af7682"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_cosine_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1184\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.5941, 'Recall': 0.5745, 'F1': 0.5841}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_annoy_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wm4HVuodKCx",
        "outputId": "dc022f02-1e10-4bd0-d132-a74a2966922d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9589 rows\n",
            "✅ After removing ignored classes: 9589 rows\n",
            "✅ After keeping only test SrcEntities: 2363 rows\n",
            "✅ After applying threshold ≥ 0.0: 2363 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_cosine_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2363 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_cosine_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1443\n",
            "📊 Evaluation (P / R / F1): {'P': 0.611, 'R': 0.542, 'F1': 0.574}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_annoy_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93oizE8OdKCx",
        "outputId": "1258ac2d-5661-42e1-8110-76a02170e3a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6107, 'Recall@1': 0.5717, 'F1@1': 0.5905}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_annoy_cosine_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ietWhdYdKCx",
        "outputId": "2d04efd5-47b7-4a02-ed33-cd0fc15c8b6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-1 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_cosine_mrr_hit_MLPencoded.tsv\n",
            "⏱️ Execution time: 4.09 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_annoy_cosine_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lhoWIEydKCy"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_annoy_cosine_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCjwmO12dKCy",
        "outputId": "996af527-3afc-4245-8103-868426b12406"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.5498461645266358, 'Hits@1': 0.536237326323695, 'Hits@5': 0.536237326323695, 'Hits@10': 0.536237326323695}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KClpr8aldKCy"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4kHs3vkdKCy",
        "outputId": "7369b663-7297-43f3-e52a-fd0e6e20ff19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-10 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_cosine_MLPencoded.tsv\n",
            "⏱️ Execution time: 7.74 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_annoy_cosine_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsQpf6xLdKCy",
        "outputId": "da943b7d-c31b-4b0f-8c61-eff75f266a0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_cosine_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1184\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.5941, 'Recall': 0.5745, 'F1': 0.5841}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_annoy_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R149EGxrdKCy",
        "outputId": "f2ecbb08-b254-44bb-a30a-13af4040c7e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 96615 rows\n",
            "✅ After removing ignored classes: 96615 rows\n",
            "✅ After keeping only test SrcEntities: 22635 rows\n",
            "✅ After applying threshold ≥ 0.0: 22635 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_cosine_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2631 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_cosine_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1484\n",
            "📊 Evaluation (P / R / F1): {'P': 0.564, 'R': 0.557, 'F1': 0.561}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_annoy_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYwcDgtIdKCy",
        "outputId": "09a9e72d-daf7-4176-9adf-8aa77d55bb7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.5896, 'Recall@1': 0.5509, 'F1@1': 0.5696}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_annoy_cosine_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tfk-CaMdKCy",
        "outputId": "a42bb964-6540-46d4-c2d3-16d6eb798ae3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-10 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_cosine_mrr_hit_MLPencoded.tsv\n",
            "⏱️ Execution time: 4.43 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_annoy_cosine_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1CUTnfZdKCz"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_annoy_cosine_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMWj1GCfdKCz",
        "outputId": "3171d9a0-1e5e-4394-b1fd-74d125aa485c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.7074817898471346, 'Hits@1': 0.6804355989485542, 'Hits@5': 0.7206158467893353, 'Hits@10': 0.7206158467893353}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ok2af88NdKCz"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_7y34AjdKCz",
        "outputId": "74b6db4e-2183-4db7-bc05-73392f8bb547"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-30 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_cosine_MLPencoded.tsv\n",
            "⏱️ Execution time: 9.37 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_annoy_cosine_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCzpEkRIdKCz",
        "outputId": "eba6a72a-6ea9-4c0a-b5e5-ddaa11097a40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_cosine_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1190\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.5971, 'Recall': 0.5774, 'F1': 0.5871}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_annoy_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNJv3BujdKCz",
        "outputId": "ea6cea38-a298-44b9-dd1d-25d39ffb1e73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 290774 rows\n",
            "✅ After removing ignored classes: 290774 rows\n",
            "✅ After keeping only test SrcEntities: 68001 rows\n",
            "✅ After applying threshold ≥ 0.0: 68001 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_cosine_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2629 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_cosine_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1491\n",
            "📊 Evaluation (P / R / F1): {'P': 0.567, 'R': 0.56, 'F1': 0.563}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_annoy_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFozRQaAdKC0",
        "outputId": "f0527279-880f-4142-8da3-c0afcc785d36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.5924, 'Recall@1': 0.5535, 'F1@1': 0.5723}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_annoy_cosine_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goVomaBkdKC0",
        "outputId": "28602c34-3364-4d35-d181-92f64dba5e1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-30 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_cosine_mrr_hit_MLPencoded.tsv\n",
            "⏱️ Execution time: 5.22 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_annoy_cosine_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ID3lPrYydKC0"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_annoy_cosine_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPTJsCjUdKC0",
        "outputId": "d1ccf3e1-60f9-4e7e-cc1a-6673b66c03c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6782611479920697, 'Hits@1': 0.6488922268118663, 'Hits@5': 0.6950807360120165, 'Hits@10': 0.6958317686819376}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4fr1Ai3dKC0"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wf2xQ80ydKC0",
        "outputId": "5e773f22-fa8f-4996-b56b-26cc095b250a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-100 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_cosine_MLPencoded.tsv\n",
            "⏱️ Execution time: 17.43 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_annoy_cosine_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqvvDOG6dKC0",
        "outputId": "d5360775-2192-490c-d1b3-24ea1d474c61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_cosine_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1325\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6648, 'Recall': 0.6429, 'F1': 0.6537}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_annoy_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEzAyj4odKC1",
        "outputId": "a9a3fb5f-41de-4741-b3fa-f7708eab1856"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 975112 rows\n",
            "✅ After removing ignored classes: 975112 rows\n",
            "✅ After keeping only test SrcEntities: 228788 rows\n",
            "✅ After applying threshold ≥ 0.0: 228788 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_cosine_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2615 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_cosine_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1668\n",
            "📊 Evaluation (P / R / F1): {'P': 0.638, 'R': 0.626, 'F1': 0.632}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_annoy_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d6paONSdKC1",
        "outputId": "c4c2cdc1-cbc8-4527-b79f-e3e59dc64379"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6616, 'Recall@1': 0.6181, 'F1@1': 0.6391}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_annoy_cosine_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEg1nEqCdKC1",
        "outputId": "5be8ff54-f7f1-4acb-f7a7-7c6c2be71f3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-100 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_cosine_mrr_hit_MLPencoded.tsv\n",
            "⏱️ Execution time: 6.56 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_annoy_cosine_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuLO7dZEdKC1"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_annoy_cosine_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdpOprDYdKC1",
        "outputId": "1325de9d-a4e3-416b-82f4-35fbf6f78ce9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.7748548094147608, 'Hits@1': 0.7405182125422456, 'Hits@5': 0.8069846038302666, 'Hits@10': 0.8081111528351483}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NhR9J3fdKC1"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49oJ7NtLdKC1",
        "outputId": "533053f0-8925-44af-b33e-f4c3acd7bb28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-200 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_cosine_MLPencoded.tsv\n",
            "⏱️ Execution time: 28.71 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using cosine distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_annoy_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_annoy_cosine_MLPencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8bdfsf0dKC1",
        "outputId": "8e4678ca-bfbf-4650-e378-4af44b13b84d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_cosine_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1376\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6904, 'Recall': 0.6676, 'F1': 0.6788}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_annoy_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzGXe-YqdKC1",
        "outputId": "3ffcc26d-fdce-4a6a-ea5b-7ed59af24a10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1957903 rows\n",
            "✅ After removing ignored classes: 1957903 rows\n",
            "✅ After keeping only test SrcEntities: 459927 rows\n",
            "✅ After applying threshold ≥ 0.0: 459927 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_cosine_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2613 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_cosine_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1739\n",
            "📊 Evaluation (P / R / F1): {'P': 0.666, 'R': 0.653, 'F1': 0.659}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_annoy_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8TCzB8bdKC2",
        "outputId": "d492b028-aa4f-40f5-b280-f5b84bebfdc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6885, 'Recall@1': 0.6433, 'F1@1': 0.6651}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_annoy_cosine_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehCursgFdKC2",
        "outputId": "de76ba08-85ce-4c22-fbf4-4f605baf7d04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-200 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_cosine_mrr_hit_MLPencoded.tsv\n",
            "⏱️ Execution time: 10.23 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_annoy_cosine_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4QiwFPkdKC2"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_annoy_cosine_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKvABDdhdKC2",
        "outputId": "915c4c8f-712d-440a-a04a-2028efc662d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8375040146871465, 'Hits@1': 0.7994742771310552, 'Hits@5': 0.8794592564776568, 'Hits@10': 0.8832144198272625}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3V4s-eMdKC2"
      },
      "source": [
        "# **LinearEncoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBmKOzT9dKC2",
        "outputId": "f91110e7-35db-4af5-a505-bbd8a31ea09c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = LinearEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugxO4VoIdKC2",
        "outputId": "cd0966f0-8e4c-457e-90cc-9d48da14f259"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzZKIMpMdKC2",
        "outputId": "5c7547ae-ef7e-4c3b-cfd9-c046cbd6d78d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_cands_with_embeddings_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6ZW5JK1dKC2",
        "outputId": "f571ed96-777e-4044-edb2-19183869d705"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_cands_with_embeddings_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pQPO6AXdKC2"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pp2EM579dKC3",
        "outputId": "7f889c51-f57a-4871-90f6-7c2e7f8e598a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-1 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_cosine_Linencoded.tsv\n",
            "⏱️ Execution time: 6.58 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_annoy_cosine_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUdt0c8-dKC3",
        "outputId": "9bc30a52-234b-440a-d783-551cb3ba5ff4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_cosine_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1210\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6071, 'Recall': 0.5871, 'F1': 0.5969}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_annoy_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nV-dtn0dKC3",
        "outputId": "37c4bd6b-0e4d-4d96-bd36-bcae45b81f59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9590 rows\n",
            "✅ After removing ignored classes: 9590 rows\n",
            "✅ After keeping only test SrcEntities: 2363 rows\n",
            "✅ After applying threshold ≥ 0.0: 2363 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_cosine_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2363 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_cosine_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1481\n",
            "📊 Evaluation (P / R / F1): {'P': 0.627, 'R': 0.556, 'F1': 0.589}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_annoy_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XIXjw1hdKC3",
        "outputId": "712e3cbb-bc8a-4f41-c251-891cd335eb2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6267, 'Recall@1': 0.5854, 'F1@1': 0.6054}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_annoy_cosine_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPybLhFmdKC3",
        "outputId": "20f302e8-2142-4afa-f160-8e027622fc50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-1 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_cosine_mrr_hit_Linencoded.tsv\n",
            "⏱️ Execution time: 4.14 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_cosine_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37c1Cly4dKC3"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_annoy_cosine_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FULjqPl9dKC3",
        "outputId": "bcdb43b7-f7c1-4355-8bc0-e02db30479f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.5607834722322942, 'Hits@1': 0.5475028163725122, 'Hits@5': 0.5475028163725122, 'Hits@10': 0.5475028163725122}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mG9me4zpdKC3"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igKDO64TdKC4",
        "outputId": "2339e3bf-1780-4254-8493-63a385f244f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-10 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_cosine_Linencoded.tsv\n",
            "⏱️ Execution time: 7.57 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_annoy_cosine_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iTrVrxYdKC4",
        "outputId": "ec92ecf1-6b9b-43a6-e48c-5712345214f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_cosine_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1210\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6071, 'Recall': 0.5871, 'F1': 0.5969}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_annoy_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QScxuhZDdKC4",
        "outputId": "3d49e846-5fc1-483b-f1a1-31479d38c012"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 96810 rows\n",
            "✅ After removing ignored classes: 96810 rows\n",
            "✅ After keeping only test SrcEntities: 22650 rows\n",
            "✅ After applying threshold ≥ 0.0: 22650 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_cosine_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2596 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_cosine_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1524\n",
            "📊 Evaluation (P / R / F1): {'P': 0.587, 'R': 0.572, 'F1': 0.58}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_annoy_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0cBS1pydKC4",
        "outputId": "f3799f60-9a7c-4214-afcb-86d37d1e45d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6077, 'Recall@1': 0.5678, 'F1@1': 0.5871}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_annoy_cosine_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYsApw7RdKC4",
        "outputId": "505fb565-7fdd-46aa-8202-40ac6db8bd54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-10 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_cosine_mrr_hit_Linencoded.tsv\n",
            "⏱️ Execution time: 4.33 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_annoy_cosine_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hs9TE0szdKC4"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_annoy_cosine_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkdEX8sxdKC4",
        "outputId": "6d7417ba-f18c-43b9-f883-d79234375468"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6815111781374843, 'Hits@1': 0.6541494555013143, 'Hits@5': 0.6935786706721743, 'Hits@10': 0.6935786706721743}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrQAtGR6dKC4"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkTwJqdadKC4",
        "outputId": "0c9c297b-7273-41d1-b6eb-406e59c31a12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-30 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_cosine_Linencoded.tsv\n",
            "⏱️ Execution time: 9.29 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using annoy_cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the annoy_cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_annoy_cosine_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGBynRgsdKC4",
        "outputId": "ca9ac465-0f1d-4b54-fa34-5bbb96e73c53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_cosine_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1217\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6106, 'Recall': 0.5905, 'F1': 0.6004}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_annoy_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pW3QUn9YdKC5",
        "outputId": "7ebe4939-537f-432b-f871-b462837bb2ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 291570 rows\n",
            "✅ After removing ignored classes: 291570 rows\n",
            "✅ After keeping only test SrcEntities: 68047 rows\n",
            "✅ After applying threshold ≥ 0.0: 68047 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_cosine_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2596 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_cosine_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1532\n",
            "📊 Evaluation (P / R / F1): {'P': 0.59, 'R': 0.575, 'F1': 0.583}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_annoy_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_HEmXiKdKC5",
        "outputId": "76579423-fafc-4467-a35f-5f84f4a2a74d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6105, 'Recall@1': 0.5704, 'F1@1': 0.5898}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_annoy_cosine_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pBQgdK7dKC5",
        "outputId": "4d57b792-9e6f-49ff-b48e-c15a18c130eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-30 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_cosine_mrr_hit_Linencoded.tsv\n",
            "⏱️ Execution time: 5.44 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_annoy_cosine_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59tW8QERdKC5"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_annoy_cosine_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao8XA8hBdKC5",
        "outputId": "14ff38ea-9012-4384-b4c9-ecb63a5b6b18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6890210675998, 'Hits@1': 0.6594066841907623, 'Hits@5': 0.7055951933909125, 'Hits@10': 0.7055951933909125}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nstvtWpdKC5"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQheAXOhdKC5",
        "outputId": "9457f426-fcbe-4ba6-9ecb-0641ab2f1d4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-100 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_cosine_Linencoded.tsv\n",
            "⏱️ Execution time: 17.00 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using annoy_cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the annoy_cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_annoy_cosine_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMMz3zEndKC5",
        "outputId": "ae54cc97-b7e3-4079-dd6a-85ff28df1ed1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_cosine_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1323\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6638, 'Recall': 0.6419, 'F1': 0.6527}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_annoy_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4Q0c2_wdKC5",
        "outputId": "1f1ab447-8232-4679-a5c5-2f4f7a640217"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 977457 rows\n",
            "✅ After removing ignored classes: 977457 rows\n",
            "✅ After keeping only test SrcEntities: 228604 rows\n",
            "✅ After applying threshold ≥ 0.0: 228604 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_cosine_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2584 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_cosine_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1672\n",
            "📊 Evaluation (P / R / F1): {'P': 0.647, 'R': 0.628, 'F1': 0.637}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_annoy_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebstg8pJdKC5",
        "outputId": "24b0a95d-6965-4746-ab1e-13756d43cd3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6652, 'Recall@1': 0.6215, 'F1@1': 0.6426}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_annoy_cosine_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ27RjyadKC6",
        "outputId": "02252f06-2a5f-4053-e559-adbb6cc89660"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-100 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_cosine_mrr_hit_Linencoded.tsv\n",
            "⏱️ Execution time: 6.49 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_annoy_cosine_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCb0Gd-odKC6"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_annoy_cosine_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPFRiQ5rdKC6",
        "outputId": "0d9e0c69-38b3-44dd-d114-45a1bb61d525"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.7729545085769328, 'Hits@1': 0.7393916635373639, 'Hits@5': 0.8017273751408186, 'Hits@10': 0.8021028914757792}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nicn9aBZdKC6"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHCbh4kVdKC6",
        "outputId": "191972d0-d020-45e4-b155-b0afd70c1a24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-200 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_cosine_Linencoded.tsv\n",
            "⏱️ Execution time: 27.70 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using annoy_cosine distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_annoy_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_annoy_cosine_Linencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWfGROQDdKC6",
        "outputId": "10dacc70-fb54-465f-a111-e923469b16ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_cosine_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1381\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6929, 'Recall': 0.6701, 'F1': 0.6813}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_annoy_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR2boWNldKC6",
        "outputId": "9e92fbc2-8441-4c43-9c04-6cc1ae382734"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1961653 rows\n",
            "✅ After removing ignored classes: 1961653 rows\n",
            "✅ After keeping only test SrcEntities: 459654 rows\n",
            "✅ After applying threshold ≥ 0.0: 459654 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_cosine_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2583 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_cosine_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1745\n",
            "📊 Evaluation (P / R / F1): {'P': 0.676, 'R': 0.655, 'F1': 0.665}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_annoy_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRGNQQ_sdKC6",
        "outputId": "188d8125-01af-483d-c39f-7f11b333ebe9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6933, 'Recall@1': 0.6478, 'F1@1': 0.6698}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_annoy_cosine_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTAhDoF4dKC6",
        "outputId": "077c658b-4d61-4deb-952f-97b918f79f29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-200 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_cosine_mrr_hit_Linencoded.tsv\n",
            "⏱️ Execution time: 9.58 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on annoy_cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_annoy_cosine_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6Rn39MjdKC6"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_annoy_cosine_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "570pu0jddKC6",
        "outputId": "0e122dbe-1223-4133-bb7b-6e1ac7f3088d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8252375117786712, 'Hits@1': 0.7874577544123169, 'Hits@5': 0.8633120540743522, 'Hits@10': 0.8648141194141945}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKmun2GVdKC7"
      },
      "source": [
        "# **Transformer Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5nYEvLKdKC7",
        "outputId": "3dd9d8e2-312a-4886-c191-4a17f1d674e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = TransformerEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp7gOd7PdKC7",
        "outputId": "52d3a357-b8be-4c64-debe-28478cdb4d96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1l0jbWn_dKC7",
        "outputId": "055bfd6f-2976-4f38-9c4c-7440fe188630"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_cands_with_embeddings_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7BblULBdKC7",
        "outputId": "65ffe886-80cf-4405-dbcd-4e5ee6047053"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_cands_with_embeddings_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ds3H1ocdKC7"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BS2QQWetdKC7",
        "outputId": "36d2561a-b6a5-428a-d06c-48b7b86dedbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-1 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_cosine_TRencoded.tsv\n",
            "⏱️ Execution time: 6.51 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_annoy_cosine_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj26Ro2VdKC7",
        "outputId": "b5a648e2-5b67-4db3-8c69-91ff81cdd0af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_cosine_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1202\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6031, 'Recall': 0.5832, 'F1': 0.593}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_annoy_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kcg-F6DtdKC7",
        "outputId": "f8ad16a4-af96-4310-9353-9d790bd5279b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9566 rows\n",
            "✅ After removing ignored classes: 9566 rows\n",
            "✅ After keeping only test SrcEntities: 2382 rows\n",
            "✅ After applying threshold ≥ 0.0: 2382 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_cosine_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2382 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_cosine_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1476\n",
            "📊 Evaluation (P / R / F1): {'P': 0.62, 'R': 0.554, 'F1': 0.585}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_annoy_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQFFQA4YdKC7",
        "outputId": "9242e32e-d164-421e-9803-9a1de7cc62b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6196, 'Recall@1': 0.5793, 'F1@1': 0.5988}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_annoy_cosine_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RW1Zsn_ldKC8",
        "outputId": "1019abfa-894a-49bd-d7be-24d9fee8231e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-1 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_annoy_cosine_mrr_hit_TRencoded.tsv\n",
            "⏱️ Execution time: 3.82 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_annoy_cosine_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmeSjPPSdKC8"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_annoy_cosine_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5ZpiypjdKC8",
        "outputId": "d73bc432-1469-4387-85fa-e1747b94a177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.5666121799827623, 'Hits@1': 0.5535110777318814, 'Hits@5': 0.5535110777318814, 'Hits@10': 0.5535110777318814}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAqvEGZNdKC8"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rACgDSKNdKC8",
        "outputId": "f1da9d32-88a4-4e44-ebf2-9d1b2052e840"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-10 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_cosine_TRencoded.tsv\n",
            "⏱️ Execution time: 8.37 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using annoy_cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the annoy_cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_annoy_cosine_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gas91nL7dKC8",
        "outputId": "832e2ac5-130f-49ba-a244-10d56918029b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_cosine_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1202\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6031, 'Recall': 0.5832, 'F1': 0.593}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_annoy_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2QysfRodKC8",
        "outputId": "d6c8dd0d-2b12-4139-ebc9-fc8a66093001"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 96533 rows\n",
            "✅ After removing ignored classes: 96533 rows\n",
            "✅ After keeping only test SrcEntities: 22565 rows\n",
            "✅ After applying threshold ≥ 0.0: 22565 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_cosine_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2596 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_cosine_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1508\n",
            "📊 Evaluation (P / R / F1): {'P': 0.581, 'R': 0.566, 'F1': 0.573}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_annoy_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhX8GQ8KdKC8",
        "outputId": "e5f91e1d-3a59-4e54-8a39-60bffd5a3421"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6029, 'Recall@1': 0.5633, 'F1@1': 0.5824}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_annoy_cosine_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEEbNg5adKC8",
        "outputId": "ed9c9af2-d1d0-4279-b649-f40bb2e3f548"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-10 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_annoy_cosine_mrr_hit_TRencoded.tsv\n",
            "⏱️ Execution time: 4.40 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_annoy_cosine_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X18hg-ZJdKC8"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_annoy_cosine_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8J_Bd5ZdKC9",
        "outputId": "7a26d9cd-986a-469e-edc4-1f430410ea7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6890542329874946, 'Hits@1': 0.6635373638753286, 'Hits@5': 0.6999624483665039, 'Hits@10': 0.6999624483665039}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAU8Vrw5dKC9"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XQBP2iNdKC9",
        "outputId": "f3b79faa-6095-42dd-9336-ef7d4b525d66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-30 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_cosine_TRencoded.tsv\n",
            "⏱️ Execution time: 9.30 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using annoy_cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the annoy_cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_annoy_cosine_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDH1UuBddKC9",
        "outputId": "2c8f03b8-161b-408e-f5ee-898a4ba2c193"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_cosine_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1210\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6071, 'Recall': 0.5871, 'F1': 0.5969}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_annoy_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1P3tM6qdKC9",
        "outputId": "10687374-1bf3-4efa-b409-f38ee9a873cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 290724 rows\n",
            "✅ After removing ignored classes: 290724 rows\n",
            "✅ After keeping only test SrcEntities: 67939 rows\n",
            "✅ After applying threshold ≥ 0.0: 67939 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_cosine_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2592 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_cosine_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1517\n",
            "📊 Evaluation (P / R / F1): {'P': 0.585, 'R': 0.57, 'F1': 0.577}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_annoy_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGvjGCa8dKC9",
        "outputId": "de643df5-9b73-402c-8484-feae7faca52f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6065, 'Recall@1': 0.5667, 'F1@1': 0.5859}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_annoy_cosine_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smO18aMcdKC9",
        "outputId": "05d0c64c-38c5-469e-9190-3606263ad3a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-30 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_annoy_cosine_mrr_hit_TRencoded.tsv\n",
            "⏱️ Execution time: 5.57 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_annoy_cosine_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Wq3-GNydKC9"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_annoy_cosine_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hb5BbG2jdKC9",
        "outputId": "8763c3dc-51e9-4c98-cc8b-d91be0ddf349"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6995934229594335, 'Hits@1': 0.67104769057454, 'Hits@5': 0.7164851671047691, 'Hits@10': 0.7164851671047691}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SC85zOpdKC9"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_pRt-2adKC-",
        "outputId": "2d1c2223-8451-4886-a118-18611de0ab5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-100 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_cosine_TRencoded.tsv\n",
            "⏱️ Execution time: 17.12 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using annoy_cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the annoy_cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_annoy_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_annoy_cosine_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2f5eYUhdKC-",
        "outputId": "b9fc4a66-9b87-4e38-aa04-d0fa39fc36d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_cosine_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1300\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6523, 'Recall': 0.6308, 'F1': 0.6413}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_annoy_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZX354jldKC-",
        "outputId": "64d1d5a6-a98d-4f74-938b-dd2b84688926"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 975472 rows\n",
            "✅ After removing ignored classes: 975472 rows\n",
            "✅ After keeping only test SrcEntities: 228173 rows\n",
            "✅ After applying threshold ≥ 0.0: 228173 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_cosine_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2590 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_cosine_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1641\n",
            "📊 Evaluation (P / R / F1): {'P': 0.634, 'R': 0.616, 'F1': 0.625}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_annoy_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G0MGYLadKC-",
        "outputId": "cc990c69-d28f-4bee-8c2f-7f87c6fb7006"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6559, 'Recall@1': 0.6128, 'F1@1': 0.6337}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_annoy_cosine_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIJU8NGJdKC-",
        "outputId": "60013a8e-b377-41b7-d71a-59902e4e28a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-100 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_annoy_cosine_mrr_hit_TRencoded.tsv\n",
            "⏱️ Execution time: 6.57 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_annoy_cosine_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ewUJLqNdKC-"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_annoy_cosine_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ml6MOlDydKC-",
        "outputId": "8cfc159f-c300-4c6a-f52c-e3639e467871"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.7857644659682671, 'Hits@1': 0.7517837025910628, 'Hits@5': 0.8163725122042809, 'Hits@10': 0.8174990612091626}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEhG90Q8dKC-"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9VbXw6qdKC_",
        "outputId": "5bd191c4-af59-4760-8f5b-07706988db34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-200 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_cosine_TRencoded.tsv\n",
            "⏱️ Execution time: 27.86 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using annoy_cosine distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_annoy_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_annoy_cosine_TRencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ntQLWsudKC_",
        "outputId": "c6dee661-a23e-4dab-b524-b0a24070c4de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_cosine_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1369\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6869, 'Recall': 0.6642, 'F1': 0.6754}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_annoy_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKqo6rV8dKC_",
        "outputId": "a942872e-d1bc-4613-ac8e-59b8f0852813"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1958646 rows\n",
            "✅ After removing ignored classes: 1958646 rows\n",
            "✅ After keeping only test SrcEntities: 458790 rows\n",
            "✅ After applying threshold ≥ 0.0: 458790 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_cosine_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2581 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_cosine_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1728\n",
            "📊 Evaluation (P / R / F1): {'P': 0.67, 'R': 0.649, 'F1': 0.659}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_annoy_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFLeWpBxdKC_",
        "outputId": "0f8f6934-0907-4af5-90ca-369b1291e44f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6893, 'Recall@1': 0.644, 'F1@1': 0.6659}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_annoy_cosine_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qasWnEidKC_",
        "outputId": "8b21c799-9b36-4193-c814-005e2a71d182"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Annoy with metric: angular\n",
            "Top-200 Annoy similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_annoy_cosine_mrr_hit_TRencoded.tsv\n",
            "⏱️ Execution time: 10.18 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_annoy_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_annoy_cosine_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESh1EWridKC_"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_annoy_cosine_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnrhnhsEdKC_",
        "outputId": "e32a21fc-1f4c-4ecb-f8e0-1ac91afe5bc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8358681277218727, 'Hits@1': 0.7983477281261735, 'Hits@5': 0.8753285767930905, 'Hits@10': 0.8775816748028539}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3uoFkIfeBBa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGD6YyDeXQZt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGkwDO7JeBkC"
      },
      "source": [
        "# **Using faiss: topk_faiss_cosine**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8wjsHoXeBkC"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvYHXKIReBkC",
        "outputId": "3ce5af43-7759-46ba-fa77-a4feeaf68e57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-1 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_cosine.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_cosine.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_4YmxV6eBkC",
        "outputId": "a88c2f49-4b20-4731-97e8-73307356b3b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_cosine_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1456\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7306, 'Recall': 0.7065, 'F1': 0.7183}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPtcLDfzeBkC",
        "outputId": "8bef96f9-ac18-4362-e098-735c86d2725c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9455 rows\n",
            "✅ After removing ignored classes: 9455 rows\n",
            "✅ After keeping only test SrcEntities: 2398 rows\n",
            "✅ After applying threshold ≥ 0.0: 2398 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_cosine_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2398 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_cosine_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1776\n",
            "📊 Evaluation (P / R / F1): {'P': 0.741, 'R': 0.667, 'F1': 0.702}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5AUmf0deBkD",
        "outputId": "92e7df29-f6a6-461c-d3e4-3b82e95f1145"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7406, 'Recall@1': 0.6929, 'F1@1': 0.716}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/neoplas_top_1_mappings_faiss_cosine_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9Hw4-DKeBkD",
        "outputId": "e08fcd92-564a-4988-ca8d-1b0d20ff0c75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-1 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_cosine_mrr_hit.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_cosine_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PlhLBS0geBkD"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_faiss_cosine_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDPovaMpeBkD",
        "outputId": "44947141-88dd-414c-9072-426e5ee65c2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6766873779177401, 'Hits@1': 0.6669170108899737, 'Hits@5': 0.6669170108899737, 'Hits@10': 0.6669170108899737}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN7DSkgGeBkD"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9b3pE7neBkD",
        "outputId": "8c5c26b0-b952-4910-cbe4-526cb5e92353"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-10 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_cosine.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_cosine.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWerTqQ7eBkD",
        "outputId": "9669e313-a940-4453-a947-745d8d8350e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_cosine_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1456\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7306, 'Recall': 0.7065, 'F1': 0.7183}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61P4fj6reBkD",
        "outputId": "ee47c902-ee49-4030-ecf3-eec81ed1a3d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 95994 rows\n",
            "✅ After removing ignored classes: 95994 rows\n",
            "✅ After keeping only test SrcEntities: 22625 rows\n",
            "✅ After applying threshold ≥ 0.0: 22625 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_cosine_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2560 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_cosine_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1845\n",
            "📊 Evaluation (P / R / F1): {'P': 0.721, 'R': 0.693, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UE0iiRxeBkD",
        "outputId": "4e65fab5-5e49-4676-b38d-e5b7a0062acf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7315, 'Recall@1': 0.6834, 'F1@1': 0.7067}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_faiss_cosine_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RaRt0RbeBkD",
        "outputId": "d6f9e2f7-b9cf-441a-8862-430ea23163a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-10 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_cosine_mrr_hit.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_cosine_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzTx9ksFeBkE"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_faiss_cosine_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDxfMM2KeBkE",
        "outputId": "3676acee-9eaf-4ecf-d31b-4e71338de834"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.899072574208393, 'Hits@1': 0.8588058580548253, 'Hits@5': 0.9421704844160721, 'Hits@10': 0.9421704844160721}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9AwlQ39eBkE"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_wVfQZceBkE",
        "outputId": "da7d54fc-28a2-400c-a80e-9781af44e27e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-30 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_cosine.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_cosine.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbunIQjoeBkE",
        "outputId": "534be6a7-1106-43e4-86e0-7f28cc408d4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_cosine_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1456\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7306, 'Recall': 0.7065, 'F1': 0.7183}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWnJJX6CeBkE",
        "outputId": "2aba6012-e6ff-4d43-8a5a-9fe070ce2956"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 290963 rows\n",
            "✅ After removing ignored classes: 290963 rows\n",
            "✅ After keeping only test SrcEntities: 68393 rows\n",
            "✅ After applying threshold ≥ 0.0: 68393 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_cosine_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2560 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_cosine_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1845\n",
            "📊 Evaluation (P / R / F1): {'P': 0.721, 'R': 0.693, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jorhwy13eBkE",
        "outputId": "dbbcefca-2d53-495d-fccc-6de213af06ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7315, 'Recall@1': 0.6834, 'F1@1': 0.7067}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_faiss_cosine_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ3HEdVReBkE",
        "outputId": "75fb16d4-6f88-4698-fa60-c550c10a572f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-30 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_cosine_mrr_hit.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_cosine_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1okyVKe3eBkE"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_faiss_cosine_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qir7tUypeBkE",
        "outputId": "73e2937e-f1c7-4d20-b3f5-49e2076f4e4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9166463442993463, 'Hits@1': 0.8689447990987608, 'Hits@5': 0.9733383402177995, 'Hits@10': 0.9767179872324446}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6NSohz6eBkF"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZCaZxQBeBkF",
        "outputId": "73d25c56-916b-4aeb-e518-290b5e2dcb4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-100 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_cosine.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_cosine.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMIv-d0XeBkF",
        "outputId": "0e8f2344-0563-42d3-d273-0b174de95970"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_cosine_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1456\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7306, 'Recall': 0.7065, 'F1': 0.7183}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tvxKlhTeBkF",
        "outputId": "741414e9-17af-438b-fa1f-dbc0cd43e80f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 979790 rows\n",
            "✅ After removing ignored classes: 979790 rows\n",
            "✅ After keeping only test SrcEntities: 230431 rows\n",
            "✅ After applying threshold ≥ 0.0: 230431 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_cosine_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2560 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_cosine_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1845\n",
            "📊 Evaluation (P / R / F1): {'P': 0.721, 'R': 0.693, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sn0EcWhFeBkF",
        "outputId": "6005a0cd-aa39-46e9-ef62-ddaedef0bc53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7315, 'Recall@1': 0.6834, 'F1@1': 0.7067}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_faiss_cosine_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIQq8iG5eBkF",
        "outputId": "088050b3-1b4f-4014-c5b5-5041e729155b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-100 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_cosine_mrr_hit.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_cosine_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuJLnw_8eBkF"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_faiss_cosine_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lM_5hKTzeBkF",
        "outputId": "388de0cb-01d2-4385-a42e-bf95c8f75cc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9213368575296516, 'Hits@1': 0.8700713481036425, 'Hits@5': 0.9846038302666166, 'Hits@10': 0.992114156965828}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEW8yetXeBkF"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1knvg7GeBkF",
        "outputId": "769399ca-b76d-4062-be41-56466c022a61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-200 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_cosine.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_cosine.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCaSsriXeBkG",
        "outputId": "404786dd-e243-499f-ed8f-b7255eca3590"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_cosine_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1456\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7306, 'Recall': 0.7065, 'F1': 0.7183}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TG2e2EkMeBkG",
        "outputId": "c6d3c552-ab81-430d-ddb7-552945539133"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1967850 rows\n",
            "✅ After removing ignored classes: 1967850 rows\n",
            "✅ After keeping only test SrcEntities: 462857 rows\n",
            "✅ After applying threshold ≥ 0.0: 462857 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_cosine_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2560 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_cosine_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1845\n",
            "📊 Evaluation (P / R / F1): {'P': 0.721, 'R': 0.693, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N7hqI1ZeBkG",
        "outputId": "c6aa166c-ed03-4a2d-e04c-d507ac0d8559"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7315, 'Recall@1': 0.6834, 'F1@1': 0.7067}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_faiss_cosine_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o91rjdloeBkG",
        "outputId": "7e4fb06c-415c-4bbc-8291-0148b77aa08b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-200 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_cosine_mrr_hit.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_cosine_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZwrTdPWeBkG"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_faiss_cosine_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkWEk3YIeBkG",
        "outputId": "6363f770-98d0-4ae2-e192-6068d96f9bf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9218645742472368, 'Hits@1': 0.8700713481036425, 'Hits@5': 0.9857303792714983, 'Hits@10': 0.9936162223056703}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unaeNtpxeBkG"
      },
      "source": [
        "# **K=500**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YEVZj4XeBkG",
        "outputId": "55fe139e-8377-465e-afa6-4d1e39a132f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-500 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_faiss_cosine.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=500,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_500_mappings_faiss_cosine.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ4jA7IzeBkG",
        "outputId": "a77769c1-04e3-445c-ac98-6c85f81b6ce1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 5703500 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 996500 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_faiss_cosine_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1456\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7306, 'Recall': 0.7065, 'F1': 0.7183}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_500_mappings_faiss_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgNEwFhheBkG",
        "outputId": "d0ad671e-771f-4de0-a268-91063f1cb45a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 5703500 rows\n",
            "✅ After removing train-only URIs: 4943894 rows\n",
            "✅ After removing ignored classes: 4943894 rows\n",
            "✅ After keeping only test SrcEntities: 1164359 rows\n",
            "✅ After applying threshold ≥ 0.0: 1164359 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_faiss_cosine_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2560 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_faiss_cosine_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1845\n",
            "📊 Evaluation (P / R / F1): {'P': 0.721, 'R': 0.693, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_500_mappings_faiss_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22Z9s_3ceBkH",
        "outputId": "88c1dad2-f2e8-4e7b-e4b6-0685d00d62fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7315, 'Recall@1': 0.6834, 'F1@1': 0.7067}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_500_mappings_faiss_cosine_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xC3tkSYReBkH",
        "outputId": "4c901f8c-64a1-4965-a308-a9c1063fe127"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-500 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_faiss_cosine_mrr_hit.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=500,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_500_mappings_faiss_cosine_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tJU7F-ReBkH"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_500_mappings_faiss_cosine_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCVke4XbeBkH",
        "outputId": "13569f8f-30e8-4d8e-caf0-71118b7e44c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9223080312033205, 'Hits@1': 0.8700713481036425, 'Hits@5': 0.98685692827638, 'Hits@10': 0.9951182876455126}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFGo8Bu-eBkH"
      },
      "source": [
        "# **K=1000**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9UnL2uQeBkH",
        "outputId": "84422732-686c-4f9b-bdca-f05ba3ea55ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-1000 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_faiss_cosine.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1000,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1000_mappings_faiss_cosine.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpLF7lJ2eBkH",
        "outputId": "a4711fa9-f89d-4d51-cebf-980e37bef1bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407000 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993000 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_faiss_cosine_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1456\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7306, 'Recall': 0.7065, 'F1': 0.7183}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1000_mappings_faiss_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBz5HkideBkH",
        "outputId": "5adddfbf-fd27-465a-e49f-dddad4fffdf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407000 rows\n",
            "✅ After removing train-only URIs: 9925625 rows\n",
            "✅ After removing ignored classes: 9925625 rows\n",
            "✅ After keeping only test SrcEntities: 2341451 rows\n",
            "✅ After applying threshold ≥ 0.0: 2341451 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_faiss_cosine_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2560 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_faiss_cosine_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1845\n",
            "📊 Evaluation (P / R / F1): {'P': 0.721, 'R': 0.693, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1000_mappings_faiss_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVS9BCMOeBkH",
        "outputId": "31929a98-c65e-4080-85d6-d34a7e38c8bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7315, 'Recall@1': 0.6834, 'F1@1': 0.7067}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1000_mappings_faiss_cosine_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Po_E7xcAeBkH",
        "outputId": "e014abe6-ef9d-4c0c-be61-ef03a675c707"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-1000 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_faiss_cosine_mrr_hit.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1000,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1000_mappings_faiss_cosine_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtLc2KmSeBkI"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1000_mappings_faiss_cosine_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQorQvjKeBkI",
        "outputId": "72128231-102b-40d2-ac78-27e267684feb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9223326529703382, 'Hits@1': 0.8700713481036425, 'Hits@5': 0.98685692827638, 'Hits@10': 0.9954938039804732}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "112k-xV_eBkI"
      },
      "source": [
        "# **K=2000**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k9oi9ldeBkI",
        "outputId": "e67e0c65-5450-45d1-9382-9c71e769c46d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-2000 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_faiss_cosine.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=2000,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_2000_mappings_faiss_cosine.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moejCgyKeBkI",
        "outputId": "6dc437e1-227a-44d2-aea4-45f3b3fa7aaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 22814000 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 3986000 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_faiss_cosine_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1456\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7306, 'Recall': 0.7065, 'F1': 0.7183}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_2000_mappings_faiss_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys4ryPUveBkI",
        "outputId": "4d588675-d6fe-4e1f-8d58-d62ca75ec23f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 22814000 rows\n",
            "✅ After removing train-only URIs: 19917638 rows\n",
            "✅ After removing ignored classes: 19917638 rows\n",
            "✅ After keeping only test SrcEntities: 4707389 rows\n",
            "✅ After applying threshold ≥ 0.0: 4707389 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_faiss_cosine_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2560 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_faiss_cosine_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1845\n",
            "📊 Evaluation (P / R / F1): {'P': 0.721, 'R': 0.693, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_2000_mappings_faiss_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rbhfkDqeBkI",
        "outputId": "dd284d36-3be5-4644-bbf8-0113de8cfe07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7315, 'Recall@1': 0.6834, 'F1@1': 0.7067}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_2000_mappings_faiss_cosine_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wElLd6vieBkI",
        "outputId": "82a82a2f-3f43-4387-985a-5cd7f5d4dd32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-2000 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_faiss_cosine_mrr_hit.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=2000,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_2000_mappings_faiss_cosine_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSMCcWtYeBkI"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_2000_mappings_faiss_cosine_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq3m0KSUeBkI",
        "outputId": "fcc50a03-d019-43cc-85dc-f70cdaf3b9dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9225189724532561, 'Hits@1': 0.8700713481036425, 'Hits@5': 0.98685692827638, 'Hits@10': 0.997371385655276}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVqeYiYkeBkJ"
      },
      "source": [
        "# **With Encoders**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSglBkFleBkJ"
      },
      "source": [
        "# **ResMLPEncoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGx5pIVneBkJ",
        "outputId": "7947d0fa-adee-4946-931d-9ded0f95c94c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = ResMLPEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IS63Jj-2eBkJ",
        "outputId": "c16eafea-8df8-4ebc-87dd-60bf12bea44d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-6D8vbjeBkJ",
        "outputId": "06c18eeb-e354-4f35-a429-acce4bdcdf61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_cands_with_embeddings_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plaHXCeleBkJ",
        "outputId": "6e8f5a2c-b80e-415a-dac9-7a8e7efe5ce4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_cands_with_embeddings_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUPzZWfLeBkJ"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nPzMQFReBkJ",
        "outputId": "3439df0d-b259-4ad7-b121-1df1b33908be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-1 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_cosine_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_cosine_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vG3NuogeBkJ",
        "outputId": "d1891aff-d8fa-4be7-9d27-d15ac3cde3d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_cosine_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1457\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7311, 'Recall': 0.7069, 'F1': 0.7188}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhiQXseIeBkJ",
        "outputId": "62190230-a48b-4f8f-a302-ac743be30618"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9457 rows\n",
            "✅ After removing ignored classes: 9457 rows\n",
            "✅ After keeping only test SrcEntities: 2399 rows\n",
            "✅ After applying threshold ≥ 0.0: 2399 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_cosine_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2399 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_cosine_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1776\n",
            "📊 Evaluation (P / R / F1): {'P': 0.74, 'R': 0.667, 'F1': 0.702}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kg_XPo3UeBkJ",
        "outputId": "8c53a015-56fb-401f-a0e1-84233bd56372"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7403, 'Recall@1': 0.6921, 'F1@1': 0.7154}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_faiss_cosine_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlJCoM2CeBkK",
        "outputId": "a272f90c-12de-4998-d35c-b02ac36e1ab6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-1 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_cosine_mrr_hit_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_cosine_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJW5KvbJeBkK"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_faiss_cosine_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUxC5dxJeBkK",
        "outputId": "ca9602da-9007-44a4-eb13-2725778a1ecc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6766873779177401, 'Hits@1': 0.6669170108899737, 'Hits@5': 0.6669170108899737, 'Hits@10': 0.6669170108899737}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccx6N26veBkK"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSQosoTOeBkK",
        "outputId": "3eb9e2b6-47a0-4ee7-d5d3-b0c035207cf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-10 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_cosine_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_cosine_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bpV9gAteBkK",
        "outputId": "66f01d14-b3f6-4efd-ff72-25c141761ede"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_cosine_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1457\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7311, 'Recall': 0.7069, 'F1': 0.7188}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2s-HDfteBkK",
        "outputId": "c960b3c7-6b89-4c6d-dadb-240d3f32ecaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 95948 rows\n",
            "✅ After removing ignored classes: 95948 rows\n",
            "✅ After keeping only test SrcEntities: 22620 rows\n",
            "✅ After applying threshold ≥ 0.0: 22620 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_cosine_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2564 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_cosine_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1844\n",
            "📊 Evaluation (P / R / F1): {'P': 0.719, 'R': 0.692, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3Bmyl5eeBkK",
        "outputId": "572f0d52-5ca6-44d4-9c20-abbe8d7313aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7303, 'Recall@1': 0.6823, 'F1@1': 0.7055}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_faiss_cosine_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMMVcCW4eBkK",
        "outputId": "6595a773-535d-4931-a6fe-2fb01fea8127"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-10 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_cosine_mrr_hit_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_cosine_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ca9RFRdXeBkK"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_faiss_cosine_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pv07vLiWeBkL",
        "outputId": "cc76c0ee-edcf-4aa0-f03a-b4dc9c5cce29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8990013817999427, 'Hits@1': 0.8595568907247465, 'Hits@5': 0.9414194517461509, 'Hits@10': 0.9414194517461509}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrk3h-FPeBkL"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVPoYZzceBkL",
        "outputId": "b6449bcb-3577-413b-8593-e7eac34a5cbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-30 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_cosine_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_cosine_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8s2KmpqeBkL",
        "outputId": "f80e3468-a503-4f8c-a27a-78839f2024e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_cosine_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1457\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7311, 'Recall': 0.7069, 'F1': 0.7188}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9ZQM1YxeBkL",
        "outputId": "ebab74a0-f3b0-420b-e471-ed2183553777"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 291017 rows\n",
            "✅ After removing ignored classes: 291017 rows\n",
            "✅ After keeping only test SrcEntities: 68440 rows\n",
            "✅ After applying threshold ≥ 0.0: 68440 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_cosine_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2564 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_cosine_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1844\n",
            "📊 Evaluation (P / R / F1): {'P': 0.719, 'R': 0.692, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "galFQdXkeBkL",
        "outputId": "4e84688f-626b-40bc-d6ff-065fe67ad894"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7303, 'Recall@1': 0.6823, 'F1@1': 0.7055}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_faiss_cosine_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRb-QuCPeBkL",
        "outputId": "8c394e0d-37ad-428e-d4b1-4073a458ea73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-30 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_cosine_mrr_hit_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_cosine_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76578WOgeBkL"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_faiss_cosine_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vO9oCnlHeBkL",
        "outputId": "698d81ea-fc5c-4a54-b188-68b4b7cdc49e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9169714140545961, 'Hits@1': 0.8704468644386031, 'Hits@5': 0.9725873075478784, 'Hits@10': 0.9752159218926023}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQf0uwVHeBkL"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVUB1WGGeBkM",
        "outputId": "46add8ce-cbb4-4108-a81e-fcdbb40dd979"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-100 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_cosine_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_cosine_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyuVnJLkeBkM",
        "outputId": "e529911b-67d9-4766-f210-4f480981109d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_cosine_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1457\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7311, 'Recall': 0.7069, 'F1': 0.7188}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZNODM1eeBkM",
        "outputId": "b45382f7-f8d3-4185-e1c3-62f4bd4fbbd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 979502 rows\n",
            "✅ After removing ignored classes: 979502 rows\n",
            "✅ After keeping only test SrcEntities: 230342 rows\n",
            "✅ After applying threshold ≥ 0.0: 230342 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_cosine_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2564 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_cosine_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1844\n",
            "📊 Evaluation (P / R / F1): {'P': 0.719, 'R': 0.692, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prTu5F9KeBkM",
        "outputId": "82e14fdd-0bc8-48de-8e55-3c03496b7ad4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7303, 'Recall@1': 0.6823, 'F1@1': 0.7055}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_faiss_cosine_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkahIaZdeBkM",
        "outputId": "e518ce68-7d76-413f-e066-f5fa96d206e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-100 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_cosine_mrr_hit_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_cosine_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNgm21IueBkM"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_faiss_cosine_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyNqttsCeBkM",
        "outputId": "e9144560-ca3e-493d-b505-5867bef089bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9225781361522407, 'Hits@1': 0.872324446113406, 'Hits@5': 0.9846038302666166, 'Hits@10': 0.9913631242959069}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ftt8D5ZeBkM"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aE7cxnwZeBkM",
        "outputId": "f846d7a4-5990-4038-ee03-d0908c36ec6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-200 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_cosine_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using cosine distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_faiss_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_cosine_ResMLPencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGmkesWMeBkM",
        "outputId": "ae615cd5-9be4-48eb-b162-44008875ee28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_cosine_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1457\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7311, 'Recall': 0.7069, 'F1': 0.7188}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9ZCVv_beBkN",
        "outputId": "de296995-ec42-4f7a-ea14-ad66bb334b1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1967499 rows\n",
            "✅ After removing ignored classes: 1967499 rows\n",
            "✅ After keeping only test SrcEntities: 462786 rows\n",
            "✅ After applying threshold ≥ 0.0: 462786 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_cosine_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2564 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_cosine_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1844\n",
            "📊 Evaluation (P / R / F1): {'P': 0.719, 'R': 0.692, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmcQkJXveBkN",
        "outputId": "03bcfb78-a4d9-4610-a4b2-23a17637caee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7303, 'Recall@1': 0.6823, 'F1@1': 0.7055}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_faiss_cosine_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH9RepwYeBkN",
        "outputId": "10c9eef9-114f-43c2-ab94-59042c9ea2b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-200 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_cosine_mrr_hit_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_cosine_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvKdInf5eBkN"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_faiss_cosine_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIdDOpEUeBkN",
        "outputId": "90b6d38c-300a-4461-ad1f-a20c0f05c270"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9230419870959452, 'Hits@1': 0.872324446113406, 'Hits@5': 0.9853548629365377, 'Hits@10': 0.9928651896357491}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnQ9MDZieBkN"
      },
      "source": [
        "# **MLPEncoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnII0u5EeBkN",
        "outputId": "346ad431-2e1a-4cef-9637-5002ae945290"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = MLPEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7ANVsuYeBkN",
        "outputId": "9fa5f2c8-92f0-4df1-b4de-c4638d7be641"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBzH9SSAeBkN",
        "outputId": "f7468bf7-b7c7-4b4b-d68b-914299f7ff5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_cands_with_embeddings_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j07NA2pYeBkO",
        "outputId": "edda98ec-4200-4e51-b2c5-9906fdde085d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_cands_with_embeddings_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6cPi_E-eBkO"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2lwihuqeBkO",
        "outputId": "5fb765f6-4372-4ff4-d68a-8b945b55393d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-1 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_cosine_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_cosine_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4T9xQHVeBkO",
        "outputId": "b907e3bc-440b-42a0-e234-b76040aa1203"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_cosine_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1445\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.725, 'Recall': 0.7011, 'F1': 0.7129}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMM4c28aeBkO",
        "outputId": "06142c5e-6754-402a-f15c-ea63b08036ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9518 rows\n",
            "✅ After removing ignored classes: 9518 rows\n",
            "✅ After keeping only test SrcEntities: 2401 rows\n",
            "✅ After applying threshold ≥ 0.0: 2401 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_cosine_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2401 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_cosine_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1762\n",
            "📊 Evaluation (P / R / F1): {'P': 0.734, 'R': 0.662, 'F1': 0.696}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVekyp5xeBkO",
        "outputId": "17eabc9c-2f47-46a3-effb-2bf0422460c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7339, 'Recall@1': 0.6869, 'F1@1': 0.7096}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_faiss_cosine_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdzGxG2AeBkO",
        "outputId": "6d847a7a-0902-4cce-9923-e8788a7600e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-1 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_cosine_mrr_hit_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_cosine_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XJx5q08eBkO"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_faiss_cosine_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4-mOpLHeBkO",
        "outputId": "17b93593-da02-4089-ee2f-acf6063d4406"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6715860358412924, 'Hits@1': 0.6616597822005257, 'Hits@5': 0.6616597822005257, 'Hits@10': 0.6616597822005257}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syI0btZKeBkO"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKX8g0o_eBkO",
        "outputId": "b3bf4185-26cf-4f4c-9d67-54c51b2ec5f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-10 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_cosine_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_cosine_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvL0NdWmeBkO",
        "outputId": "46e2d05c-b442-4d3b-b14d-55d231951430"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_cosine_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1445\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.725, 'Recall': 0.7011, 'F1': 0.7129}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsgYED4NeBkP",
        "outputId": "cfd12467-bfb8-4ea1-9e4b-5526a64825cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 95954 rows\n",
            "✅ After removing ignored classes: 95954 rows\n",
            "✅ After keeping only test SrcEntities: 22647 rows\n",
            "✅ After applying threshold ≥ 0.0: 22647 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_cosine_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2596 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_cosine_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1835\n",
            "📊 Evaluation (P / R / F1): {'P': 0.707, 'R': 0.689, 'F1': 0.698}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDKbex1FeBkP",
        "outputId": "00d30b67-5c86-422a-ceec-6f2666e29d4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7247, 'Recall@1': 0.6771, 'F1@1': 0.7001}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_faiss_cosine_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN9yTdqteBkP",
        "outputId": "c139bb79-e5b3-40fa-9599-baa18b84fab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-10 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_cosine_mrr_hit_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_cosine_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPqoWpaaeBkP"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_faiss_cosine_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE-2WfKieBkP",
        "outputId": "6eefc71f-24cf-4254-c132-d23cf660c0ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8990013817999427, 'Hits@1': 0.8595568907247465, 'Hits@5': 0.9414194517461509, 'Hits@10': 0.9414194517461509}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_yk8v_peBkR"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcVIhfAfeBkS",
        "outputId": "db6f62e3-0bd1-4284-d7fc-78b26cd96c76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-30 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_cosine_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_cosine_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loWvf-kYeBkS",
        "outputId": "e1154cc3-2e39-45d9-b02b-99f059aa80fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_cosine_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1445\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.725, 'Recall': 0.7011, 'F1': 0.7129}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcH_9x5aeBkS",
        "outputId": "baa765ec-7da8-49fc-d50f-649334eba07a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 290775 rows\n",
            "✅ After removing ignored classes: 290775 rows\n",
            "✅ After keeping only test SrcEntities: 68428 rows\n",
            "✅ After applying threshold ≥ 0.0: 68428 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_cosine_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2596 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_cosine_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1835\n",
            "📊 Evaluation (P / R / F1): {'P': 0.707, 'R': 0.689, 'F1': 0.698}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3cUrdVeeBkS",
        "outputId": "5bc1bb90-986c-42f6-c0ea-174ddd4162d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7247, 'Recall@1': 0.6771, 'F1@1': 0.7001}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_faiss_cosine_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1x0_H-7eBkS",
        "outputId": "d242b384-aeb1-4eaf-80a6-5a5928e387a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-30 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_cosine_mrr_hit_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_cosine_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXGZJifUeBkS"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_faiss_cosine_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXewIEw_eBkS",
        "outputId": "aa059ea0-cb07-424f-8eeb-6cb9224a3aa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9086804193020087, 'Hits@1': 0.8621855050694706, 'Hits@5': 0.9650769808486669, 'Hits@10': 0.9677055951933909}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUX0P793eBkT"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-unF63h-eBkT",
        "outputId": "59e2914f-619c-4fb0-a2c8-b6efec0e9d87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-100 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_cosine_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_cosine_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQFyi7PjeBkT",
        "outputId": "436cf2e2-423d-4030-e96b-9eca708127ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_cosine_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1445\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.725, 'Recall': 0.7011, 'F1': 0.7129}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bsxJDLUeBkT",
        "outputId": "78d8cf94-94b3-404f-c8d1-157154f33649"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 978050 rows\n",
            "✅ After removing ignored classes: 978050 rows\n",
            "✅ After keeping only test SrcEntities: 230444 rows\n",
            "✅ After applying threshold ≥ 0.0: 230444 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_cosine_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2596 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_cosine_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1835\n",
            "📊 Evaluation (P / R / F1): {'P': 0.707, 'R': 0.689, 'F1': 0.698}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciPBuEGZeBkT",
        "outputId": "7e128a08-72e2-47f7-ea00-e27596dc5306"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7247, 'Recall@1': 0.6771, 'F1@1': 0.7001}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_faiss_cosine_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rNO_VM1eBkT",
        "outputId": "5dc72422-80bc-433e-f6f8-dbfb88e02941"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-100 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_cosine_mrr_hit_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_cosine_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbp4rTMneBkT"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_faiss_cosine_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puiy_LeeeBkT",
        "outputId": "28254f66-fec0-47e0-e9c5-ac598f641aec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9143861821360183, 'Hits@1': 0.8633120540743522, 'Hits@5': 0.9774690199023658, 'Hits@10': 0.9864814119414195}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g_-0CdieBkT"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNk4CrgmeBkT",
        "outputId": "6bc4989a-1a41-4fb8-8cf7-1fdcfbc61984"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-200 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_cosine_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using cosine distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_faiss_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_cosine_MLPencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9El-Z_IeBkT",
        "outputId": "b3480511-996b-41f9-d2c5-cfb949ab2d46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_cosine_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1445\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.725, 'Recall': 0.7011, 'F1': 0.7129}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKA8lktUeBkT",
        "outputId": "31e64003-f293-45ba-af5b-61837ad25410"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1964463 rows\n",
            "✅ After removing ignored classes: 1964463 rows\n",
            "✅ After keeping only test SrcEntities: 462881 rows\n",
            "✅ After applying threshold ≥ 0.0: 462881 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_cosine_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2596 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_cosine_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1835\n",
            "📊 Evaluation (P / R / F1): {'P': 0.707, 'R': 0.689, 'F1': 0.698}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVgqtS61eBkT",
        "outputId": "03679c92-fcf7-42ab-decb-0cebea90ef69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7247, 'Recall@1': 0.6771, 'F1@1': 0.7001}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_faiss_cosine_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vd5ia-nFeBkU",
        "outputId": "3da8e29e-910d-4a8b-c6c0-0d27090a0038"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-200 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_cosine_mrr_hit_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_cosine_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Od0D_KqfeBkU"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_faiss_cosine_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEk0ydkjeBkU",
        "outputId": "b117fad7-4511-48f3-88e6-d86501e98b68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9154687329302721, 'Hits@1': 0.8633120540743522, 'Hits@5': 0.9797221179121292, 'Hits@10': 0.989485542621104}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZqMoRljeBkU"
      },
      "source": [
        "# **LinearEncoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xQsq0BheBkU",
        "outputId": "310c4e9d-4247-4208-822f-a3ce63a34f9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = LinearEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pU8BKfUeBkU",
        "outputId": "287c8149-2a4f-432a-9e02-7bda0c214d34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSehEAN-eBkU",
        "outputId": "6a957596-4a62-437f-b5c8-2b6181b223f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_cands_with_embeddings_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaAkYPbdeBkU",
        "outputId": "06f729c8-ff99-4130-cac2-a12ded2c55b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_cands_with_embeddings_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6gis1f5eBkU"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeP1K0b0eBkU",
        "outputId": "20d39fa4-0e25-4785-ef1a-33792121ebf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-1 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_cosine_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_cosine_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk7pAIxdeBkU",
        "outputId": "6e21b160-2ce6-4afd-a993-0fd43ed683c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_cosine_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1431\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.718, 'Recall': 0.6943, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWAYfXe6eBkU",
        "outputId": "5a269bb3-6756-4888-a49c-59b941997efa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9463 rows\n",
            "✅ After removing ignored classes: 9463 rows\n",
            "✅ After keeping only test SrcEntities: 2399 rows\n",
            "✅ After applying threshold ≥ 0.0: 2399 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_cosine_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2399 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_cosine_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1754\n",
            "📊 Evaluation (P / R / F1): {'P': 0.731, 'R': 0.659, 'F1': 0.693}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJN9eGxoeBkU",
        "outputId": "85a5912f-7495-4951-fb7c-97f3d70b46b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7311, 'Recall@1': 0.6836, 'F1@1': 0.7065}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_faiss_cosine_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COIjvC2yeBkU",
        "outputId": "ecb947e2-6fb8-4b05-817c-d4315462272a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-1 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_cosine_mrr_hit_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_cosine_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9doaT-TbeBkU"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_faiss_cosine_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbBHtONpeBkU",
        "outputId": "1b1425e5-770f-4613-9f1a-7fa25f226d66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6686686841465777, 'Hits@1': 0.6586556515208412, 'Hits@5': 0.6586556515208412, 'Hits@10': 0.6586556515208412}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rT3fdjoHeBkV"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV1dVWCzeBkV",
        "outputId": "55de5f12-d062-4bee-96cb-7e25ba1749f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-10 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_cosine_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_cosine_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ulzC9tReBkV",
        "outputId": "dcef87cf-98f5-4e11-bd3d-871e037ed3f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_cosine_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1431\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.718, 'Recall': 0.6943, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDhMQi9ceBkV",
        "outputId": "c0498e6c-5e42-4e35-957b-74070ad50775"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 95783 rows\n",
            "✅ After removing ignored classes: 95783 rows\n",
            "✅ After keeping only test SrcEntities: 22563 rows\n",
            "✅ After applying threshold ≥ 0.0: 22563 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_cosine_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2558 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_cosine_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1826\n",
            "📊 Evaluation (P / R / F1): {'P': 0.714, 'R': 0.686, 'F1': 0.699}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6U4nvcJeBkV",
        "outputId": "8c59d3b5-4a68-4eee-d079-debaf5eabfc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7215, 'Recall@1': 0.6741, 'F1@1': 0.697}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_faiss_cosine_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACMBAWnEeBkV",
        "outputId": "93d28d48-871e-48fd-dff4-556b0c451e8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-10 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_cosine_mrr_hit_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_cosine_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pS7nzZqBeBkV"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_faiss_cosine_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfteMxeHeBkV",
        "outputId": "f2f1ebd5-0008-42c1-b171-24ddaf52ada3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8923751515741968, 'Hits@1': 0.8516710476905746, 'Hits@5': 0.9361622230567029, 'Hits@10': 0.9361622230567029}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2rWbVRWeBkV"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5Gd6ZS4eBkV",
        "outputId": "a31efbea-068d-45ac-d385-ebf54b2be2e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-30 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_cosine_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using faiss_cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the faiss_cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_cosine_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eKPOVBzeBkV",
        "outputId": "ebfde353-3186-48fa-b445-da5e4d1b9b56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_cosine_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1431\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.718, 'Recall': 0.6943, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cm8qwBYeBkV",
        "outputId": "7581dbc6-1f34-40aa-869d-2c1ab140508b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 290661 rows\n",
            "✅ After removing ignored classes: 290661 rows\n",
            "✅ After keeping only test SrcEntities: 68379 rows\n",
            "✅ After applying threshold ≥ 0.0: 68379 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_cosine_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2558 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_cosine_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1826\n",
            "📊 Evaluation (P / R / F1): {'P': 0.714, 'R': 0.686, 'F1': 0.699}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oz3Mv5cXeBkV",
        "outputId": "7ff1ea95-944e-472c-8a90-75325400ccdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7215, 'Recall@1': 0.6741, 'F1@1': 0.697}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_faiss_cosine_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2pd1fObeBkV",
        "outputId": "b5a16750-1b58-4a1a-f695-ea3c5724e405"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-30 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_cosine_mrr_hit_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_cosine_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gu9gw4CeBkV"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_faiss_cosine_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzNp4KIZeBkW",
        "outputId": "971aa9a6-606e-4744-c930-1e9105344185"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9113772343157598, 'Hits@1': 0.8633120540743522, 'Hits@5': 0.9692076605332332, 'Hits@10': 0.9733383402177995}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhHxEGpceBkW"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-2fbb9_eBkW",
        "outputId": "b73c646d-81d6-404e-fed8-4c1bb019c8a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-100 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_cosine_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using faiss_cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the faiss_cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_cosine_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmOjt2ZoeBkW",
        "outputId": "aa6aeb59-19ec-4baf-8ee2-ca215ccfe468"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_cosine_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1431\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.718, 'Recall': 0.6943, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DdhOKfJeBkW",
        "outputId": "69bb860f-644b-40ba-a04d-22abb0539744"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 977811 rows\n",
            "✅ After removing ignored classes: 977811 rows\n",
            "✅ After keeping only test SrcEntities: 229901 rows\n",
            "✅ After applying threshold ≥ 0.0: 229901 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_cosine_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2558 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_cosine_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1826\n",
            "📊 Evaluation (P / R / F1): {'P': 0.714, 'R': 0.686, 'F1': 0.699}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHISJz7MeBkW",
        "outputId": "9e6153c9-250e-43e2-c0a9-05a8a384cf6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7215, 'Recall@1': 0.6741, 'F1@1': 0.697}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_faiss_cosine_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8MbvfJweBkW",
        "outputId": "db12c6f6-93f1-4e71-8d49-54283284bad8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-100 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_cosine_mrr_hit_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_cosine_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIQeW63XeBkW"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_faiss_cosine_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShiGX7N-eBkW",
        "outputId": "347479ed-11cb-4963-ecb4-ec97ba57f225"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.916907430941842, 'Hits@1': 0.8651896357491551, 'Hits@5': 0.9819752159218926, 'Hits@10': 0.989485542621104}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsPiHT-IeBkW"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqSBqsIieBkW",
        "outputId": "59b2aefa-864b-4bca-f604-3bc29b495f69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-200 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_cosine_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using faiss_cosine distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_faiss_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_cosine_Linencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHHeksrteBkW",
        "outputId": "a29798a9-6e66-4908-e953-e5666ea268ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_cosine_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1431\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.718, 'Recall': 0.6943, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrnBpsjdeBkW",
        "outputId": "88617a9c-51f9-46d1-e625-dc54d8b2b8ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1963547 rows\n",
            "✅ After removing ignored classes: 1963547 rows\n",
            "✅ After keeping only test SrcEntities: 461638 rows\n",
            "✅ After applying threshold ≥ 0.0: 461638 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_cosine_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2558 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_cosine_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1826\n",
            "📊 Evaluation (P / R / F1): {'P': 0.714, 'R': 0.686, 'F1': 0.699}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6YoHxeTeBkW",
        "outputId": "463e59f9-91fb-4fcc-c914-c983bdb24420"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7215, 'Recall@1': 0.6741, 'F1@1': 0.697}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_faiss_cosine_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihS1gx4VeBkX",
        "outputId": "8bf8b70e-1e1e-414d-ce76-05e9c4be9c79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-200 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_cosine_mrr_hit_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on faiss_cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_cosine_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGUzWEGbeBkX"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_faiss_cosine_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5yBDD1AeBkX",
        "outputId": "4163c697-b7ee-415d-9d5a-47ef3577c09c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.91807850822531, 'Hits@1': 0.8659406684190762, 'Hits@5': 0.9831017649267744, 'Hits@10': 0.9928651896357491}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0-ewggBeBkX"
      },
      "source": [
        "# **Transformer Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVFYK3RZeBkX",
        "outputId": "7d9c43b0-6a76-4245-a3da-0ce65256ac21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = TransformerEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3CyQ7j9eBkX",
        "outputId": "44b828e9-94a7-4040-b184-ee4b3c4e9dfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6UWg9L7eBkX",
        "outputId": "18eb2e7f-a93c-4b2d-e9f8-2aaef7a37210"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_cands_with_embeddings_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiudRLQPeBkX",
        "outputId": "84eae264-4302-4292-df82-3d864def2113"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_cands_with_embeddings_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG62fJaleBkX"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_s8ACSheeBkY",
        "outputId": "d9d2cb18-23b4-489a-f293-45c3bca44d0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-1 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_cosine_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_cosine_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2PMCWMZeBkY",
        "outputId": "6b723263-d490-4a11-f963-273cb32226f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_cosine_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1457\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7311, 'Recall': 0.7069, 'F1': 0.7188}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjge9O78eBkY",
        "outputId": "4532bc48-c9c9-475d-ac04-e163bbabc137"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9463 rows\n",
            "✅ After removing ignored classes: 9463 rows\n",
            "✅ After keeping only test SrcEntities: 2395 rows\n",
            "✅ After applying threshold ≥ 0.0: 2395 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_cosine_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2395 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_cosine_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1777\n",
            "📊 Evaluation (P / R / F1): {'P': 0.742, 'R': 0.667, 'F1': 0.703}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7w4dazbeBkY",
        "outputId": "205a482e-1ca4-4ea4-f0b3-c279608a100b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.742, 'Recall@1': 0.6939, 'F1@1': 0.7171}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_faiss_cosine_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KklyWrireBkY",
        "outputId": "4954bda5-53eb-4f56-9d55-6ae5540acaa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-1 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_cosine_mrr_hit_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_cosine_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liRGM6dReBkY"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_faiss_cosine_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqmxRJeVeBkY",
        "outputId": "a32fc543-f05c-4da9-8b48-356b31aa9c1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6770527963344496, 'Hits@1': 0.6672925272249343, 'Hits@5': 0.6672925272249343, 'Hits@10': 0.6672925272249343}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFukmGIPeBkY"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab7GKYmseBkY",
        "outputId": "61cea38c-0ae0-4442-b6f5-0f24944823b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-10 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_cosine_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using faiss_cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the faiss_cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_cosine_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eioOTWXfeBkY",
        "outputId": "a22ed7ad-02a6-495b-e474-d5609189c4a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_cosine_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1457\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7311, 'Recall': 0.7069, 'F1': 0.7188}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oj0_vN04eBkZ",
        "outputId": "398bf8d1-5099-4d3a-c1ea-3dd92ca8e8fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 96024 rows\n",
            "✅ After removing ignored classes: 96024 rows\n",
            "✅ After keeping only test SrcEntities: 22639 rows\n",
            "✅ After applying threshold ≥ 0.0: 22639 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_cosine_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2571 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_cosine_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1843\n",
            "📊 Evaluation (P / R / F1): {'P': 0.717, 'R': 0.692, 'F1': 0.704}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBbWM3TueBkZ",
        "outputId": "f1de0fb4-12b7-45e2-fd29-3a735cdd62b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7311, 'Recall@1': 0.6831, 'F1@1': 0.7063}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_faiss_cosine_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4Qg7NoheBkZ",
        "outputId": "d666165e-9087-4685-e038-4912ce4ef4b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-10 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_cosine_mrr_hit_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_cosine_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwXvQOxQeBkZ"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_faiss_cosine_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjyRcRkNeBkZ",
        "outputId": "0c8bebeb-5699-489b-f247-6c36515b86d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.897721381584642, 'Hits@1': 0.8588058580548253, 'Hits@5': 0.9395418700713482, 'Hits@10': 0.9395418700713482}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgzEs1b8eBkZ"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WDgBgsMeBkZ",
        "outputId": "96aa560d-3bab-425b-ce85-a69aa05be254"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-30 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_cosine_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using faiss_cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the faiss_cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_cosine_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhKdtgAHeBkZ",
        "outputId": "8ef95d7f-09db-4df7-a1ee-81eb9426d776"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_cosine_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1457\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7311, 'Recall': 0.7069, 'F1': 0.7188}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuGo_dX8eBkZ",
        "outputId": "e3115dc9-bae2-48a5-b821-a83bb34d777d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 291264 rows\n",
            "✅ After removing ignored classes: 291264 rows\n",
            "✅ After keeping only test SrcEntities: 68501 rows\n",
            "✅ After applying threshold ≥ 0.0: 68501 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_cosine_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2571 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_cosine_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1843\n",
            "📊 Evaluation (P / R / F1): {'P': 0.717, 'R': 0.692, 'F1': 0.704}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSl8w4z_eBka",
        "outputId": "205aeb89-3755-4186-bf0b-64a612d2bdec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7311, 'Recall@1': 0.6831, 'F1@1': 0.7063}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_faiss_cosine_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Il9wBZ9PeBka",
        "outputId": "fb24df18-6a17-41b1-9361-3d2159878136"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-30 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_cosine_mrr_hit_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_cosine_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8i7aPb-jeBka"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_faiss_cosine_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FchhQ2jjeBka",
        "outputId": "9353884c-b0a1-473b-f1b5-c8a80109e72a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9154906743159793, 'Hits@1': 0.8693203154337213, 'Hits@5': 0.9703342095381149, 'Hits@10': 0.97371385655276}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OO0nwvmieBka"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWWe21lreBka",
        "outputId": "ddf4ad68-2c2e-4720-814e-0e85ff0e8fd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-100 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_cosine_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using faiss_cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the faiss_cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_cosine_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkebpSR8eBka",
        "outputId": "dfe48a46-8449-4071-96f6-7b3e0d751415"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_cosine_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1457\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7311, 'Recall': 0.7069, 'F1': 0.7188}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pflABm6WeBka",
        "outputId": "424af142-b0f5-431e-e2cf-f65698eaa1bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 980686 rows\n",
            "✅ After removing ignored classes: 980686 rows\n",
            "✅ After keeping only test SrcEntities: 230640 rows\n",
            "✅ After applying threshold ≥ 0.0: 230640 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_cosine_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2571 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_cosine_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1843\n",
            "📊 Evaluation (P / R / F1): {'P': 0.717, 'R': 0.692, 'F1': 0.704}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzsNc7OveBka",
        "outputId": "b336d7e8-a972-431e-b849-f862c75f1af3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7311, 'Recall@1': 0.6831, 'F1@1': 0.7063}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_faiss_cosine_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLmA3PjceBka",
        "outputId": "976fe83e-63fe-4820-966b-cff1c34dfaf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-100 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_cosine_mrr_hit_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_cosine_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QH_iy0TPeBkb"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_faiss_cosine_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCyVjlQceBkb",
        "outputId": "e6250f9a-0f75-44f4-aca5-161196868d45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9214331839333023, 'Hits@1': 0.8711978971085242, 'Hits@5': 0.9838527975966954, 'Hits@10': 0.9913631242959069}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueRo8KB1eBkb"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csom8CrbeBkb",
        "outputId": "4ac2ce7f-e09e-44d8-a623-49dde7baf07d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-200 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_cosine_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using faiss_cosine distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_faiss_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_cosine_TRencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2CuOLe7eBkb",
        "outputId": "13406081-013f-4229-cbfa-1d9132e73b5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_cosine_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1457\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7311, 'Recall': 0.7069, 'F1': 0.7188}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4mcOViceBkb",
        "outputId": "d473339d-1a80-4534-e260-e1a8bd272e6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1969084 rows\n",
            "✅ After removing ignored classes: 1969084 rows\n",
            "✅ After keeping only test SrcEntities: 463250 rows\n",
            "✅ After applying threshold ≥ 0.0: 463250 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_cosine_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2571 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_cosine_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1843\n",
            "📊 Evaluation (P / R / F1): {'P': 0.717, 'R': 0.692, 'F1': 0.704}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqlTOlLReBkb",
        "outputId": "9117a256-6e54-4fc6-9449-afdea24a131c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7311, 'Recall@1': 0.6831, 'F1@1': 0.7063}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_faiss_cosine_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoc2KBwYeBkb",
        "outputId": "fd6617c3-6c5f-426f-fe0a-050c4ccfedfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Top-200 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_cosine_mrr_hit_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_cosine_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dMCefQheBkb"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_faiss_cosine_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBEVx2zoeBkc",
        "outputId": "f9d5d11e-04fc-4d82-be53-23a8afb8aee2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9221363841644391, 'Hits@1': 0.8715734134434848, 'Hits@5': 0.9849793466015772, 'Hits@10': 0.9924896733007886}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljGEyKNOerBT"
      },
      "source": [
        "# **Using faiss: topk_faiss_l2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu2LKSl2erBT"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcKeRd8kerBT",
        "outputId": "68dec6ba-215a-4278-967a-056bcb0ef681"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-1 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_l2.tsv\n",
            "⏱️ Execution time: 5.08 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_l2.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2-n_0NIerBT",
        "outputId": "d3dd4b61-2d2a-446e-bd25-ceb515248516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_l2_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1486\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7456, 'Recall': 0.721, 'F1': 0.7331}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_l2.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBWf13qgerBT",
        "outputId": "15dc0218-3c77-4dad-c449-ce095cb5d625"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9338 rows\n",
            "✅ After removing ignored classes: 9338 rows\n",
            "✅ After keeping only test SrcEntities: 2401 rows\n",
            "✅ After applying threshold ≥ 0.0: 2401 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_l2_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2401 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_l2_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1815\n",
            "📊 Evaluation (P / R / F1): {'P': 0.756, 'R': 0.682, 'F1': 0.717}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_l2.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHX8qq34erBT",
        "outputId": "13b87f4c-a8ef-4516-a378-d38ec55e70b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7559, 'Recall@1': 0.7071, 'F1@1': 0.7307}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/neoplas_top_1_mappings_faiss_l2_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDchgP8uerBT",
        "outputId": "1fce922e-2197-4b64-b9a2-3e2c8ec50c53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-1 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_l2_mrr_hit.tsv\n",
            "⏱️ Execution time: 3.01 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_l2_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIUIc1YeerBT"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_faiss_l2_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02OpuyA4erBT",
        "outputId": "e03952f9-3dad-481a-bf81-7b304225ed25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6909033534555333, 'Hits@1': 0.681562147953436, 'Hits@5': 0.681562147953436, 'Hits@10': 0.681562147953436}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSVSr0h8erBU"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0Ww3caFerBU",
        "outputId": "1cfdade1-a4b2-4aa7-c760-ef0b8141a51c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-10 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2.tsv\n",
            "⏱️ Execution time: 5.58 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xEEZC-uerBU",
        "outputId": "72adff07-7238-4609-e2c7-03203190ce7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1486\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7456, 'Recall': 0.721, 'F1': 0.7331}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFDg7rIjerBU",
        "outputId": "4e7857a9-6864-492e-9297-c87d9b378594"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 93974 rows\n",
            "✅ After removing ignored classes: 93974 rows\n",
            "✅ After keeping only test SrcEntities: 22353 rows\n",
            "✅ After applying threshold ≥ 0.0: 22353 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2500 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1871\n",
            "📊 Evaluation (P / R / F1): {'P': 0.748, 'R': 0.703, 'F1': 0.725}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5iztqT_erBU",
        "outputId": "b0a2a1ef-fe6c-42d0-c8eb-788e8aa13d99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7492, 'Recall@1': 0.7, 'F1@1': 0.7237}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_faiss_l2_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4T666pozerBU",
        "outputId": "54a325b5-1586-44db-b185-92bc55888fb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-10 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_mrr_hit.tsv\n",
            "⏱️ Execution time: 3.10 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_A_mSreSerBU"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCtxdwknerBU",
        "outputId": "18086561-96ee-40e5-e09c-7071a3ba9ea7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9087012240228131, 'Hits@1': 0.8708223807735637, 'Hits@5': 0.9504318437852046, 'Hits@10': 0.9504318437852046}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSdvu2FKerBU"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwlZ5IFoerBU",
        "outputId": "1d02f2f6-29c2-4fc4-c57f-1cc339a76f87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-30 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_l2.tsv\n",
            "⏱️ Execution time: 7.97 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_l2.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msu5cLvZerBU",
        "outputId": "0fd37f3a-9e5f-4c1b-91af-4d9c9681ab14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_l2_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1486\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7456, 'Recall': 0.721, 'F1': 0.7331}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_l2.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUgpX1c0erBU",
        "outputId": "941211dd-a482-4d5a-d88b-0e967fde5973"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 284213 rows\n",
            "✅ After removing ignored classes: 284213 rows\n",
            "✅ After keeping only test SrcEntities: 67469 rows\n",
            "✅ After applying threshold ≥ 0.0: 67469 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_l2_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2500 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_l2_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1871\n",
            "📊 Evaluation (P / R / F1): {'P': 0.748, 'R': 0.703, 'F1': 0.725}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_l2.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4taXdkq0erBU",
        "outputId": "48a36c1a-cf96-4e22-fa77-e73732a69c39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7492, 'Recall@1': 0.7, 'F1@1': 0.7237}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_faiss_l2_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bM7NMBPterBU",
        "outputId": "630ea0d5-af03-45df-ee41-702b0f591222"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-30 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_l2_mrr_hit.tsv\n",
            "⏱️ Execution time: 3.42 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_l2_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2H-q2RherBU"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_faiss_l2_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjuPLpqwerBU",
        "outputId": "847af26d-9e39-481f-a577-fd7a567e29f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9210168581050832, 'Hits@1': 0.8768306421329328, 'Hits@5': 0.97371385655276, 'Hits@10': 0.9778445362373264}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8s7EUeRerBV"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4lFnHJTerBV",
        "outputId": "adfc2c70-d258-44f6-8274-713f996348cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-100 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_l2.tsv\n",
            "⏱️ Execution time: 12.61 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_l2.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG_XlPSOerBV",
        "outputId": "0f0032bd-2a02-45a5-d062-92c7ef20eda5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_l2_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1486\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7456, 'Recall': 0.721, 'F1': 0.7331}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_l2.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CXqYsT6erBV",
        "outputId": "f7d49a53-5214-491c-e32b-ed543164ffb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 953701 rows\n",
            "✅ After removing ignored classes: 953701 rows\n",
            "✅ After keeping only test SrcEntities: 226196 rows\n",
            "✅ After applying threshold ≥ 0.0: 226196 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_l2_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2500 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_l2_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1871\n",
            "📊 Evaluation (P / R / F1): {'P': 0.748, 'R': 0.703, 'F1': 0.725}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_l2.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIThbGryerBV",
        "outputId": "c71308ae-ad61-4818-cce1-0184cf681279"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7492, 'Recall@1': 0.7, 'F1@1': 0.7237}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_faiss_l2_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRiu2xGgerBV",
        "outputId": "8a291f6d-623f-4350-b95a-a04d0314675b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-100 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_l2_mrr_hit.tsv\n",
            "⏱️ Execution time: 4.16 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_l2_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hS4cPvaLerBV"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_faiss_l2_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXKsZRvCerBV",
        "outputId": "71e872f4-0815-4aab-ed4f-d7b0c0765c39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9249873795274303, 'Hits@1': 0.8775816748028539, 'Hits@5': 0.984228313931656, 'Hits@10': 0.9906120916259857}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6R6R7zZerBV"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0gx7PjzerBV",
        "outputId": "d80691c1-2968-4ed1-baf6-6daafdc75bad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-200 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_l2.tsv\n",
            "⏱️ Execution time: 18.85 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_l2.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdQpQ4yZerBV",
        "outputId": "2f9d913b-2315-4f09-cc3f-78b48555b53a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_l2_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1486\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7456, 'Recall': 0.721, 'F1': 0.7331}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_l2.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buYTQuEIerBV",
        "outputId": "d87cc60c-5057-4a0e-db3d-1166f8d9ed00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1912330 rows\n",
            "✅ After removing ignored classes: 1912330 rows\n",
            "✅ After keeping only test SrcEntities: 453381 rows\n",
            "✅ After applying threshold ≥ 0.0: 453381 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_l2_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2500 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_l2_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1871\n",
            "📊 Evaluation (P / R / F1): {'P': 0.748, 'R': 0.703, 'F1': 0.725}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_l2.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMCpE8CoerBV",
        "outputId": "f56c77e7-a35e-4b0a-d5be-6970e3062714"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7492, 'Recall@1': 0.7, 'F1@1': 0.7237}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_faiss_l2_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFCoDigierBV",
        "outputId": "8629b093-8ba7-4955-aec5-73308058399d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-200 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_l2_mrr_hit.tsv\n",
            "⏱️ Execution time: 6.19 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_l2_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWknk11JerBV"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_faiss_l2_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9X9vwC1XerBV",
        "outputId": "277c7eae-d05f-4657-cfaa-6110c75bcd80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.925705592253055, 'Hits@1': 0.8779571911378145, 'Hits@5': 0.9849793466015772, 'Hits@10': 0.9932407059707097}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrhBYF5verBV"
      },
      "source": [
        "# **K=500**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C56E0nGVerBW",
        "outputId": "1b93f3bf-97a0-4316-844d-9413c3ab2241"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-500 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_faiss_l2.tsv\n",
            "⏱️ Execution time: 39.43 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=500,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_500_mappings_faiss_l2.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jWLEF1merBW",
        "outputId": "76f4866c-7f26-40f1-e37d-e972cecea6b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 5703500 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 996500 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_faiss_l2_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1486\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7456, 'Recall': 0.721, 'F1': 0.7331}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_500_mappings_faiss_l2.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma9yk4xHerBW",
        "outputId": "f88fca0f-7fc5-431f-8d92-d89ac71677ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 5703500 rows\n",
            "✅ After removing train-only URIs: 4791553 rows\n",
            "✅ After removing ignored classes: 4791553 rows\n",
            "✅ After keeping only test SrcEntities: 1135511 rows\n",
            "✅ After applying threshold ≥ 0.0: 1135511 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_faiss_l2_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2500 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_faiss_l2_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1871\n",
            "📊 Evaluation (P / R / F1): {'P': 0.748, 'R': 0.703, 'F1': 0.725}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_500_mappings_faiss_l2.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7MXJfNCerBW",
        "outputId": "04b3cba5-9339-46c8-80ce-67b9abf24496"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7492, 'Recall@1': 0.7, 'F1@1': 0.7237}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_500_mappings_faiss_l2_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-DAAsVterBW",
        "outputId": "ce570a03-6d76-4252-91e5-7a7cdd59f0b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-500 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_faiss_l2_mrr_hit.tsv\n",
            "⏱️ Execution time: 10.32 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=500,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_500_mappings_faiss_l2_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWoy-spkerBW"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_500_mappings_faiss_l2_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diMto9RierBW",
        "outputId": "3f9d03fc-974f-4947-eb5f-c10a5bc1ee21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9260917581785761, 'Hits@1': 0.8779571911378145, 'Hits@5': 0.9853548629365377, 'Hits@10': 0.9951182876455126}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTHKHsQUerBW"
      },
      "source": [
        "# **K=1000**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5E58Z6kerBW",
        "outputId": "c36ba2a1-d0df-4191-a812-73840f096bea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-1000 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_faiss_l2.tsv\n",
            "⏱️ Execution time: 74.68 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1000,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1000_mappings_faiss_l2.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2WqM0SXerBW",
        "outputId": "e21ce8fc-a7bb-4ef9-a10d-0e1134120d2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407000 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993000 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_faiss_l2_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1486\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7456, 'Recall': 0.721, 'F1': 0.7331}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1000_mappings_faiss_l2.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkarRwgFerBW",
        "outputId": "200c1661-d5cd-4ebe-8cba-ae1a8136d2fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407000 rows\n",
            "✅ After removing train-only URIs: 9607031 rows\n",
            "✅ After removing ignored classes: 9607031 rows\n",
            "✅ After keeping only test SrcEntities: 2277216 rows\n",
            "✅ After applying threshold ≥ 0.0: 2277216 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_faiss_l2_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2500 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_faiss_l2_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1871\n",
            "📊 Evaluation (P / R / F1): {'P': 0.748, 'R': 0.703, 'F1': 0.725}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1000_mappings_faiss_l2.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbIYhljperBW",
        "outputId": "534d8f69-5c49-4bd9-a3ec-97eaf8909ff6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7492, 'Recall@1': 0.7, 'F1@1': 0.7237}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1000_mappings_faiss_l2_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MysSFn1yerBX",
        "outputId": "c8bd158c-c449-4258-cbab-301b96a32751"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-1000 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_faiss_l2_mrr_hit.tsv\n",
            "⏱️ Execution time: 17.33 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1000,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1000_mappings_faiss_l2_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNcVmoAoerBX"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1000_mappings_faiss_l2_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zTawT2KerBX",
        "outputId": "91581cf7-d940-45cd-e032-379fe6518672"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.926348935066863, 'Hits@1': 0.8779571911378145, 'Hits@5': 0.9857303792714983, 'Hits@10': 0.9962448366503943}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OQ_FZ0verBX"
      },
      "source": [
        "# **K=2000**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JE_Fh2TFerBX",
        "outputId": "da3fbcd0-81d2-4574-c53a-3581fa5ba5b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-2000 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_faiss_l2.tsv\n",
            "⏱️ Execution time: 139.75 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=2000,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_2000_mappings_faiss_l2.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERYN1MJTerBX",
        "outputId": "e1c36729-a735-4258-e7f7-ba9e3d0509b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 22814000 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 3986000 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_faiss_l2_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1486\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7456, 'Recall': 0.721, 'F1': 0.7331}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_2000_mappings_faiss_l2.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pogmxzR3erBX",
        "outputId": "f897e4ed-f5d7-45f5-acd4-4565aea02ac5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 22814000 rows\n",
            "✅ After removing train-only URIs: 19293601 rows\n",
            "✅ After removing ignored classes: 19293601 rows\n",
            "✅ After keeping only test SrcEntities: 4576412 rows\n",
            "✅ After applying threshold ≥ 0.0: 4576412 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_faiss_l2_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2500 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_faiss_l2_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1871\n",
            "📊 Evaluation (P / R / F1): {'P': 0.748, 'R': 0.703, 'F1': 0.725}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_2000_mappings_faiss_l2.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-745a3S6erBX",
        "outputId": "558cebe4-33e5-4c2f-df01-539e4dabef46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7492, 'Recall@1': 0.7, 'F1@1': 0.7237}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_2000_mappings_faiss_l2_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cisg0wEherBX",
        "outputId": "04cecbc9-7aa4-4458-8831-e394b2b56731"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-2000 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_faiss_l2_mrr_hit.tsv\n",
            "⏱️ Execution time: 33.66 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=2000,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_2000_mappings_faiss_l2_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gReu16-KerBX"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_2000_mappings_faiss_l2_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgRj0pSperBY",
        "outputId": "3669d5dd-216c-4b5f-cac1-0bf7b402fa4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.926392698248757, 'Hits@1': 0.8779571911378145, 'Hits@5': 0.9857303792714983, 'Hits@10': 0.9966203529853549}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dG8pGSW3erBY"
      },
      "source": [
        "# **With Encoders**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMzg4z7AerBY"
      },
      "source": [
        "# **ResMLPEncoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Pox3G3uerBY",
        "outputId": "32d8050a-9203-4282-f787-76d42a28b60e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = ResMLPEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlEu9DCmerBY",
        "outputId": "58274218-3715-4acd-ed30-bd0ffa7166e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1shdG0YerBY",
        "outputId": "7f645750-7e64-49dc-8d00-d9a22c11f98a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_cands_with_embeddings_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7aXhVJperBY",
        "outputId": "4ed6357e-a78c-4eb8-d890-dcce2b20f370"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_cands_with_embeddings_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eguJgapZerBY"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8ihqooAerBY",
        "outputId": "2cd6fbc2-227e-4547-efaa-118232ab999b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-1 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_l2_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 5.19 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using l2 distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the l2 distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_l2(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_l2_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5NUB8WUerBY",
        "outputId": "63974f17-6c47-4aa6-bbb1-18ae6f2012ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_l2_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1486\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7456, 'Recall': 0.721, 'F1': 0.7331}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_l2_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5-ZpFoserBY",
        "outputId": "22a54c9f-c970-4502-8817-2dd730519d31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9334 rows\n",
            "✅ After removing ignored classes: 9334 rows\n",
            "✅ After keeping only test SrcEntities: 2400 rows\n",
            "✅ After applying threshold ≥ 0.0: 2400 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_l2_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2400 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_l2_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1812\n",
            "📊 Evaluation (P / R / F1): {'P': 0.755, 'R': 0.68, 'F1': 0.716}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_l2_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J073UJG4erBZ",
        "outputId": "01b3598f-de12-43ab-8067-f809b1ee2bab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.755, 'Recall@1': 0.7062, 'F1@1': 0.7298}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_faiss_l2_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dp6Vr8FAerBZ",
        "outputId": "298f4773-2df5-4128-eea5-1bc88a0ef1ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-1 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_l2_mrr_hit_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 5.12 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_l2_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ic-64yxIerBZ"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_faiss_l2_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qG_hSSQerBZ",
        "outputId": "f2d36bf7-30f5-4bbe-ed74-dd1155b80d6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6898089915650769, 'Hits@1': 0.6804355989485542, 'Hits@5': 0.6804355989485542, 'Hits@10': 0.6804355989485542}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MazVlbOgerBZ"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-cAcuprerBZ",
        "outputId": "f899f109-b383-4fc6-89f9-b5524f3f2555"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-10 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 6.38 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using l2 distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the l2 distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_l2(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdqO_QG3erBZ",
        "outputId": "fc1bed21-f66a-4a20-fa12-8fdc5cafc49f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1486\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7456, 'Recall': 0.721, 'F1': 0.7331}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keci5fvZerBZ",
        "outputId": "fc91abbb-874b-4eaa-f28d-b1297f265f8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 94032 rows\n",
            "✅ After removing ignored classes: 94032 rows\n",
            "✅ After keeping only test SrcEntities: 22357 rows\n",
            "✅ After applying threshold ≥ 0.0: 22357 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2504 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1870\n",
            "📊 Evaluation (P / R / F1): {'P': 0.747, 'R': 0.702, 'F1': 0.724}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LWEDWP3erBZ",
        "outputId": "222bb6ab-537f-4112-dea4-11182eaa9392"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7484, 'Recall@1': 0.6992, 'F1@1': 0.723}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_faiss_l2_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzuXSn9DerBZ",
        "outputId": "4d5d1990-3c72-4085-88bc-2cb14a7b18e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-10 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_mrr_hit_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 3.21 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8NoVUcFerBa"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-GhF9RLerBa",
        "outputId": "e9a07d88-f0f8-401f-a483-cb41a20feaf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9080009263796606, 'Hits@1': 0.8704468644386031, 'Hits@5': 0.9485542621104018, 'Hits@10': 0.9489297784453624}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTB9A9HyerBa"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Rg1t55QerBa",
        "outputId": "5fb01d43-d1a8-40a4-8ddd-7786b5de6f57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-30 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_l2_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 7.13 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using l2 distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the l2 distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_l2(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_l2_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOdScF1DerBa",
        "outputId": "c0b72e10-1430-42a3-95cb-3e767f7709b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_l2_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1486\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7456, 'Recall': 0.721, 'F1': 0.7331}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_l2_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aK7d82-WerBa",
        "outputId": "ec98aebe-e17d-4c11-e459-f7a3c63a94ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 284200 rows\n",
            "✅ After removing ignored classes: 284200 rows\n",
            "✅ After keeping only test SrcEntities: 67484 rows\n",
            "✅ After applying threshold ≥ 0.0: 67484 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_l2_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2504 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_l2_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1870\n",
            "📊 Evaluation (P / R / F1): {'P': 0.747, 'R': 0.702, 'F1': 0.724}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_l2_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnjULFZWerBa",
        "outputId": "1b06b031-3e47-4c32-a9ac-0670fb88e178"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7484, 'Recall@1': 0.6992, 'F1@1': 0.723}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_faiss_l2_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIJV-fSUerBa",
        "outputId": "dcee300a-2a38-42ec-b238-e5ff9e399fd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-30 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_l2_mrr_hit_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 3.57 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_l2_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-Nr-7AcerBa"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_faiss_l2_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhSnorGzerBb",
        "outputId": "b76ce52c-4b6f-4376-8489-0b3fd5678f4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9214169618191189, 'Hits@1': 0.8768306421329328, 'Hits@5': 0.9744648892226812, 'Hits@10': 0.9785955689072474}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_08JlXVerBb"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpShzBqwerBb",
        "outputId": "ff4363b0-1294-4b6e-acd3-60692082edab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-100 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_l2_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 11.81 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using l2 distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the l2 distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_l2(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_l2_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59dE012UerBb",
        "outputId": "858e5159-94af-4b41-d1d1-3386abe7feb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_l2_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1486\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7456, 'Recall': 0.721, 'F1': 0.7331}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_l2_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnOXJKxlerBb",
        "outputId": "d8602d04-47a5-4b98-9e57-fa1a6ac1cea2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 953449 rows\n",
            "✅ After removing ignored classes: 953449 rows\n",
            "✅ After keeping only test SrcEntities: 226178 rows\n",
            "✅ After applying threshold ≥ 0.0: 226178 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_l2_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2504 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_l2_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1870\n",
            "📊 Evaluation (P / R / F1): {'P': 0.747, 'R': 0.702, 'F1': 0.724}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_l2_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUOprVzoerBb",
        "outputId": "5e4f821b-9d69-45f1-8233-f8b91c5b2f0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7484, 'Recall@1': 0.6992, 'F1@1': 0.723}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_faiss_l2_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TZKZHP8erBb",
        "outputId": "86f7ee43-2b33-4c93-9382-787bd1999df9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-100 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_l2_mrr_hit_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 4.70 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_l2_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIczJ8kqerBb"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_faiss_l2_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8x-DLjWjerBb",
        "outputId": "abfb707c-2a8f-401c-af43-275c89efa222"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9247532954068625, 'Hits@1': 0.8772061584678934, 'Hits@5': 0.9834772812617348, 'Hits@10': 0.9906120916259857}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUzL_GTHerBb"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oFP60wserBb",
        "outputId": "9f424f61-3f0c-4538-d8fe-42140db4ca58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-200 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_l2_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 20.25 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using l2 distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_faiss_l2(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_l2_ResMLPencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC-C3_GuerBc",
        "outputId": "2e53502f-4b6a-4d0d-c37c-393c5c5622ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_l2_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1486\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7456, 'Recall': 0.721, 'F1': 0.7331}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_l2_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58SeHUPuerBc",
        "outputId": "cea7d939-d5bf-478e-a2ed-89152d23e807"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1911786 rows\n",
            "✅ After removing ignored classes: 1911786 rows\n",
            "✅ After keeping only test SrcEntities: 453296 rows\n",
            "✅ After applying threshold ≥ 0.0: 453296 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_l2_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2504 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_l2_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1870\n",
            "📊 Evaluation (P / R / F1): {'P': 0.747, 'R': 0.702, 'F1': 0.724}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_l2_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhzH58VHerBc",
        "outputId": "5e300062-c3c3-4367-85be-a151db012efe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7484, 'Recall@1': 0.6992, 'F1@1': 0.723}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_faiss_l2_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqvDUjweerBc",
        "outputId": "37583098-a103-4bcc-8f1a-b35495dcc972"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-200 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_l2_mrr_hit_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 6.08 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_l2_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jG0HXeYjerBc"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_faiss_l2_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gj-T_JDUerBc",
        "outputId": "bcc46a4f-8030-4003-946f-2cbc205757ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.925244479008162, 'Hits@1': 0.8772061584678934, 'Hits@5': 0.9846038302666166, 'Hits@10': 0.9928651896357491}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZjHNgVCerBc"
      },
      "source": [
        "# **MLPEncoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcDkh9oterBc",
        "outputId": "a6868163-8861-4e19-bbf4-1abbf648be53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = MLPEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHeVZV_zerBc",
        "outputId": "a8936b94-dcec-4d6b-cdac-9b0c95f46a3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6RJWOu9erBd",
        "outputId": "1d798d75-e03d-4f33-faec-ab462753ca44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_cands_with_embeddings_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cI2Xn0qRerBd",
        "outputId": "12308635-568a-4ebd-f420-34934b5aef6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_cands_with_embeddings_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "es5XqN1derBd"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9K7kCC0erBd",
        "outputId": "bbd55c0b-6f09-45de-f00e-306e0e7132f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-1 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_l2_MLPencoded.tsv\n",
            "⏱️ Execution time: 4.96 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using l2 distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the l2 distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_l2(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_l2_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8NSR3aHerBd",
        "outputId": "c6ba897f-b3ac-4067-de68-360085432057"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_l2_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1470\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7376, 'Recall': 0.7132, 'F1': 0.7252}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_l2_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHgaS3NjerBd",
        "outputId": "1c1952ee-ab61-4adc-e31a-3bf391a77fe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9388 rows\n",
            "✅ After removing ignored classes: 9388 rows\n",
            "✅ After keeping only test SrcEntities: 2392 rows\n",
            "✅ After applying threshold ≥ 0.0: 2392 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_l2_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2392 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_l2_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1785\n",
            "📊 Evaluation (P / R / F1): {'P': 0.746, 'R': 0.67, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_l2_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU79-JnFerBd",
        "outputId": "d6edbf7e-b73a-4fec-f8b2-ba67575c9fe0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7462, 'Recall@1': 0.6981, 'F1@1': 0.7214}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_faiss_l2_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYlsOBOXerBd",
        "outputId": "b6293900-1472-4a40-c07a-05d82515a888"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-1 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_l2_mrr_hit_MLPencoded.tsv\n",
            "⏱️ Execution time: 5.24 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_l2_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUJl94mMerBd"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_faiss_l2_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4KVpac-erBd",
        "outputId": "fe94f5bd-e6aa-4c01-84e7-ec7f52933c73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6799660457498751, 'Hits@1': 0.6702966579046189, 'Hits@5': 0.6702966579046189, 'Hits@10': 0.6702966579046189}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQvqGGYzerBe"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lumR6EYFerBe",
        "outputId": "1c20ab20-2d5b-451e-8348-36c380b63bb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-10 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_MLPencoded.tsv\n",
            "⏱️ Execution time: 6.45 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using l2 distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the l2 distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_l2(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpcoJJgJerBe",
        "outputId": "52dca763-f053-48f4-e00f-a0687fbaa408"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1470\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7376, 'Recall': 0.7132, 'F1': 0.7252}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ck6n9gQnerBe",
        "outputId": "7b3dfc9f-b9a9-493a-f68a-6f2a833d7310"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 93890 rows\n",
            "✅ After removing ignored classes: 93890 rows\n",
            "✅ After keeping only test SrcEntities: 22307 rows\n",
            "✅ After applying threshold ≥ 0.0: 22307 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2527 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1844\n",
            "📊 Evaluation (P / R / F1): {'P': 0.73, 'R': 0.692, 'F1': 0.711}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xf5xnFxEerBe",
        "outputId": "e05820a6-de7e-4fb6-ab89-2a6599e5533e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7375, 'Recall@1': 0.6891, 'F1@1': 0.7125}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_faiss_l2_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmuWiHlJerBe",
        "outputId": "f42d5371-5302-4a6f-e371-ab4cd6c60508"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-10 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_mrr_hit_MLPencoded.tsv\n",
            "⏱️ Execution time: 2.69 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwXueOhyerBe"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRQLOpqlerBe",
        "outputId": "ccdfae30-be38-4909-e245-ff5cbaebddc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9080009263796606, 'Hits@1': 0.8704468644386031, 'Hits@5': 0.9485542621104018, 'Hits@10': 0.9489297784453624}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phH74HZherBe"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMEyeh6lerBe",
        "outputId": "1ec60ef7-4ef3-4838-a2a4-e875286b901d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-30 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_l2_MLPencoded.tsv\n",
            "⏱️ Execution time: 7.06 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using l2 distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the l2 distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_l2(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_l2_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQ2_69E0erBe",
        "outputId": "2dfd4668-bb01-42d5-f60d-04392b01b55e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_l2_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1470\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7376, 'Recall': 0.7132, 'F1': 0.7252}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_l2_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFQtpG9derBf",
        "outputId": "06554b1d-bf44-4823-8e1a-6f8d41ccec4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 283510 rows\n",
            "✅ After removing ignored classes: 283510 rows\n",
            "✅ After keeping only test SrcEntities: 67232 rows\n",
            "✅ After applying threshold ≥ 0.0: 67232 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_l2_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2527 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_l2_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1844\n",
            "📊 Evaluation (P / R / F1): {'P': 0.73, 'R': 0.692, 'F1': 0.711}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_l2_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIWw7eUZerBf",
        "outputId": "d63520dc-131e-4754-ff49-2f24dd39aa54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7375, 'Recall@1': 0.6891, 'F1@1': 0.7125}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_faiss_l2_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs-t71VderBf",
        "outputId": "73abcc48-8814-47aa-c3f9-b083c80d7ce8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-30 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_l2_mrr_hit_MLPencoded.tsv\n",
            "⏱️ Execution time: 3.45 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_l2_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfq6CQLkerBf"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_faiss_l2_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cws2BxcDerBf",
        "outputId": "d0e3bfa9-df7c-4841-a457-9a85c766a836"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9134069854408421, 'Hits@1': 0.8648141194141945, 'Hits@5': 0.972962823882839, 'Hits@10': 0.9759669545625235}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdGl4dmierBf"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abKPZ5iTerBf",
        "outputId": "8d789492-be1d-4276-9846-c135e98cb8ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-100 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_l2_MLPencoded.tsv\n",
            "⏱️ Execution time: 12.29 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using l2 distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the l2 distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_l2(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_l2_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4PPCsDgerBf",
        "outputId": "7b33af66-1e8e-46c9-b61d-2aab5d62c5ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_l2_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1470\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7376, 'Recall': 0.7132, 'F1': 0.7252}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_l2_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IREDNkRxerBf",
        "outputId": "bd8621b3-7e0b-4a07-da30-1f8b18417c2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 950097 rows\n",
            "✅ After removing ignored classes: 950097 rows\n",
            "✅ After keeping only test SrcEntities: 225061 rows\n",
            "✅ After applying threshold ≥ 0.0: 225061 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_l2_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2527 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_l2_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1844\n",
            "📊 Evaluation (P / R / F1): {'P': 0.73, 'R': 0.692, 'F1': 0.711}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_l2_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLRiK085erBf",
        "outputId": "344194f4-7565-45ba-ae61-bbde13c1dfa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7375, 'Recall@1': 0.6891, 'F1@1': 0.7125}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_faiss_l2_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABH9YsWierBg",
        "outputId": "44ba5149-9467-4c00-9986-28bef493fcca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-100 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_l2_mrr_hit_MLPencoded.tsv\n",
            "⏱️ Execution time: 4.61 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_l2_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9m4DlCPerBg"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_faiss_l2_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3k-ntv3erBg",
        "outputId": "5ad6248d-147f-4a6f-d457-a8899af59011"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9173304171319376, 'Hits@1': 0.8659406684190762, 'Hits@5': 0.9812241832519715, 'Hits@10': 0.9887345099511828}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxNaNB0jerBg"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhjAXKA8erBg",
        "outputId": "c2c62071-3ccc-411f-e862-56fadbae26ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-200 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_l2_MLPencoded.tsv\n",
            "⏱️ Execution time: 19.58 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using l2 distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_faiss_l2(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_l2_MLPencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40FPk1p3erBg",
        "outputId": "0469060d-b873-4de9-bab2-83338989c49c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_l2_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1470\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7376, 'Recall': 0.7132, 'F1': 0.7252}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_l2_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPZzt3k5erBg",
        "outputId": "abaebdf4-da9e-4f63-9c07-d431f88c6dcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1903317 rows\n",
            "✅ After removing ignored classes: 1903317 rows\n",
            "✅ After keeping only test SrcEntities: 450881 rows\n",
            "✅ After applying threshold ≥ 0.0: 450881 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_l2_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2527 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_l2_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1844\n",
            "📊 Evaluation (P / R / F1): {'P': 0.73, 'R': 0.692, 'F1': 0.711}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_l2_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTtBQpcPerBg",
        "outputId": "431d8e45-6c3c-4cd7-8b3b-787987585879"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7375, 'Recall@1': 0.6891, 'F1@1': 0.7125}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_faiss_l2_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N32JqrCkerBg",
        "outputId": "c36959b1-6127-43e0-9a23-a05902fd3e42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-200 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_l2_mrr_hit_MLPencoded.tsv\n",
            "⏱️ Execution time: 5.98 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_l2_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EC-ga5NberBg"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_faiss_l2_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TflUu3ixerBh",
        "outputId": "a5d1a138-5406-45c4-e216-a7f777f00b1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9179299338803377, 'Hits@1': 0.8659406684190762, 'Hits@5': 0.9827262485918138, 'Hits@10': 0.9913631242959069}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9uVGvSierBh"
      },
      "source": [
        "# **LinearEncoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZRn4vtlerBh",
        "outputId": "d78fd0d0-66da-4008-9cf7-a44fa29babe9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = LinearEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fr1ZaBk_erBh",
        "outputId": "3315664b-f3d8-4dee-e7f2-0a8282819ccd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJHY6mXWerBh",
        "outputId": "6482abab-aac1-40c6-b35c-64088414d460"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_cands_with_embeddings_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8x2BNQamerBh",
        "outputId": "9d32de26-c773-4310-8921-afa91e3b6d07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_cands_with_embeddings_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD-mvVjaerBh"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0y9PGOjerBh",
        "outputId": "ebc351cb-0661-4c5e-a85d-cdecbd48d8c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-1 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_l2_Linencoded.tsv\n",
            "⏱️ Execution time: 4.86 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using l2 distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the l2 distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_l2(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_l2_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeRNEgDVerBh",
        "outputId": "51185e03-f53e-413c-bd19-9abd1c31e229"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_l2_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1507\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7561, 'Recall': 0.7312, 'F1': 0.7435}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_l2_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlGebRZgerBh",
        "outputId": "7cf10cdc-cb2a-4cff-d61b-1cee385e2738"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9355 rows\n",
            "✅ After removing ignored classes: 9355 rows\n",
            "✅ After keeping only test SrcEntities: 2403 rows\n",
            "✅ After applying threshold ≥ 0.0: 2403 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_l2_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2403 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_l2_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1839\n",
            "📊 Evaluation (P / R / F1): {'P': 0.765, 'R': 0.691, 'F1': 0.726}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_l2_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wk-B3ayYerBh",
        "outputId": "32e47e0c-1db8-4cda-8acc-3f7690995623"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7653, 'Recall@1': 0.7156, 'F1@1': 0.7396}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_faiss_l2_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osEH4XDserBi",
        "outputId": "2bf31c16-e7e9-47bb-94aa-5cabe68c7265"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-1 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_l2_mrr_hit_Linencoded.tsv\n",
            "⏱️ Execution time: 2.98 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_l2_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaUNMlwaerBi"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_l2_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osyA61noerBi",
        "outputId": "27498bde-fcac-45ce-9f23-c9395d1399dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6996506751404974, 'Hits@1': 0.6905745399924896, 'Hits@5': 0.6905745399924896, 'Hits@10': 0.6905745399924896}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3fxua9GdP9y"
      },
      "source": [
        "# **K=5**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoRGQEQMdP9y",
        "outputId": "c77efab6-f9fa-4b8e-bd6f-c9265ae40d1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-5 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_5_mappings_faiss_l2_Linencoded.tsv\n",
            "⏱️ Execution time: 6.46 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using l2 distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the l2 distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_l2(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=5,\n",
        "    output_file=f\"{results_dir}/{task}_top_5_mappings_faiss_l2_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zD-o0gsjdP9z",
        "outputId": "d181c318-1f9c-44e4-a506-a68f0a164958"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 57035 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 9965 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_5_mappings_faiss_l2_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1477\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7411, 'Recall': 0.7166, 'F1': 0.7287}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_5_mappings_faiss_l2_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QguIZl_jdP9z",
        "outputId": "6a9257cc-fd3b-4b2f-ce33-f66ed9b72ce2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 57035 rows\n",
            "✅ After removing train-only URIs: 46750 rows\n",
            "✅ After removing ignored classes: 46750 rows\n",
            "✅ After keeping only test SrcEntities: 11239 rows\n",
            "✅ After applying threshold ≥ 0.0: 11239 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_5_mappings_faiss_l2_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2508 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_5_mappings_faiss_l2_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1850\n",
            "📊 Evaluation (P / R / F1): {'P': 0.738, 'R': 0.695, 'F1': 0.716}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_5_mappings_faiss_l2_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP60BFN3dP9z",
        "outputId": "32e47e0c-1db8-4cda-8acc-3f7690995623"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7653, 'Recall@1': 0.7156, 'F1@1': 0.7396}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_faiss_l2_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du8xFPMudP9z",
        "outputId": "2bf31c16-e7e9-47bb-94aa-5cabe68c7265"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-1 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_l2_mrr_hit_Linencoded.tsv\n",
            "⏱️ Execution time: 2.98 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_l2_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYcd6j38dP9z"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_l2_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlaGrUV8dP9z",
        "outputId": "27498bde-fcac-45ce-9f23-c9395d1399dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6996506751404974, 'Hits@1': 0.6905745399924896, 'Hits@5': 0.6905745399924896, 'Hits@10': 0.6905745399924896}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMkcjOUverBi"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOSRYREwerBi",
        "outputId": "5add6ca1-14a9-4df1-a408-c6f734db3396"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-10 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_Linencoded.tsv\n",
            "⏱️ Execution time: 6.45 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using l2 distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the l2 distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_l2(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j0NHqeLerBi",
        "outputId": "b6de2c80-dc27-48f2-a9ef-8117e6375961"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1507\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7561, 'Recall': 0.7312, 'F1': 0.7435}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WZKJM46erBi",
        "outputId": "3dd7c6ec-8783-4a45-f5a0-02cc81221424"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 93795 rows\n",
            "✅ After removing ignored classes: 93795 rows\n",
            "✅ After keeping only test SrcEntities: 22311 rows\n",
            "✅ After applying threshold ≥ 0.0: 22311 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2504 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1890\n",
            "📊 Evaluation (P / R / F1): {'P': 0.755, 'R': 0.71, 'F1': 0.732}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KB51RvjSerBi",
        "outputId": "90b5b3fe-199a-4398-efdb-ebdf29a2d3f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7576, 'Recall@1': 0.7078, 'F1@1': 0.7319}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_faiss_l2_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ubxpu_67erBi",
        "outputId": "154cc5ec-d277-4d71-c5a2-7a3d4917685b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-10 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_mrr_hit_Linencoded.tsv\n",
            "⏱️ Execution time: 2.87 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kydq6R4erBi"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJpg3uW8erBj",
        "outputId": "ad8f1439-1c0b-498e-8866-5763d0296785"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9103672402853702, 'Hits@1': 0.8745775441231693, 'Hits@5': 0.9504318437852046, 'Hits@10': 0.9504318437852046}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzEGdKZIerBj"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0r0Y4JcerBj",
        "outputId": "08cf4d6e-190e-46f9-bd56-1ff3e92c28c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-30 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_l2_Linencoded.tsv\n",
            "⏱️ Execution time: 7.77 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using faiss_l2 distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the faiss_l2 distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_l2(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_l2_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cNRb5H2erBj",
        "outputId": "b4ddf9b4-152a-48ba-ab4a-2ce6554cac54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_l2_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1507\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7561, 'Recall': 0.7312, 'F1': 0.7435}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_l2_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5mpQenierBj",
        "outputId": "c0f23dcf-671e-4fc4-b258-d0e2eeef48fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 283680 rows\n",
            "✅ After removing ignored classes: 283680 rows\n",
            "✅ After keeping only test SrcEntities: 67347 rows\n",
            "✅ After applying threshold ≥ 0.0: 67347 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_l2_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2504 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_l2_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1890\n",
            "📊 Evaluation (P / R / F1): {'P': 0.755, 'R': 0.71, 'F1': 0.732}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_l2_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8QHU8yzerBj",
        "outputId": "4d9b67cc-b5a5-44de-8b29-eaffb4e0b28b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7576, 'Recall@1': 0.7078, 'F1@1': 0.7319}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_faiss_l2_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24kNOgpWerBj",
        "outputId": "6ef7ef11-0477-4f3d-fa14-1c1eeebe392b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-30 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_l2_mrr_hit_Linencoded.tsv\n",
            "⏱️ Execution time: 3.07 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_l2_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdVtmokterBj"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_faiss_l2_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLNHynNIerBj",
        "outputId": "b0adc0ff-f298-429f-bd25-678510ccc05b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9226893995024598, 'Hits@1': 0.8805858054825385, 'Hits@5': 0.9748404055576417, 'Hits@10': 0.9770935035674052}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJCjCXh4erBj"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzdQh7-aerBj",
        "outputId": "dda46ff3-f645-4e1e-f337-34cdfd87935b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-100 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_l2_Linencoded.tsv\n",
            "⏱️ Execution time: 12.46 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using faiss_l2 distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the faiss_l2 distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_l2(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_l2_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvRrxmfoerBk",
        "outputId": "5313a419-c0a4-43f0-d376-2d81e4861a9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_l2_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1507\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7561, 'Recall': 0.7312, 'F1': 0.7435}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_l2_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAMd1aLYerBk",
        "outputId": "2cb84d61-4602-44e4-ff5a-b1b0670241d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 952518 rows\n",
            "✅ After removing ignored classes: 952518 rows\n",
            "✅ After keeping only test SrcEntities: 225857 rows\n",
            "✅ After applying threshold ≥ 0.0: 225857 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_l2_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2504 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_l2_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1890\n",
            "📊 Evaluation (P / R / F1): {'P': 0.755, 'R': 0.71, 'F1': 0.732}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_l2_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UV_0OcTRerBk",
        "outputId": "c298d58d-b319-47b3-ab5e-0cca653cd8c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7576, 'Recall@1': 0.7078, 'F1@1': 0.7319}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_faiss_l2_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtlGyxyeerBk",
        "outputId": "13696c03-de4f-4d26-a6b3-96435f3a6c5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-100 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_l2_mrr_hit_Linencoded.tsv\n",
            "⏱️ Execution time: 4.32 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_l2_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUyXhaZ0erBk"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_faiss_l2_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyJ2lKMoerBk",
        "outputId": "0613a7d1-9d2b-4cbd-d4c8-1dcf9e224bef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9270179455446481, 'Hits@1': 0.8820878708223808, 'Hits@5': 0.9853548629365377, 'Hits@10': 0.9906120916259857}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jvEcWJderBk"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VE2kiQvMerBk",
        "outputId": "083a4bf7-5253-4c2e-ddb2-523e0f5638d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-200 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_l2_Linencoded.tsv\n",
            "⏱️ Execution time: 18.97 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using faiss_l2 distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_faiss_l2(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_l2_Linencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29yvmqyOerBk",
        "outputId": "a5762e72-1287-4a22-c663-785a8318cbd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_l2_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1507\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7561, 'Recall': 0.7312, 'F1': 0.7435}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_l2_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoKjc5pWerBk",
        "outputId": "2c43c6d7-a47c-4bfe-949d-e96d9269e277"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1909239 rows\n",
            "✅ After removing ignored classes: 1909239 rows\n",
            "✅ After keeping only test SrcEntities: 452431 rows\n",
            "✅ After applying threshold ≥ 0.0: 452431 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_l2_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2504 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_l2_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1890\n",
            "📊 Evaluation (P / R / F1): {'P': 0.755, 'R': 0.71, 'F1': 0.732}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_l2_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBU5UU0merBl",
        "outputId": "29563c1e-1919-439b-af4b-a6ea2fab3656"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7576, 'Recall@1': 0.7078, 'F1@1': 0.7319}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_faiss_l2_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BgQMQzperBl",
        "outputId": "e05f2ef1-17e9-4966-9f21-757b2b753bea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-200 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_l2_mrr_hit_Linencoded.tsv\n",
            "⏱️ Execution time: 5.78 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on faiss_l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_l2_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpzkN2-verBl"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_faiss_l2_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quXigRGeerBl",
        "outputId": "ef3f0e82-954a-43f4-ee76-b2b78ad0ec9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9272521559404618, 'Hits@1': 0.8820878708223808, 'Hits@5': 0.9857303792714983, 'Hits@10': 0.9924896733007886}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnKJTCAVerBl"
      },
      "source": [
        "# **Transformer Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JysWIaFeerBl",
        "outputId": "85daa7da-4db3-4a5b-b39e-154ae65a25e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = TransformerEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_sqPY_CerBl",
        "outputId": "d4245be1-39e4-4251-c59b-b08937389e89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xei7Mm36erBl",
        "outputId": "579a034d-b04f-4eb6-fb4b-057a7ff23de9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_cands_with_embeddings_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qcwmYNNerBl",
        "outputId": "5a83152d-eb86-455c-9f70-b07ae18fd484"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_cands_with_embeddings_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QDpZ7YberBl"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-BYhnJeerBm",
        "outputId": "42b859f9-ad1a-4f48-be4b-764d510395a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-1 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_l2_TRencoded.tsv\n",
            "⏱️ Execution time: 5.30 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using l2 distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the l2 distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_l2(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_l2_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXegJD7serBm",
        "outputId": "52bb7b03-b549-4c74-cbe8-28f7e12ba8c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_l2_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1453\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7291, 'Recall': 0.705, 'F1': 0.7168}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_l2_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGE0MjdnerBm",
        "outputId": "4232f906-00bb-4dce-d15c-f63f595bc2d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9453 rows\n",
            "✅ After removing ignored classes: 9453 rows\n",
            "✅ After keeping only test SrcEntities: 2393 rows\n",
            "✅ After applying threshold ≥ 0.0: 2393 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_l2_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2393 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_l2_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1779\n",
            "📊 Evaluation (P / R / F1): {'P': 0.743, 'R': 0.668, 'F1': 0.704}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_l2_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSk0SY_-erBm",
        "outputId": "a06907d2-449e-45cd-f72e-d1af1b41ee7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7434, 'Recall@1': 0.6955, 'F1@1': 0.7186}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_faiss_l2_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pjQ9jXuerBm",
        "outputId": "9c8cc914-faeb-4455-ed76-990a3414e22d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-1 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_l2_mrr_hit_TRencoded.tsv\n",
            "⏱️ Execution time: 5.00 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_l2_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "de42rZw4erBm"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_faiss_l2_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMo9raygerBm",
        "outputId": "65505f7b-6aef-49a5-b279-34f7a70986b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6777814242482513, 'Hits@1': 0.6680435598948554, 'Hits@5': 0.6680435598948554, 'Hits@10': 0.6680435598948554}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WzjPVXMerBm"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMDQXLn4erBm",
        "outputId": "e73870c2-56d2-4463-a7f0-4cfa439e93da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-10 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_TRencoded.tsv\n",
            "⏱️ Execution time: 6.22 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using faiss_l2 distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the faiss_l2 distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_l2(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwFPaCFBerBn",
        "outputId": "d3e04ce8-b95b-4ec8-a408-996d432c7da6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1453\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7291, 'Recall': 0.705, 'F1': 0.7168}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_Dco3P_erBn",
        "outputId": "f5d695b7-3bbe-45f9-a166-21475888d6bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 95903 rows\n",
            "✅ After removing ignored classes: 95903 rows\n",
            "✅ After keeping only test SrcEntities: 22612 rows\n",
            "✅ After applying threshold ≥ 0.0: 22612 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2506 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1823\n",
            "📊 Evaluation (P / R / F1): {'P': 0.727, 'R': 0.685, 'F1': 0.705}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pZTPX8DerBn",
        "outputId": "99018057-bb47-4969-a591-b9780f8c3562"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7315, 'Recall@1': 0.6834, 'F1@1': 0.7067}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_faiss_l2_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyneoiLWerBn",
        "outputId": "8b626bd6-7e8d-4e6f-d661-146e2c7b7b2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-10 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_l2_mrr_hit_TRencoded.tsv\n",
            "⏱️ Execution time: 3.07 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQXRwj4rerBn"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_faiss_l2_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyMenrkZerBn",
        "outputId": "3ab9c620-0fe8-4347-9e35-ce7e2de02102"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8967946170873795, 'Hits@1': 0.8580548253849043, 'Hits@5': 0.938790837401427, 'Hits@10': 0.938790837401427}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaW7piGperBn"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNJmPC8cerBn",
        "outputId": "250a36e8-7f68-44d6-a52b-4d9e818fb1f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-30 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_l2_TRencoded.tsv\n",
            "⏱️ Execution time: 7.76 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using faiss_l2 distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the faiss_l2 distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_l2(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_l2_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq7A2k2jerBn",
        "outputId": "353a412d-b41d-4745-9d4a-ee9d01a2b3c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_l2_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1453\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7291, 'Recall': 0.705, 'F1': 0.7168}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_l2_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0I2ZynmgerBn",
        "outputId": "618be13a-5bfe-4e55-c5e5-bd66f21c2512"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 290798 rows\n",
            "✅ After removing ignored classes: 290798 rows\n",
            "✅ After keeping only test SrcEntities: 68332 rows\n",
            "✅ After applying threshold ≥ 0.0: 68332 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_l2_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2506 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_l2_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1823\n",
            "📊 Evaluation (P / R / F1): {'P': 0.727, 'R': 0.685, 'F1': 0.705}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_l2_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnpdh_9nerBo",
        "outputId": "17e5dcc3-e335-4484-a088-51b838df492f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7315, 'Recall@1': 0.6834, 'F1@1': 0.7067}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_faiss_l2_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysaRYE_HerBo",
        "outputId": "335853aa-784e-4b21-a8c8-98d9daf9356f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-30 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_l2_mrr_hit_TRencoded.tsv\n",
            "⏱️ Execution time: 3.66 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_l2_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2RbU_oDerBo"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_faiss_l2_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLsGmxVkerBo",
        "outputId": "47e2dd49-0cae-425d-f514-bcce4aea7d03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9142168560797507, 'Hits@1': 0.8689447990987608, 'Hits@5': 0.9680811115283515, 'Hits@10': 0.9714607585429966}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jP95QkZYerBo"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1ko1KIAerBo",
        "outputId": "d3a49b44-9ddb-4ed3-f83e-aa8292ea7e1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-100 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_l2_TRencoded.tsv\n",
            "⏱️ Execution time: 12.75 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using faiss_l2 distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the faiss_l2 distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_l2(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_l2_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90wYZIlperBo",
        "outputId": "be5d675c-6e0e-47b7-b235-a494dd6c4846"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_l2_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1453\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7291, 'Recall': 0.705, 'F1': 0.7168}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_l2_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BC6DE82erBo",
        "outputId": "48fe0683-82d0-4315-9de8-e7fa4685df5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 978885 rows\n",
            "✅ After removing ignored classes: 978885 rows\n",
            "✅ After keeping only test SrcEntities: 230060 rows\n",
            "✅ After applying threshold ≥ 0.0: 230060 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_l2_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2506 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_l2_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1823\n",
            "📊 Evaluation (P / R / F1): {'P': 0.727, 'R': 0.685, 'F1': 0.705}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_l2_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vq5LFVMderBo",
        "outputId": "8f78b8cf-c972-4ba0-a26c-af2b03300e4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7315, 'Recall@1': 0.6834, 'F1@1': 0.7067}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_faiss_l2_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItUf9GqSerBo",
        "outputId": "1d423d8a-0b3b-45a1-8199-3e1ec501fa61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-100 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_l2_mrr_hit_TRencoded.tsv\n",
            "⏱️ Execution time: 4.45 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_l2_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwCzmczoerBp"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_faiss_l2_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyYKH3GWerBp",
        "outputId": "d2d02d81-3f8f-443c-cd9f-d8946b742990"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9206826946966872, 'Hits@1': 0.8719489297784454, 'Hits@5': 0.9808486669170109, 'Hits@10': 0.9883589936162223}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20QzzFtderBp"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okFo0_69erBp",
        "outputId": "fd8fd107-62ae-4ebe-c1fa-f952f3c3ad6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-200 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_l2_TRencoded.tsv\n",
            "⏱️ Execution time: 19.60 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using faiss_l2 distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_faiss_l2(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_l2_TRencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xre8wY3VerBp",
        "outputId": "887c2910-860f-46c8-cd10-b6f6352d0859"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_l2_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1453\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7291, 'Recall': 0.705, 'F1': 0.7168}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_l2_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSw7ByBferBp",
        "outputId": "2df2efcb-ee6d-4d94-d938-c88c495af7e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1966091 rows\n",
            "✅ After removing ignored classes: 1966091 rows\n",
            "✅ After keeping only test SrcEntities: 462227 rows\n",
            "✅ After applying threshold ≥ 0.0: 462227 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_l2_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2506 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_l2_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1823\n",
            "📊 Evaluation (P / R / F1): {'P': 0.727, 'R': 0.685, 'F1': 0.705}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_l2_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-Td1CTCerBp",
        "outputId": "80105b15-ee86-44b4-8928-a5415f0acc8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7315, 'Recall@1': 0.6834, 'F1@1': 0.7067}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_faiss_l2_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KL9iLmO2erBp",
        "outputId": "652a636d-ee81-4075-b967-24bb00d689d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using L2 (Euclidean) distance with FAISS\n",
            "Top-200 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_l2_mrr_hit_TRencoded.tsv\n",
            "⏱️ Execution time: 6.28 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_l2(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on l2 distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_l2_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4I0CJ_q2erBp"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_faiss_l2_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiygMjaMerBq",
        "outputId": "e5eb7e3d-7645-4614-bc7b-8006a8c76f52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9216429019703534, 'Hits@1': 0.872324446113406, 'Hits@5': 0.9823507322568532, 'Hits@10': 0.9924896733007886}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUtkkgkPfx5I"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCzDMsWafyfE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boQCdiCxfyfE"
      },
      "source": [
        "# **Using faiss: topk_faiss_inner_product**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kal1dgBffyfE"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ms_L55HmfyfF",
        "outputId": "762a3bea-a29c-48f6-8e65-6dfcc1ee5765"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-1 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_inner_product.tsv\n",
            "⏱️ Execution time: 5.19 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxxNbX2xfyfF",
        "outputId": "64124db6-f506-4762-ab23-57355e90ced8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_inner_product_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1262\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6332, 'Recall': 0.6123, 'F1': 0.6226}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jazqxz7OfyfF",
        "outputId": "6960629b-d0dd-4974-d4b7-f94c37c66ef5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9748 rows\n",
            "✅ After removing ignored classes: 9748 rows\n",
            "✅ After keeping only test SrcEntities: 2399 rows\n",
            "✅ After applying threshold ≥ 0.0: 2399 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_inner_product_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2399 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_inner_product_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1534\n",
            "📊 Evaluation (P / R / F1): {'P': 0.639, 'R': 0.576, 'F1': 0.606}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zKvFX_hfyfF",
        "outputId": "92e89d07-b05a-4502-8d89-91dd69c16b90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6394, 'Recall@1': 0.5978, 'F1@1': 0.6179}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/neoplas_top_1_mappings_faiss_inner_product_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BkieVq-fyfF",
        "outputId": "ed6a6b89-f0f3-41ff-d74a-3942fb55cf95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-1 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_inner_product_mrr_hit.tsv\n",
            "⏱️ Execution time: 2.61 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6ZBagmhfyfF"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMZb_M1cfyfF",
        "outputId": "dadbfdff-5cc9-412f-b3bb-a0f6a8a0ac05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.5884842709145166, 'Hits@1': 0.5760420578295156, 'Hits@5': 0.5760420578295156, 'Hits@10': 0.5760420578295156}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46nLO0SpfyfF"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XObr69NzfyfF",
        "outputId": "43a9d173-937d-4959-941a-72503973944f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-10 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_inner_product.tsv\n",
            "⏱️ Execution time: 6.61 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBuW59w1fyfF",
        "outputId": "9544598d-8a26-43dd-ecf2-e7b188384a0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_inner_product_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1262\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6332, 'Recall': 0.6123, 'F1': 0.6226}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xH1U-8nSfyfG",
        "outputId": "69b45d43-dbda-4de1-f930-ccc1cda3f259"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 98509 rows\n",
            "✅ After removing ignored classes: 98509 rows\n",
            "✅ After keeping only test SrcEntities: 23139 rows\n",
            "✅ After applying threshold ≥ 0.0: 23139 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_inner_product_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2585 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_inner_product_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1589\n",
            "📊 Evaluation (P / R / F1): {'P': 0.615, 'R': 0.597, 'F1': 0.606}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktGgBmxlfyfG",
        "outputId": "d4465902-a7aa-4fe2-9543-4eb08cf67d52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6286, 'Recall@1': 0.5873, 'F1@1': 0.6073}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tj0HjJLfyfG",
        "outputId": "82d6103e-bd1d-4ce4-bf8c-e68f72a10d40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-10 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_inner_product_mrr_hit.tsv\n",
            "⏱️ Execution time: 3.41 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLZAPnpefyfG"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9fmMbPefyfG",
        "outputId": "6cb0d7eb-ce84-4969-977c-cdca0c786736"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8466162113795246, 'Hits@1': 0.7990987607960947, 'Hits@5': 0.896733007885843, 'Hits@10': 0.8978595568907247}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtisFklLfyfG"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrgBBP78fyfG",
        "outputId": "5f6e784e-efb3-4cd4-8d5c-3233760c2269"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-30 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_inner_product.tsv\n",
            "⏱️ Execution time: 7.55 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIVD6AG_fyfG",
        "outputId": "6879d919-698c-4c94-b475-a4f445401d2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_inner_product_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1262\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6332, 'Recall': 0.6123, 'F1': 0.6226}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTyeOWKTfyfG",
        "outputId": "b5c32478-94da-4d08-a259-fcfa3be4b604"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 297991 rows\n",
            "✅ After removing ignored classes: 297991 rows\n",
            "✅ After keeping only test SrcEntities: 69921 rows\n",
            "✅ After applying threshold ≥ 0.0: 69921 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_inner_product_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2585 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_inner_product_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1589\n",
            "📊 Evaluation (P / R / F1): {'P': 0.615, 'R': 0.597, 'F1': 0.606}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7OLYR41fyfG",
        "outputId": "25901f7f-e8d7-44ff-ad9c-53b2a81124b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6286, 'Recall@1': 0.5873, 'F1@1': 0.6073}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uMpNBkgfyfH",
        "outputId": "f5b421bf-1bfe-43e6-c7ac-dfbf07548d2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-30 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_inner_product_mrr_hit.tsv\n",
            "⏱️ Execution time: 3.36 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9u41za3fyfH"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5SKtdmQfyfH",
        "outputId": "3e48b962-60db-4ab3-d807-894556283e4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8831730515483852, 'Hits@1': 0.8238828389034923, 'Hits@5': 0.955313556139692, 'Hits@10': 0.9586932031543373}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjQWP6DvfyfH"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZd8rHg1fyfH",
        "outputId": "d3d1b037-d3b3-4003-af28-17b9bd3d0143"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-100 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_inner_product.tsv\n",
            "⏱️ Execution time: 12.84 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRNQfEo-fyfH",
        "outputId": "16a6a197-4c47-49c2-fb64-e29169459a05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_inner_product_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1262\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6332, 'Recall': 0.6123, 'F1': 0.6226}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1Q1g_DIfyfH",
        "outputId": "3058f135-4203-4f45-a652-d269fd6af1ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 1000304 rows\n",
            "✅ After removing ignored classes: 1000304 rows\n",
            "✅ After keeping only test SrcEntities: 235235 rows\n",
            "✅ After applying threshold ≥ 0.0: 235235 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_inner_product_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2585 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_inner_product_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1589\n",
            "📊 Evaluation (P / R / F1): {'P': 0.615, 'R': 0.597, 'F1': 0.606}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OM5jKHLfyfH",
        "outputId": "18f432da-2072-4780-df1a-5f44afbacabc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6286, 'Recall@1': 0.5873, 'F1@1': 0.6073}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yefOlGN2fyfH",
        "outputId": "de194976-1e50-49ea-fcc0-a75b3565af6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-100 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_inner_product_mrr_hit.tsv\n",
            "⏱️ Execution time: 4.91 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_OnWxh1fyfI"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qavnC4DmfyfI",
        "outputId": "bca47bcd-992d-4ae1-ea80-64e5e476e348"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8936496525951082, 'Hits@1': 0.8287645512579798, 'Hits@5': 0.9748404055576417, 'Hits@10': 0.9846038302666166}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pP2cJYffyfI"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zqMtk3rfyfI",
        "outputId": "d8839f88-1be7-46e9-ff6d-592ace345177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-200 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_inner_product.tsv\n",
            "⏱️ Execution time: 20.22 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfWvu-hHfyfI",
        "outputId": "183b3649-a5e5-4a36-f3a0-40e1dfebece4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_inner_product_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1262\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6332, 'Recall': 0.6123, 'F1': 0.6226}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2NRBOhOfyfI",
        "outputId": "0690ec37-2811-42cd-c802-ed4d4725523f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 2006426 rows\n",
            "✅ After removing ignored classes: 2006426 rows\n",
            "✅ After keeping only test SrcEntities: 472235 rows\n",
            "✅ After applying threshold ≥ 0.0: 472235 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_inner_product_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2585 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_inner_product_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1589\n",
            "📊 Evaluation (P / R / F1): {'P': 0.615, 'R': 0.597, 'F1': 0.606}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6J__3AefyfI",
        "outputId": "962503ff-c958-443a-e2ec-ca29575d5d2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6286, 'Recall@1': 0.5873, 'F1@1': 0.6073}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT8-jXg_fyfI",
        "outputId": "29206fff-5545-42d9-8b34-bcb19f8616a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-200 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_inner_product_mrr_hit.tsv\n",
            "⏱️ Execution time: 9.71 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9nX3oPPfyfI"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UdoyXx3fyfI",
        "outputId": "fb91b58c-fbf1-4d5d-c4fc-ed3480768bca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8955138733932495, 'Hits@1': 0.8287645512579798, 'Hits@5': 0.9797221179121292, 'Hits@10': 0.992114156965828}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oREs792yfyfJ"
      },
      "source": [
        "# **K=500**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwb6pU0PfyfJ",
        "outputId": "dc42c917-56e1-41cc-b305-d69b9455358f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-500 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_faiss_inner_product.tsv\n",
            "⏱️ Execution time: 42.12 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=500,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_500_mappings_faiss_inner_product.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfArKBAQfyfJ",
        "outputId": "324fbc82-6791-46d8-cb6e-9dc87ccd0fc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 5703500 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 996500 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_faiss_inner_product_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1262\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6332, 'Recall': 0.6123, 'F1': 0.6226}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_500_mappings_faiss_inner_product.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvu6pSiTfyfJ",
        "outputId": "1c65c95f-0bb7-4b15-b63b-59743b4bd339"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 5703500 rows\n",
            "✅ After removing train-only URIs: 5030995 rows\n",
            "✅ After removing ignored classes: 5030995 rows\n",
            "✅ After keeping only test SrcEntities: 1186335 rows\n",
            "✅ After applying threshold ≥ 0.0: 1186335 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_faiss_inner_product_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2585 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_faiss_inner_product_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1589\n",
            "📊 Evaluation (P / R / F1): {'P': 0.615, 'R': 0.597, 'F1': 0.606}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_500_mappings_faiss_inner_product.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBjQ1MgJfyfJ",
        "outputId": "da008700-a06a-41b1-c0bb-c6b798953765"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6286, 'Recall@1': 0.5873, 'F1@1': 0.6073}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_500_mappings_faiss_inner_product_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8vdPDFyfyfJ",
        "outputId": "19b074e3-447b-4e42-b0e6-6ba51163842c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-500 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_faiss_inner_product_mrr_hit.tsv\n",
            "⏱️ Execution time: 11.85 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=500,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_500_mappings_faiss_inner_product_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChjBmffqfyfJ"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_500_mappings_faiss_inner_product_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4a3AJyRfyfJ",
        "outputId": "ecad332c-0d79-4834-a919-1477f11f4438"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8962798453918591, 'Hits@1': 0.8291400675929403, 'Hits@5': 0.9808486669170109, 'Hits@10': 0.9943672549755914}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiWjrR9FfyfJ"
      },
      "source": [
        "# **K=1000**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwCp89fRfyfK",
        "outputId": "39483087-8621-4b57-8533-a8f7e42194c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-1000 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_faiss_inner_product.tsv\n",
            "⏱️ Execution time: 83.84 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1000,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1000_mappings_faiss_inner_product.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgEZHjlFfyfK",
        "outputId": "d08b723c-093c-49d2-d471-8b2564938681"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407000 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993000 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_faiss_inner_product_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1262\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6332, 'Recall': 0.6123, 'F1': 0.6226}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1000_mappings_faiss_inner_product.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gd_KmGMtfyfK",
        "outputId": "1d34b3da-5390-418b-c565-a9e92adbf44c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407000 rows\n",
            "✅ After removing train-only URIs: 10078399 rows\n",
            "✅ After removing ignored classes: 10078399 rows\n",
            "✅ After keeping only test SrcEntities: 2381130 rows\n",
            "✅ After applying threshold ≥ 0.0: 2381130 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_faiss_inner_product_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2585 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_faiss_inner_product_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1589\n",
            "📊 Evaluation (P / R / F1): {'P': 0.615, 'R': 0.597, 'F1': 0.606}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1000_mappings_faiss_inner_product.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXEXptmefyfK",
        "outputId": "b0237d5c-b230-446e-b633-ab8399910138"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6286, 'Recall@1': 0.5873, 'F1@1': 0.6073}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1000_mappings_faiss_inner_product_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vvw-BfOnfyfK",
        "outputId": "b72f9ca9-4295-4343-b96b-0dbb7ef2e5c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-1000 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_faiss_inner_product_mrr_hit.tsv\n",
            "⏱️ Execution time: 17.35 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1000,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1000_mappings_faiss_inner_product_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OOpb_e2fyfK"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1000_mappings_faiss_inner_product_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbCXRFHZfyfK",
        "outputId": "04ffa364-8e1c-47e7-83e6-cbba55c03609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8963189197942609, 'Hits@1': 0.8291400675929403, 'Hits@5': 0.9808486669170109, 'Hits@10': 0.994742771310552}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjIPAxSDfyfK"
      },
      "source": [
        "# **K=2000**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKv1sQY6fyfK",
        "outputId": "d1286250-98fa-4958-8d70-e5455506771e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-2000 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_faiss_inner_product.tsv\n",
            "⏱️ Execution time: 140.45 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=2000,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_2000_mappings_faiss_inner_product.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TIqq919fyfK",
        "outputId": "b64bad4c-d481-4ccb-9310-085b44a6763d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 22814000 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 3986000 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_faiss_inner_product_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1262\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6332, 'Recall': 0.6123, 'F1': 0.6226}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_2000_mappings_faiss_inner_product.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ84JI1DfyfL",
        "outputId": "633167b7-a1f2-4613-98c0-5ff820608580"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 22814000 rows\n",
            "✅ After removing train-only URIs: 20163955 rows\n",
            "✅ After removing ignored classes: 20163955 rows\n",
            "✅ After keeping only test SrcEntities: 4771027 rows\n",
            "✅ After applying threshold ≥ 0.0: 4771027 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_faiss_inner_product_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2585 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_faiss_inner_product_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1589\n",
            "📊 Evaluation (P / R / F1): {'P': 0.615, 'R': 0.597, 'F1': 0.606}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_2000_mappings_faiss_inner_product.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBYrj9g0fyfL",
        "outputId": "907d0b24-250f-4cf4-bd6d-670f37a289fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6286, 'Recall@1': 0.5873, 'F1@1': 0.6073}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_2000_mappings_faiss_inner_product_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v_MrF0ufyfL",
        "outputId": "332519b1-0c10-449e-96cd-404aee967a94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-2000 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_faiss_inner_product_mrr_hit.tsv\n",
            "⏱️ Execution time: 31.73 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=2000,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_2000_mappings_faiss_inner_product_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItwkAsNsfyfL"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_2000_mappings_faiss_inner_product_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ah0tYX0zfyfL",
        "outputId": "affc1c28-556d-4188-e5f3-51293d3d0b7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8964221400568136, 'Hits@1': 0.8291400675929403, 'Hits@5': 0.9808486669170109, 'Hits@10': 0.9958693203154337}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCaV4XACfyfL"
      },
      "source": [
        "# **With Encoders**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6EuIaVifyfL"
      },
      "source": [
        "# **ResMLPEncoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-q6ALYDTfyfL",
        "outputId": "a3bc2790-4256-4208-cad3-f85371b42364"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = ResMLPEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueyALN0mfyfL",
        "outputId": "45b6835c-239c-41fe-d3d4-2eee50256221"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lb39y_VxfyfM",
        "outputId": "616cf392-fdb5-4616-860b-4573c40bd4ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_cands_with_embeddings_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDeDNFEjfyfM",
        "outputId": "8f570fc3-9d94-48d9-88ef-4367641a7011"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_cands_with_embeddings_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DakHCZU6fyfM"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDtmmeb0fyfM",
        "outputId": "fbaf9486-6370-4747-f334-1510a8a0ae49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-1 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_inner_product_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 4.83 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_inner_product(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Dyn-TRTfyfM",
        "outputId": "5d395918-98ec-4599-ed13-09bb7e92e5f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_inner_product_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1256\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6302, 'Recall': 0.6094, 'F1': 0.6196}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8e0P2I9fyfM",
        "outputId": "37f0bab2-265c-4bd4-a39a-88ba4a112a99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9779 rows\n",
            "✅ After removing ignored classes: 9779 rows\n",
            "✅ After keeping only test SrcEntities: 2405 rows\n",
            "✅ After applying threshold ≥ 0.0: 2405 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_inner_product_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2405 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_inner_product_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1524\n",
            "📊 Evaluation (P / R / F1): {'P': 0.634, 'R': 0.572, 'F1': 0.601}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiZ2lStcfyfM",
        "outputId": "65da4812-9bbe-4e94-dd72-37091f713b6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6337, 'Recall@1': 0.5935, 'F1@1': 0.6129}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_8Xp1RRfyfM",
        "outputId": "d76a8484-74d8-4fe5-cefd-5ab566b7be4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-1 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_inner_product_mrr_hit_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 4.94 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k03T-y_2fyfN"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DTWAMHMfyfN",
        "outputId": "cbfd88a7-1c12-48d0-9298-fc025e267ece"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.5848379757460549, 'Hits@1': 0.5722868944799099, 'Hits@5': 0.5722868944799099, 'Hits@10': 0.5722868944799099}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bendvQOjfyfN"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0eME-K2fyfN",
        "outputId": "3597fc65-7d44-4732-adb1-d0124c371994"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-10 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_inner_product_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 5.75 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_inner_product(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dery3QKSfyfN",
        "outputId": "944600a9-37b4-4f50-bccf-e8f93617d37c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_inner_product_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1256\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6302, 'Recall': 0.6094, 'F1': 0.6196}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIULLYKtfyfN",
        "outputId": "9b9f2b97-2019-4aeb-b5b8-dc47beaea47a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 98750 rows\n",
            "✅ After removing ignored classes: 98750 rows\n",
            "✅ After keeping only test SrcEntities: 23187 rows\n",
            "✅ After applying threshold ≥ 0.0: 23187 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_inner_product_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2604 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_inner_product_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1580\n",
            "📊 Evaluation (P / R / F1): {'P': 0.607, 'R': 0.593, 'F1': 0.6}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfaXK4UqfyfN",
        "outputId": "350616e4-b242-4e47-e6c3-390aff9da784"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6254, 'Recall@1': 0.5843, 'F1@1': 0.6042}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXEBKGKyfyfN",
        "outputId": "0e378dcd-3abf-4409-d571-60147418e3d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-10 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_inner_product_mrr_hit_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 2.91 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFGD3-9gfyfN"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QojiMzvyfyfO",
        "outputId": "468e5a2a-0520-49e0-9383-e82e4d39c193"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8457790848592895, 'Hits@1': 0.7975966954562523, 'Hits@5': 0.8978595568907247, 'Hits@10': 0.8989861058956065}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYhE23TufyfO"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVD6by68fyfO",
        "outputId": "06975764-6e15-407c-8b6a-78dcaebcd081"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-30 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_inner_product_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 7.40 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_inner_product(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOt-fDgBfyfO",
        "outputId": "281b42f9-1b9e-4e40-d791-44317a125cb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_inner_product_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1256\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6302, 'Recall': 0.6094, 'F1': 0.6196}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8p5WoIEfyfO",
        "outputId": "a0caa21a-cb2e-48d1-b081-3895d59fa640"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 298695 rows\n",
            "✅ After removing ignored classes: 298695 rows\n",
            "✅ After keeping only test SrcEntities: 70042 rows\n",
            "✅ After applying threshold ≥ 0.0: 70042 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_inner_product_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2604 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_inner_product_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1580\n",
            "📊 Evaluation (P / R / F1): {'P': 0.607, 'R': 0.593, 'F1': 0.6}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PA1vfqBYfyfO",
        "outputId": "4ad9e091-580d-4d4d-a423-a25eaa0d0308"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6254, 'Recall@1': 0.5843, 'F1@1': 0.6042}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z64OHVOufyfO",
        "outputId": "a23de149-ada9-420a-c083-439d54311412"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-30 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_inner_product_mrr_hit_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 3.34 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ze-56GlefyfP"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a_03WngfyfP",
        "outputId": "b4159329-c759-47c8-bdc9-d2ed16479272"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8819902169634306, 'Hits@1': 0.8220052572286894, 'Hits@5': 0.955313556139692, 'Hits@10': 0.9586932031543373}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdS7E90JfyfP"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKO5iBl1fyfP",
        "outputId": "258233b1-953b-42c4-bca4-9d67d3638746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-100 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_inner_product_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 11.56 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_inner_product(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikN20W0afyfP",
        "outputId": "147aab34-935a-449d-da6c-bbf906961b1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_inner_product_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1256\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6302, 'Recall': 0.6094, 'F1': 0.6196}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DT6avEkvfyfP",
        "outputId": "5f0b44ba-40d2-467e-ede6-ccab5d8d565f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 1001885 rows\n",
            "✅ After removing ignored classes: 1001885 rows\n",
            "✅ After keeping only test SrcEntities: 235569 rows\n",
            "✅ After applying threshold ≥ 0.0: 235569 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_inner_product_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2604 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_inner_product_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1580\n",
            "📊 Evaluation (P / R / F1): {'P': 0.607, 'R': 0.593, 'F1': 0.6}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XB9jTjtfyfP",
        "outputId": "a7d6074d-0700-4cef-e993-b2af84a4f5bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6254, 'Recall@1': 0.5843, 'F1@1': 0.6042}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWozDLX_fyfP",
        "outputId": "75451cb7-0537-4e6c-a40b-b54a4698f2ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-100 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_inner_product_mrr_hit_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 4.43 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4AJXLEJfyfP"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4SFnGUzfyfQ",
        "outputId": "12d115fa-86ee-4d8e-c196-c2418c57d2fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8920469937990735, 'Hits@1': 0.8268869695831769, 'Hits@5': 0.9748404055576417, 'Hits@10': 0.9834772812617348}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1s0TdLNfyfQ"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6szgaWqGfyfQ",
        "outputId": "530cded1-66dd-4aba-8066-4bcb14da7412"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-200 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_inner_product_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 18.36 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using inner_product distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_faiss_inner_product(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product_ResMLPencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XB3EfXZfyfQ",
        "outputId": "d573bb48-70b6-4926-c04c-c3f3bc5a607c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_inner_product_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1256\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6302, 'Recall': 0.6094, 'F1': 0.6196}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_WMuK-ufyfQ",
        "outputId": "22ab6bc6-3a9a-420f-83e0-055dd3f9fcb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 2009966 rows\n",
            "✅ After removing ignored classes: 2009966 rows\n",
            "✅ After keeping only test SrcEntities: 473060 rows\n",
            "✅ After applying threshold ≥ 0.0: 473060 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_inner_product_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2604 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_inner_product_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1580\n",
            "📊 Evaluation (P / R / F1): {'P': 0.607, 'R': 0.593, 'F1': 0.6}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFHABXjyfyfQ",
        "outputId": "c3db3b9f-2119-44d1-d132-497d7a311243"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6254, 'Recall@1': 0.5843, 'F1@1': 0.6042}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSgCLoyIfyfQ",
        "outputId": "3f9ceb3a-808d-4361-f113-42bb94c98d32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-200 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_inner_product_mrr_hit_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 5.91 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "086i4fHAfyfQ"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvB6A3_mfyfR",
        "outputId": "80eba1a2-f66d-4fa9-c388-0cc3d1a61c21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8945893711479325, 'Hits@1': 0.8272624859181374, 'Hits@5': 0.9804731505820503, 'Hits@10': 0.9917386406308675}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bz4E8YgfyfR"
      },
      "source": [
        "# **MLPEncoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egpJ443LfyfR",
        "outputId": "5843a68b-da4d-4614-b06a-3c189c1afc62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = MLPEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R52kDhfefyfR",
        "outputId": "aa0de5cd-10e1-4ff0-cad5-284c06c3e796"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRK-2YrffyfR",
        "outputId": "c1ed551c-1313-4bd4-f229-8ddb74899d6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_cands_with_embeddings_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAyyhAq-fyfR",
        "outputId": "c4da0de3-8b0b-4411-afe1-c8d14307eddf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_cands_with_embeddings_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-X2M6j8nfyfR"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_6VoAc7fyfR",
        "outputId": "5fd29725-255e-4b90-ff2b-3444d9db93f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-1 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_inner_product_MLPencoded.tsv\n",
            "⏱️ Execution time: 5.34 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_inner_product(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYW4xLZQfyfR",
        "outputId": "bcc6a23b-c399-470f-991f-aba96ed24c81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_inner_product_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1039\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.5213, 'Recall': 0.5041, 'F1': 0.5126}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7GLyVR1fyfS",
        "outputId": "49472889-2f01-4343-c2f2-8635b46302cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 10039 rows\n",
            "✅ After removing ignored classes: 10039 rows\n",
            "✅ After keeping only test SrcEntities: 2416 rows\n",
            "✅ After applying threshold ≥ 0.0: 2416 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_inner_product_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2416 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_inner_product_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1255\n",
            "📊 Evaluation (P / R / F1): {'P': 0.519, 'R': 0.471, 'F1': 0.494}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZsEzn1GfyfS",
        "outputId": "43b6cc14-faf0-48d1-c055-a0bf34a5af6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.5195, 'Recall@1': 0.4859, 'F1@1': 0.5021}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGZwFwKJfyfS",
        "outputId": "db313948-0f91-4c12-d593-0957fd6fea68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-1 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_inner_product_mrr_hit_MLPencoded.tsv\n",
            "⏱️ Execution time: 4.74 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epj_n5Z5fyfS"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyCJ16GwfyfS",
        "outputId": "cb07c89e-1df6-4f83-cfc2-577c38b2daa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.4867928696074652, 'Hits@1': 0.47127300037551634, 'Hits@5': 0.47127300037551634, 'Hits@10': 0.47127300037551634}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJFmgyBZfyfS"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE1OBZPufyfS",
        "outputId": "4d2394e7-3da2-46a2-93cc-7f9a5e6360a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-10 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_inner_product_MLPencoded.tsv\n",
            "⏱️ Execution time: 6.52 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_inner_product(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IazSblzqfyfS",
        "outputId": "84f1c54f-33ad-47f3-f6a7-039ede827dd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_inner_product_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1039\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.5213, 'Recall': 0.5041, 'F1': 0.5126}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dzgt0znhfyfT",
        "outputId": "39c94fcb-72a2-43c0-9412-f148632062ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 100791 rows\n",
            "✅ After removing ignored classes: 100791 rows\n",
            "✅ After keeping only test SrcEntities: 23716 rows\n",
            "✅ After applying threshold ≥ 0.0: 23716 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_inner_product_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2659 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_inner_product_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1310\n",
            "📊 Evaluation (P / R / F1): {'P': 0.493, 'R': 0.492, 'F1': 0.492}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gp7vhq5fyfT",
        "outputId": "bb595a68-fb38-4d31-9d09-1a61445ab368"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.5129, 'Recall@1': 0.4792, 'F1@1': 0.4954}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1Lh8bksfyfT",
        "outputId": "0ecfeab9-c370-4fb6-9a7d-be949d02ae20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-10 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_inner_product_mrr_hit_MLPencoded.tsv\n",
            "⏱️ Execution time: 2.99 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GXkAB7TfyfT"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVN9fHgQfyfT",
        "outputId": "a2dab87f-f268-4282-f25d-69e2218b766d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8457790848592895, 'Hits@1': 0.7975966954562523, 'Hits@5': 0.8978595568907247, 'Hits@10': 0.8989861058956065}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lcLYEglfyfT"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwsVDo9KfyfT",
        "outputId": "1aa2b334-f1cd-4b3d-a0d5-9dfb7e4911d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-30 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_inner_product_MLPencoded.tsv\n",
            "⏱️ Execution time: 8.14 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_inner_product(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SP-tkpilfyfU",
        "outputId": "d69aae99-197d-42fd-a0e1-e5f41753df3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_inner_product_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1039\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.5213, 'Recall': 0.5041, 'F1': 0.5126}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B21QxpK0fyfU",
        "outputId": "b56a045b-45b4-4aa2-d92a-64d1a03de879"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 304150 rows\n",
            "✅ After removing ignored classes: 304150 rows\n",
            "✅ After keeping only test SrcEntities: 71573 rows\n",
            "✅ After applying threshold ≥ 0.0: 71573 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_inner_product_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2659 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_inner_product_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1310\n",
            "📊 Evaluation (P / R / F1): {'P': 0.493, 'R': 0.492, 'F1': 0.492}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfavrRLMfyfU",
        "outputId": "de4066df-5616-4566-d89f-44ef053287c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.5129, 'Recall@1': 0.4792, 'F1@1': 0.4954}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQm68mMcfyfU",
        "outputId": "418fae47-59ef-421e-a2f3-bb1a4e4010d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-30 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_inner_product_mrr_hit_MLPencoded.tsv\n",
            "⏱️ Execution time: 3.15 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7n-lzX3IfyfU"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYUKn8dTfyfU",
        "outputId": "3a0cd178-d318-4e52-d640-840954fa7da0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8128102405359304, 'Hits@1': 0.7465264739016148, 'Hits@5': 0.8880961321817499, 'Hits@10': 0.8937288772061585}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKddP5DefyfV"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvaOPrsifyfV",
        "outputId": "608d33c1-a865-45b3-e944-86a0e9be11bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-100 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_inner_product_MLPencoded.tsv\n",
            "⏱️ Execution time: 12.23 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_inner_product(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFVhuxQGfyfV",
        "outputId": "816498fe-e5a1-4bca-b960-8e6f53d846d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_inner_product_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1039\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.5213, 'Recall': 0.5041, 'F1': 0.5126}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLHJGa3SfyfV",
        "outputId": "ec745e3d-8a4d-4498-a75b-9aa202319dd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 1018720 rows\n",
            "✅ After removing ignored classes: 1018720 rows\n",
            "✅ After keeping only test SrcEntities: 240325 rows\n",
            "✅ After applying threshold ≥ 0.0: 240325 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_inner_product_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2659 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_inner_product_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1310\n",
            "📊 Evaluation (P / R / F1): {'P': 0.493, 'R': 0.492, 'F1': 0.492}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIJ5ZmMLfyfV",
        "outputId": "99f60912-e535-42e6-f596-ae9d42850e84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.5129, 'Recall@1': 0.4792, 'F1@1': 0.4954}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCLvABTVfyfV",
        "outputId": "ee379fad-2fc1-4032-c5b0-45c0d372ffa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-100 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_inner_product_mrr_hit_MLPencoded.tsv\n",
            "⏱️ Execution time: 4.10 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qt4ksd9gfyfV"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWPN6YS9fyfV",
        "outputId": "859f4e63-f0ab-4de6-92af-89eb9052e377"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8423187288882651, 'Hits@1': 0.7645512579797221, 'Hits@5': 0.9380398047315058, 'Hits@10': 0.9519339091250469}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Wqr-NgifyfV"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoVzb-LafyfW",
        "outputId": "8440c40b-0f10-4226-8ec4-906411700dad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-200 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_inner_product_MLPencoded.tsv\n",
            "⏱️ Execution time: 19.51 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using inner_product distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_faiss_inner_product(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product_MLPencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWPDk1YsfyfW",
        "outputId": "94e0715b-f8c5-4ad0-ba88-c24b93e2490b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_inner_product_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1039\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.5213, 'Recall': 0.5041, 'F1': 0.5126}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JkEqpv_fyfW",
        "outputId": "b52005dd-94fb-44ed-87b2-9c0c5de8f178"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 2042024 rows\n",
            "✅ After removing ignored classes: 2042024 rows\n",
            "✅ After keeping only test SrcEntities: 482604 rows\n",
            "✅ After applying threshold ≥ 0.0: 482604 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_inner_product_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2659 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_inner_product_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1310\n",
            "📊 Evaluation (P / R / F1): {'P': 0.493, 'R': 0.492, 'F1': 0.492}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeLp0zUZfyfW",
        "outputId": "c1942c4f-2175-406b-9b61-ec7dace7d816"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.5129, 'Recall@1': 0.4792, 'F1@1': 0.4954}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCHjs3B8fyfW",
        "outputId": "198a75f8-da68-4688-bc72-2ba6b8c2c400"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-200 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_inner_product_mrr_hit_MLPencoded.tsv\n",
            "⏱️ Execution time: 5.94 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQzPefwmfyfW"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4guL7gffyfW",
        "outputId": "744fd1a8-dfa7-4fa3-cf12-e00b907ea953"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8491103074347518, 'Hits@1': 0.7683064213293278, 'Hits@5': 0.9519339091250469, 'Hits@10': 0.9688321441982726}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHNc5hXBfyfW"
      },
      "source": [
        "# **LinearEncoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aK9iiKDjfyfX",
        "outputId": "08879ed0-e7b3-4f06-85a9-5765c0d710c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = LinearEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yy85IaT-fyfX",
        "outputId": "e16c869a-f013-4de8-cbbe-974f4e9cc951"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znGFia85fyfX",
        "outputId": "92e74d34-c20a-4880-a288-5ea63d1af028"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_cands_with_embeddings_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf1NrF6tfyfX",
        "outputId": "61d7eef3-7b61-4e3b-9ab1-bb318922e30e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_cands_with_embeddings_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2DwyZT3fyfX"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPj5jvGbfyfX",
        "outputId": "9de52bb6-76a9-4808-f212-cd8348f734ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-1 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_inner_product_Linencoded.tsv\n",
            "⏱️ Execution time: 4.96 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_inner_product(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gQ-QkG-fyfX",
        "outputId": "0cba177d-4a2f-463c-bc8b-2ef90f91afa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_inner_product_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1225\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6147, 'Recall': 0.5944, 'F1': 0.6043}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iIEUQ7QfyfY",
        "outputId": "9dfe7bb4-3754-4562-eb5a-0810ea98762b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9778 rows\n",
            "✅ After removing ignored classes: 9778 rows\n",
            "✅ After keeping only test SrcEntities: 2398 rows\n",
            "✅ After applying threshold ≥ 0.0: 2398 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_inner_product_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2398 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_inner_product_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1475\n",
            "📊 Evaluation (P / R / F1): {'P': 0.615, 'R': 0.554, 'F1': 0.583}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsE4sPi6fyfY",
        "outputId": "55cae41f-e311-4286-ebbc-52abf95a204f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6151, 'Recall@1': 0.5759, 'F1@1': 0.5949}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9n8OUQifyfY",
        "outputId": "9d5131e5-0c0f-4cc2-e356-1d50d983a8f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-1 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_inner_product_mrr_hit_Linencoded.tsv\n",
            "⏱️ Execution time: 2.47 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xV1ok-eEfyfY"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn7Wx1qZfyfY",
        "outputId": "cdeb3d22-71d8-4904-af61-7fd0a7af007e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.5669779139594173, 'Hits@1': 0.5538865940668419, 'Hits@5': 0.5538865940668419, 'Hits@10': 0.5538865940668419}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl73CzxefyfY"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRmsi8H4fyfY",
        "outputId": "6372540b-e8be-46a7-b63c-6d0a95467b1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-10 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_inner_product_Linencoded.tsv\n",
            "⏱️ Execution time: 6.09 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_inner_product(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdjpDE-zfyfY",
        "outputId": "66d69a10-28a1-4909-94cd-45e7ae6f9174"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_inner_product_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1225\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6147, 'Recall': 0.5944, 'F1': 0.6043}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAFXO0PRfyfZ",
        "outputId": "a83e062c-a533-4d12-98a4-49fb00219120"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 98542 rows\n",
            "✅ After removing ignored classes: 98542 rows\n",
            "✅ After keeping only test SrcEntities: 23164 rows\n",
            "✅ After applying threshold ≥ 0.0: 23164 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_inner_product_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2593 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_inner_product_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1532\n",
            "📊 Evaluation (P / R / F1): {'P': 0.591, 'R': 0.575, 'F1': 0.583}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3R6bf8vfyfZ",
        "outputId": "672f3ace-5c31-48e8-9bdc-832da18881f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6049, 'Recall@1': 0.5652, 'F1@1': 0.5844}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxR_9ajlfyfZ",
        "outputId": "3fae08bb-0379-437a-9903-47329a71296f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-10 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_inner_product_mrr_hit_Linencoded.tsv\n",
            "⏱️ Execution time: 2.64 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGYlZq24fyfZ"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72LG-gD7fyfZ",
        "outputId": "9ea816c0-fb81-47aa-bcb6-2ed8f2e63077"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8279229997913028, 'Hits@1': 0.7769432970334209, 'Hits@5': 0.8813368381524597, 'Hits@10': 0.8820878708223808}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TatqfOCzfyfZ"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1h7E-U9Yfyfa",
        "outputId": "fb497346-7bba-4e26-ac9d-46b7d912de33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-30 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_inner_product_Linencoded.tsv\n",
            "⏱️ Execution time: 7.53 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using faiss_inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the faiss_inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_inner_product(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RisBWuokfyfa",
        "outputId": "216e228f-282f-4fbc-c3e0-d651e2c404ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_inner_product_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1225\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6147, 'Recall': 0.5944, 'F1': 0.6043}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMVLQQ8rfyfa",
        "outputId": "91666e08-c1b9-42af-9ccb-aaace5a88473"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 298103 rows\n",
            "✅ After removing ignored classes: 298103 rows\n",
            "✅ After keeping only test SrcEntities: 69996 rows\n",
            "✅ After applying threshold ≥ 0.0: 69996 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_inner_product_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2593 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_inner_product_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1532\n",
            "📊 Evaluation (P / R / F1): {'P': 0.591, 'R': 0.575, 'F1': 0.583}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RilWIMPtfyfa",
        "outputId": "5603afe6-7d6f-4250-e28d-1dd0bf133598"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6049, 'Recall@1': 0.5652, 'F1@1': 0.5844}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxlOSM3Gfyfb",
        "outputId": "c065b040-41a0-4679-bf6b-03cc84433835"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-30 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_inner_product_mrr_hit_Linencoded.tsv\n",
            "⏱️ Execution time: 3.17 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAvf0HGSfyfb"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2D3FavhMfyfb",
        "outputId": "5dfe7138-d11c-492c-c74b-bbd6c9b041f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.870148416611878, 'Hits@1': 0.806609087495306, 'Hits@5': 0.9459256477656778, 'Hits@10': 0.9485542621104018}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "st_-3J2Dfyfb"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8JtEMB1fyfb",
        "outputId": "6b7fd302-cc14-4ad3-f8a9-4a6b7c074406"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-100 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_inner_product_Linencoded.tsv\n",
            "⏱️ Execution time: 12.96 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using faiss_inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the faiss_inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_inner_product(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTbCJckXfyfc",
        "outputId": "84cedf50-b666-4af4-eea2-b6ad0a9f0449"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_inner_product_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1225\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6147, 'Recall': 0.5944, 'F1': 0.6043}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CwLk1nQfyfc",
        "outputId": "ae212c49-0d1c-4af0-d861-da3574d4d786"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 1000493 rows\n",
            "✅ After removing ignored classes: 1000493 rows\n",
            "✅ After keeping only test SrcEntities: 235482 rows\n",
            "✅ After applying threshold ≥ 0.0: 235482 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_inner_product_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2593 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_inner_product_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1532\n",
            "📊 Evaluation (P / R / F1): {'P': 0.591, 'R': 0.575, 'F1': 0.583}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3D2eeL9fyfc",
        "outputId": "17a8b030-8092-4ea6-fa3c-b0b417c17b33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6049, 'Recall@1': 0.5652, 'F1@1': 0.5844}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vb3KB2Zfyfc",
        "outputId": "d4a9ab49-d362-4245-9306-7ad3ed57f392"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-100 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_inner_product_mrr_hit_Linencoded.tsv\n",
            "⏱️ Execution time: 4.69 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DyN40iyfyfc"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaC3egsNfyfd",
        "outputId": "37af4f5b-bd6f-4a71-a59e-111dbcccf5ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.885032446039347, 'Hits@1': 0.8144949305294781, 'Hits@5': 0.9725873075478784, 'Hits@10': 0.9819752159218926}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tbUFslofyfd"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2m68VnNfyfd",
        "outputId": "ad524292-ed4b-4053-f643-0d142288b5b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-200 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_inner_product_Linencoded.tsv\n",
            "⏱️ Execution time: 19.77 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using faiss_inner_product distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_faiss_inner_product(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product_Linencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Yr2clvdfyfd",
        "outputId": "636a086b-486e-4586-f0e0-4d2f3a01fcea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_inner_product_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1225\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.6147, 'Recall': 0.5944, 'F1': 0.6043}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q60P9rAVfyfd",
        "outputId": "084946f1-1c07-43ff-950c-2daba7811a07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 2006508 rows\n",
            "✅ After removing ignored classes: 2006508 rows\n",
            "✅ After keeping only test SrcEntities: 472703 rows\n",
            "✅ After applying threshold ≥ 0.0: 472703 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_inner_product_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2593 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_inner_product_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1532\n",
            "📊 Evaluation (P / R / F1): {'P': 0.591, 'R': 0.575, 'F1': 0.583}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYCugmB1fyfd",
        "outputId": "de80c8a9-2375-4a88-b803-7079ca714cd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.6049, 'Recall@1': 0.5652, 'F1@1': 0.5844}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvYAg-Ktfyfe",
        "outputId": "6f1cb893-7f36-4608-9d20-c7b6792d65ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-200 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_inner_product_mrr_hit_Linencoded.tsv\n",
            "⏱️ Execution time: 5.85 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on faiss_inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mR5a4GQnfyfe"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPLMkwI4fyfe",
        "outputId": "de485b98-355c-4987-a1a0-eb75bbf0fbe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8870608792414517, 'Hits@1': 0.8152459631993991, 'Hits@5': 0.9774690199023658, 'Hits@10': 0.9883589936162223}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdH-15PTfyfe"
      },
      "source": [
        "# **Transformer Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fr5GeV0gfyfe",
        "outputId": "635e7776-3ad1-4f0e-d7c0-15882429fe18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = TransformerEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVNWI6Glfyfe",
        "outputId": "7d263659-65a5-42c6-e884-347201d49cbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qd47UqN4fyfe",
        "outputId": "7585def2-bab8-485e-9577-1b75c6dc6b71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_cands_with_embeddings_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoV_pJt8fyfe",
        "outputId": "1d2118a4-c801-4c3f-af64-c23e1e538ffe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_cands_with_embeddings_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIzGVeqOfyfe"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjW-bmtkfyff",
        "outputId": "cee17f2c-db5e-41c0-8eb9-d2aace7b28f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-1 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_inner_product_TRencoded.tsv\n",
            "⏱️ Execution time: 5.32 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_inner_product(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WctygDjsfyff",
        "outputId": "be223a73-a038-485e-8f8b-efb9c5255c13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_inner_product_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1457\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7311, 'Recall': 0.7069, 'F1': 0.7188}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_nsOxI4fyff",
        "outputId": "8223483d-e4c6-4e17-d70b-b429776a77e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9466 rows\n",
            "✅ After removing ignored classes: 9466 rows\n",
            "✅ After keeping only test SrcEntities: 2397 rows\n",
            "✅ After applying threshold ≥ 0.0: 2397 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_inner_product_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2397 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_inner_product_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1775\n",
            "📊 Evaluation (P / R / F1): {'P': 0.741, 'R': 0.667, 'F1': 0.702}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJ-bjPLofyff",
        "outputId": "4b2fe1aa-ae47-4160-ad8a-a7cfb7848142"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7405, 'Recall@1': 0.6931, 'F1@1': 0.716}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnqX88Hzfyff",
        "outputId": "1e7f5fc8-ad8c-4e78-d9c6-69b92ecacb6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-1 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_faiss_inner_product_mrr_hit_TRencoded.tsv\n",
            "⏱️ Execution time: 5.02 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-0mMlp2fyff"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_faiss_inner_product_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwAQ_Vgzfyff",
        "outputId": "50a1cab0-3611-4d04-9e36-7231f2d24c3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6763238528607026, 'Hits@1': 0.6665414945550131, 'Hits@5': 0.6665414945550131, 'Hits@10': 0.6665414945550131}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3-4BPEnfyff"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FTU9nDBfyfg",
        "outputId": "1d464eda-0389-4270-a16a-0c008fd0267f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-10 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_inner_product_TRencoded.tsv\n",
            "⏱️ Execution time: 6.39 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using faiss_inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the faiss_inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_inner_product(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKdrv88hfyfg",
        "outputId": "fa50f4ac-2d19-426a-c9ce-e5bc27cadca7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_inner_product_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1457\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7311, 'Recall': 0.7069, 'F1': 0.7188}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAQYplMtfyfg",
        "outputId": "5651770e-3e72-4724-b0a0-b769925aeb88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 96004 rows\n",
            "✅ After removing ignored classes: 96004 rows\n",
            "✅ After keeping only test SrcEntities: 22604 rows\n",
            "✅ After applying threshold ≥ 0.0: 22604 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_inner_product_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2560 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_inner_product_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1843\n",
            "📊 Evaluation (P / R / F1): {'P': 0.72, 'R': 0.692, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk9EYxaAfyfg",
        "outputId": "24309b94-1002-4f17-dea3-9f56e628e097"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7299, 'Recall@1': 0.6819, 'F1@1': 0.7051}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "564cB8itfyfg",
        "outputId": "34334429-85bf-4fb7-b0ca-9d8faa930b7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-10 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_faiss_inner_product_mrr_hit_TRencoded.tsv\n",
            "⏱️ Execution time: 3.34 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDCJEWoMfyfg"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_faiss_inner_product_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRw9e6F-fyfg",
        "outputId": "74f77cda-941d-46a9-b7a5-dd9bac9a51e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8987402924288271, 'Hits@1': 0.8584303417198648, 'Hits@5': 0.9417949680811115, 'Hits@10': 0.9417949680811115}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMMtxWr2fyfg"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap-UUy91fyfh",
        "outputId": "b5045839-ab53-4793-8d74-3b2907cf43c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-30 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_inner_product_TRencoded.tsv\n",
            "⏱️ Execution time: 8.12 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using faiss_inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the faiss_inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_inner_product(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrEkuXtwfyfh",
        "outputId": "cbb0ec8b-1e52-4882-e184-e821b6b2e621"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_inner_product_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1457\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7311, 'Recall': 0.7069, 'F1': 0.7188}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jupdzT-qfyfh",
        "outputId": "8054bf24-c5dc-4268-d255-021ec00b9bd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 291142 rows\n",
            "✅ After removing ignored classes: 291142 rows\n",
            "✅ After keeping only test SrcEntities: 68457 rows\n",
            "✅ After applying threshold ≥ 0.0: 68457 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_inner_product_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2560 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_inner_product_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1843\n",
            "📊 Evaluation (P / R / F1): {'P': 0.72, 'R': 0.692, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kttmD9ozfyfh",
        "outputId": "61cb3e74-ada2-4e2a-d0bb-84a73cbf3fa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7299, 'Recall@1': 0.6819, 'F1@1': 0.7051}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmtIm6mefyfh",
        "outputId": "8496b0e8-2fba-44ac-ab7b-f56e00ffb7db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-30 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_faiss_inner_product_mrr_hit_TRencoded.tsv\n",
            "⏱️ Execution time: 3.35 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m47KBQ2Bfyfh"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_faiss_inner_product_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCHes1VZfyfh",
        "outputId": "933a9c2c-aaf5-4fc7-fa8d-8145181ddca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.915202074555657, 'Hits@1': 0.867818250093879, 'Hits@5': 0.9714607585429966, 'Hits@10': 0.9744648892226812}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t8COAY8fyfh"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKpKjtaBfyfi",
        "outputId": "fabbfda3-9b87-4070-9e11-9ab0b144656e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-100 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_inner_product_TRencoded.tsv\n",
            "⏱️ Execution time: 11.64 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using faiss_inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the faiss_inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_faiss_inner_product(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pequcvwDfyfi",
        "outputId": "692eca6c-10b7-4a81-ff90-ff663484ef76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_inner_product_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1457\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7311, 'Recall': 0.7069, 'F1': 0.7188}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1TBl8Mzfyfi",
        "outputId": "341b93c8-b82b-4a0f-adb8-3ffb706fd0d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 979504 rows\n",
            "✅ After removing ignored classes: 979504 rows\n",
            "✅ After keeping only test SrcEntities: 230334 rows\n",
            "✅ After applying threshold ≥ 0.0: 230334 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_inner_product_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2560 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_inner_product_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1843\n",
            "📊 Evaluation (P / R / F1): {'P': 0.72, 'R': 0.692, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gx1u-Uc3fyfi",
        "outputId": "0ff371c4-9a67-4a71-b12e-0a9b52fdcc42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7299, 'Recall@1': 0.6819, 'F1@1': 0.7051}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaWmsG7qfyfi",
        "outputId": "7c315dd3-b837-4aa0-9c6e-c64eb93e88ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-100 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_faiss_inner_product_mrr_hit_TRencoded.tsv\n",
            "⏱️ Execution time: 4.09 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqHNsjZmfyfi"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_faiss_inner_product_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_nceBrxfyfi",
        "outputId": "6009be60-892c-478a-fa6c-e632473ad3b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9206396708137127, 'Hits@1': 0.8693203154337213, 'Hits@5': 0.9827262485918138, 'Hits@10': 0.9917386406308675}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-phbXKmjfyfj"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DwHKZfefyfj",
        "outputId": "29e0a4c5-e4ce-4919-be0d-f0b658e374b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-200 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_inner_product_TRencoded.tsv\n",
            "⏱️ Execution time: 19.04 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using faiss_inner_product distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_faiss_inner_product(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product_TRencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mKB2d1efyfj",
        "outputId": "4c66a160-4932-4d6c-ab41-29a124e3cf61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_inner_product_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1457\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7311, 'Recall': 0.7069, 'F1': 0.7188}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2Upjhkufyfj",
        "outputId": "86dbbc4a-55f3-4e30-b93a-66a125b033da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1966711 rows\n",
            "✅ After removing ignored classes: 1966711 rows\n",
            "✅ After keeping only test SrcEntities: 462464 rows\n",
            "✅ After applying threshold ≥ 0.0: 462464 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_inner_product_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2560 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_inner_product_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1843\n",
            "📊 Evaluation (P / R / F1): {'P': 0.72, 'R': 0.692, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6WDFKpMfyfj",
        "outputId": "8fa52e36-3693-4a9f-b567-cfe446face3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7299, 'Recall@1': 0.6819, 'F1@1': 0.7051}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJEFEzpsfyfj",
        "outputId": "4ce533eb-c9ee-4a8c-da88-0da1e972f7d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-200 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_faiss_inner_product_mrr_hit_TRencoded.tsv\n",
            "⏱️ Execution time: 5.55 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J13UCRM3fyfj"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_faiss_inner_product_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OupGGi-fyfj",
        "outputId": "52ef0e5e-9ffe-4758-86ea-dc5eb3c2bb45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9209066960283051, 'Hits@1': 0.8693203154337213, 'Hits@5': 0.9834772812617348, 'Hits@10': 0.9932407059707097}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JH6HWQlvgSA0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BLSuVyagSha"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNJczDq0gSha"
      },
      "source": [
        "# **Using faiss: topk_diem**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFLdfwAngSha"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFrf4hPqgSha",
        "outputId": "a669391d-6691-46f1-959e-a53bf12e9524"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-1 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_diem.tsv\n",
            "⏱️ Execution time: 7.94 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_diem.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qx8q_a11gSha",
        "outputId": "28709dd8-722a-427d-bae5-f457bd4d47d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_diem_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1459\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7321, 'Recall': 0.7079, 'F1': 0.7198}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_diem.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDrtG5jhgShb",
        "outputId": "b9c0123b-91ca-473e-d7a1-412d91b7255d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9451 rows\n",
            "✅ After removing ignored classes: 9451 rows\n",
            "✅ After keeping only test SrcEntities: 2399 rows\n",
            "✅ After applying threshold ≥ 0.0: 2399 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_diem_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2399 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_diem_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1780\n",
            "📊 Evaluation (P / R / F1): {'P': 0.742, 'R': 0.668, 'F1': 0.703}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_diem.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5nzLlH5gShb",
        "outputId": "d1f4a654-596e-4e1b-e89b-5a40f3c21f97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.742, 'Recall@1': 0.6942, 'F1@1': 0.7173}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/neoplas_top_1_mappings_diem_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZYKDJcYgShb",
        "outputId": "34ef8340-1e6a-47ef-f673-37ef271de86c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-1 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_diem_mrr_hit.tsv\n",
            "⏱️ Execution time: 8.25 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_diem_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLHiNzQ4gShb"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_diem_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8ykwyH4gShb",
        "outputId": "3fa36c8a-d432-4a1c-9666-80892c1f9fd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.5884842709145166, 'Hits@1': 0.5760420578295156, 'Hits@5': 0.5760420578295156, 'Hits@10': 0.5760420578295156}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk57UX2agShb"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_ksUrBtgShb",
        "outputId": "99f59a63-3bfa-466e-b701-f1f9748f0301"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-10 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_diem.tsv\n",
            "⏱️ Execution time: 12.00 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_diem.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkA6nC-zgShb",
        "outputId": "d1f04de0-47da-4cae-d9d5-4cdc75ea4874"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_diem_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1459\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7321, 'Recall': 0.7079, 'F1': 0.7198}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_diem.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cFKLGv4gShb",
        "outputId": "951f4364-c806-4fb6-bdfd-fe34c1ac0a3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 95820 rows\n",
            "✅ After removing ignored classes: 95820 rows\n",
            "✅ After keeping only test SrcEntities: 22590 rows\n",
            "✅ After applying threshold ≥ 0.0: 22590 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_diem_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2559 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_diem_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1850\n",
            "📊 Evaluation (P / R / F1): {'P': 0.723, 'R': 0.695, 'F1': 0.709}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_diem.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_bHx2KPgShb",
        "outputId": "60b98680-98e1-4e62-ef7f-6e49d5e6cb94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7323, 'Recall@1': 0.6842, 'F1@1': 0.7074}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_diem_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsGE3qyBgShb",
        "outputId": "64d0cdde-5907-4505-bd3e-7a935b00f92c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-10 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_diem_mrr_hit.tsv\n",
            "⏱️ Execution time: 3.89 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_diem_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFSrmz_ngShb"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_diem_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EweG2VWlgShb",
        "outputId": "e245a7da-56d9-45ee-a915-36f436bc40bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.900416649202266, 'Hits@1': 0.8603079233946677, 'Hits@5': 0.9432970334209538, 'Hits@10': 0.9432970334209538}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DauiXnYJgShb"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iRmMfqjgShb",
        "outputId": "54ec7b7d-33f9-4be7-f97f-84d5c51c7ef2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-30 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_diem.tsv\n",
            "⏱️ Execution time: 11.52 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_diem.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dG8q_5t_gShc",
        "outputId": "f9d402d0-94ef-4962-cb95-508ba1a0de34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_diem_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1459\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7321, 'Recall': 0.7079, 'F1': 0.7198}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_diem.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Funz6GBKgShc",
        "outputId": "fcbd6b82-d8e6-41e5-b8bd-1332037bb42b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 290477 rows\n",
            "✅ After removing ignored classes: 290477 rows\n",
            "✅ After keeping only test SrcEntities: 68300 rows\n",
            "✅ After applying threshold ≥ 0.0: 68300 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_diem_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2559 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_diem_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1850\n",
            "📊 Evaluation (P / R / F1): {'P': 0.723, 'R': 0.695, 'F1': 0.709}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_diem.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azka_BnvgShc",
        "outputId": "7de8ea00-7cb9-43b7-c216-c911fa9858f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7323, 'Recall@1': 0.6842, 'F1@1': 0.7074}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_diem_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqwgLgoOgShc",
        "outputId": "615c6a7a-afaf-4b02-8c3f-b8fa8d7bcee4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-30 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_diem_mrr_hit.tsv\n",
            "⏱️ Execution time: 3.70 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_diem_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5SORamfgShc"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_diem_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThU2aGN0gShc",
        "outputId": "a113d704-8531-4585-a5cb-167033554984"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8831730515483852, 'Hits@1': 0.8238828389034923, 'Hits@5': 0.955313556139692, 'Hits@10': 0.9586932031543373}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hfjlwa_gShc"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHQF6ElBgShc",
        "outputId": "a21cf0c0-00c0-4f30-b3c7-372c339cb39b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-100 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_diem.tsv\n",
            "⏱️ Execution time: 16.86 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_diem.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05J06MgfgShc",
        "outputId": "c9c2d9f7-fe56-4583-e61e-332c25acd689"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_diem_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1459\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7321, 'Recall': 0.7079, 'F1': 0.7198}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_diem.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abTWIEr2gShc",
        "outputId": "f9d4977f-03b6-4bc5-ac58-3892c6223c93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 977660 rows\n",
            "✅ After removing ignored classes: 977660 rows\n",
            "✅ After keeping only test SrcEntities: 229936 rows\n",
            "✅ After applying threshold ≥ 0.0: 229936 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_diem_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2559 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_diem_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1850\n",
            "📊 Evaluation (P / R / F1): {'P': 0.723, 'R': 0.695, 'F1': 0.709}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_diem.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HQfAjs6gShc",
        "outputId": "aae1aa7b-62a3-407a-9d3a-c257ca0a994b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7323, 'Recall@1': 0.6842, 'F1@1': 0.7074}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_diem_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZR73_EbgShc",
        "outputId": "6ba3a6c5-e037-4e2c-9d7c-fdc018810323"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-100 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_diem_mrr_hit.tsv\n",
            "⏱️ Execution time: 5.56 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_diem_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSz2f4fHgShc"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_diem_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuFRK9N_gShc",
        "outputId": "02b6b138-9fd1-4254-db7f-72b3249a282e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9222835490341191, 'Hits@1': 0.8715734134434848, 'Hits@5': 0.9853548629365377, 'Hits@10': 0.9917386406308675}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouZgNYmegShd"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIxYqsbTgShd",
        "outputId": "8a0f201d-25f1-4924-997b-546519c19126"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-200 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_diem.tsv\n",
            "⏱️ Execution time: 25.58 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_diem.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iatPzRSgShd",
        "outputId": "9d3fe2ca-d36f-4572-810b-dd3027e936a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_diem_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1459\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7321, 'Recall': 0.7079, 'F1': 0.7198}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_diem.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6gV8PQPgShd",
        "outputId": "31a89a0e-2dc6-4c8b-d3ad-1c93f80bd147"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1963408 rows\n",
            "✅ After removing ignored classes: 1963408 rows\n",
            "✅ After keeping only test SrcEntities: 461845 rows\n",
            "✅ After applying threshold ≥ 0.0: 461845 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_diem_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2559 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_diem_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1850\n",
            "📊 Evaluation (P / R / F1): {'P': 0.723, 'R': 0.695, 'F1': 0.709}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_diem.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AvPU6QzgShd",
        "outputId": "cd89ae78-d2cb-49ff-c60f-21d957bacc4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7323, 'Recall@1': 0.6842, 'F1@1': 0.7074}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_diem_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mI7hKMNBgShd",
        "outputId": "c35e7213-291c-4393-89ad-1488c3401806"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-200 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_diem_mrr_hit.tsv\n",
            "⏱️ Execution time: 6.75 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_diem_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELFM_196gShd"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_diem_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5sbx-okgShd",
        "outputId": "3eb5eb3a-5417-4a46-fcac-cada5ccd51ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9228282869993054, 'Hits@1': 0.8715734134434848, 'Hits@5': 0.9864814119414195, 'Hits@10': 0.9936162223056703}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7mrZg3wgShd"
      },
      "source": [
        "# **K=500**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0D4RCn3gShd",
        "outputId": "9be5ba24-59a8-421d-f095-7e296e33b9b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-500 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_diem.tsv\n",
            "⏱️ Execution time: 46.53 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=500,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_500_mappings_diem.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OL3h-uGFgShd",
        "outputId": "a63d1e58-36f8-465c-b6bb-34117f82815b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 5703500 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 996500 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_diem_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1459\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7321, 'Recall': 0.7079, 'F1': 0.7198}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_500_mappings_diem.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfDhy0w9gShd",
        "outputId": "ae69c31e-1e4e-4ec5-f16a-dd81562caf0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 5703500 rows\n",
            "✅ After removing train-only URIs: 4931351 rows\n",
            "✅ After removing ignored classes: 4931351 rows\n",
            "✅ After keeping only test SrcEntities: 1161325 rows\n",
            "✅ After applying threshold ≥ 0.0: 1161325 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_diem_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2559 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_diem_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1850\n",
            "📊 Evaluation (P / R / F1): {'P': 0.723, 'R': 0.695, 'F1': 0.709}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_500_mappings_diem.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51pJsyBVgShd",
        "outputId": "4479de96-8c44-4180-978a-4db9e097ebac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7323, 'Recall@1': 0.6842, 'F1@1': 0.7074}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_500_mappings_diem_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbPJ5ea5gShd",
        "outputId": "142c9534-c335-4f1f-8c10-835d9fc0fc8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-500 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_diem_mrr_hit.tsv\n",
            "⏱️ Execution time: 12.44 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=500,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_500_mappings_diem_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bzQYV5jgShd"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_500_mappings_diem_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_XkqfI3gShe",
        "outputId": "34754edf-f443-468d-a5e4-c155b90d103d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9232734999880481, 'Hits@1': 0.8715734134434848, 'Hits@5': 0.9872324446113406, 'Hits@10': 0.9954938039804732}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmF6trbRgShe"
      },
      "source": [
        "# **K=1000**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pF8LNnjNgShe",
        "outputId": "0f8d0017-642d-422d-dc5b-38329c36303e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-1000 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_diem.tsv\n",
            "⏱️ Execution time: 83.44 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1000,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1000_mappings_diem.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDCZ0FCZgShe",
        "outputId": "eac83686-26ec-4498-ca2a-5ff737b82733"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407000 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993000 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_diem_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1459\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7321, 'Recall': 0.7079, 'F1': 0.7198}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1000_mappings_diem.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66BndI1bgShe",
        "outputId": "7d9e7e7b-42ed-4ea5-fb57-399b99c79e37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407000 rows\n",
            "✅ After removing train-only URIs: 9899485 rows\n",
            "✅ After removing ignored classes: 9899485 rows\n",
            "✅ After keeping only test SrcEntities: 2334909 rows\n",
            "✅ After applying threshold ≥ 0.0: 2334909 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_diem_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2559 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_diem_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1850\n",
            "📊 Evaluation (P / R / F1): {'P': 0.723, 'R': 0.695, 'F1': 0.709}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1000_mappings_diem.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lklcpm9DgShe",
        "outputId": "35e5a237-e752-4dd2-f92c-f32305577e85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7323, 'Recall@1': 0.6842, 'F1@1': 0.7074}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1000_mappings_diem_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb4W7RF0gShe",
        "outputId": "a96fcb85-bb6e-4874-f1fe-7db1421f0250"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-1000 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_diem_mrr_hit.tsv\n",
            "⏱️ Execution time: 19.77 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1000,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1000_mappings_diem_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jQDS9ftgShe"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1000_mappings_diem_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxc8yVaRgShe",
        "outputId": "96300e8e-2c76-4e77-b5f3-60692a3443e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9233136280892157, 'Hits@1': 0.8715734134434848, 'Hits@5': 0.9872324446113406, 'Hits@10': 0.9958693203154337}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PucwGnwogShe"
      },
      "source": [
        "# **K=2000**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfucSXdmgShe",
        "outputId": "92be2135-a42a-4f80-e5ab-f6b2c5ad012a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-2000 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_diem.tsv\n",
            "⏱️ Execution time: 153.99 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=2000,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_2000_mappings_diem.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2wBQkS1gShe",
        "outputId": "02439338-5c57-49b2-bb04-cc44dc163da3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 22814000 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 3986000 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_diem_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1459\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7321, 'Recall': 0.7079, 'F1': 0.7198}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_2000_mappings_diem.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tc1sRwJggShe",
        "outputId": "76f52ffc-c494-4e59-ba6f-5668a1c5db8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 22814000 rows\n",
            "✅ After removing train-only URIs: 19869004 rows\n",
            "✅ After removing ignored classes: 19869004 rows\n",
            "✅ After keeping only test SrcEntities: 4694947 rows\n",
            "✅ After applying threshold ≥ 0.0: 4694947 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_diem_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2559 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_diem_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1850\n",
            "📊 Evaluation (P / R / F1): {'P': 0.723, 'R': 0.695, 'F1': 0.709}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_2000_mappings_diem.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBbrg3hagShf",
        "outputId": "1e737b75-4705-4a5e-82dd-ddb1add696a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7323, 'Recall@1': 0.6842, 'F1@1': 0.7074}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_2000_mappings_diem_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKUPV5icgShf",
        "outputId": "1d7fdcea-a4c7-4c6f-c202-4ecdad0c8fc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-2000 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_diem_mrr_hit.tsv\n",
            "⏱️ Execution time: 35.50 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=2000,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_2000_mappings_diem_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lfuSkNQgShf"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_2000_mappings_diem_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJslyfQ8gShf",
        "outputId": "b0d92ba3-3637-486b-f8c5-49e3e8f8e0f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9234778831821223, 'Hits@1': 0.8715734134434848, 'Hits@5': 0.9876079609463012, 'Hits@10': 0.997371385655276}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY3aKJVzgShf"
      },
      "source": [
        "# **With Encoders**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhnXr-FLgShf"
      },
      "source": [
        "# **ResMLPEncoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Bj8PMvcgShf",
        "outputId": "ef5f6b79-f6cc-49f3-f206-38aba04cad29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = ResMLPEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bJUQSvjgShf",
        "outputId": "e13fd4a5-b7f1-4a45-aab9-b219cc166b21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2ZaI9RZgShf",
        "outputId": "25b3ee2c-c7f1-4edd-f7bf-c0e8c25ca847"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_cands_with_embeddings_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AKjxOT8gShf",
        "outputId": "eefcf016-8c24-4189-a264-13a4b9a25398"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_cands_with_embeddings_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDTHdjcLgShf"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxYaVdS6gShf",
        "outputId": "e556e79f-6d29-439c-d335-34711c96efce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-1 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_diem_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 8.21 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_diem(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_diem_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkvnS-ISgShf",
        "outputId": "fdf98e36-cb9d-435d-c831-f1aeeeed94a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_diem_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1464\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7346, 'Recall': 0.7103, 'F1': 0.7222}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_diem_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubQ8APK5gShf",
        "outputId": "87eb8990-5137-4298-a1af-4f21706d4942"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9444 rows\n",
            "✅ After removing ignored classes: 9444 rows\n",
            "✅ After keeping only test SrcEntities: 2397 rows\n",
            "✅ After applying threshold ≥ 0.0: 2397 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_diem_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2397 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_diem_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1785\n",
            "📊 Evaluation (P / R / F1): {'P': 0.745, 'R': 0.67, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_diem_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7X-aiDPgShg",
        "outputId": "97c2815e-ae5c-4ae7-ca8c-67bf814ab14e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7447, 'Recall@1': 0.6967, 'F1@1': 0.7199}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_diem_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYyzNxODgShg",
        "outputId": "5f6437f1-35d8-4084-b33b-82830c2b153d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-1 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_diem_mrr_hit_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 4.02 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_diem_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckE8EFTigShg"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_diem_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4p3Ih24gShg",
        "outputId": "11ea1b81-11ee-450b-c3e7-245c93dd5161"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6799692013493283, 'Hits@1': 0.6702966579046189, 'Hits@5': 0.6702966579046189, 'Hits@10': 0.6702966579046189}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPCBy7LTgShg"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrp8kmzAgShg",
        "outputId": "2d498395-aee3-4bb7-e9e1-e0e57eff229f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-10 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_diem_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 9.43 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_diem(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_diem_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ohdc_KOXgShg",
        "outputId": "1ec4ad92-5508-443f-a2fc-b39d0a682ed7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_diem_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1464\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7346, 'Recall': 0.7103, 'F1': 0.7222}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_diem_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W549GHhYgShg",
        "outputId": "4f5816a2-dc0f-44c1-9825-2a7cdc82cdce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 95705 rows\n",
            "✅ After removing ignored classes: 95705 rows\n",
            "✅ After keeping only test SrcEntities: 22571 rows\n",
            "✅ After applying threshold ≥ 0.0: 22571 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_diem_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2552 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_diem_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1850\n",
            "📊 Evaluation (P / R / F1): {'P': 0.725, 'R': 0.695, 'F1': 0.709}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_diem_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kuq_p_YAgShg",
        "outputId": "46e3060a-91d5-4879-9857-d659422b7436"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7343, 'Recall@1': 0.6861, 'F1@1': 0.7094}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_diem_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGhm-AzigShg",
        "outputId": "ec60ac3c-c6ca-4d07-b970-7e812967815c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-10 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_diem_mrr_hit_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 3.93 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_diem_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RP521IxvgShg"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_diem_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGZwInlFgShg",
        "outputId": "c986ddad-5c98-4703-a307-5882bf99ad83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9020555138931134, 'Hits@1': 0.8640630867442733, 'Hits@5': 0.9429215170859933, 'Hits@10': 0.9429215170859933}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW5RWG1sgShh"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqUmzea5gShh",
        "outputId": "9ca41b1a-c28c-40fa-804c-44c2053566ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-30 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_diem_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 10.61 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_diem(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_diem_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Jo310fpgShh",
        "outputId": "8661053d-b01a-494d-c1ce-c244de39bbee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_diem_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1464\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7346, 'Recall': 0.7103, 'F1': 0.7222}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_diem_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMWWoqQ8gShh",
        "outputId": "a674e76e-b01f-41a8-e15c-ccd8396db338"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 290224 rows\n",
            "✅ After removing ignored classes: 290224 rows\n",
            "✅ After keeping only test SrcEntities: 68256 rows\n",
            "✅ After applying threshold ≥ 0.0: 68256 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_diem_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2552 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_diem_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1850\n",
            "📊 Evaluation (P / R / F1): {'P': 0.725, 'R': 0.695, 'F1': 0.709}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_diem_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpBmMgRJgShh",
        "outputId": "3270a4a6-dd39-4279-cb36-0b6060c73549"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7343, 'Recall@1': 0.6861, 'F1@1': 0.7094}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_diem_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygkbi83ggShh",
        "outputId": "5aa9563d-c806-446d-b9a5-f41f725cab59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-30 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_diem_mrr_hit_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 4.25 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_diem_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiGjVKfkgShh"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_diem_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vptz_XDKgShh",
        "outputId": "66d3f9ab-5bf3-4bfd-a70c-8f05ed2f625b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9195738101716044, 'Hits@1': 0.8738265114532482, 'Hits@5': 0.9740893728877206, 'Hits@10': 0.9770935035674052}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJk2q5-ZgShh"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2WGs-KTgShh",
        "outputId": "8721345d-d12a-4029-ab30-8e40e95e547d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-100 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_diem_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 17.18 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_diem(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_diem_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdybHcJHgShh",
        "outputId": "7bea3815-8265-4498-904c-64aa5c1f6678"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_diem_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1464\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7346, 'Recall': 0.7103, 'F1': 0.7222}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_diem_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhhAjX3XgShh",
        "outputId": "92821651-bd82-4d5e-c7bf-614e0681038b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 976988 rows\n",
            "✅ After removing ignored classes: 976988 rows\n",
            "✅ After keeping only test SrcEntities: 229786 rows\n",
            "✅ After applying threshold ≥ 0.0: 229786 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_diem_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2552 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_diem_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1850\n",
            "📊 Evaluation (P / R / F1): {'P': 0.725, 'R': 0.695, 'F1': 0.709}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_diem_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gM64PrEgShh",
        "outputId": "032202cd-9f23-4394-87a0-502c8a0c8a2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7343, 'Recall@1': 0.6861, 'F1@1': 0.7094}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_diem_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpIUFE0CgShh",
        "outputId": "31cf340f-be6b-4950-904b-5a07e87c6baa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-100 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_diem_mrr_hit_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 5.41 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_diem_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veqjAPGfgShi"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_diem_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYlD8xCxgShi",
        "outputId": "6cdeb4d9-f296-4d41-8f26-cb4067463af2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9240646788301962, 'Hits@1': 0.8749530604581299, 'Hits@5': 0.9849793466015772, 'Hits@10': 0.992114156965828}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUcmMuhCgShi"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XYW99pNgShi",
        "outputId": "37153645-d733-4256-8a44-f6e9fab1f5f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-200 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_diem_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 26.13 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using inner_product distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_diem(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_diem_ResMLPencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0ETP_t-gShi",
        "outputId": "e5c48217-7392-43bf-c2e8-6df05939e22b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_diem_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1464\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7346, 'Recall': 0.7103, 'F1': 0.7222}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_diem_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1pSzVyFgShi",
        "outputId": "6a65f6d0-63ac-4756-9317-85bdf568758c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1961966 rows\n",
            "✅ After removing ignored classes: 1961966 rows\n",
            "✅ After keeping only test SrcEntities: 461508 rows\n",
            "✅ After applying threshold ≥ 0.0: 461508 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_diem_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2552 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_diem_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1850\n",
            "📊 Evaluation (P / R / F1): {'P': 0.725, 'R': 0.695, 'F1': 0.709}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_diem_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdd9APgQgShi",
        "outputId": "25e4dcab-42d5-41aa-b9bb-466c0232942b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7343, 'Recall@1': 0.6861, 'F1@1': 0.7094}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_diem_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t0BtlrigShi",
        "outputId": "2e338435-1eb4-4d12-f396-0d826f576bde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-200 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_diem_mrr_hit_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 7.38 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_diem_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pItrVofigShi"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_diem_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJPrpRP6gShi",
        "outputId": "97a912a0-38c7-421c-ac6a-1b002d9b0ae9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9244213449817997, 'Hits@1': 0.8749530604581299, 'Hits@5': 0.9857303792714983, 'Hits@10': 0.9936162223056703}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hgzFGukgShi"
      },
      "source": [
        "# **MLPEncoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKMBSsv6gShi",
        "outputId": "ba0c694a-1d3a-4323-99e7-253085e9d698"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = MLPEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbhDQURngShi",
        "outputId": "fee57b4e-6996-4ba5-876b-168fba4d8098"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5jPvoyxgShj",
        "outputId": "f1ba4bdc-fdb8-4d03-ba94-ac4c34bfae27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_cands_with_embeddings_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZC-ZGN5gShj",
        "outputId": "d778ff59-a323-40e6-f77f-1dea4794cd95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_cands_with_embeddings_MLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjS37oB4gShj"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5YHkOlrgShj",
        "outputId": "4349aedb-c678-4c67-9f7b-58ee1fd48fca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-1 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_diem_MLPencoded.tsv\n",
            "⏱️ Execution time: 8.95 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_diem(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_diem_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EN_IENHgShj",
        "outputId": "4eee58cc-d24f-4892-816c-1bab2cca6a7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_diem_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1456\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7306, 'Recall': 0.7065, 'F1': 0.7183}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_diem_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDtS21isgShj",
        "outputId": "11212fa3-135a-46d8-99d3-d9437ba5d1ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9513 rows\n",
            "✅ After removing ignored classes: 9513 rows\n",
            "✅ After keeping only test SrcEntities: 2403 rows\n",
            "✅ After applying threshold ≥ 0.0: 2403 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_diem_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2403 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_diem_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1770\n",
            "📊 Evaluation (P / R / F1): {'P': 0.737, 'R': 0.665, 'F1': 0.699}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_diem_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXJM29JOgShj",
        "outputId": "78e2cf3e-d809-413e-a10a-0eadbc98f028"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7366, 'Recall@1': 0.6893, 'F1@1': 0.7121}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_diem_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJm8QL_JgShj",
        "outputId": "bfa10a36-96c4-459d-db89-9ee9bb32a71b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-1 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_diem_mrr_hit_MLPencoded.tsv\n",
            "⏱️ Execution time: 4.21 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_diem_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTT4tdcrgShk"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_diem_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtiNcT8cgShk",
        "outputId": "fcae8630-0cdf-47c4-f495-bcf45623e01b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6745014941763351, 'Hits@1': 0.6646639128802103, 'Hits@5': 0.6646639128802103, 'Hits@10': 0.6646639128802103}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g4YGzp1gShk"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_IGXMdGgShk",
        "outputId": "9d6414e6-308d-492d-94a6-993d6d0df9af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-10 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_diem_MLPencoded.tsv\n",
            "⏱️ Execution time: 10.84 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_diem(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_diem_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKn9iTA9gShk",
        "outputId": "38c26090-7470-45c6-f5b2-8148060d8abf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_diem_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1456\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7306, 'Recall': 0.7065, 'F1': 0.7183}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_diem_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_igLvwFgShk",
        "outputId": "91840247-b5fc-4cec-b60f-53bec4985e3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 96074 rows\n",
            "✅ After removing ignored classes: 96074 rows\n",
            "✅ After keeping only test SrcEntities: 22624 rows\n",
            "✅ After applying threshold ≥ 0.0: 22624 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_diem_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2577 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_diem_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1833\n",
            "📊 Evaluation (P / R / F1): {'P': 0.711, 'R': 0.688, 'F1': 0.7}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_diem_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4NeinEZgShk",
        "outputId": "e2e854fc-13ca-4126-875c-6f831c723849"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7255, 'Recall@1': 0.6778, 'F1@1': 0.7008}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_diem_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUGE72PggShk",
        "outputId": "1b49391b-45a4-49da-be01-cce09f2d2e35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-10 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_diem_mrr_hit_MLPencoded.tsv\n",
            "⏱️ Execution time: 3.97 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_diem_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BUU4MNmgShk"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_diem_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpKO9gzsgShk",
        "outputId": "626564f4-b99d-4b3a-d8cf-e759287e8bd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9020555138931134, 'Hits@1': 0.8640630867442733, 'Hits@5': 0.9429215170859933, 'Hits@10': 0.9429215170859933}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RwE5sr-gShk"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pJytexMgShk",
        "outputId": "116d984f-70ce-4f6b-95c0-464cf98ef134"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-30 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_diem_MLPencoded.tsv\n",
            "⏱️ Execution time: 11.75 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_diem(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_diem_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-ht7vAngShk",
        "outputId": "623337c5-026b-4736-bfdd-97f856223aeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_diem_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1456\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7306, 'Recall': 0.7065, 'F1': 0.7183}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_diem_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDItl8rTgShl",
        "outputId": "c44fa3fe-7899-42d3-82e5-1e2defb0c02c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 290631 rows\n",
            "✅ After removing ignored classes: 290631 rows\n",
            "✅ After keeping only test SrcEntities: 68295 rows\n",
            "✅ After applying threshold ≥ 0.0: 68295 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_diem_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2577 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_diem_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1833\n",
            "📊 Evaluation (P / R / F1): {'P': 0.711, 'R': 0.688, 'F1': 0.7}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_diem_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lneU4qXEgShl",
        "outputId": "e109e021-b65f-4ed7-9476-f7b72ada3fd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7255, 'Recall@1': 0.6778, 'F1@1': 0.7008}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_diem_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33wRZYi8gShl",
        "outputId": "cae3393c-18b0-40df-bc88-379771869e30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-30 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_diem_mrr_hit_MLPencoded.tsv\n",
            "⏱️ Execution time: 4.40 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_diem_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "901V_55xgShl"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_diem_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooZ-EM6sgShl",
        "outputId": "f81ff663-263e-4eae-9120-648e4e693f6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9166003245771688, 'Hits@1': 0.8738265114532482, 'Hits@5': 0.9680811115283515, 'Hits@10': 0.9714607585429966}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2u9A6fzVgShl"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yWUXSkogShl",
        "outputId": "137c83d9-29c8-4774-9f5e-32749b67cc50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-100 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_diem_MLPencoded.tsv\n",
            "⏱️ Execution time: 16.44 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_diem(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_diem_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ar8meDO8gShl",
        "outputId": "f3c29157-00e8-41af-d92c-49bda9cc3658"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_diem_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1456\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7306, 'Recall': 0.7065, 'F1': 0.7183}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_diem_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa4NMaHGgShl",
        "outputId": "07ca9f79-3492-472f-b10d-944fcb5972f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 976887 rows\n",
            "✅ After removing ignored classes: 976887 rows\n",
            "✅ After keeping only test SrcEntities: 229617 rows\n",
            "✅ After applying threshold ≥ 0.0: 229617 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_diem_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2577 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_diem_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1833\n",
            "📊 Evaluation (P / R / F1): {'P': 0.711, 'R': 0.688, 'F1': 0.7}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_diem_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcOC_1AMgShl",
        "outputId": "f5db69d7-0fab-40b7-e2de-638fc1e03360"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7255, 'Recall@1': 0.6778, 'F1@1': 0.7008}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_diem_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWeZPZXjgShl",
        "outputId": "a31ed943-c165-47c9-f181-bd98952208bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-100 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_diem_mrr_hit_MLPencoded.tsv\n",
            "⏱️ Execution time: 5.09 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_diem_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWtRfBoIgShl"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_diem_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIO4nU-SgShm",
        "outputId": "33f86163-e43a-40d4-848b-6038b57744a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9219123573077704, 'Hits@1': 0.8757040931280511, 'Hits@5': 0.9804731505820503, 'Hits@10': 0.9876079609463012}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jzXme_agShm"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "to2xmJp2gShm",
        "outputId": "b9e0056b-6a16-4771-8b6a-991f21e0f865"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-200 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_diem_MLPencoded.tsv\n",
            "⏱️ Execution time: 25.49 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using inner_product distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_diem(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_diem_MLPencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4s31gJR4gShm",
        "outputId": "0093a865-df5f-400a-9a53-e08704421b40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_diem_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1456\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7306, 'Recall': 0.7065, 'F1': 0.7183}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_diem_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmTz7bmFgShm",
        "outputId": "397b0bab-0c7e-4ad1-df41-427da6228794"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1961369 rows\n",
            "✅ After removing ignored classes: 1961369 rows\n",
            "✅ After keeping only test SrcEntities: 461470 rows\n",
            "✅ After applying threshold ≥ 0.0: 461470 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_diem_MLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2577 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_diem_MLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1833\n",
            "📊 Evaluation (P / R / F1): {'P': 0.711, 'R': 0.688, 'F1': 0.7}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_diem_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGdGY9WEgShm",
        "outputId": "728c8c99-b808-453b-e771-343851ae0e78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7255, 'Recall@1': 0.6778, 'F1@1': 0.7008}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_diem_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73hQL2NygShm",
        "outputId": "3aa2dd9a-9d4b-49e0-df0c-b9647aa310ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-200 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_diem_mrr_hit_MLPencoded.tsv\n",
            "⏱️ Execution time: 7.11 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_diem_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfcPUhG0gShm"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_diem_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY9kJ8KLgShm",
        "outputId": "09e22658-4fd8-43c6-f0d5-8b536c15caf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9227123773502218, 'Hits@1': 0.8760796094630117, 'Hits@5': 0.9827262485918138, 'Hits@10': 0.9902365752910252}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UlgeqFAgShm"
      },
      "source": [
        "# **LinearEncoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4YWyBBugShm",
        "outputId": "3a8c0d3b-82c2-4016-c03d-c9432a0beb1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = LinearEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v44wbyyZgShm",
        "outputId": "659ed3f5-49d3-4fc6-f432-61cf0ddba641"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iw91jndYgShn",
        "outputId": "2157bfae-3baf-4546-b1f5-313e97ef8429"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_cands_with_embeddings_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwjYB1TsgShn",
        "outputId": "ba20ec2e-a630-415d-e8fd-d9490e91baf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_cands_with_embeddings_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmfxqA02gShn"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wq4IoBDRgShn",
        "outputId": "40c656e1-314c-4366-98ef-c24bf395965e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-1 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_diem_Linencoded.tsv\n",
            "⏱️ Execution time: 10.44 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_diem(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_diem_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH5a4TRsgShn",
        "outputId": "aba95692-2ffb-4aba-c3a8-6a4bcea6e453"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_diem_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1464\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7346, 'Recall': 0.7103, 'F1': 0.7222}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_diem_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQgWiN9MgShn",
        "outputId": "f08ec058-0286-43ea-8dca-3b132063536b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9502 rows\n",
            "✅ After removing ignored classes: 9502 rows\n",
            "✅ After keeping only test SrcEntities: 2399 rows\n",
            "✅ After applying threshold ≥ 0.0: 2399 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_diem_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2399 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_diem_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1785\n",
            "📊 Evaluation (P / R / F1): {'P': 0.744, 'R': 0.67, 'F1': 0.705}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_diem_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLv_NlW_gShn",
        "outputId": "6dc1ce34-b142-478d-d400-69cf2d0d7dd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7441, 'Recall@1': 0.6962, 'F1@1': 0.7193}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_diem_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMOvArDrgShn",
        "outputId": "050b7a60-7e2e-4964-ae43-57172e740838"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-1 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_diem_mrr_hit_Linencoded.tsv\n",
            "⏱️ Execution time: 4.09 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_diem_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXbxy3LygShn"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_diem_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4kzfLwegShn",
        "outputId": "0da036df-6ddf-4e17-d84f-4683959c5591"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6799679391095469, 'Hits@1': 0.6702966579046189, 'Hits@5': 0.6702966579046189, 'Hits@10': 0.6702966579046189}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFLI1ULTgShn"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL0uczA0gSho",
        "outputId": "063d25e5-9fc7-4aad-9c94-33463c1439ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-10 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_diem_Linencoded.tsv\n",
            "⏱️ Execution time: 10.14 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_diem(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_diem_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vifv50rHgSho",
        "outputId": "a9c22b94-bb31-42ee-dee6-f57a98fc711d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_diem_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1464\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7346, 'Recall': 0.7103, 'F1': 0.7222}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_diem_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYty27YJgSho",
        "outputId": "2b26cd6c-bba2-412a-99ec-65086648125b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 95985 rows\n",
            "✅ After removing ignored classes: 95985 rows\n",
            "✅ After keeping only test SrcEntities: 22595 rows\n",
            "✅ After applying threshold ≥ 0.0: 22595 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_diem_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2549 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_diem_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1844\n",
            "📊 Evaluation (P / R / F1): {'P': 0.723, 'R': 0.692, 'F1': 0.708}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_diem_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhwCv0tjgSho",
        "outputId": "fee5e8cb-cb98-4947-94f8-1a75744dfdef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7343, 'Recall@1': 0.6861, 'F1@1': 0.7094}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_diem_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gy1Ed8YBgSho",
        "outputId": "dc8b6137-6c0e-4706-ec84-8a8c107bae46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-10 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_diem_mrr_hit_Linencoded.tsv\n",
            "⏱️ Execution time: 4.00 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_diem_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KToBTVRgSho"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_diem_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q33aXN9BgSho",
        "outputId": "efcc0a37-3ce4-488b-f26f-2b80749cdd55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9013042021469044, 'Hits@1': 0.8629365377393917, 'Hits@5': 0.9414194517461509, 'Hits@10': 0.9414194517461509}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS1dfYpVgSho"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESsx7-41gSho",
        "outputId": "cd366f81-d58d-4bf8-e021-1d3bd83d026e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-30 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_diem_Linencoded.tsv\n",
            "⏱️ Execution time: 11.85 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using diem distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the diem distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_diem(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_diem_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ux9b3aB-gSho",
        "outputId": "699a6ebd-a5a3-4d3c-d756-e75c83efab13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_diem_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1464\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7346, 'Recall': 0.7103, 'F1': 0.7222}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_diem_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lw2vPHWgSho",
        "outputId": "d7e62bec-9334-460e-f81c-a28be8059ff5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 290964 rows\n",
            "✅ After removing ignored classes: 290964 rows\n",
            "✅ After keeping only test SrcEntities: 68394 rows\n",
            "✅ After applying threshold ≥ 0.0: 68394 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_diem_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2549 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_diem_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1844\n",
            "📊 Evaluation (P / R / F1): {'P': 0.723, 'R': 0.692, 'F1': 0.708}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_diem_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wst8_R6FgSho",
        "outputId": "0b61b54e-0602-4da1-e66f-f5c677381059"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7343, 'Recall@1': 0.6861, 'F1@1': 0.7094}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_diem_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QogEEHp6gSho",
        "outputId": "6b5ead4d-afe0-4a9b-e564-2d026e80f64f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-30 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_diem_mrr_hit_Linencoded.tsv\n",
            "⏱️ Execution time: 4.35 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_diem_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmDDqaaOgShp"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_diem_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrnyV2uggShp",
        "outputId": "89faf114-6ea6-4053-a4fe-9231eb5d375f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9191138111434182, 'Hits@1': 0.873075478783327, 'Hits@5': 0.97371385655276, 'Hits@10': 0.9770935035674052}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMREd22EgShp"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbzxgSOXgShp",
        "outputId": "4e0d81c9-8b26-41fc-e768-c531a65b09a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-100 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_diem_Linencoded.tsv\n",
            "⏱️ Execution time: 17.49 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using diem distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the diem distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_diem(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_diem_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "higsoCWGgShp",
        "outputId": "549b3b69-602f-4d7b-dee0-f321bbb1dacb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_diem_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1464\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7346, 'Recall': 0.7103, 'F1': 0.7222}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_diem_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FJeLooIgShp",
        "outputId": "7a9e9279-03a9-4c18-8ee5-0b78387256db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 979090 rows\n",
            "✅ After removing ignored classes: 979090 rows\n",
            "✅ After keeping only test SrcEntities: 230087 rows\n",
            "✅ After applying threshold ≥ 0.0: 230087 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_diem_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2549 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_diem_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1844\n",
            "📊 Evaluation (P / R / F1): {'P': 0.723, 'R': 0.692, 'F1': 0.708}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_diem_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAMHsOpAgShp",
        "outputId": "92a74c91-9288-4a9b-f03b-5267c3cfb10b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7343, 'Recall@1': 0.6861, 'F1@1': 0.7094}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_diem_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzHAwzlVgShp",
        "outputId": "272db642-27b6-410c-db52-a3ee478d5332"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-100 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_diem_mrr_hit_Linencoded.tsv\n",
            "⏱️ Execution time: 8.36 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_diem_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYwRq4regShp"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_diem_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TsBz6xFgShq",
        "outputId": "c9a98b2b-2ed7-4bdb-ba2d-a52d1f4b814e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9233031653605134, 'Hits@1': 0.8738265114532482, 'Hits@5': 0.984228313931656, 'Hits@10': 0.9913631242959069}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n68Q1BBgShq"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "554jWpaigShq",
        "outputId": "47520a5d-3b30-4e38-d935-8346a96fbcd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-200 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_diem_Linencoded.tsv\n",
            "⏱️ Execution time: 25.62 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using diem distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_diem(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_diem_Linencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzQQGMf0gShq",
        "outputId": "49e952b9-bb63-47bd-b2a3-e1b270abb38b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_diem_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1464\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7346, 'Recall': 0.7103, 'F1': 0.7222}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_diem_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPaDHt3tgShq",
        "outputId": "1ef1f3bc-f444-492a-fc54-69949a67b236"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1966645 rows\n",
            "✅ After removing ignored classes: 1966645 rows\n",
            "✅ After keeping only test SrcEntities: 462464 rows\n",
            "✅ After applying threshold ≥ 0.0: 462464 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_diem_Linencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2549 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_diem_Linencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1844\n",
            "📊 Evaluation (P / R / F1): {'P': 0.723, 'R': 0.692, 'F1': 0.708}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_diem_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXDdLzgSgShq",
        "outputId": "8b3e8bb0-9986-456f-9af9-40814d65729e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7343, 'Recall@1': 0.6861, 'F1@1': 0.7094}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_diem_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zK2q6tegShq",
        "outputId": "db84d1b1-5d01-4ba2-ab29-42aaab1953be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-200 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_diem_mrr_hit_Linencoded.tsv\n",
            "⏱️ Execution time: 8.71 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on diem distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_diem_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXf-uxEZgShq"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_diem_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZLiytc4gShq",
        "outputId": "f0fa825d-3331-4d41-cf3d-bd82e02ba389"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9236716963852937, 'Hits@1': 0.8738265114532482, 'Hits@5': 0.9849793466015772, 'Hits@10': 0.9932407059707097}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3neM-5ZgShr"
      },
      "source": [
        "# **Transformer Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWnNoJbsgShr",
        "outputId": "72dadfd6-20be-4c29-e1f2-e3b47ebd72fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = TransformerEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbpt2iQAgShr",
        "outputId": "7bc8b690-6108-41cf-bc2f-b23b6f6b3ad7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XSRO3AlgShr",
        "outputId": "54f813c5-9397-43fc-aaa7-d97fa728d29d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_cands_with_embeddings_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YmSSnQ1gShr",
        "outputId": "054883b0-9b71-403e-b95d-1f24e3a451d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_cands_with_embeddings_TRencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgBqltAQgShr"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7omEgjQgShr",
        "outputId": "45e44b95-ab56-44ea-ab7f-718df6e7d805"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-1 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_diem_TRencoded.tsv\n",
            "⏱️ Execution time: 9.11 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_diem(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_diem_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2JDSKDXgShr",
        "outputId": "a2f0a32f-7d4b-4f48-f4a0-d40b761bdc95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_diem_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1451\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.728, 'Recall': 0.704, 'F1': 0.7158}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_diem_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTZHGQ2ngShr",
        "outputId": "f0ad6c7a-5d78-4d0c-97b0-80029a6e2d49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9486 rows\n",
            "✅ After removing ignored classes: 9486 rows\n",
            "✅ After keeping only test SrcEntities: 2402 rows\n",
            "✅ After applying threshold ≥ 0.0: 2402 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_diem_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2402 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_diem_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1772\n",
            "📊 Evaluation (P / R / F1): {'P': 0.738, 'R': 0.665, 'F1': 0.7}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_diem_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5lHaLPmgShs",
        "outputId": "d28f9f24-88ac-4202-f298-550f9933b650"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7377, 'Recall@1': 0.6906, 'F1@1': 0.7134}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_diem_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnZQz2EagShs",
        "outputId": "a16186d1-cc34-4d37-e205-2742baf38cb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-1 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_diem_mrr_hit_TRencoded.tsv\n",
            "⏱️ Execution time: 4.37 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_diem_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0xAFXNGgShs"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_diem_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2gIQgUhgShs",
        "outputId": "ec12b187-8f55-45bf-e430-cb2b236c1f01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6752298065301915, 'Hits@1': 0.6654149455501315, 'Hits@5': 0.6654149455501315, 'Hits@10': 0.6654149455501315}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAy5-gNAgShs"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMOPZr_agShs",
        "outputId": "098a9a2f-dea9-4046-f0f0-5342f730b64f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-10 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_diem_TRencoded.tsv\n",
            "⏱️ Execution time: 11.17 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using diem distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the diem distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_diem(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_diem_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGN_W03ygShs",
        "outputId": "bad58014-5168-4689-ccd3-d45c8358bdc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_diem_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1451\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.728, 'Recall': 0.704, 'F1': 0.7158}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_diem_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZTJf-c0gShs",
        "outputId": "53f22e87-f7d5-4a8a-c89b-1a88a0078976"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 96146 rows\n",
            "✅ After removing ignored classes: 96146 rows\n",
            "✅ After keeping only test SrcEntities: 22638 rows\n",
            "✅ After applying threshold ≥ 0.0: 22638 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_diem_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2557 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_diem_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1829\n",
            "📊 Evaluation (P / R / F1): {'P': 0.715, 'R': 0.687, 'F1': 0.701}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_diem_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDiLxpsbgSht",
        "outputId": "cf4432a0-d978-41d3-8d74-f677470bb29e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7287, 'Recall@1': 0.6808, 'F1@1': 0.7039}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_diem_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJLY7NSFgSht",
        "outputId": "d8c9240a-ec35-4299-cfef-5a7c33e20e23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-10 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_diem_mrr_hit_TRencoded.tsv\n",
            "⏱️ Execution time: 4.47 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_diem_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neuVzzswgSht"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_diem_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_7hd2BdgSht",
        "outputId": "22f80b5a-c2dc-41fd-f47c-b889ea587ede"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8984349166358322, 'Hits@1': 0.8603079233946677, 'Hits@5': 0.9391663537363876, 'Hits@10': 0.9391663537363876}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0HIPru1gSht"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-9YZroggSht",
        "outputId": "180db21d-8cf7-4a94-b8b4-08658b84f2a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-30 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_diem_TRencoded.tsv\n",
            "⏱️ Execution time: 11.89 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using diem distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the diem distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_diem(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_diem_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LIqAU8ogSht",
        "outputId": "ae2beda9-320a-426a-cefe-1c02b6e8f45a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_diem_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1451\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.728, 'Recall': 0.704, 'F1': 0.7158}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_diem_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fExUZ92ugSht",
        "outputId": "f6aa9488-2b00-4722-b223-b7822cbeb200"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 291483 rows\n",
            "✅ After removing ignored classes: 291483 rows\n",
            "✅ After keeping only test SrcEntities: 68488 rows\n",
            "✅ After applying threshold ≥ 0.0: 68488 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_diem_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2557 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_diem_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1829\n",
            "📊 Evaluation (P / R / F1): {'P': 0.715, 'R': 0.687, 'F1': 0.701}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_diem_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z07lu3V8gSht",
        "outputId": "405df8c1-371b-4886-8bc1-729b71d1c697"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7287, 'Recall@1': 0.6808, 'F1@1': 0.7039}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_diem_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ze1mq8IgShu",
        "outputId": "ac7463b5-a0e5-46b2-a9fe-95e8f3e07488"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-30 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_diem_mrr_hit_TRencoded.tsv\n",
            "⏱️ Execution time: 5.24 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_diem_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SQte1PugShu"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_diem_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a68kldMgShu",
        "outputId": "ac520e5c-8eed-4c7c-b2c0-b8c9b03fd515"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9168946417504511, 'Hits@1': 0.8711978971085242, 'Hits@5': 0.9722117912129178, 'Hits@10': 0.9744648892226812}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmzVGqrsgShu"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXb4ckyygShu",
        "outputId": "03583c9e-244b-4ec2-8a13-a8930925f575"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-100 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_diem_TRencoded.tsv\n",
            "⏱️ Execution time: 17.47 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using diem distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the diem distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_diem(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_diem_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBzqOr3kgShu",
        "outputId": "eae06650-4bbd-41aa-d661-641384009559"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_diem_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1451\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.728, 'Recall': 0.704, 'F1': 0.7158}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_diem_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfy4_9f5gShu",
        "outputId": "5b10f522-2a48-4dd1-e327-a586731422ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 981153 rows\n",
            "✅ After removing ignored classes: 981153 rows\n",
            "✅ After keeping only test SrcEntities: 230587 rows\n",
            "✅ After applying threshold ≥ 0.0: 230587 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_diem_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2557 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_diem_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1829\n",
            "📊 Evaluation (P / R / F1): {'P': 0.715, 'R': 0.687, 'F1': 0.701}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_diem_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACjpwNTygShu",
        "outputId": "2a892b09-f274-4df6-a5a1-8a01618bbcb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7287, 'Recall@1': 0.6808, 'F1@1': 0.7039}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_diem_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uq_5SI9AgShu",
        "outputId": "7bcebec5-56f6-4986-dbe6-6b05e1c54245"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-100 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_diem_mrr_hit_TRencoded.tsv\n",
            "⏱️ Execution time: 6.24 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_diem_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WR0aJPT2gShv"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_diem_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrB0I7kfgShv",
        "outputId": "59d6420b-9a41-4a5d-d5b5-6ebdf4b6db81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9226968207979722, 'Hits@1': 0.8734509951182876, 'Hits@5': 0.9846038302666166, 'Hits@10': 0.9913631242959069}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CKZSyFJgShv"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pO3qARRpgShv",
        "outputId": "f6d6fc4f-1b25-4474-8795-adbdc1ebf669"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-200 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_diem_TRencoded.tsv\n",
            "⏱️ Execution time: 25.83 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using diem distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_diem(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_diem_TRencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnrY-Q8pgShv",
        "outputId": "33b2ea73-e2f1-41dd-ffd1-73ae511f0601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_diem_TRencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1451\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.728, 'Recall': 0.704, 'F1': 0.7158}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_diem_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKvBqyeggShv",
        "outputId": "14a74da6-0dd0-41cc-e8ab-0b3ab80bb91c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1970864 rows\n",
            "✅ After removing ignored classes: 1970864 rows\n",
            "✅ After keeping only test SrcEntities: 463457 rows\n",
            "✅ After applying threshold ≥ 0.0: 463457 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_diem_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2557 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_diem_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1829\n",
            "📊 Evaluation (P / R / F1): {'P': 0.715, 'R': 0.687, 'F1': 0.701}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_diem_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PP9-oi7ogShv",
        "outputId": "4377cdbf-0b17-48aa-a8ff-4058ac7462fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7287, 'Recall@1': 0.6808, 'F1@1': 0.7039}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_diem_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNiXCMQJgShv",
        "outputId": "2b96298c-c8a4-439b-aa23-03165b1b430a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using DIEM similarity measure\n",
            "Top-200 DIEM similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_diem_mrr_hit_TRencoded.tsv\n",
            "⏱️ Execution time: 9.05 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_diem(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_diem_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AuK5HOMgShw"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_diem_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlfDmuzxgShw",
        "outputId": "7a4cc124-3afc-4636-a9bd-09e79ac234cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9232885668953403, 'Hits@1': 0.8738265114532482, 'Hits@5': 0.9853548629365377, 'Hits@10': 0.9924896733007886}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AI7XzyvUhMp8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oatkRs-FhNZQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "504nGCnEhNZQ"
      },
      "source": [
        "# **Using faiss: topk_cosine**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7FOxAozhNZR"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDtiPCTfhNZR",
        "outputId": "4f16dceb-1fb2-46d2-8547-ee1ece63bc95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Cosine Similarity (Sentence-Transformers)\n",
            "Top-1 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_cosine.tsv\n",
            "⏱️ Execution time: 4.94 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_cosine.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZgKmIvThNZR",
        "outputId": "7d254855-6164-4641-9dc8-c3130dce167f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_cosine_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1456\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7306, 'Recall': 0.7065, 'F1': 0.7183}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcmlchsYhNZR",
        "outputId": "de8b14ad-6c86-470a-e53b-fa46699feeab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9455 rows\n",
            "✅ After removing ignored classes: 9455 rows\n",
            "✅ After keeping only test SrcEntities: 2398 rows\n",
            "✅ After applying threshold ≥ 0.0: 2398 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_cosine_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2398 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_cosine_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1776\n",
            "📊 Evaluation (P / R / F1): {'P': 0.741, 'R': 0.667, 'F1': 0.702}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0tdC_ByhNZS",
        "outputId": "dba6efe7-adf8-479f-b123-ec27efe7421c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7406, 'Recall@1': 0.6929, 'F1@1': 0.716}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/neoplas_top_1_mappings_cosine_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFHcTouDhNZS",
        "outputId": "bb22fbd3-8733-4cbf-e8e8-b803351fdb82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-1 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_cosine_mrr_hit.tsv\n",
            "⏱️ Execution time: 3.48 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_cosine_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3leOe_4hNZS"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_cosine_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0KNGK7ThNZS",
        "outputId": "21d4e090-029c-4aad-8ce7-57eecf90b2e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.5884842709145166, 'Hits@1': 0.5760420578295156, 'Hits@5': 0.5760420578295156, 'Hits@10': 0.5760420578295156}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La3QMuIxhNZS"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0Vv3kH7hNZT",
        "outputId": "b7dc338e-4f4c-4fbf-e41d-99c4e6e8d998"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Cosine Similarity (Sentence-Transformers)\n",
            "Top-10 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_cosine.tsv\n",
            "⏱️ Execution time: 6.30 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_cosine.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GTe8eSWhNZT",
        "outputId": "179d0542-bc1c-49a5-c816-fba2186771de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_cosine_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1456\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7306, 'Recall': 0.7065, 'F1': 0.7183}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZyGGbwKhNZT",
        "outputId": "a206222b-b809-4141-df9c-174fa355ccf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 95994 rows\n",
            "✅ After removing ignored classes: 95994 rows\n",
            "✅ After keeping only test SrcEntities: 22625 rows\n",
            "✅ After applying threshold ≥ 0.0: 22625 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_cosine_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2560 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_cosine_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1845\n",
            "📊 Evaluation (P / R / F1): {'P': 0.721, 'R': 0.693, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALrEfq4IhNZT",
        "outputId": "cd06028b-8585-4499-8f2e-c96e73b667ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7315, 'Recall@1': 0.6834, 'F1@1': 0.7067}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_cosine_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U0_zWJIhNZT",
        "outputId": "a06462f5-8602-4cbe-81c4-719b0357a3f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Cosine Similarity (Sentence-Transformers)\n",
            "Top-10 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_cosine_mrr_hit.tsv\n",
            "⏱️ Execution time: 4.03 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_cosine_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDZXwpI3hNZT"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_cosine_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X20ui76hNZU",
        "outputId": "0d8550df-72a2-4ffb-8fe4-fcd68ccdb723"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.899072574208393, 'Hits@1': 0.8588058580548253, 'Hits@5': 0.9421704844160721, 'Hits@10': 0.9421704844160721}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EH-z2OPhNZU"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqfLwK3khNZU",
        "outputId": "d2c9b29f-7300-41b2-9efd-7d9f745bdd7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Cosine Similarity (Sentence-Transformers)\n",
            "Top-30 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_cosine.tsv\n",
            "⏱️ Execution time: 8.49 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_cosine.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc5fpnlIhNZU",
        "outputId": "a2a215e5-57ec-4a89-86cf-112ede85f75f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_cosine_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1456\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7306, 'Recall': 0.7065, 'F1': 0.7183}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMRIvlKchNZU",
        "outputId": "1003305f-cc72-4d26-c7c2-2b4641a55a2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "✅ After removing train-only URIs: 290962 rows\n",
            "✅ After removing ignored classes: 290962 rows\n",
            "✅ After keeping only test SrcEntities: 68393 rows\n",
            "✅ After applying threshold ≥ 0.0: 68393 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_cosine_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2560 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_cosine_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1845\n",
            "📊 Evaluation (P / R / F1): {'P': 0.721, 'R': 0.693, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N04j_u4hNZU",
        "outputId": "6784f3ea-cda3-4d18-ca1a-50f0fe25a523"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7315, 'Recall@1': 0.6834, 'F1@1': 0.7067}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_cosine_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rguWDoKbhNZU",
        "outputId": "bb33d097-3b8c-4183-a5ba-d257ad35eb00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Inner Product (dot product) with FAISS\n",
            "Top-30 FAISS similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_cosine_mrr_hit.tsv\n",
            "⏱️ Execution time: 4.19 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_faiss_inner_product(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_cosine_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEL8pJX8hNZU"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_cosine_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRqdmoJhhNZU",
        "outputId": "7d997f2e-365a-4d13-a0b8-8eeca762c3d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8831730515483852, 'Hits@1': 0.8238828389034923, 'Hits@5': 0.955313556139692, 'Hits@10': 0.9586932031543373}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDsMkq2DhNZU"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5IeI4PyhNZV",
        "outputId": "34d0f94d-db32-46fb-9b97-2565c23858a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Cosine Similarity (Sentence-Transformers)\n",
            "Top-100 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_cosine.tsv\n",
            "⏱️ Execution time: 19.06 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_cosine.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeYrZeZ1hNZV",
        "outputId": "c2be3b78-ea12-4fe0-b4f8-faacffd9e87e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_cosine_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1456\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7306, 'Recall': 0.7065, 'F1': 0.7183}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxDujRc4hNZV",
        "outputId": "0e8656cf-541a-43f6-f407-cdf569929fb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 979790 rows\n",
            "✅ After removing ignored classes: 979790 rows\n",
            "✅ After keeping only test SrcEntities: 230431 rows\n",
            "✅ After applying threshold ≥ 0.0: 230431 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_cosine_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2560 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_cosine_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1845\n",
            "📊 Evaluation (P / R / F1): {'P': 0.721, 'R': 0.693, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOethOnKhNZV",
        "outputId": "4d4ce473-15d0-4a1b-86f5-06032623961d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7315, 'Recall@1': 0.6834, 'F1@1': 0.7067}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_cosine_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGmMMOC_hNZV",
        "outputId": "5df0be88-d9b6-4e26-bd94-ef753d084916"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Cosine Similarity (Sentence-Transformers)\n",
            "Top-100 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_cosine_mrr_hit.tsv\n",
            "⏱️ Execution time: 5.25 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_cosine_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Mjq41pUhNZV"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_cosine_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ry1BoA6hNZV",
        "outputId": "9b32f105-6f39-4a8e-e9ba-09327d38e8e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9213368575296516, 'Hits@1': 0.8700713481036425, 'Hits@5': 0.9846038302666166, 'Hits@10': 0.992114156965828}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNua-9F4hNZV"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RsG6oqJhNZV",
        "outputId": "a8371e20-03ed-4563-b40a-e06cf6243826"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Cosine Similarity (Sentence-Transformers)\n",
            "Top-200 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_cosine.tsv\n",
            "⏱️ Execution time: 35.76 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_cosine.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTOneF-4hNZW",
        "outputId": "f4289a06-70d3-4d0d-c390-7bb0d7a74920"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 398600 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_cosine_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1456\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7306, 'Recall': 0.7065, 'F1': 0.7183}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXMb5kLGhNZW",
        "outputId": "47c23c91-5426-4252-9bd6-e2c205159de5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 2281400 rows\n",
            "✅ After removing train-only URIs: 1967850 rows\n",
            "✅ After removing ignored classes: 1967850 rows\n",
            "✅ After keeping only test SrcEntities: 462857 rows\n",
            "✅ After applying threshold ≥ 0.0: 462857 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_cosine_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2560 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_cosine_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1845\n",
            "📊 Evaluation (P / R / F1): {'P': 0.721, 'R': 0.693, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PY5GWvx4hNZW",
        "outputId": "3fdf4845-cdd7-48b0-df38-5df43a41fac8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7315, 'Recall@1': 0.6834, 'F1@1': 0.7067}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_cosine_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uocnzpk1hNZW",
        "outputId": "c5eb10bf-5174-419e-b769-30b5874bcf27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Cosine Similarity (Sentence-Transformers)\n",
            "Top-200 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_200_mappings_cosine_mrr_hit.tsv\n",
            "⏱️ Execution time: 8.73 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_cosine_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRpyk1aKhNZW"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_cosine_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dErnjpmWhNZW",
        "outputId": "d052af12-c85f-4d41-c701-f517ec78198e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9218645742472368, 'Hits@1': 0.8700713481036425, 'Hits@5': 0.9857303792714983, 'Hits@10': 0.9936162223056703}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mHhM-YFhNZW"
      },
      "source": [
        "# **K=500**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVmKXFikhNZW",
        "outputId": "0c2b6bb4-346f-4cf4-c196-3265e34c6f96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Cosine Similarity (Sentence-Transformers)\n",
            "Top-500 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_cosine.tsv\n",
            "⏱️ Execution time: 81.45 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=500,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_500_mappings_cosine.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8OuHkcPhNZW",
        "outputId": "6db7538c-7b5e-4325-a66a-596b90d70e0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 5703500 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 996500 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_cosine_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1456\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7306, 'Recall': 0.7065, 'F1': 0.7183}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_500_mappings_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZJ2kBe_hNZX",
        "outputId": "33d52f25-7633-4b11-9a48-e31f0474fcbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 5703500 rows\n",
            "✅ After removing train-only URIs: 4943894 rows\n",
            "✅ After removing ignored classes: 4943894 rows\n",
            "✅ After keeping only test SrcEntities: 1164359 rows\n",
            "✅ After applying threshold ≥ 0.0: 1164359 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_cosine_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2560 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_cosine_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1845\n",
            "📊 Evaluation (P / R / F1): {'P': 0.721, 'R': 0.693, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_500_mappings_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cp8lCYthhNZX",
        "outputId": "b2a7794f-dead-4570-a376-620780432566"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7315, 'Recall@1': 0.6834, 'F1@1': 0.7067}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_500_mappings_cosine_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--wlfzp3hNZX",
        "outputId": "1ce75b09-83d2-499c-d519-d614bb724456"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Cosine Similarity (Sentence-Transformers)\n",
            "Top-500 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_500_mappings_cosine_mrr_hit.tsv\n",
            "⏱️ Execution time: 17.96 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=500,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_500_mappings_cosine_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMg1kKPUhNZX"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_500_mappings_cosine_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPELhRslhNZX",
        "outputId": "ea866f72-5ac6-498a-b77c-0ac68495a7fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9223080312033205, 'Hits@1': 0.8700713481036425, 'Hits@5': 0.98685692827638, 'Hits@10': 0.9951182876455126}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ys504ET8hNZY"
      },
      "source": [
        "# **K=1000**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5ZNxRIwhNZY",
        "outputId": "d101827b-a228-496f-8db2-7982fd271876"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Cosine Similarity (Sentence-Transformers)\n",
            "Top-1000 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_cosine.tsv\n",
            "⏱️ Execution time: 157.44 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1000,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1000_mappings_cosine.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCVwgkcihNZY",
        "outputId": "61da77f6-03f0-492d-fd46-cf27f3f85ec1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407000 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 1993000 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_cosine_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1456\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7306, 'Recall': 0.7065, 'F1': 0.7183}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1000_mappings_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmy0uVnrhNZY",
        "outputId": "38de4e38-fc46-47a4-c090-9aff263765f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407000 rows\n",
            "✅ After removing train-only URIs: 9925622 rows\n",
            "✅ After removing ignored classes: 9925622 rows\n",
            "✅ After keeping only test SrcEntities: 2341451 rows\n",
            "✅ After applying threshold ≥ 0.0: 2341451 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_cosine_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2560 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_cosine_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1845\n",
            "📊 Evaluation (P / R / F1): {'P': 0.721, 'R': 0.693, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1000_mappings_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_Nq7BkrhNZY",
        "outputId": "5e3b1502-1066-427e-9252-56b23e346756"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7315, 'Recall@1': 0.6834, 'F1@1': 0.7067}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1000_mappings_cosine_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e67JSpoLhNZZ",
        "outputId": "65ac7c20-2fb1-495a-909c-511cefc72384"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Cosine Similarity (Sentence-Transformers)\n",
            "Top-1000 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1000_mappings_cosine_mrr_hit.tsv\n",
            "⏱️ Execution time: 34.02 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1000,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1000_mappings_cosine_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjI7Y9aEhNZZ"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1000_mappings_cosine_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGZtf-wyhNZZ",
        "outputId": "5427b142-43d2-44f5-cc6e-45e295a0bc7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9223326529703382, 'Hits@1': 0.8700713481036425, 'Hits@5': 0.98685692827638, 'Hits@10': 0.9954938039804732}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKbYazMQhNZZ"
      },
      "source": [
        "# **K=2000**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlG-YnY8hNZZ",
        "outputId": "fcff2175-8652-4a72-9821-e99c14293b3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Cosine Similarity (Sentence-Transformers)\n",
            "Top-2000 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_cosine.tsv\n",
            "⏱️ Execution time: 312.69 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=2000,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_2000_mappings_cosine.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MARX3zXhNZZ",
        "outputId": "74ea8d18-13b2-41b8-ff51-a4f699b99511"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 22814000 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 3986000 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_cosine_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1456\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7306, 'Recall': 0.7065, 'F1': 0.7183}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_2000_mappings_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ7zefB0hNZZ",
        "outputId": "b3e291d9-d63c-4674-8240-636df4f53c78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 22814000 rows\n",
            "✅ After removing train-only URIs: 19917638 rows\n",
            "✅ After removing ignored classes: 19917638 rows\n",
            "✅ After keeping only test SrcEntities: 4707389 rows\n",
            "✅ After applying threshold ≥ 0.0: 4707389 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_cosine_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2560 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_cosine_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1845\n",
            "📊 Evaluation (P / R / F1): {'P': 0.721, 'R': 0.693, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_2000_mappings_cosine.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp-Tsx_0hNZa",
        "outputId": "2d978ce3-4166-42c3-b5b5-9cb0b4a8808d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7315, 'Recall@1': 0.6834, 'F1@1': 0.7067}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_2000_mappings_cosine_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-1\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGVisloDhNZa",
        "outputId": "e22533a0-8917-421d-e193-eee6aa64b4b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Cosine Similarity (Sentence-Transformers)\n",
            "Top-2000 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_2000_mappings_cosine_mrr_hit.tsv\n",
            "⏱️ Execution time: 64.92 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=2000,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_2000_mappings_cosine_mrr_hit.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSDaP0o0hNZa"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_2000_mappings_cosine_mrr_hit.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX7DjiWwhNZa",
        "outputId": "f1063edb-d553-4700-a2af-84a9f7968586"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9225189724532561, 'Hits@1': 0.8700713481036425, 'Hits@5': 0.98685692827638, 'Hits@10': 0.997371385655276}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWhyOLEZhNZa"
      },
      "source": [
        "# **With Encoders**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFyQLZwchNZa"
      },
      "source": [
        "# **ResMLPEncoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zr1fWBH2hNZa",
        "outputId": "c86c8078-42d8-438a-f8c3-ffe10b590c6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = ResMLPEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jwp4KLThNZa",
        "outputId": "b88ca585-4744-45a2-ed8a-94eea928adcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuMk3kdOhNZa"
      },
      "outputs": [],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3jr9NPrhNZb",
        "outputId": "d677bcbf-23c6-4a57-d9aa-4a50b32556d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/ncit.neoplas_cands_with_embeddings_ResMLPencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-uJc7nXhNZb"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-V9_fEFhNZb"
      },
      "outputs": [],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_cosine_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4BC-R7shNZb"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlAbrSYzhNZb",
        "outputId": "b7ac0018-b7a0-4f60-817e-733d9372007e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 11407 rows\n",
            "✅ After removing train-only URIs: 9457 rows\n",
            "✅ After removing ignored classes: 9457 rows\n",
            "✅ After keeping only test SrcEntities: 2399 rows\n",
            "✅ After applying threshold ≥ 0.0: 2399 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_cosine_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2399 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_cosine_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1776\n",
            "📊 Evaluation (P / R / F1): {'P': 0.74, 'R': 0.667, 'F1': 0.702}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWvguGlKhNZb",
        "outputId": "faca0073-ec0f-49a4-e7fd-57e003674526"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7403, 'Recall@1': 0.6921, 'F1@1': 0.7154}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_cosine_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8YJObH2hNZc",
        "outputId": "e433e749-7954-4c2c-b680-1d630392bae3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Cosine Similarity (Sentence-Transformers)\n",
            "Top-1 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_cosine_mrr_hit_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 2.38 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_cosine_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwIQs6N-hNZc"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_cosine_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXQL4hvghNZc",
        "outputId": "7df234c8-13e3-4cc1-ca17-16a4377ba5db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.6766873779177401, 'Hits@1': 0.6669170108899737, 'Hits@5': 0.6669170108899737, 'Hits@10': 0.6669170108899737}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIsHF0SShNZc"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdDpFmhShNZc"
      },
      "outputs": [],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_cosine_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQidysjQhNZc",
        "outputId": "50c43ad6-3366-4fae-d4e0-0637c49e4126"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 19930 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_cosine_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1457\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7311, 'Recall': 0.7069, 'F1': 0.7188}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rJdxWBVhNZc",
        "outputId": "f05850ad-6e34-4a00-c1e6-739e0878b0d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 114070 rows\n",
            "✅ After removing train-only URIs: 95948 rows\n",
            "✅ After removing ignored classes: 95948 rows\n",
            "✅ After keeping only test SrcEntities: 22620 rows\n",
            "✅ After applying threshold ≥ 0.0: 22620 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_cosine_ResMLPencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2564 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_cosine_ResMLPencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1844\n",
            "📊 Evaluation (P / R / F1): {'P': 0.719, 'R': 0.692, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQVivkyahNZd",
        "outputId": "0a43462c-ded5-49d4-b8d7-c89f67c3f119"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Precision@1': 0.7303, 'Recall@1': 0.6823, 'F1@1': 0.7055}\n"
          ]
        }
      ],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_cosine_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPiSSrGFhNZd",
        "outputId": "16bc5382-384d-425f-f5e5-7db2fd026128"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Cosine Similarity (Sentence-Transformers)\n",
            "Top-10 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_10_mappings_cosine_mrr_hit_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 3.06 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_cosine_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHTuHIOhhNZd"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_cosine_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nssPIFg-hNZd",
        "outputId": "cb898aca-040f-4b1b-a993-7e0f0ca821e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.8990013817999427, 'Hits@1': 0.8595568907247465, 'Hits@5': 0.9414194517461509, 'Hits@10': 0.9414194517461509}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhZz5StRhNZd"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmDyjeRChNZd"
      },
      "outputs": [],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_cosine_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-9V_pZDhNZd",
        "outputId": "4970447f-f675-48ae-a4c4-023b1f3973ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_cosine_ResMLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1457\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.7311, 'Recall': 0.7069, 'F1': 0.7188}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yqRlOa6hNZd"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6y8NF1CWhNZd"
      },
      "outputs": [],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_cosine_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1bmia84hNZd",
        "outputId": "60cd7ca8-3464-46fc-801e-cffc94a917c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Cosine Similarity (Sentence-Transformers)\n",
            "Top-30 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_cosine_mrr_hit_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 3.66 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_cosine_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eD7DTnwLhNZe"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_cosine_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTRcV3AYhNZe"
      },
      "outputs": [],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgczohuohNZe"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dg6QpGqWhNZe",
        "outputId": "cbd58aed-a9b6-4319-ea85-4255678981e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Cosine Similarity (Sentence-Transformers)\n",
            "Top-100 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_cosine_ResMLPencoded.tsv\n",
            "⏱️ Execution time: 18.49 seconds\n"
          ]
        }
      ],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_cosine_ResMLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50cMUB2WhNZe"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9_m5GX6hNZe"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1xxYMSRhNZe"
      },
      "outputs": [],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_cosine_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5JtP2kShNZe"
      },
      "outputs": [],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_cosine_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBFx6kJ8hNZf"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_cosine_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csYTCmp9hNZf",
        "outputId": "52b88aeb-dd0f-4193-f91a-5f5e563e5bc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9225781361522407, 'Hits@1': 0.872324446113406, 'Hits@5': 0.9846038302666166, 'Hits@10': 0.9913631242959069}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzu_Jnd-hNZf"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbs9xNFJhNZf"
      },
      "outputs": [],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using inner_product distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_ResMLPencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_cosine_ResMLPencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiomqPQdhNZf"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAv8HIPQhNZf"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_cosine_ResMLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u87ix1sDhNZf"
      },
      "outputs": [],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_cosine_ResMLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQdBDZUBhNZf"
      },
      "outputs": [],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_cosine_mrr_hit_ResMLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7URQM0HzhNZg"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_cosine_mrr_hit_ResMLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ct_D9tUchNZg",
        "outputId": "f058a6a6-6e9a-42ae-d5c6-81c952ebe2b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9230419870959452, 'Hits@1': 0.872324446113406, 'Hits@5': 0.9853548629365377, 'Hits@10': 0.9928651896357491}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPgXOLjhhNZg"
      },
      "source": [
        "# **MLPEncoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDGIK5AThNZg"
      },
      "outputs": [],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = MLPEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMKBHKSKhNZg"
      },
      "outputs": [],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riK0KWEfhNZg"
      },
      "outputs": [],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idlUMGylhNZg"
      },
      "outputs": [],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhasHPtGhNZg"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cL6pYWF1hNZg"
      },
      "outputs": [],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_cosine_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHPqHOj3hNZh"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCT3hSyzhNZh"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-4s2ulOhNZh"
      },
      "outputs": [],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_cosine_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZOLMioOhNZh"
      },
      "outputs": [],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_cosine_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0mlRWPxhNZh"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_cosine_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQThO5-WhNZh"
      },
      "outputs": [],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKSVJyp2hNZh"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQzGDSVPhNZh"
      },
      "outputs": [],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_cosine_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxaFdepBhNZi"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qK9_u9GHhNZi"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpKLv1wghNZi"
      },
      "outputs": [],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_cosine_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWgixbRrhNZi"
      },
      "outputs": [],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_ResMLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_cosine_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IU1h33yohNZi"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_cosine_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oqoqo26mhNZi"
      },
      "outputs": [],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc3k7bjchNZi"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0ngOj2ChNZi"
      },
      "outputs": [],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_cosine_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OHa-khIhNZj"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INX6ZtechNZj"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98JgvXRahNZj"
      },
      "outputs": [],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_cosine_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OojKb0zOhNZj"
      },
      "outputs": [],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_cosine_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcD1WSzDhNZj"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_cosine_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbyBr7nPhNZj"
      },
      "outputs": [],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1aYr7iLhNZj"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIMv9OqnhNZj"
      },
      "outputs": [],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_cosine_MLPencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtOZsT8JhNZj",
        "outputId": "5006a4a4-f36b-41a3-d4ab-04a781c12344"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 199300 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_cosine_MLPencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1445\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.725, 'Recall': 0.7011, 'F1': 0.7129}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FI3dkijhNZk"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMhHzXQVhNZk"
      },
      "outputs": [],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_cosine_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1ZYXMgHhNZk"
      },
      "outputs": [],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_cosine_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04KzGV4dhNZk"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_cosine_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wftOCxBvhNZk"
      },
      "outputs": [],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXetR571hNZk"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYplg-3XhNZk"
      },
      "outputs": [],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using inner_product distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_MLPencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_cosine_MLPencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IiT1bzbhNZk"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbIKTZQUhNZk"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_cosine_MLPencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwj2iMghhNZl"
      },
      "outputs": [],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_cosine_MLPencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xav955q0hNZl"
      },
      "outputs": [],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_MLPencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_cosine_mrr_hit_MLPencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zN9iQOJShNZl"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_cosine_mrr_hit_MLPencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebJCJwxBhNZl"
      },
      "outputs": [],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMfxeEbkhNZl"
      },
      "source": [
        "# **LinearEncoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdpRjS3mhNZl",
        "outputId": "9df996ff-c1ff-455a-8aed-715ef8bc534f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Encoded embeddings saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Data/snomed.neoplas_final_embeddings_ignored_class_cleaned_Linencoded.tsv\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = LinearEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2FAXQibhNZl"
      },
      "outputs": [],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkNnIi1nhNZl"
      },
      "outputs": [],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlVWtr7whNZl"
      },
      "outputs": [],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_EP4-80hNZm"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zh8n9bjhNZm"
      },
      "outputs": [],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_cosine_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZtYuk6LhNZm"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNwcE1z3hNZm"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyvmDwRihNZm"
      },
      "outputs": [],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_cosine_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ec89ytFhNZm"
      },
      "outputs": [],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_inner_product_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dToLImSmhNZm"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_cosine_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lE43koJOhNZm"
      },
      "outputs": [],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UftQpt6xhNZn"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWKxlC0XhNZn"
      },
      "outputs": [],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_cosine_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBbYAnsvhNZn"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jqqm9WfqhNZn"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09eV8_wBhNZn"
      },
      "outputs": [],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_cosine_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZTNVNaGhNZn"
      },
      "outputs": [],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_cosine_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMjZ6R1uhNZn"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_cosine_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvZ59dtrhNZo"
      },
      "outputs": [],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiV4HIiJhNZo"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Is5EolhphNZo"
      },
      "outputs": [],
      "source": [
        "# Compute the top-10 most similar mappings using cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_cosine_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fttPNArNhNZo",
        "outputId": "a0ee53de-9c0c-4137-d1c2-ed1c6ae42087"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 342210 rows\n",
            "❗ Common entities to remove: 502\n",
            "✅ After filtering to test SrcEntities only: 59790 rows\n",
            "🏆 After Top-1 selection: 1993 rows\n",
            "📁 Final Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_30_mappings_cosine_Linencoded_Top1_testclean.tsv\n",
            "🎯 Correct mappings (Top-1): 1431\n",
            "📊 Evaluation (P / R / F1): {'Precision': 0.718, 'Recall': 0.6943, 'F1': 0.706}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mEKvghFhNZo"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgGJN3V2hNZp"
      },
      "outputs": [],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_cosine_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZRAdQP1hNZp"
      },
      "outputs": [],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_cosine_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZjhzhWchNZp"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_cosine_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yYisf-yhNZp"
      },
      "outputs": [],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYD7EtNihNZp"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TB06oME2hNZp"
      },
      "outputs": [],
      "source": [
        "# Compute the top-10 most similar mappings using cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_cosine_Linencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_RHab3lhNZq"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EY7Tg_AqhNZq"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycqu6qqghNZq"
      },
      "outputs": [],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_cosine_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LtIbnGxhNZq"
      },
      "outputs": [],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_cosine_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcZj2XSqhNZq"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_cosine_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeNMNxUYhNZq",
        "outputId": "06e6b530-2e21-4dc1-fe32-9e9f8bb20917"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.916907430941842, 'Hits@1': 0.8651896357491551, 'Hits@5': 0.9819752159218926, 'Hits@10': 0.989485542621104}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVAiicGxhNZq"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYoY_E0bhNZq"
      },
      "outputs": [],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using cosine distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_Linencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_cosine_Linencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkaFmbgzhNZr"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdhNgZoNhNZr"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_cosine_Linencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VZuBN67hNZr"
      },
      "outputs": [],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_cosine_Linencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CI981WrLhNZr"
      },
      "outputs": [],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_Linencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on cosine distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_cosine_mrr_hit_Linencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jInZW9ZEhNZr"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_cosine_mrr_hit_Linencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrkacxLThNZr"
      },
      "outputs": [],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoR05lnIhNZr"
      },
      "source": [
        "# **Transformer Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8BrF-BrhNZr"
      },
      "outputs": [],
      "source": [
        "# Instantiate the encoder model: Residual Multi-Layer Perceptron with input/output dimension = 768\n",
        "# (You can also use LinearEncoder or MLPEncoder depending on the encoding strategy)\n",
        "encoder = TransformerEncoder(embedding_dim=768)\n",
        "\n",
        "# Apply the encoder model to the cleaned source embeddings (after removing ignored classes)\n",
        "# The encoded embeddings are saved to a new TSV file, preserving the original 'Concept' URIs\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cu332cOfhNZs"
      },
      "outputs": [],
      "source": [
        "# Apply the encoder model to the cleaned target embeddings (after removing ignored classes)\n",
        "# This will generate a new file where each embedding vector has been transformed using the encoder,\n",
        "# and the concept URIs are preserved in the \"Concept\" column.\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned.tsv\",\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9L6CskVzhNZs"
      },
      "outputs": [],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{src_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlffbzE6hNZs"
      },
      "outputs": [],
      "source": [
        "# Encode the candidate entity embeddings using the specified encoder model.\n",
        "# This will transform the existing embeddings (e.g., semantic + structural)\n",
        "# into new representations via the encoder (e.g., ResMLP, Transformer, etc.)\n",
        "\n",
        "encode_embeddings_with_concept_column(\n",
        "    encoder_model=encoder,  # The trained encoder model (e.g., ResMLP or GatedCombination)\n",
        "\n",
        "    input_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings.tsv\",\n",
        "    # Input file: contains source-target candidate pairs with their initial embeddings and a \"Concept\" column\n",
        "\n",
        "    output_file=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\"\n",
        "    # Output file: will contain the same candidate pairs but with updated embeddings produced by the encoder\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF0IwCXKhNZs"
      },
      "source": [
        "# **K=1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jojyYrAhNZs"
      },
      "outputs": [],
      "source": [
        "# Compute the top-10 most similar mappings using inner_product distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the inner_product distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=1,\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_cosine_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byAj6l4BhNZs"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbEyc2zmhNZs"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_1_mappings_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKIr7NCRhNZs"
      },
      "outputs": [],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_1_mappings_cosine_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceEpZgaYhNZs",
        "outputId": "596e076c-bf8f-415c-edbd-8ead574d63b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔹 Using Cosine Similarity (Sentence-Transformers)\n",
            "Top-1 cosine similarity results saved to: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_1_mappings_cosine_mrr_hit_TRencoded.tsv\n",
            "⏱️ Execution time: 5.14 seconds\n"
          ]
        }
      ],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=1,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_1_mappings_cosine_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73ky4tE4hNZt"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_1_mappings_cosine_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUOT70adhNZt"
      },
      "outputs": [],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alLQTsU5hNZt"
      },
      "source": [
        "# **K=10**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cP22iporhNZt"
      },
      "outputs": [],
      "source": [
        "# Compute the top-10 most similar mappings using cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=10,\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_cosine_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXc5o1skhNZt"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6J_Mo6dhNZt"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_10_mappings_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-OMBzbahNZt"
      },
      "outputs": [],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_10_mappings_cosine_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qavtM5gRhNZt"
      },
      "outputs": [],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=10,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_10_mappings_cosine_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNoF5AYWhNZt"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_10_mappings_cosine_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qas4E77hNZu"
      },
      "outputs": [],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epRbBEq_hNZu"
      },
      "source": [
        "# **K=30**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhl2x8MehNZu"
      },
      "outputs": [],
      "source": [
        "# Compute the top-10 most similar mappings using cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=30,\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_cosine_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQIqBfrWhNZu"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8H89KE3hNZu"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_30_mappings_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrTq3svphNZu"
      },
      "outputs": [],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_30_mappings_cosine_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bokgsXs3hNZu"
      },
      "outputs": [],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=30,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_30_mappings_cosine_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9MwJZ0shNZu"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_30_mappings_cosine_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qd3d6WoehNZv"
      },
      "outputs": [],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc8-K1vbhNZv"
      },
      "source": [
        "# **K=100**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5O8HxoKohNZv"
      },
      "outputs": [],
      "source": [
        "# Compute the top-10 most similar mappings using cosine distance\n",
        "# between ResMLP-encoded embeddings of the source and target ontologies.\n",
        "# The input embeddings were previously encoded using the ResMLPEncoder,\n",
        "# and the similarity score is computed as the inverse of the cosine distance.\n",
        "# Results are saved in a TSV file with columns: SrcEntity, TgtEntity, Score.\n",
        "topk_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",\n",
        "    top_k=100,\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_cosine_TRencoded.tsv\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2EI-yDdhNZv"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg6F_N1ihNZv",
        "outputId": "5ef906db-08b2-49f4-c074-7743da554350"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Initial file: 1140700 rows\n",
            "✅ After removing train-only URIs: 980686 rows\n",
            "✅ After removing ignored classes: 980686 rows\n",
            "✅ After keeping only test SrcEntities: 230640 rows\n",
            "✅ After applying threshold ≥ 0.0: 230640 rows\n",
            "📁 Filtered predictions saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_cosine_TRencoded_filtered.tsv\n",
            "🏆 Selected candidates within 99.7% of best score per SrcEntity: 2571 rows\n",
            "📁 Filtered Top-1 file saved: /content/gdrive/My Drive/BioGITOM-VLDB//neoplas/Results/neoplas_top_100_mappings_cosine_TRencoded_filtered_top1_th0.0.tsv\n",
            "🎯 Correct mappings (Top-1): 1843\n",
            "📊 Evaluation (P / R / F1): {'P': 0.717, 'R': 0.692, 'F1': 0.704}\n"
          ]
        }
      ],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_100_mappings_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto,\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBS-AU6JhNZv"
      },
      "outputs": [],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_100_mappings_cosine_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B09CGb7ShNZv"
      },
      "outputs": [],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=100,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_100_mappings_cosine_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3mHLqInhNZw"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_100_mappings_cosine_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUV4f--whNZw"
      },
      "outputs": [],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3l-4deIhNZw"
      },
      "source": [
        "# **K=200**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITOoZeSohNZw"
      },
      "outputs": [],
      "source": [
        "# Compute the top-200 most similar mappings between source and target entities\n",
        "# using cosine distance on ResMLP-encoded embeddings, then save the results.\n",
        "\n",
        "topk_cosine(\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",  # Source embeddings after ResMLP encoding and filtering\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_final_embeddings_ignored_class_cleaned_TRencoded.tsv\",  # Target embeddings after ResMLP encoding and filtering\n",
        "    top_k=200,  # Retrieve the top 200 most similar target entities per source entity\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_cosine_TRencoded.tsv\"  # Save results to this output file\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBCuL1A-hNZw"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1_remove_common_entities(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\"\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJClkySRhNZx"
      },
      "outputs": [],
      "source": [
        "# Run the evaluation on the predicted top-1 mappings using a filtering and evaluation function.\n",
        "\n",
        "output_file, metrics, correct = filter_and_evaluate_predictions_top1(\n",
        "    topk_file=f\"{results_dir}/{task}_top_200_mappings_cosine_TRencoded.tsv\",\n",
        "    # Path to the TSV file containing predicted mappings with scores (before filtering).\n",
        "\n",
        "    train_file=f\"{dataset_dir}/refs_equiv/train.tsv\",\n",
        "    # Path to the training reference file (used to exclude mappings involving train-only entities).\n",
        "\n",
        "    test_file=f\"{dataset_dir}/refs_equiv/test.tsv\",\n",
        "    # Path to the test reference file (used as the gold standard for evaluation).\n",
        "\n",
        "    src_onto=src_onto,\n",
        "    # The source ontology object, used to detect ignored classes or perform additional filtering.\n",
        "\n",
        "    tgt_onto=tgt_onto\n",
        "    # The target ontology object, used similarly for filtering ignored or irrelevant classes.\n",
        ")\n",
        "\n",
        "# This function returns:\n",
        "# - `output_file`: the path to the filtered and evaluated output file.\n",
        "# - `metrics`: a tuple containing (Precision, Recall, F1-score).\n",
        "# - `correct`: the number of correctly predicted mappings found in the gold standard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxkVaSNWhNZx"
      },
      "outputs": [],
      "source": [
        "# Supposons que tu as chargé les fichiers suivants :\n",
        "predictions_df = pd.read_csv(f\"{results_dir}/{task}_top_200_mappings_cosine_TRencoded_filtered_top1_th0.0.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity', 'Score'\n",
        "reference_df = pd.read_csv(f\"{dataset_dir}/refs_equiv/test.tsv\", sep=\"\\t\")  # contient 'SrcEntity', 'TgtEntity'\n",
        "\n",
        "# Appel de la fonction avec top-15\n",
        "results = evaluate_topk(predictions_df, reference_df, k=1)\n",
        "\n",
        "# Affichage des résultats\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUpt-2cehNZx"
      },
      "outputs": [],
      "source": [
        "topk_cosine(\n",
        "    # Path to the source ontology embeddings (after removing ignored classes)\n",
        "    src_emb_path=f\"{data_dir}/{src_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Path to the target ontology embeddings (after removing ignored classes)\n",
        "    tgt_emb_path=f\"{data_dir}/{tgt_ent}_cands_with_embeddings_TRencoded.tsv\",\n",
        "\n",
        "    # Number of top matches to retrieve per source entity\n",
        "    top_k=200,\n",
        "\n",
        "    # Path to save the top-10 similarity mappings based on inner_product distance\n",
        "    output_file=f\"{results_dir}/{task}_top_200_mappings_cosine_mrr_hit_TRencoded.tsv\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruhxgYVhhNZx"
      },
      "outputs": [],
      "source": [
        "# Compute MRR and Hits@k metrics\n",
        "# This function evaluates the predicted rankings against the reference mappings\n",
        "results = compute_mrr_and_hits(\n",
        "    reference_file=test_cands,             # Reference file with true ranks\n",
        "    predicted_file=f\"{results_dir}/{task}_top_200_mappings_cosine_mrr_hit_TRencoded.tsv\",             # File containing predicted rankings\n",
        "    output_file=formatted_predictions_path,    # File path to save formatted predictions\n",
        "    k_values=[1, 5, 10]                        # Evaluate Hits@1, Hits@5, and Hits@10\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV2keOjdhNZx",
        "outputId": "ba8bab59-353f-4e87-ecfb-8832f1033d0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ranking Evaluation Results at K=1, 5, and 10:\n",
            "{'MRR': 0.9221363841644391, 'Hits@1': 0.8715734134434848, 'Hits@5': 0.9849793466015772, 'Hits@10': 0.9924896733007886}\n"
          ]
        }
      ],
      "source": [
        "results = ranking_eval(formatted_predictions_path, Ks=[1, 5, 10])\n",
        "print(\"Ranking Evaluation Results at K=1, 5, and 10:\")\n",
        "print(results)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "aLJ5j9FNMVhy",
        "jPuzmu6f_Y8W"
      ],
      "gpuType": "V28",
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}